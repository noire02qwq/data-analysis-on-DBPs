epoch,train_loss,val_loss
1,0.880458,0.296116
2,0.363655,0.213712
3,0.162762,0.199902
4,0.134741,0.194980
5,0.119726,0.178441
6,0.096206,0.191082
7,0.084556,0.189010
8,0.078241,0.210116
9,0.078970,0.223839
10,0.082667,0.226503
11,0.073092,0.224098
12,0.066740,0.371000
13,0.067361,0.577616
14,0.059313,0.286238
15,0.056919,0.323022
16,0.055227,0.437113
17,0.053689,0.428306
18,0.049783,0.536740
19,0.065832,0.563186
20,0.080125,0.251296
21,0.058731,0.329191
22,0.047255,0.249731
23,0.058351,0.723083
24,0.054026,0.318053
25,0.057535,0.250833
26,0.052970,0.656571
27,0.054746,0.487175
28,0.046435,0.550629
29,0.043626,0.484847
30,0.045907,0.347559
31,0.045365,0.317214
32,0.047013,0.312196
33,0.045259,0.428072
34,0.043043,0.481260
35,0.042081,0.419914
36,0.042337,0.433540
37,0.043484,0.587057
38,0.051948,0.498737
39,0.050298,0.515126
40,0.042453,0.478457
41,0.043676,0.517178
42,0.053604,0.308643
43,0.043711,0.529669
44,0.038921,0.357752
45,0.041354,0.511765
46,0.042159,0.704572
47,0.047718,0.424198
48,0.039736,0.583549
49,0.038428,0.588209
50,0.044837,0.464902
51,0.040608,0.509980
52,0.039326,0.466896
53,0.039002,0.470211
54,0.040454,0.457964
55,0.040465,0.475844
56,0.041223,0.509714
57,0.049563,0.378577
58,0.041213,0.472405
59,0.038375,0.396871
60,0.036962,0.370389
61,0.038176,0.399558
62,0.041982,0.539851
63,0.036889,0.485798
64,0.034923,0.519650
65,0.037362,0.358583
66,0.039008,0.566767
67,0.037703,0.373611
68,0.045066,0.481755
69,0.039582,0.600122
70,0.036766,0.420633
71,0.036008,0.472888
72,0.036371,0.444789
73,0.035912,0.311098
74,0.034189,0.449362
75,0.034889,0.372818
76,0.037855,0.580880
77,0.037066,0.510338
78,0.037826,0.422348
79,0.039274,0.400857
80,0.037080,0.421902
