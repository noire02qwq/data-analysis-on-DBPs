epoch,train_loss,val_loss
1,0.999673,0.349321
2,0.999255,0.344781
3,0.999319,0.353624
4,0.999183,0.352925
5,0.999122,0.353528
6,0.999116,0.352203
7,0.999194,0.353469
8,0.999265,0.350978
9,0.999137,0.354828
10,0.999096,0.353206
11,0.999073,0.351708
12,0.999115,0.352274
13,0.999091,0.352276
14,0.999125,0.352856
15,0.999125,0.351194
16,0.999099,0.352806
17,0.999114,0.351605
18,0.999265,0.353659
19,0.999098,0.351798
20,0.999099,0.351582
21,0.999037,0.352740
22,0.999052,0.352468
23,0.999065,0.352052
24,0.999076,0.352759
25,0.999130,0.353041
26,0.999028,0.352535
27,0.999057,0.352355
28,0.999030,0.352177
29,0.999058,0.352465
30,0.999046,0.351437
31,0.999036,0.352808
32,0.999028,0.352904
33,0.999068,0.352659
34,0.999096,0.351664
35,0.999049,0.352195
36,0.999025,0.353245
37,0.999063,0.353417
38,0.999029,0.352584
39,0.999060,0.352667
40,0.999092,0.352044
41,0.999026,0.352393
42,0.999046,0.352683
43,0.999073,0.353729
44,0.999093,0.351940
45,0.999041,0.352980
46,0.999037,0.352812
47,0.999049,0.352700
48,0.999072,0.352323
49,0.999089,0.352499
50,0.999152,0.352655
