{
  "model_name": "mlp_with_history-trc-value/trial_16_5609c4",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 71,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.3873616599508461,
    "mid_layer_count": 9,
    "mid_layer_size": 523
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 472,
    "learning_rate": 0.0017166595706429786,
    "weight_decay": 0.0014657252829061657,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7726,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 710,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112
    ],
    "train_loss": [
      0.9753633384842839,
      0.9635701463563807,
      0.6508207661081651,
      0.6925843161775015,
      0.3676849255560594,
      0.21616676306280175,
      0.1910166508780222,
      0.18180231702372474,
      0.1914474107566165,
      0.15835089335440355,
      0.15600149277158887,
      0.1519832611469725,
      0.15393378491456294,
      0.1568163214509363,
      0.15833699806209306,
      0.14794319897211186,
      0.15796339736758136,
      0.1472329609857888,
      0.13705042136894308,
      0.13295837676713357,
      0.13465892361516074,
      0.1279616237820784,
      0.13291263879271267,
      0.12260674292555813,
      0.11061884146718945,
      0.13908031802318765,
      0.14224094681879598,
      0.11545687884771234,
      0.10671716855577074,
      0.10044070918603848,
      0.11158395726199968,
      0.12198288867179205,
      0.13033815182469652,
      0.1113222939322225,
      0.10340168170482422,
      0.1053324430783641,
      0.10015702400565796,
      0.09473576100262032,
      0.09954043749335081,
      0.10005257151579258,
      0.1040379683179248,
      0.31258790615831294,
      0.5913692176604314,
      0.520659400589442,
      0.3297664315210486,
      0.2678758056321787,
      0.2244861503470416,
      0.19149178670009986,
      0.20144771337277712,
      0.16877342258714315,
      0.17112150778663673,
      0.1560619380223822,
      0.16775756836932712,
      0.15682717928638304,
      0.150381283021146,
      0.18561638156860996,
      0.195449408489961,
      0.16292716772205126,
      0.1511298514673076,
      0.14545387334768678,
      0.1382480108179393,
      0.12909343971386494,
      0.13215985869130045,
      0.12981946312552625,
      0.14342489811984055,
      0.1188766832468024,
      0.12587329667373054,
      0.13171126630418573,
      0.12070886556607838,
      0.11811133915591727,
      0.12498166462839992,
      0.10787293095833089,
      0.11213689264071101,
      0.11364892373739546,
      0.11387012631217958,
      0.12389555344719236,
      0.16057273854894277,
      0.12591187357748232,
      0.1102446263109715,
      0.10742537863986529,
      0.09771738552018024,
      0.10106064342184139,
      0.10804960644294523,
      0.10654239021116299,
      0.10671711647692599,
      0.09908386977949261,
      0.10246670457317272,
      0.09811804172036379,
      0.09695310166060786,
      0.09630411804694448,
      0.10906088654624037,
      0.09536716196355256,
      0.10421084766325604,
      0.0969328918151216,
      0.09137954148616996,
      0.10686840602432296,
      0.09738548060263373,
      0.0920380768155206,
      0.092180832400783,
      0.0920771825484837,
      0.08722931786565437,
      0.09644240855306595,
      0.09713163377860344,
      0.09559723164923846,
      0.10347090059191706,
      0.10988819171750974,
      0.15655226351265583,
      0.10544008057860553,
      0.09327841105159934,
      0.09465647074547019,
      0.0873578705420125,
      0.09824300373376665
    ],
    "val_loss": [
      0.37809421195241505,
      0.4094950904389341,
      0.29483870591767536,
      0.8192578359992204,
      0.272251797864537,
      0.2644628412441579,
      0.28086515149313535,
      0.28843994123671585,
      0.27523112620957596,
      0.266063765280261,
      0.2770825114881921,
      0.26844569981812005,
      0.2661988085347735,
      0.27438199677153263,
      0.2693449731715425,
      0.263724255240606,
      0.2613701535913045,
      0.26991627173509425,
      0.36117050430018033,
      0.29616069028120556,
      0.2867487377570775,
      0.2758824614707581,
      0.28497501163782474,
      0.37838203944488913,
      0.33108353131188606,
      0.6604641549333841,
      0.3306651949168679,
      0.2909224211812733,
      0.278844982885315,
      0.2894951226022429,
      0.32157483215103605,
      1.250830668817737,
      0.29973671132040597,
      0.3320516097331475,
      0.3124396240907515,
      0.3141958968189662,
      0.30978613848279335,
      0.402438375184279,
      0.373757904535996,
      0.31805573501094375,
      0.5568084363898117,
      0.2724660055544562,
      0.31986828107319903,
      0.2812050916299135,
      0.3294240219864303,
      0.2844984168599466,
      0.2942611009596351,
      0.28951910391539154,
      0.2995229720890879,
      0.298433255970835,
      0.3042417853356835,
      0.30397179519344947,
      0.2983262466456362,
      0.29394114918694525,
      0.3346245594367296,
      0.4563066391173951,
      0.29327424477317376,
      0.3090009322958792,
      0.2762805552182797,
      0.2788649734979618,
      0.32889761664196404,
      0.23589829455414218,
      0.2875711474054588,
      0.5595372887071736,
      0.3196012234884108,
      0.2753037261927199,
      0.2745862578025121,
      0.2900578117656137,
      0.305253727368252,
      0.29282159990893153,
      0.28480686628354523,
      0.47149731948704066,
      0.28192220603277585,
      0.28408395076047877,
      0.29104655902542753,
      0.2716132698747926,
      0.3193560977895817,
      0.26774743606230456,
      0.45597171456870916,
      0.2970846815112822,
      0.43988152821799237,
      0.5236588346030184,
      0.351518723109882,
      0.4939584782648229,
      0.3479718486884397,
      0.28907375163482335,
      0.41414656004684414,
      0.3748693503751726,
      0.4228629047642211,
      0.5067786714987841,
      0.5377987904730671,
      0.4179216228470117,
      0.27848622179673815,
      0.4876975090739256,
      0.3599607999542516,
      0.3825242730136403,
      0.4868931444462188,
      0.41112343781365607,
      0.3820899678829187,
      0.39577821032729693,
      0.4317338326555526,
      0.4086381180914576,
      0.6088269985364583,
      0.3199793385977517,
      0.4179134015373127,
      0.2866469230926679,
      0.30639704531895184,
      0.33513054778119045,
      0.3260365251652495,
      0.5879309047660428,
      0.5376843386959886,
      0.3913272829915949
    ],
    "best_epoch": 62,
    "best_val_loss": 0.23589829455414218,
    "test_loss": 4.3434193910023815,
    "tracker": {
      "initial_train_loss": 0.9753633384842839,
      "train_threshold": 0.32512111282809464,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.23589829455414218,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_16_5609c4/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_16_5609c4/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_16_5609c4/config.yaml"
}