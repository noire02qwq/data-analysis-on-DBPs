epoch,train_loss,val_loss
1,1.002866,0.348966
2,1.001768,0.342163
3,1.001646,0.348208
4,1.001915,0.345336
5,1.001641,0.348480
6,1.001554,0.351073
7,1.001513,0.350391
8,1.001595,0.345068
9,1.001465,0.348690
10,1.001450,0.348229
11,1.001440,0.347772
12,1.001447,0.347964
13,1.001411,0.350654
14,1.001482,0.350650
15,1.001476,0.349994
16,1.001433,0.349655
17,1.001434,0.348033
18,1.001498,0.347713
19,1.001478,0.349503
20,1.001440,0.349168
21,1.001446,0.348403
22,1.001460,0.348143
23,1.001407,0.349199
24,1.001526,0.348928
25,1.001451,0.349340
26,1.001516,0.348539
27,1.001436,0.350378
28,1.001495,0.348130
29,1.001438,0.349009
30,1.001444,0.348507
31,1.001421,0.348553
32,1.001474,0.348942
33,1.001439,0.347510
34,1.001538,0.346302
35,1.001529,0.348882
36,1.001468,0.348850
37,1.001416,0.347718
38,1.001480,0.348027
39,1.001491,0.347649
40,1.001463,0.348883
41,1.001514,0.348266
42,1.001456,0.347975
43,1.001544,0.347533
44,1.001482,0.348057
45,1.001570,0.349138
46,1.001455,0.348811
47,1.001522,0.349102
48,1.001487,0.349085
49,1.001457,0.348485
50,1.001607,0.347221
