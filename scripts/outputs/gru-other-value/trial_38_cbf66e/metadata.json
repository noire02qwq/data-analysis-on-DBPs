{
  "model_name": "gru-other-value/trial_38_cbf66e",
  "model_type": "GRU",
  "model_format": "torch",
  "model_params": {
    "history_length": 85,
    "units": 319,
    "num_layers": 2,
    "dropout": 0.4555698743138497
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 239,
    "learning_rate": 0.0007998152278808938,
    "weight_decay": 0.00012134241387832829,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7712,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 85,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116
    ],
    "train_loss": [
      0.3620748283047832,
      0.23607671589694948,
      0.21220859909561537,
      0.1934269997754996,
      0.1693027233917467,
      0.15899011147830683,
      0.14498464655444118,
      0.1269187216890427,
      0.11596528614225847,
      0.12357430104591355,
      0.10932857794706474,
      0.09437302789067331,
      0.08773838808659572,
      0.07742898685314704,
      0.07334980539614296,
      0.06849938887509584,
      0.054362500802308505,
      0.05864102665394838,
      0.04894616545073657,
      0.045127146450814275,
      0.04626440035258478,
      0.06317957261812977,
      0.04283455940189528,
      0.03952707397158323,
      0.03665842220459628,
      0.03741759158012987,
      0.03420224257878171,
      0.03886413494128873,
      0.03217912096017199,
      0.03127503561322612,
      0.03333293456420944,
      0.030113035726990877,
      0.0321047498561496,
      0.02957395862723233,
      0.026661674158997384,
      0.027209693760392777,
      0.026631402974384082,
      0.026060974212117973,
      0.026803719242348787,
      0.026123409359947742,
      0.02650965702564444,
      0.02524087085901601,
      0.026843199247486613,
      0.024957264390246578,
      0.02505602035478252,
      0.02714142297284438,
      0.02468316096071486,
      0.024271392419980647,
      0.023818332641781598,
      0.024550528069900126,
      0.02605268146810837,
      0.025096557663195223,
      0.025116037402284637,
      0.023988862583776974,
      0.023563396375475613,
      0.023126502321352913,
      0.022693150656257228,
      0.027071492787531706,
      0.025313135908425814,
      0.02393590873474433,
      0.022908644329010668,
      0.02322882039427054,
      0.02333126363708711,
      0.08141677585383104,
      0.07012101642969083,
      0.050276728172079344,
      0.031623763083944025,
      0.02655243759282142,
      0.02630214213057425,
      0.02417389039071934,
      0.02447919976797063,
      0.023497796709228046,
      0.02275472172754295,
      0.02314240475116622,
      0.023295691318730764,
      0.022534346600938435,
      0.022609045610693573,
      0.022270023447212173,
      0.022066571889348574,
      0.022125102383716427,
      0.023150667408819377,
      0.022211671641185354,
      0.021578424560201752,
      0.021558541043746552,
      0.02192373032521271,
      0.022690736613800572,
      0.022705962344051506,
      0.021965143551201757,
      0.021486473421921715,
      0.020820823563040616,
      0.02143628135733152,
      0.02149196456285982,
      0.02072102112982507,
      0.021361850117308116,
      0.02146156287401397,
      0.022519147770838712,
      0.022252667647220302,
      0.05736067357397719,
      0.10042292885414685,
      0.0469478149782418,
      0.027772417610812606,
      0.023494300172380193,
      0.022928540957888734,
      0.02187736314253812,
      0.021945025335902667,
      0.022115838780363488,
      0.021825360594350165,
      0.020363563318356207,
      0.0205452063058588,
      0.021234068795661847,
      0.02030216703259993,
      0.0260086118577423,
      0.022209305181197004,
      0.020916285089418077,
      0.020694504049268484,
      0.020573489892796934
    ],
    "val_loss": [
      0.44021575245671646,
      0.47291375848347555,
      0.6475427164199823,
      0.6741601038300349,
      0.8763346291587738,
      0.6815809406652422,
      0.8625210648436032,
      0.836346488066776,
      0.8029657737312916,
      0.5833980521488332,
      0.7276357373077712,
      0.6507513282809428,
      0.6277548164307715,
      0.6379843758073396,
      0.6767957635625393,
      0.6391297029877852,
      0.6419307528587872,
      0.5528218198054565,
      0.52584196276472,
      0.4700427863501503,
      0.8627984809750568,
      0.6349772302690381,
      0.5470688563710201,
      0.6210922088094815,
      0.5906270245948951,
      0.6011880272341346,
      0.5843252575058423,
      0.5122750540693363,
      0.5141922031423289,
      0.5163968973174067,
      0.4959199825179077,
      0.4702237822427721,
      0.5277254093014552,
      0.49553458232901054,
      0.4955801109264711,
      0.441847355387168,
      0.4345200878863563,
      0.4781199427332707,
      0.5249897335906942,
      0.4765385279487707,
      0.4736898200954506,
      0.49550397761924536,
      0.4703676132920259,
      0.43188965035055926,
      0.44638116228544783,
      0.4386774564217665,
      0.468929195029293,
      0.4350613548459407,
      0.41750905079220585,
      0.4347270475979337,
      0.43183667935475617,
      0.4657789489466273,
      0.41608260779859063,
      0.4419871287520774,
      0.4715079959727333,
      0.4587972426753558,
      0.48105103866961185,
      0.47906558482411377,
      0.48634598028517056,
      0.44814904649814447,
      0.4921754631899788,
      0.48076346636175393,
      0.49548595605674617,
      0.4210767586698789,
      0.4207708717284802,
      0.36030319119820337,
      0.4230343523853553,
      0.4138629645555319,
      0.42418964718451757,
      0.4371845364302932,
      0.4174667422553736,
      0.4152929165406141,
      0.45000473461643664,
      0.46338967988769453,
      0.44934237965209756,
      0.4495738680223505,
      0.45771810163459375,
      0.4544262066751183,
      0.46771993901201353,
      0.46672350912393923,
      0.47673807858885403,
      0.4807344049215317,
      0.4851934469656316,
      0.48131201271703855,
      0.48210641757813755,
      0.4718628176672016,
      0.4672143949363046,
      0.4786075282685771,
      0.4702794406139208,
      0.4915265352604632,
      0.4944704412432488,
      0.5011695804353246,
      0.47242157285263436,
      0.4778489833731137,
      0.4810901078813804,
      0.4954479985340627,
      0.4848638850860967,
      0.6894469288294901,
      0.5096553819800566,
      0.500901877906865,
      0.5027705174898673,
      0.5191800006046267,
      0.4940498798728703,
      0.501675991160784,
      0.48902532396737686,
      0.4855734277628139,
      0.493097779547383,
      0.48976195393029803,
      0.49468585399988885,
      0.4820849377951936,
      0.5114406580518106,
      0.5094743634412389,
      0.5060461291474496,
      0.504627984503429,
      0.525446467931399,
      0.518537757068337
    ],
    "best_epoch": 66,
    "best_val_loss": 0.36030319119820337,
    "test_loss": 0.4533884610232126,
    "tracker": {
      "initial_train_loss": 0.3620748283047832,
      "train_threshold": 0.12069160943492774,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.36030319119820337,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/gru-other-value/trial_38_cbf66e/best_model.pt",
    "last": "scripts/outputs/gru-other-value/trial_38_cbf66e/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/gru-other-value/trial_38_cbf66e/config.yaml"
}