epoch,train_loss,val_loss
1,0.784452,0.515679
2,0.237482,0.184424
3,0.145019,0.181084
4,0.124776,0.220019
5,0.120357,0.230235
6,0.124998,0.238866
7,0.119610,0.244243
8,0.133444,0.279720
9,0.142373,0.268150
10,0.112917,0.253632
11,0.109046,0.324385
12,0.108264,0.267018
13,0.114106,0.304616
14,0.106283,0.252455
15,0.104064,0.290176
16,0.104445,0.262492
17,0.102423,0.546928
18,0.110244,0.260322
19,0.126078,0.242265
20,0.132567,0.280048
21,0.105574,0.265859
22,0.100900,0.321194
23,0.100909,0.289961
24,0.100274,0.272169
25,0.103214,0.276848
26,0.118767,0.260241
27,0.098849,0.320021
28,0.099120,0.282975
29,0.097293,0.386945
30,0.105268,0.364455
31,0.097732,0.281029
32,0.101411,0.270588
33,0.096893,0.280670
34,0.100011,0.270745
35,0.094434,0.302899
36,0.103705,0.267210
37,0.108569,0.267386
38,0.100278,0.281867
39,0.091904,0.284004
40,0.090902,0.408390
41,0.092079,0.269739
42,0.095114,0.280929
43,0.092773,0.293545
44,0.092839,0.302367
45,0.094826,0.266256
46,0.093415,0.351581
47,0.286193,0.398882
48,1.038540,0.457082
49,0.876404,1.103285
50,0.516760,0.366128
51,0.332562,0.208035
52,0.191718,0.219337
53,0.162213,0.266788
54,0.154180,0.490472
55,0.140466,0.247318
56,0.138821,0.290581
57,0.135031,0.245596
58,0.153964,0.247998
59,0.124763,0.273019
60,0.117363,0.253779
61,0.123137,0.303804
62,0.118210,0.364657
63,0.120679,0.289766
64,0.112717,0.272084
65,0.112099,0.267089
66,0.103232,0.324331
67,0.093022,0.281880
68,0.086068,0.283722
69,0.086666,0.284596
70,0.089905,0.372841
71,0.083404,0.323072
72,0.083683,0.357325
73,0.079530,0.473631
74,0.075811,0.380993
75,0.078217,0.296699
76,0.099630,0.335950
77,0.151417,0.287960
78,0.088191,0.300036
79,0.081833,0.284403
80,0.075761,0.289508
