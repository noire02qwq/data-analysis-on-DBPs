epoch,train_loss,val_loss
1,0.729509,0.500943
2,0.416230,0.504301
3,0.373963,0.465425
4,0.364794,0.459865
5,0.355759,0.475770
6,0.347995,0.496757
7,0.332391,0.586135
8,0.316249,0.427243
9,0.265976,0.332283
10,0.254693,0.394977
11,0.247385,0.368267
12,0.247772,0.363171
13,0.257909,0.353657
14,0.240789,0.399650
15,0.234320,0.409609
16,0.222293,0.450925
17,0.222819,0.524071
18,0.213598,0.539846
19,0.198390,0.520385
20,0.189262,0.495258
21,0.177418,0.573214
22,0.229928,0.541849
23,0.191146,0.753472
24,0.185789,0.492770
25,0.166212,0.503634
26,0.160387,0.534504
27,0.150886,0.636192
28,0.147549,0.573092
29,0.154872,0.557828
30,0.141771,0.606891
31,0.134601,0.534916
32,0.139751,0.569790
33,0.136796,0.595815
34,0.138194,0.563421
35,0.135554,0.521380
36,0.124350,0.582974
37,0.122467,0.562422
38,0.129182,0.633326
39,0.124738,0.558191
40,0.124056,0.569053
41,0.121011,0.532637
42,0.124077,0.516848
43,0.116910,0.566920
44,0.119228,0.680401
45,0.117786,0.620626
46,0.109957,0.590896
47,0.109230,0.592209
48,0.109037,0.546498
49,0.111684,0.542723
50,0.108431,0.555747
51,0.105245,0.524485
52,0.112830,0.543227
53,0.113249,0.471173
54,0.106387,0.486923
55,0.106862,0.423222
56,0.105264,0.528923
57,0.105185,0.625191
58,0.108121,0.498253
59,0.104336,0.510836
60,0.104069,0.525968
61,0.106653,0.632292
62,0.106642,0.486037
63,0.102266,0.467460
64,0.100133,0.524209
65,0.103521,0.463198
66,0.101988,0.574963
67,0.100304,0.458496
68,0.098896,0.686867
69,0.106605,0.470069
70,0.095281,0.594505
71,0.101725,0.509531
72,0.098195,0.501055
73,0.096381,0.465766
74,0.097154,0.461331
75,0.097400,0.600299
76,0.100077,0.506685
77,0.092350,0.499723
78,0.098054,0.459739
79,0.093007,0.498733
80,0.090779,0.523591
