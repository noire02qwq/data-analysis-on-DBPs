{
  "model_name": "mlp_with_history-trc-value/trial_39_c3751d",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 111,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.42742659362972235,
    "mid_layer_count": 9,
    "mid_layer_size": 990
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 451,
    "learning_rate": 0.0010600423299841981,
    "weight_decay": 0.005990360290352523,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7686,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 1110,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83
    ],
    "train_loss": [
      1.0454171157708367,
      1.000709221957408,
      0.9993838091055428,
      1.000050191275316,
      0.9996471605068564,
      0.9994435650031144,
      0.9999028955497314,
      0.999996591430141,
      0.9998702885286901,
      0.9995517401824915,
      0.9994760798641769,
      0.9994297181756553,
      0.9999071417408872,
      0.999508139423613,
      0.9998370579543475,
      0.9997809877812537,
      0.9993989357190178,
      0.9999435972010379,
      0.9996116058515627,
      0.9996155673812958,
      0.999838397794796,
      0.9996694217365979,
      0.9997378302185045,
      0.9995237056736893,
      0.9994908684620843,
      0.9997678687880817,
      0.999913915708727,
      0.9996310755156801,
      0.9997659152974196,
      0.999731812049348,
      0.9998229095906663,
      0.9996301657654735,
      0.9997221747320703,
      0.9996298772188142,
      0.9995885496722079,
      0.9996488164977546,
      0.9995247374094621,
      0.999692875745549,
      0.9997698197661357,
      0.9994974771096251,
      0.9993514046984168,
      0.9997351796032083,
      0.9995802358711817,
      0.9995182019920359,
      0.9995536864067532,
      0.9996456015770738,
      0.999587174818102,
      0.9996050611049162,
      0.9996588250179635,
      0.9994484659457871,
      0.9998394381463326,
      0.999555390428014,
      0.9994478667353145,
      0.9996852656143456,
      0.9994630541476985,
      0.99961226471321,
      0.9996778768640677,
      0.9995242920109235,
      0.9995470472589434,
      0.9995557103900279,
      0.9994718283608715,
      0.9995300840065872,
      0.9995304516073381,
      0.999630499383977,
      0.9995410252200605,
      0.9994705775008672,
      0.9995645227808831,
      0.9995676333818031,
      0.9996158272113274,
      0.9995506563798977,
      0.9996422202348896,
      0.9995281847386257,
      0.9995639971650084,
      0.9995596928969355,
      0.9996230237626049,
      0.9996243760730338,
      0.9995216599067238,
      0.9995780545242001,
      0.9995472059952788,
      0.999574141284621,
      0.9995706474799648,
      0.9996489630432883,
      0.9996172835080536
    ],
    "val_loss": [
      0.32749296490571456,
      0.3471847095978474,
      0.3533865006071722,
      0.35374055584658404,
      0.35196115557929714,
      0.3528268780224694,
      0.3544355771944908,
      0.3467799378057083,
      0.3513735121818717,
      0.34935604274540605,
      0.3514202742341036,
      0.35821306320453833,
      0.3532496655727932,
      0.35339693853598153,
      0.3535506308480294,
      0.3555510946911966,
      0.3507374586950162,
      0.348491008967875,
      0.349303866195643,
      0.3490259298128996,
      0.3538724560089811,
      0.35423666746941157,
      0.3526920169993432,
      0.3527094657728058,
      0.3502922836133463,
      0.34915230700266575,
      0.3542462899031753,
      0.35567538973367857,
      0.35983102509896914,
      0.3571690701751295,
      0.3562843062251271,
      0.34963629780682975,
      0.34566914603381815,
      0.34813724212393077,
      0.34820164048118507,
      0.3510043168853143,
      0.3507093986708247,
      0.35218667664570724,
      0.3482632212296218,
      0.348551425543017,
      0.3487999195422598,
      0.35371194603200445,
      0.35434503104247733,
      0.35326626262443506,
      0.3519038146350555,
      0.35118073543121003,
      0.3525012630634679,
      0.35067683167889446,
      0.3502849979582661,
      0.34832849376305136,
      0.34915310430847957,
      0.3494972250507977,
      0.34797870461901503,
      0.34764921282847483,
      0.3488678815389822,
      0.3485348428527038,
      0.3512786384381934,
      0.35264327285621694,
      0.3534288123473079,
      0.35271697697971394,
      0.3496503598229614,
      0.35048996281481076,
      0.3505486113359471,
      0.35177821597742465,
      0.3528334585269411,
      0.34885221529685095,
      0.34705193094953807,
      0.34821185444197256,
      0.35014982484504137,
      0.349427632523511,
      0.3492006498182605,
      0.3508906539641098,
      0.3510621264755369,
      0.3496973505678648,
      0.3489657427022557,
      0.3527926778365038,
      0.3514394915523286,
      0.34863197153021475,
      0.3513492985578354,
      0.35306648630760384,
      0.3537858533020505,
      0.3559935849539177,
      0.3521616142800825
    ],
    "best_epoch": 83,
    "best_val_loss": 0.3521616142800825,
    "test_loss": 5.676574656053593,
    "tracker": {
      "initial_train_loss": 1.0454171157708367,
      "train_threshold": 0.34847237192361225,
      "best_tracking": false,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.34566914603381815,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_39_c3751d/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_39_c3751d/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_39_c3751d/config.yaml"
}