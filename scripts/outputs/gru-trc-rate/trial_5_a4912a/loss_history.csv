epoch,train_loss,val_loss
1,0.641304,0.557253
2,0.236354,0.306128
3,0.193700,0.391776
4,0.175612,0.345854
5,0.157490,0.307969
6,0.134351,0.284748
7,0.109892,0.253877
8,0.096384,0.246904
9,0.079289,0.239593
10,0.069658,0.253741
11,0.062484,0.244061
12,0.055836,0.229809
13,0.058117,0.218460
14,0.050303,0.218638
15,0.051685,0.231432
16,0.058210,0.215219
17,0.047966,0.212390
18,0.045189,0.212029
19,0.042881,0.216574
20,0.043863,0.213761
21,0.044711,0.214575
22,0.042790,0.229796
23,0.044313,0.218894
24,0.042403,0.226786
25,0.039851,0.224926
26,0.039611,0.235904
27,0.040264,0.240534
28,0.044723,0.226969
29,0.039303,0.225471
30,0.040007,0.229870
31,0.039922,0.243137
32,0.039163,0.231280
33,0.037784,0.245430
34,0.038826,0.242462
35,0.037739,0.290039
36,0.040421,0.254062
37,0.036592,0.240682
38,0.037263,0.273123
39,0.037256,0.262328
40,0.036703,0.263551
41,0.036647,0.289345
42,0.035520,0.275933
43,0.037431,0.291513
44,0.033728,0.282105
45,0.033811,0.267842
46,0.035385,0.290125
47,0.034137,0.295581
48,0.035644,0.272095
49,0.035882,0.277883
50,0.036038,0.293111
51,0.032656,0.289038
52,0.032833,0.290471
53,0.033126,0.289446
54,0.032453,0.289519
55,0.032062,0.302305
56,0.031116,0.313418
57,0.031377,0.294228
58,0.033432,0.322070
59,0.031762,0.305148
60,0.031573,0.321764
61,0.030803,0.316598
62,0.030792,0.304950
63,0.030976,0.289823
64,0.031760,0.341008
65,0.032180,0.292319
66,0.031203,0.335009
67,0.031632,0.362798
68,0.033472,0.318324
69,0.033274,0.332869
70,0.029819,0.304054
71,0.030500,0.316007
72,0.030829,0.359225
73,0.031291,0.317576
74,0.029759,0.308805
75,0.032853,0.348018
76,0.032375,0.330636
77,0.029172,0.303404
78,0.031119,0.324653
79,0.032526,0.336449
80,0.028469,0.325678
