epoch,train_loss,val_loss
1,0.680744,0.510969
2,0.369986,0.491950
3,0.342830,0.482996
4,0.330261,0.480808
5,0.307982,0.406155
6,0.267596,0.372448
7,0.255186,0.395063
8,0.249893,0.386083
9,0.244465,0.434378
10,0.239542,0.486591
11,0.238223,0.441996
12,0.232150,0.495480
13,0.229755,0.521983
14,0.223261,0.508175
15,0.218092,0.584876
16,0.212416,0.521973
17,0.210895,0.587182
18,0.207147,0.609820
19,0.204973,0.665004
20,0.206677,0.571906
21,0.201922,0.649823
22,0.198990,0.624687
23,0.198806,0.653982
24,0.196037,0.694699
25,0.194591,0.722471
26,0.191446,0.756064
27,0.192164,0.693928
28,0.190591,0.679300
29,0.187813,0.673826
30,0.186606,0.710480
31,0.186286,0.676432
32,0.184087,0.687693
33,0.183297,0.697201
34,0.181706,0.707150
35,0.178211,0.703302
36,0.179459,0.726138
37,0.180465,0.687908
38,0.174211,0.695537
39,0.171866,0.719796
40,0.174098,0.692957
41,0.167747,0.698285
42,0.166452,0.678832
43,0.164636,0.678630
44,0.163780,0.680738
45,0.162421,0.729210
46,0.162846,0.683186
47,0.161954,0.702286
48,0.158984,0.691433
49,0.155146,0.679011
50,0.155107,0.681377
51,0.152966,0.688720
52,0.152796,0.666326
53,0.150145,0.726034
54,0.148434,0.726424
55,0.151486,0.701748
56,0.145175,0.713067
57,0.144227,0.701389
58,0.146812,0.748133
59,0.143885,0.722827
60,0.142111,0.735707
61,0.142468,0.732867
62,0.138760,0.728835
63,0.139831,0.723718
64,0.138239,0.733521
65,0.136364,0.743375
66,0.134174,0.733476
67,0.134939,0.781146
68,0.134285,0.747199
69,0.130820,0.762623
70,0.129377,0.794433
71,0.129504,0.767467
72,0.129722,0.750817
73,0.133259,0.766823
74,0.126680,0.762487
75,0.125140,0.768551
76,0.123050,0.769242
77,0.122105,0.771987
78,0.121899,0.788137
79,0.124998,0.759329
80,0.120606,0.794042
