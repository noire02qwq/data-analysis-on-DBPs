{
  "model_name": "mlp-trc-rate/trial_33_3a53f7",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.2296649139305501,
    "mid_layer_count": 6,
    "mid_layer_size": 438
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 349,
    "learning_rate": 0.0005104079726565502,
    "weight_decay": 0.0001545340401563449,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.5283553410338676,
      0.16671554137378733,
      0.11874603591152127,
      0.09655413321152964,
      0.0814235723921967,
      0.07475382510645305,
      0.07138961419967764,
      0.0679113697083815,
      0.06450105069387702,
      0.06381803472359603,
      0.06264985334787569,
      0.05917427945153844,
      0.06061921665505179,
      0.057910846651418504,
      0.056094703717532834,
      0.05490656697185086,
      0.05436391656785408,
      0.052505486334204335,
      0.052909270988795436,
      0.052553019358782725,
      0.0506653212839446,
      0.05005171281329068,
      0.04917669417637626,
      0.048734991725681374,
      0.04693347347346925,
      0.04828744552926322,
      0.046735467432232135,
      0.04594378449020858,
      0.045506397833719875,
      0.045725528535941064,
      0.04585746383813404,
      0.04505400271276791,
      0.0436019625184076,
      0.044611358891344946,
      0.043870481964451126,
      0.04410698687205671,
      0.04382243522587665,
      0.04202386656543837,
      0.042039619767326404,
      0.04184297043753701,
      0.041222530596814536,
      0.04119952634123157,
      0.04061345991345477,
      0.04131422359391229,
      0.04029713385571664,
      0.03986132645376481,
      0.039642507968716066,
      0.039673281323667396,
      0.03856443617685964,
      0.03965937383205326,
      0.038200449830675165,
      0.03940626583790828,
      0.038004664900598464,
      0.038737497377993514,
      0.0380141280864816,
      0.03822550518613112,
      0.037866245514176604,
      0.036349657633169344,
      0.037702696214407576,
      0.03676382376558662,
      0.03823659080737727,
      0.03690484612167126,
      0.03642303637277169,
      0.03574263462256841,
      0.03654870659322227,
      0.03720589689365667,
      0.03622228860579863,
      0.03639731196406607,
      0.03565865463570999,
      0.036996994187158,
      0.036050809965898524,
      0.0367197508327835,
      0.03615023030934348,
      0.03575037971708547,
      0.03578141826243661,
      0.03647307443287722,
      0.0352589694224967,
      0.03397415809475723,
      0.0349371305395925,
      0.03407494268839316
    ],
    "val_loss": [
      0.45697658108826167,
      0.3570892274290502,
      0.2404008150279165,
      0.19406484356986548,
      0.19638878868636256,
      0.2072783486404551,
      0.21209643997787359,
      0.20557677910668765,
      0.22397276058146162,
      0.21675539862721444,
      0.22305945984260764,
      0.23945509213842675,
      0.23463750756540877,
      0.24355723526953402,
      0.24321657647518163,
      0.23894276552036137,
      0.25076544805468914,
      0.23795920830822276,
      0.24610300490599193,
      0.2613671886026413,
      0.25811485765713776,
      0.25587036077847736,
      0.2594827176054973,
      0.26995207391523135,
      0.2845649761276063,
      0.28325346826525505,
      0.27453458963441635,
      0.29025133106255246,
      0.2895612470961795,
      0.30933898197163545,
      0.29114502655888747,
      0.30237278349273755,
      0.2821147746177847,
      0.2850708427610333,
      0.288909455353093,
      0.3046168409276776,
      0.29315377554248373,
      0.32275757108575215,
      0.31053682891150075,
      0.3093402943914076,
      0.32153275066730147,
      0.2888245179200779,
      0.3079473836559378,
      0.3022812084958493,
      0.32516246552685063,
      0.3322017487618113,
      0.3339319765433937,
      0.2891898898296281,
      0.3450888276880908,
      0.344781376379068,
      0.34714409714107386,
      0.32403695279074285,
      0.2982534035605317,
      0.31869275496636856,
      0.3130561674437569,
      0.34162668902315424,
      0.3524559269965944,
      0.3388015671371075,
      0.3248915605882774,
      0.3582697075696852,
      0.3225869625974112,
      0.3573918450712979,
      0.316545922780956,
      0.3394857624735304,
      0.3575801376364902,
      0.3264187420400495,
      0.33213464675616183,
      0.3222482116959855,
      0.32946431348156074,
      0.3449797385890862,
      0.343253370220522,
      0.3204268926788055,
      0.35844129033409017,
      0.37192083852153696,
      0.32203025537358965,
      0.3567926994619701,
      0.33146091997065763,
      0.37137832304763935,
      0.3628303887110627,
      0.3281388583052123
    ],
    "best_epoch": 4,
    "best_val_loss": 0.19406484356986548,
    "best_val_abs_mse": 0.16672037541866302,
    "test_loss": 5.205436024084046,
    "test_abs_mse": 49.41691207885742,
    "tracker": {
      "initial_train_loss": 0.5283553410338676,
      "train_threshold": 0.1761184470112892,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.19406484356986548,
      "patience_no_improve_epochs": 76,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_33_3a53f7/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_33_3a53f7/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_33_3a53f7/config.yaml"
}