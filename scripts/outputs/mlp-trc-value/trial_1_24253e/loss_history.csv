epoch,train_loss,val_loss
1,0.250581,0.397583
2,0.083024,0.233752
3,0.068599,0.229486
4,0.062195,0.333852
5,0.059124,0.444655
6,0.059018,0.308773
7,0.056082,0.292996
8,0.055052,0.422490
9,0.053231,0.260576
10,0.051251,0.526507
11,0.052851,0.344126
12,0.049277,0.347382
13,0.048602,0.363122
14,0.049749,0.433255
15,0.047670,0.398126
16,0.048811,0.380446
17,0.047673,0.316217
18,0.049126,0.356766
19,0.047091,0.302826
20,0.047147,0.310658
21,0.048008,0.332523
22,0.048722,0.316668
23,0.047205,0.310170
24,0.046054,0.295476
25,0.044728,0.295843
26,0.046494,0.322938
27,0.045336,0.307799
28,0.044912,0.310782
29,0.046155,0.341741
30,0.044878,0.343234
31,0.044956,0.386139
32,0.044699,0.314145
33,0.044193,0.357905
34,0.045004,0.375459
35,0.045271,0.361673
36,0.043186,0.362380
37,0.044176,0.348016
38,0.045777,0.334470
39,0.045584,0.309245
40,0.043795,0.375727
41,0.044653,0.340208
42,0.043395,0.315286
43,0.044727,0.403329
44,0.044124,0.447881
45,0.046925,0.338788
46,0.044519,0.348323
47,0.045379,0.390738
48,0.043415,0.293868
49,0.044190,0.299815
50,0.043417,0.390852
51,0.045847,0.356191
52,0.043978,0.376761
53,0.045826,0.312504
54,0.043556,0.342947
55,0.043451,0.284323
56,0.043613,0.369291
57,0.044016,0.299062
58,0.043749,0.389481
59,0.044549,0.340483
60,0.043354,0.358228
61,0.045314,0.363884
62,0.045022,0.329340
63,0.043595,0.331654
64,0.043056,0.325209
65,0.046403,0.367140
66,0.044295,0.281244
67,0.043571,0.287111
68,0.043802,0.290234
69,0.042898,0.335615
70,0.043118,0.355540
71,0.044641,0.347802
72,0.043868,0.330065
73,0.043269,0.370591
74,0.044201,0.293684
75,0.043878,0.316958
76,0.044538,0.337553
77,0.044341,0.271787
78,0.043490,0.371078
79,0.042333,0.369577
80,0.041362,0.319442
