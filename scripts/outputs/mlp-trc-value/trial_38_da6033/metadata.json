{
  "model_name": "mlp-trc-value/trial_38_da6033",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.23760290884066762,
    "mid_layer_count": 13,
    "mid_layer_size": 231
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 176,
    "learning_rate": 0.0004991967886819864,
    "weight_decay": 0.0011104271250753533,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.364185767067647,
      0.11576832747569507,
      0.08816830626186681,
      0.07550407672781648,
      0.07199873854757395,
      0.06641505793188095,
      0.0627204779327191,
      0.06224425003628293,
      0.061142306985107066,
      0.05913497566633985,
      0.0599344360592917,
      0.055995990282804796,
      0.057027163996092166,
      0.05631159294517056,
      0.05433170885428702,
      0.054010532280308825,
      0.050667855068620746,
      0.051607766708100127,
      0.04965506784384712,
      0.04998984216321059,
      0.0509663652657331,
      0.04923118544257929,
      0.04943198326682665,
      0.0484655822864736,
      0.047329055150161344,
      0.04736382011735115,
      0.047716666056964264,
      0.04653966647614388,
      0.04554590226947619,
      0.04676435420097541,
      0.04591633507331069,
      0.04548027949181198,
      0.045110340249758615,
      0.04689587654212366,
      0.04422560170399892,
      0.04373735634026129,
      0.04337544938412735,
      0.04315415517894839,
      0.045523837384595325,
      0.043400652033815386,
      0.04419110220149274,
      0.042681667504554044,
      0.04365498799660562,
      0.0421306991126826,
      0.043474364893873144,
      0.04240195963984731,
      0.04166723612510528,
      0.04158645713479168,
      0.04123902408020994,
      0.04213819204575897,
      0.041946458579134246,
      0.04225062283798632,
      0.04244595450497762,
      0.04158033026509434,
      0.04168064153445966,
      0.04096548661413775,
      0.04065815677408563,
      0.041464172555979485,
      0.04139543845370343,
      0.04056576594878552,
      0.04054078358818532,
      0.042231503822456086,
      0.04131255253744223,
      0.04129438010498828,
      0.04024974079950765,
      0.040030241389116185,
      0.040153272788285475,
      0.03968759136835449,
      0.04063472958552097,
      0.0400810012504986,
      0.0398499474900389,
      0.040172302003103136,
      0.039453668623069364,
      0.0408621556319109,
      0.040131148279645985,
      0.03973381156880713,
      0.03964190750266724,
      0.039007516666719276,
      0.0396301525660727,
      0.040291926464693796
    ],
    "val_loss": [
      0.22919512944307155,
      0.1896786657814494,
      0.19566837608100413,
      0.2669987138516889,
      0.24709677289346021,
      0.2769239658367134,
      0.24609896210496296,
      0.2556351371332557,
      0.30027132014671487,
      0.2859225540104027,
      0.29152647856466785,
      0.27501819415720635,
      0.27085680984808297,
      0.28574256111761764,
      0.3119313928895368,
      0.3087512711921852,
      0.34726244061293005,
      0.3037717289553431,
      0.30380937712278194,
      0.3422218330606015,
      0.31423658519804837,
      0.30544197689630315,
      0.3030459288530007,
      0.3302939655538091,
      0.3192033235541361,
      0.31947800347548044,
      0.3147842571228564,
      0.3150864105917023,
      0.3599989656202807,
      0.3321823104769884,
      0.32301916215948,
      0.31208165118437325,
      0.3476727468346407,
      0.31371367008029344,
      0.3272821843802572,
      0.338601969619711,
      0.4049331487652784,
      0.3402418817767126,
      0.3328175650206869,
      0.32743820610517516,
      0.3086693525314331,
      0.31149891484640313,
      0.3399080568266486,
      0.3441678674991973,
      0.3291536057602146,
      0.3076770682534772,
      0.3225009383734115,
      0.28766035576780397,
      0.31564632211616656,
      0.31304511613474634,
      0.3524324257395225,
      0.3188643103588127,
      0.29669165886090904,
      0.31565168946089145,
      0.31141166376496504,
      0.32761033295157427,
      0.3217548266499342,
      0.33056565394658527,
      0.3377925022990404,
      0.3472684396776611,
      0.3302852412362299,
      0.3399981688239617,
      0.3458245477098191,
      0.35988045532903273,
      0.3183003629574519,
      0.3375020197765556,
      0.3055169633762565,
      0.3295943357451947,
      0.3412279414024182,
      0.3002254280144583,
      0.3596848389524186,
      0.30818371005400924,
      0.3031523448442984,
      0.310751872594485,
      0.29614636860564797,
      0.31604529513927276,
      0.2961206617648016,
      0.3225817231361024,
      0.3481373186418396,
      0.31167896059815753
    ],
    "best_epoch": 2,
    "best_val_loss": 0.1896786657814494,
    "test_loss": 5.004544101263347,
    "tracker": {
      "initial_train_loss": 0.364185767067647,
      "train_threshold": 0.12139525568921566,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.1896786657814494,
      "patience_no_improve_epochs": 79,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_38_da6033/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_38_da6033/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_38_da6033/config.yaml"
}