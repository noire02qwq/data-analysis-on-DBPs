{
  "model_name": "mlp-trc-rate/trial_37_e9dbdf",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.3028002549963179,
    "mid_layer_count": 12,
    "mid_layer_size": 422
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 359,
    "learning_rate": 0.00043679906612248057,
    "weight_decay": 0.0003904713884240604,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.5934271239252688,
      0.19887575926713114,
      0.14281319260784545,
      0.11390722773036417,
      0.10138100569350038,
      0.09326146697752626,
      0.08755706104064306,
      0.0830419110970475,
      0.07983368135063602,
      0.07650120799673894,
      0.07560016615904022,
      0.07086999395603229,
      0.07098874074955011,
      0.0705814226609337,
      0.06693264281758518,
      0.06971128994007411,
      0.06465199601532115,
      0.0638324998480661,
      0.0625464977637285,
      0.06297942283317225,
      0.06033445169873012,
      0.05910079195004066,
      0.061755371455861977,
      0.059082580922413266,
      0.05728006687038232,
      0.05795430870016625,
      0.055453907909123114,
      0.05628349002414388,
      0.05584004570110264,
      0.053463999313871455,
      0.05481635423051265,
      0.05395656545049658,
      0.05328245832321505,
      0.052859067621083215,
      0.05425544315160636,
      0.053454114028131765,
      0.05247091096211865,
      0.05119730938004264,
      0.05204147089314788,
      0.05037613662620151,
      0.05112593000484253,
      0.04932417591155462,
      0.05191133029590728,
      0.05114306643721827,
      0.050921708953233794,
      0.04981868056099711,
      0.04885752493082682,
      0.04903147114931069,
      0.047717495458253135,
      0.049243213623196364,
      0.047572780398603215,
      0.04726755572267913,
      0.04737956718034687,
      0.04625908377317051,
      0.04616189152747775,
      0.046069029285708656,
      0.045373498738813606,
      0.04569877441465977,
      0.04548688318146504,
      0.04540654371041956,
      0.04519602539435434,
      0.04522963596738229,
      0.044210623346246196,
      0.0433881433328003,
      0.04496737033044637,
      0.0439770849982612,
      0.045315687562324194,
      0.04544555974465768,
      0.04299289945096328,
      0.04418540738519184,
      0.04480706549188903,
      0.043513960226521604,
      0.04383131029803961,
      0.041965324292604494,
      0.04417305154340765,
      0.042800254951120796,
      0.044719139039478224,
      0.043746455586403075,
      0.04311334821522205,
      0.042445380085378716
    ],
    "val_loss": [
      0.5788667814817258,
      0.25402645351822506,
      0.20168795589201466,
      0.22173278818944256,
      0.19828227945006716,
      0.19670185729258968,
      0.19606684886677536,
      0.19436885190648054,
      0.2045536240964325,
      0.20460428065079414,
      0.209929610957241,
      0.2137821545121734,
      0.22327785735983335,
      0.22617570305811965,
      0.23432470931264454,
      0.22321911854056006,
      0.2329487875550093,
      0.2367181904781275,
      0.24134482151778516,
      0.24746567103454095,
      0.24835348198647628,
      0.25151347709250843,
      0.2599952957174646,
      0.26488286013307866,
      0.25456309634299873,
      0.25912771729674344,
      0.2615056081769798,
      0.26327852362064186,
      0.26634870544856715,
      0.27246615037009747,
      0.27222902640410346,
      0.28652348403824485,
      0.2788870627149761,
      0.2742445539816946,
      0.27461612506875555,
      0.27315440413592285,
      0.27715823006464874,
      0.2907848477285511,
      0.28321252929905577,
      0.2888750690977998,
      0.2918506186990859,
      0.28305122137270466,
      0.2955643646452509,
      0.2910367812414815,
      0.29182918670358593,
      0.29998524247440034,
      0.3197144739017515,
      0.28632376749001576,
      0.3074629129875384,
      0.3067425138021479,
      0.32234303972232126,
      0.29900055157500294,
      0.3085520784554635,
      0.3170456259673138,
      0.3118976212926432,
      0.3266243838342632,
      0.3246745151439737,
      0.33298442947405005,
      0.3325328812962342,
      0.33344125576919603,
      0.3217605635479182,
      0.321485269280474,
      0.30476818170153097,
      0.30978825441310687,
      0.32668450179615777,
      0.3280408415865309,
      0.32153400310432306,
      0.32230710773700905,
      0.31525349588674345,
      0.31116850837775156,
      0.319078751434823,
      0.32753173855138934,
      0.3199642941188402,
      0.3243015817539421,
      0.3208243245024702,
      0.33386626476812326,
      0.33665131224308187,
      0.35024979059656935,
      0.32853833084847933,
      0.3163578844344812
    ],
    "best_epoch": 8,
    "best_val_loss": 0.19436885190648054,
    "best_val_abs_mse": 0.25242701172828674,
    "test_loss": 4.6095813720990595,
    "test_abs_mse": 45.78188705444336,
    "tracker": {
      "initial_train_loss": 0.5934271239252688,
      "train_threshold": 0.19780904130842292,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.19436885190648054,
      "patience_no_improve_epochs": 72,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_37_e9dbdf/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_37_e9dbdf/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_37_e9dbdf/config.yaml"
}