{
  "model_name": "mlp-trc-value/trial_46_8a1830",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.25470748730390985,
    "mid_layer_count": 11,
    "mid_layer_size": 339
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 129,
    "learning_rate": 0.00042053594125183324,
    "weight_decay": 0.002791397103626145,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.34841791790584653,
      0.1139770460861227,
      0.08959682197861943,
      0.07963516763108029,
      0.0740013540382681,
      0.07112909781399172,
      0.06620657978328055,
      0.06748281605254998,
      0.06572617291868987,
      0.06222382381275533,
      0.062157358392679336,
      0.06007332684450222,
      0.05910754059725706,
      0.060401891707024584,
      0.05865815613397792,
      0.05589607807775609,
      0.05692444575913232,
      0.054838635461293105,
      0.05600079511454269,
      0.054831743027236965,
      0.053548606841315086,
      0.054207724929543996,
      0.054075485334304924,
      0.052652647631819156,
      0.053484666425010347,
      0.052987650011963816,
      0.052431268966338644,
      0.05218170389768143,
      0.05210052364209085,
      0.05169900286447671,
      0.05131234089414345,
      0.0500984873236556,
      0.05148781825568032,
      0.050674628260893785,
      0.05149304995427014,
      0.0491774599070256,
      0.049355737226568414,
      0.048831641912964935,
      0.049737910846637236,
      0.049750366626644726,
      0.05059376944777765,
      0.0496466550450407,
      0.04993395714099787,
      0.04855880768479385,
      0.04924427067957486,
      0.0505022494172082,
      0.04812366058624681,
      0.048340241962316524,
      0.048956242329768335,
      0.04938502348300018,
      0.04863512563997504,
      0.049407403996398716,
      0.04796903001468508,
      0.04801788162143797,
      0.048610832139356526,
      0.04820771983324365,
      0.04857687765384536,
      0.04709964870150775,
      0.048632045981286426,
      0.047229458493829965,
      0.048437577249408684,
      0.048340550087690504,
      0.0482636369758115,
      0.05000256541533431,
      0.04772269839861489,
      0.0468261327839176,
      0.04820402848102791,
      0.04880885985857206,
      0.04756680916251281,
      0.047180760525675415,
      0.04758252613982324,
      0.04853021547202118,
      0.04768544294727558,
      0.04613775943046108,
      0.04640825645230699,
      0.047742401843669784,
      0.047410456028854374,
      0.04825099129893991,
      0.047373861351598524,
      0.046399748393393225
    ],
    "val_loss": [
      0.2983559277243243,
      0.19720250931596328,
      0.22235198200842043,
      0.2367544152891029,
      0.21946154861393088,
      0.256701277699433,
      0.2329210555950503,
      0.2429094687282682,
      0.2472361754336043,
      0.29409276360567815,
      0.24401637915923388,
      0.2669752797926079,
      0.25537709958382887,
      0.27850316271498177,
      0.27680251100797676,
      0.2559889325972446,
      0.2648123918826173,
      0.29330774568422824,
      0.26318301197565247,
      0.2826411189187965,
      0.29801690198570313,
      0.27602672457115024,
      0.2782169410166983,
      0.2908553170397164,
      0.2887887407607304,
      0.27864241490508623,
      0.28523328675481374,
      0.3037274951104097,
      0.32357568293252215,
      0.3121161828330623,
      0.29699815192823104,
      0.3030213952097975,
      0.3393671173111586,
      0.3497038829023253,
      0.37598549328231345,
      0.3158224581813295,
      0.38639089213628436,
      0.35621762528993234,
      0.340370291761474,
      0.3772146079823107,
      0.36747422430352,
      0.3403439453440512,
      0.31285293724856333,
      0.33031930095644413,
      0.3406198701481084,
      0.32318737342909065,
      0.35005574177080645,
      0.29076349867764345,
      0.30190127504889125,
      0.37113787648072855,
      0.34286011398217814,
      0.3380284190992128,
      0.30598460141413225,
      0.3447865113114079,
      0.30577742688937815,
      0.2893509660217309,
      0.3014482422168562,
      0.35744307753434795,
      0.30707299862235427,
      0.3454736764537182,
      0.3344624609524708,
      0.33637958715061944,
      0.3098899231532109,
      0.2865386051700233,
      0.3472256033140385,
      0.29858010016091746,
      0.32394604556552486,
      0.3183880016519995,
      0.33335404633404964,
      0.31766088089186273,
      0.33434391404072683,
      0.29442127708479493,
      0.2803405959025293,
      0.317944274482479,
      0.2946053838591554,
      0.325678205783451,
      0.28304343088613654,
      0.3017487115734173,
      0.3248753870876428,
      0.3559569550811977
    ],
    "best_epoch": 2,
    "best_val_loss": 0.19720250931596328,
    "test_loss": 4.845048531961213,
    "tracker": {
      "initial_train_loss": 0.34841791790584653,
      "train_threshold": 0.1161393059686155,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.19720250931596328,
      "patience_no_improve_epochs": 79,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_46_8a1830/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_46_8a1830/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_46_8a1830/config.yaml"
}