{
  "model_name": "mlp-trc-rate/trial_1_9970ec",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.22150850319534224,
    "mid_layer_count": 3,
    "mid_layer_size": 321
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 333,
    "learning_rate": 0.0006072151661310764,
    "weight_decay": 0.00021797351337101014,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.4657639525410241,
      0.14570322100182048,
      0.10256673874053483,
      0.08453791289508587,
      0.07571360112677757,
      0.06735943218959775,
      0.06625026412807088,
      0.06316808621045976,
      0.061139095206197834,
      0.057222839925589165,
      0.05771323314711658,
      0.05651852956281572,
      0.05498006245051594,
      0.05408491112249762,
      0.05256855801003997,
      0.05102005285120594,
      0.04970723740792828,
      0.04980660903015737,
      0.04846468184997694,
      0.04920113079867237,
      0.04745827766642808,
      0.047783319546858764,
      0.047324991532686954,
      0.04452356506901683,
      0.0448531957793352,
      0.044702929703125956,
      0.043387073903067896,
      0.04392964901233435,
      0.04191512329070965,
      0.04340470837655665,
      0.04270332221041174,
      0.041970143885494596,
      0.041657160786484654,
      0.04166980532249804,
      0.042076753015668655,
      0.0400917808118617,
      0.03954511722372993,
      0.04104212554207042,
      0.03937175856036382,
      0.03978874436840071,
      0.04026284253510483,
      0.03913630059934109,
      0.03941788053041608,
      0.03864442103620276,
      0.038072474718976936,
      0.03922714497760252,
      0.03759013403736518,
      0.0385697883964273,
      0.03699178797546,
      0.036815203660826704,
      0.036439718680027176,
      0.03687335773891535,
      0.037632582092532486,
      0.03651172861030632,
      0.036794593325959926,
      0.035843048742630654,
      0.03581390007823828,
      0.036126106348616946,
      0.03560125246441413,
      0.03567298877293319,
      0.03402752856250418,
      0.03491340647344064,
      0.035247001598654584,
      0.03638863632466936,
      0.03539019890450679,
      0.03547578764526989,
      0.035147457998083484,
      0.03458951728245489,
      0.03507444600198607,
      0.0344254409496779,
      0.03398196725580954,
      0.03437529152245851,
      0.0333093974886012,
      0.033486284930574366,
      0.034001055074422755,
      0.034010588815278076,
      0.034071984617474405,
      0.03316311969212985,
      0.03281618258880003,
      0.0330651130318439
    ],
    "val_loss": [
      0.31129145642775974,
      0.27707178740801214,
      0.22280159620066245,
      0.20560109103042745,
      0.2203336311169638,
      0.21868439740696533,
      0.2274324324807364,
      0.22614859101658097,
      0.2289127235964476,
      0.24150758244231074,
      0.23043407457072043,
      0.24983115946528262,
      0.2471175670913772,
      0.2759513520797391,
      0.2779253838516906,
      0.2582752721294939,
      0.2637644544734569,
      0.27792218173826166,
      0.27583946118878566,
      0.28711854184972135,
      0.2812783974418026,
      0.2943088920262759,
      0.2821372639187082,
      0.3234231205021371,
      0.2897115843883621,
      0.29630115693379305,
      0.2950313192552435,
      0.31306906963982983,
      0.3367872444143195,
      0.3119766279653518,
      0.3047522665921621,
      0.29090623348438277,
      0.29676100034489783,
      0.3158155544008502,
      0.31533067233436657,
      0.3210002462563668,
      0.316197374896955,
      0.29669166106708394,
      0.32075448440510534,
      0.3124636793988729,
      0.3061911724407427,
      0.31049922542858444,
      0.3074087931791287,
      0.3284389854447838,
      0.3203185342809933,
      0.31257560715793137,
      0.32694268802370496,
      0.29997144470961684,
      0.3232585647918596,
      0.32134222304058113,
      0.34062390283397037,
      0.3230524480722086,
      0.3203010207945537,
      0.33286104771659936,
      0.3072467327876362,
      0.35194206768256464,
      0.3391566608859572,
      0.3305248946531447,
      0.3134244742797699,
      0.3557943170009081,
      0.35961929605660325,
      0.3552870452872472,
      0.32697983008257286,
      0.31476455465137604,
      0.3465351519849664,
      0.33142959294606467,
      0.33918260099912834,
      0.3189131718987744,
      0.35814036412755706,
      0.3665343119578804,
      0.37423684853881956,
      0.3519562370260943,
      0.3342459742526362,
      0.33189905857009266,
      0.3556332961561348,
      0.32800550187106975,
      0.33247764596637497,
      0.3556590265410389,
      0.32930618241920084,
      0.34101315235752544
    ],
    "best_epoch": 4,
    "best_val_loss": 0.20560109103042745,
    "best_val_abs_mse": 0.16961251199245453,
    "test_loss": 5.340466982653837,
    "test_abs_mse": 50.739768981933594,
    "tracker": {
      "initial_train_loss": 0.4657639525410241,
      "train_threshold": 0.15525465084700804,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.20560109103042745,
      "patience_no_improve_epochs": 76,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_1_9970ec/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_1_9970ec/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_1_9970ec/config.yaml"
}