epoch,train_loss,val_loss
1,0.520999,0.280543
2,0.181432,0.291366
3,0.136185,0.252650
4,0.095816,0.194144
5,0.070008,0.216003
6,0.062208,0.191718
7,0.055276,0.241335
8,0.049271,0.202085
9,0.047581,0.206221
10,0.044508,0.246990
11,0.043437,0.236303
12,0.040803,0.232975
13,0.038480,0.252460
14,0.038967,0.233302
15,0.037085,0.263150
16,0.037532,0.254853
17,0.036438,0.253091
18,0.034419,0.251320
19,0.032800,0.260162
20,0.032499,0.265996
21,0.030652,0.267819
22,0.031005,0.301741
23,0.029353,0.283272
24,0.032050,0.287878
25,0.029670,0.294000
26,0.028257,0.303530
27,0.027864,0.307214
28,0.027806,0.301660
29,0.028271,0.327120
30,0.027860,0.306451
31,0.027565,0.294007
32,0.027983,0.299830
33,0.026890,0.356094
34,0.026627,0.295187
35,0.028560,0.323457
36,0.025828,0.333035
37,0.026162,0.336153
38,0.025902,0.408149
39,0.025260,0.350394
40,0.025059,0.337751
41,0.024241,0.356143
42,0.024473,0.332648
43,0.023571,0.367273
44,0.023308,0.377691
45,0.022894,0.397618
46,0.023741,0.395799
47,0.022592,0.378783
48,0.022248,0.374437
49,0.022727,0.406844
50,0.021922,0.374597
51,0.022759,0.456183
52,0.022519,0.377156
53,0.022528,0.308550
54,0.022235,0.413733
55,0.022416,0.350836
56,0.021138,0.331017
57,0.023140,0.434934
58,0.021018,0.364223
59,0.020923,0.383334
60,0.020295,0.352395
61,0.020782,0.340401
62,0.021663,0.393567
63,0.021221,0.332236
64,0.020962,0.343526
65,0.022041,0.375416
66,0.021065,0.371708
67,0.019881,0.351640
68,0.019509,0.331156
69,0.021196,0.340855
70,0.020961,0.389451
71,0.020009,0.373256
72,0.019261,0.355373
73,0.020454,0.364723
74,0.019708,0.349246
75,0.020776,0.342382
76,0.019868,0.356149
77,0.019469,0.393888
78,0.019452,0.346038
79,0.019689,0.322825
80,0.019687,0.341100
