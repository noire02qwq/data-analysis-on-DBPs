{
  "model_name": "mlp-trc-rate/trial_12_303fc9",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.18207820843602635,
    "mid_layer_count": 2,
    "mid_layer_size": 396
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 198,
    "learning_rate": 0.0007551373244036434,
    "weight_decay": 0.0007958498171170598,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.3123804132003488,
      0.09476636437027347,
      0.07124316807799978,
      0.06681704127147083,
      0.05989803480182231,
      0.057491082449626654,
      0.05293885888335887,
      0.05207737025758467,
      0.05230157827817978,
      0.05094922208568877,
      0.04999008499613446,
      0.050809206695259075,
      0.04957534457767634,
      0.046565480276047726,
      0.046473561434898086,
      0.045967835370067024,
      0.04457772279940947,
      0.04400513667886596,
      0.0419557928119625,
      0.04385690205659299,
      0.04254889835518957,
      0.043999859726791386,
      0.04296385183387563,
      0.041877491436917824,
      0.04197451813560287,
      0.04237567406031124,
      0.04000711695445446,
      0.03933890731293248,
      0.03980933512637957,
      0.04058205360893625,
      0.038458650747267266,
      0.03970742530178464,
      0.03924098084673568,
      0.03998183336858186,
      0.03898977236788798,
      0.03874617721025319,
      0.03841982131012514,
      0.038347485358647626,
      0.03814542856021546,
      0.03690332291899139,
      0.039485272365584474,
      0.03748312118960656,
      0.03827460132359602,
      0.03652164382786476,
      0.03605340882225976,
      0.03622668822142575,
      0.036425565983459786,
      0.03700695629100224,
      0.03633391128288149,
      0.03811397658170738,
      0.03792022408037353,
      0.03624177213161878,
      0.03529339598271023,
      0.03594108277061173,
      0.03672245538971741,
      0.035434153087230726,
      0.03616130959554138,
      0.035803851184591444,
      0.03580536263081708,
      0.03572110501354538,
      0.036852272497867544,
      0.0352711336837251,
      0.03521051128734651,
      0.03777825921580861,
      0.03509916666906619,
      0.035851604471498266,
      0.036774839569416455,
      0.03550444024659429,
      0.034649179531610154,
      0.035212991033332385,
      0.03509515284127214,
      0.03439834632463046,
      0.035417824446975325,
      0.03462922946717676,
      0.03506379679997971,
      0.03442051055568297,
      0.0340544381874182,
      0.033971828648418176,
      0.035239116930947084,
      0.03464724042244053
    ],
    "val_loss": [
      0.2484082793359628,
      0.2129329265591627,
      0.22840740758769526,
      0.2708160052644814,
      0.2656494509852575,
      0.26647460038611986,
      0.2658728483975112,
      0.29096325085147057,
      0.2886291118706772,
      0.2833446489100506,
      0.26826865907066955,
      0.28732026219144907,
      0.27891069773116156,
      0.3047071838249525,
      0.3232601653405292,
      0.30801735537539343,
      0.2910661856080601,
      0.3133021742953155,
      0.27885435222017907,
      0.31086056278851215,
      0.311256339833765,
      0.28843609569315426,
      0.2845371427940216,
      0.3019528226692698,
      0.2958500183940291,
      0.33436684759701796,
      0.33477295558386577,
      0.33876008337843205,
      0.3476130413014196,
      0.32315766172048577,
      0.327634054185923,
      0.30158480386846437,
      0.2953819630232578,
      0.31697398505792646,
      0.36211226510252065,
      0.34725836705483365,
      0.33417349762679216,
      0.3045930021001907,
      0.3078597027317671,
      0.3343387111686839,
      0.33259521211737286,
      0.30956338581790827,
      0.3807463289154861,
      0.344202327560968,
      0.39182030785003463,
      0.2987153496660158,
      0.35519062644038013,
      0.3186780769087954,
      0.3187725865064624,
      0.29410622220062566,
      0.35017977113763016,
      0.34581446080819933,
      0.3098217376914924,
      0.3336058398206791,
      0.3033296072509831,
      0.3017235077248362,
      0.2965909072560465,
      0.3157148019706239,
      0.3460702417674893,
      0.2985219848749345,
      0.3123274867874598,
      0.3386281704206667,
      0.3675444173420261,
      0.3029360585204677,
      0.33130719437749084,
      0.32835245475976055,
      0.3222462188251718,
      0.3206799156896904,
      0.33037592117301007,
      0.3012636788925546,
      0.3514582145758375,
      0.3005096388501143,
      0.3130633300516063,
      0.3094743907317787,
      0.29380735797350277,
      0.3340172637499378,
      0.2909774126094615,
      0.31382124070858886,
      0.3222002934039888,
      0.3206238627456084
    ],
    "best_epoch": 2,
    "best_val_loss": 0.2129329265591627,
    "best_val_abs_mse": 0.1706482470035553,
    "test_loss": 5.302576816395709,
    "test_abs_mse": 50.20829391479492,
    "tracker": {
      "initial_train_loss": 0.3123804132003488,
      "train_threshold": 0.10412680440011628,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.2129329265591627,
      "patience_no_improve_epochs": 79,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_12_303fc9/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_12_303fc9/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_12_303fc9/config.yaml"
}