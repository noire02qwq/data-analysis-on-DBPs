epoch,train_loss,val_loss
1,0.970682,0.330146
2,1.032722,0.386364
3,0.839286,0.301611
4,0.455429,0.147112
5,0.225454,0.256215
6,0.177977,0.346486
7,0.173077,0.759381
8,0.157687,0.175678
9,0.161118,0.270606
10,0.195310,1.491900
11,0.417496,0.248005
12,0.226832,0.358303
13,0.170133,0.300640
14,0.165330,0.225593
15,0.161920,0.266413
16,0.154476,0.296575
17,0.150965,0.248557
18,0.144010,0.232832
19,0.145171,0.257779
20,0.139493,0.422172
21,0.140205,0.335799
22,0.180026,0.306281
23,0.153824,0.267078
24,0.137419,0.240996
25,0.146382,0.264330
26,0.148219,0.266175
27,0.147770,0.284042
28,0.238824,0.414305
29,0.183110,0.236322
30,0.157935,0.241943
31,0.146291,0.249170
32,0.138103,0.273706
33,0.134958,0.256215
34,0.133157,0.266657
35,0.149319,0.289639
36,0.140960,0.261608
37,0.133165,0.262614
38,0.129253,0.244028
39,0.131335,0.287996
40,0.128850,0.268426
41,0.123836,0.282315
42,0.145166,0.269543
43,0.538945,0.284272
44,0.652352,0.273147
45,1.234906,0.326131
46,1.311362,0.358738
47,1.005360,0.789992
48,0.975264,0.332732
49,0.991350,0.498290
50,0.850102,0.294811
51,0.733791,0.410387
52,0.659782,0.383517
53,0.487201,0.330967
54,0.766989,0.348743
55,0.385061,0.522111
56,0.283862,0.328935
57,0.228613,0.293952
58,0.225554,0.300740
59,0.196705,0.288741
60,0.193903,0.314346
61,0.178370,0.308887
62,0.197164,0.270336
63,0.209163,0.279776
64,0.180447,0.288809
65,0.188392,0.293549
66,0.170070,0.286702
67,0.180095,0.290299
68,0.189166,0.267951
69,0.186597,0.335911
70,0.159910,0.343658
71,0.163839,0.293256
72,0.184451,0.300842
73,0.223178,0.272013
74,0.177064,0.339531
75,0.171292,0.296715
76,0.169892,0.274700
77,0.170669,0.286378
78,0.182413,0.269391
79,0.174472,0.276299
80,0.172847,0.417310
