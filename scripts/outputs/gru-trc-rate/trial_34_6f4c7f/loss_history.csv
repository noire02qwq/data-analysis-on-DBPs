epoch,train_loss,val_loss
1,0.448852,0.321100
2,0.173577,0.299851
3,0.118225,0.253715
4,0.080515,0.177668
5,0.062637,0.180701
6,0.050367,0.187560
7,0.049328,0.240948
8,0.046313,0.208226
9,0.041420,0.220782
10,0.038624,0.235464
11,0.037542,0.241982
12,0.036405,0.250737
13,0.034700,0.253447
14,0.034606,0.252966
15,0.034179,0.328329
16,0.031955,0.279731
17,0.029942,0.281750
18,0.029462,0.281121
19,0.032733,0.275877
20,0.028423,0.300725
21,0.027355,0.281364
22,0.027565,0.288979
23,0.025999,0.291662
24,0.026016,0.280259
25,0.024350,0.290883
26,0.025571,0.302218
27,0.024579,0.298629
28,0.025373,0.277599
29,0.025152,0.278715
30,0.023415,0.279530
31,0.023469,0.281984
32,0.022160,0.289093
33,0.022362,0.275646
34,0.021600,0.279977
35,0.021396,0.291827
36,0.020796,0.273187
37,0.020072,0.279099
38,0.020695,0.294778
39,0.019486,0.279796
40,0.020291,0.279590
41,0.020522,0.279696
42,0.020452,0.276928
43,0.020170,0.271737
44,0.019838,0.269955
45,0.019968,0.279311
46,0.020267,0.275552
47,0.019160,0.277504
48,0.019041,0.269995
49,0.019499,0.280066
50,0.019472,0.280385
51,0.018356,0.289351
52,0.018765,0.284652
53,0.019130,0.297585
54,0.018932,0.290541
55,0.018981,0.288179
56,0.019422,0.288258
57,0.020317,0.287422
58,0.018823,0.294489
59,0.018092,0.281810
60,0.018350,0.283667
61,0.019296,0.286467
62,0.018674,0.290534
63,0.020521,0.288198
64,0.020457,0.302058
65,0.018895,0.295216
66,0.017806,0.286818
67,0.017687,0.295688
68,0.017707,0.301712
69,0.019312,0.311272
70,0.019232,0.296580
71,0.017649,0.300125
72,0.018116,0.313627
73,0.020207,0.298639
74,0.018273,0.296978
75,0.019090,0.300863
76,0.018617,0.307082
77,0.017440,0.306830
78,0.017046,0.309993
79,0.017686,0.298398
80,0.018658,0.294872
