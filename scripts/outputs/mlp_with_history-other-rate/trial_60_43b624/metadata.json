{
  "model_name": "mlp_with_history-other-rate/trial_60_43b624",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 30,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.11043814746522038,
    "mid_layer_count": 15,
    "mid_layer_size": 316
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 496,
    "learning_rate": 0.0006149114092175815,
    "weight_decay": 0.0074650938675471425,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7767,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 300,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.9791279043472303,
      0.5525976182588114,
      0.37264215318073374,
      0.3464165175837471,
      0.3393080213462215,
      0.3340130721078472,
      0.3316300552723505,
      0.3280229015678486,
      0.3226003128465913,
      0.31307833719947276,
      0.2976308203816368,
      0.2726221953148054,
      0.29559792523158784,
      0.26918659241323506,
      0.2509165499544027,
      0.24439272939107493,
      0.25090267301733865,
      0.24528433841229774,
      0.24020021511341316,
      0.24037250935133472,
      0.23925712469063995,
      0.23616844561856057,
      0.24247799027153344,
      0.2383271948863322,
      0.23767700203715628,
      0.23588979778732436,
      0.23451266546453214,
      0.23243833477814502,
      0.23077204671930712,
      0.24551163981385069,
      0.243571894991823,
      0.23992889256025812,
      0.235748622636008,
      0.23587387404617416,
      0.23189000189457834,
      0.23125487080416318,
      0.23188762350272407,
      0.23225066104734268,
      0.23007267515747123,
      0.23323165130642862,
      0.23648707177075115,
      0.23255846523649215,
      0.2303324143648209,
      0.23322874518286174,
      0.23256708000891763,
      0.23213674221295746,
      0.23197402791948074,
      0.23150930218604812,
      0.23107211650169937,
      0.230557152202603,
      0.23404064900368296,
      0.23008853681140906,
      0.23093737907984918,
      0.229755197733821,
      0.2325132170269292,
      0.2336994139030355,
      0.2285870151068846,
      0.2264023605358559,
      0.2273962640948042,
      0.22518670593846546,
      0.23452216088081151,
      0.23372303079312504,
      0.23148769456799678,
      0.22794319579918074,
      0.2271319899769905,
      0.2297812115083994,
      0.2287577369106588,
      0.24191716751936274,
      0.48874990345659103,
      0.4251903551831521,
      0.35133495723877356,
      0.33877857216493923,
      0.33039900401898054,
      0.30511422953167305,
      0.28037455883076157,
      0.2652025649572748,
      0.26046348561248495,
      0.25630286317143613,
      0.25289174596652786,
      0.2521890595802795
    ],
    "val_loss": [
      0.8027658636698466,
      0.5232061014917796,
      0.45653662810068646,
      0.4639883602450708,
      0.4676819268814818,
      0.4652567533675782,
      0.483359437788318,
      0.4850907415686967,
      0.49136014170275477,
      0.4993027471496673,
      0.4841586425632774,
      0.525266955427067,
      0.6400158565201445,
      0.5078134481064573,
      0.4885214307351027,
      0.48939189425485574,
      0.49077028771360476,
      0.48717736912344745,
      0.47186970917764537,
      0.43901947672495584,
      0.43264076438492644,
      0.44092023115672035,
      0.4619193776638922,
      0.44905287619836315,
      0.4722393830379326,
      0.4616528158416291,
      0.4494823417263831,
      0.45246276270129726,
      0.4760744885770147,
      0.5233891074528951,
      0.48688784887690745,
      0.4766043127653842,
      0.4497742585793227,
      0.47801734787261413,
      0.4817715392141285,
      0.4653646724666664,
      0.45574668981357963,
      0.48833015307694855,
      0.48833776712417604,
      0.48167167252409243,
      0.4853482938812165,
      0.4569857885737619,
      0.47045616261259526,
      0.4712342654873511,
      0.47062751147561444,
      0.501870682353745,
      0.5338703231897183,
      0.4516727413246018,
      0.4634813113126926,
      0.4638476259694128,
      0.4564861016359158,
      0.4426831458143132,
      0.4711008588710945,
      0.47569941132368443,
      0.4806251849243027,
      0.44494880159458,
      0.46494336156787985,
      0.49254278444244476,
      0.45596874959454564,
      0.46801936883412437,
      0.47228545414473483,
      0.48238809337159116,
      0.46194848643091624,
      0.47964063775753546,
      0.4730310307291454,
      0.4669281900999789,
      0.4720597302842283,
      0.47949938302982353,
      1.0142952809076824,
      0.6253867541958472,
      0.5539091922565849,
      0.5780510876706975,
      0.6450763770920074,
      0.6383923406372527,
      0.663631270460026,
      0.6047753902252563,
      0.5771141497674817,
      0.5848943873079951,
      0.6202064232911892,
      0.613656149510138
    ],
    "best_epoch": 21,
    "best_val_loss": 0.43264076438492644,
    "best_val_abs_mse": 0.5275877714157104,
    "test_loss": 0.5161961930220207,
    "test_abs_mse": 1.133581280708313,
    "tracker": {
      "initial_train_loss": 0.9791279043472303,
      "train_threshold": 0.32637596811574343,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.43264076438492644,
      "patience_no_improve_epochs": 59,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-rate/trial_60_43b624/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-rate/trial_60_43b624/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-rate/trial_60_43b624/config.yaml"
}