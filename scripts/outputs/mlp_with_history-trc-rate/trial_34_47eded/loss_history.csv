epoch,train_loss,val_loss
1,0.749116,0.222875
2,0.186839,0.226721
3,0.148282,0.456793
4,0.137596,0.227803
5,0.140203,0.235772
6,0.135400,0.274413
7,0.142549,0.284727
8,0.128953,0.262118
9,0.126523,0.301118
10,0.149982,0.240055
11,0.123318,0.346561
12,0.123619,0.327254
13,0.125624,0.284763
14,0.131470,0.264206
15,0.121391,0.287422
16,0.131420,0.317690
17,0.122801,0.273323
18,0.122172,0.394196
19,0.118429,0.344677
20,0.121665,0.264490
21,0.156616,0.274165
22,0.143894,0.257897
23,0.126717,0.423709
24,0.122131,0.274129
25,0.121973,0.272321
26,0.128213,0.334005
27,0.122008,0.337878
28,0.122523,0.268995
29,0.119325,0.287680
30,0.129250,0.282312
31,0.127643,0.261795
32,0.118768,0.268399
33,0.117446,0.278074
34,0.133646,0.272257
35,0.116942,0.288212
36,0.118843,0.275502
37,0.154343,0.254094
38,0.142770,0.270739
39,0.128251,0.339267
40,0.119714,0.279468
41,0.118354,0.286098
42,0.121234,0.266244
43,0.115322,0.261536
44,0.117609,0.262647
45,0.118108,0.279414
46,0.125181,0.268546
47,0.117943,0.279053
48,0.121432,0.276060
49,0.121008,0.459793
50,0.131885,0.360868
51,0.585476,0.287589
52,0.288574,0.326973
53,0.157027,0.362039
54,0.147457,0.265582
55,0.144498,0.276095
56,0.142556,0.284874
57,0.132540,0.298714
58,0.134465,0.331972
59,0.133667,0.275582
60,0.130417,0.420094
61,0.129337,0.295462
62,0.127430,0.325356
63,0.129476,0.276182
64,0.121313,0.266665
65,0.124751,0.369851
66,0.127059,0.349558
67,0.122514,0.364672
68,0.120571,0.289823
69,0.205905,0.278049
70,0.231962,0.316297
71,0.152275,0.300099
72,0.143140,0.371819
73,0.127314,0.363703
74,0.133039,0.388043
75,0.132114,0.320007
76,0.131523,0.292213
77,0.145679,0.327545
78,0.127376,0.285572
79,0.134701,0.292198
80,0.151762,0.278026
