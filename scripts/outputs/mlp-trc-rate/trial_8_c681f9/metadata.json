{
  "model_name": "mlp-trc-rate/trial_8_c681f9",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.12994679809640003,
    "mid_layer_count": 9,
    "mid_layer_size": 507
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 167,
    "learning_rate": 0.0011404490751383083,
    "weight_decay": 0.00597301573531356,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.23894599395751065,
      0.08295315407119068,
      0.07025222773408052,
      0.06274594797233378,
      0.06153160414198321,
      0.06077622646430537,
      0.058350931698711576,
      0.05619953360729657,
      0.055340610016873244,
      0.05382383299782192,
      0.05490459333015763,
      0.05147093609825977,
      0.051322154156966907,
      0.05326367915489005,
      0.050385822119595546,
      0.05234553325078376,
      0.05211142495201911,
      0.053357922627837645,
      0.05040354827460018,
      0.052286250712211435,
      0.05076761419271784,
      0.05368684712088279,
      0.05122470086236881,
      0.050127608515226636,
      0.048496962660181026,
      0.05141958555807787,
      0.05040113096067605,
      0.04968411293121608,
      0.0510246501423193,
      0.05021558184054355,
      0.04980657692604902,
      0.04971011518560476,
      0.05089313298150354,
      0.05012016906701659,
      0.051823287828609906,
      0.04897886438590554,
      0.04982042646445544,
      0.050908353967661885,
      0.049205035753710616,
      0.049270602544266,
      0.05094577848295819,
      0.050550868882849744,
      0.05002798464124389,
      0.04924909772161201,
      0.05202036540957217,
      0.05177512783041102,
      0.05252187402432487,
      0.04966202322890616,
      0.05072230175414671,
      0.04917333593277625,
      0.05183837499198102,
      0.04963650747420713,
      0.05225157517731465,
      0.04958560457572593,
      0.04965595308243999,
      0.04877706669871167,
      0.05027298166585265,
      0.050575564203524874,
      0.05114937650795745,
      0.0497622883789291,
      0.05236439954244812,
      0.05094879439885247,
      0.050259487733546895,
      0.04992306098225347,
      0.05298647495715847,
      0.050828877860836,
      0.04951369866208886,
      0.050625117955344225,
      0.0499175931554022,
      0.048830445983918766,
      0.05066211393514907,
      0.05019435086638775,
      0.04984589578061072,
      0.05036898380075665,
      0.050618740074382405,
      0.04994136323744269,
      0.05021367591398153,
      0.049834590385156204,
      0.04814946016830977,
      0.04752317960137523
    ],
    "val_loss": [
      0.415622828155756,
      0.21584696564823388,
      0.24899261835962533,
      0.3084521900862455,
      0.5030363783240318,
      0.3120845003053546,
      0.3327632324770093,
      0.49347458221018314,
      0.40371212977916004,
      0.5973734887316823,
      0.3956294870004058,
      0.3618163365870714,
      0.3524232475087047,
      0.4213603788986802,
      0.36879366748034953,
      0.3932852014899254,
      0.30054064430296423,
      0.34089298266917467,
      0.34174066688865423,
      0.309322327375412,
      0.3461205894127488,
      0.3519821513444185,
      0.33962821755558253,
      0.29818156324326994,
      0.2872015045955777,
      0.3693941667675972,
      0.28686817847192286,
      0.3105875991284847,
      0.37502566184848546,
      0.32935043778270484,
      0.3188338287174702,
      0.2794858137145638,
      0.35515918489545584,
      0.38335299380123616,
      0.3251628804951906,
      0.36877876687794925,
      0.3475139057263732,
      0.32188675571233033,
      0.32591497115790846,
      0.3450599186122417,
      0.313901923596859,
      0.2920527312904596,
      0.3135141158476472,
      0.3622679982334375,
      0.32847255989909174,
      0.28537904694676397,
      0.3194329969584942,
      0.27672147043049333,
      0.27990645822137594,
      0.3336784340441227,
      0.3015846015885472,
      0.3138682469725609,
      0.2797376148402691,
      0.33221417255699637,
      0.2700955767184496,
      0.30564140174537896,
      0.2833030875772238,
      0.3627439780160785,
      0.32188657354563477,
      0.2887388912960887,
      0.29023398254066707,
      0.29402411840856074,
      0.302320752479136,
      0.2612343430519104,
      0.3093216521665454,
      0.2678651664406061,
      0.2797450290992856,
      0.27496675923466685,
      0.25966097600758076,
      0.29768127035349606,
      0.26872939616441727,
      0.2735552739351988,
      0.2902757529169321,
      0.26036720536649227,
      0.2649697791785002,
      0.2672624642029405,
      0.2645377773791552,
      0.2788686925545335,
      0.3040995949879289,
      0.2942781951278448
    ],
    "best_epoch": 3,
    "best_val_loss": 0.24899261835962533,
    "best_val_abs_mse": 0.18208959698677063,
    "test_loss": 5.223129308537433,
    "test_abs_mse": 48.8397331237793,
    "tracker": {
      "initial_train_loss": 0.23894599395751065,
      "train_threshold": 0.07964866465250355,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.24899261835962533,
      "patience_no_improve_epochs": 78,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_8_c681f9/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_8_c681f9/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_8_c681f9/config.yaml"
}