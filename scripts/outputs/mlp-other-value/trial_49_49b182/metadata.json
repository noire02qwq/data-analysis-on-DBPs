{
  "model_name": "mlp-other-value/trial_49_49b182",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.23492949820936398,
    "mid_layer_count": 2,
    "mid_layer_size": 493
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 180,
    "learning_rate": 0.0018566079547223295,
    "weight_decay": 0.00010200938559608774,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112
    ],
    "train_loss": [
      0.3471259502889928,
      0.2271517394612299,
      0.20566820034832756,
      0.18771323771920798,
      0.1741242489871641,
      0.1692496870208117,
      0.15911690863265082,
      0.1523596414500105,
      0.1481993103284234,
      0.1448584613454776,
      0.1409189457340446,
      0.13581055479593435,
      0.13487634638476334,
      0.13013587382097866,
      0.1295557184065532,
      0.12434237326503472,
      0.12577362044720602,
      0.11835784155812369,
      0.1172765431693421,
      0.11696905834268705,
      0.114765378937561,
      0.11413380141255793,
      0.10986210441378338,
      0.11003585189596209,
      0.10573388884592326,
      0.10528533054031183,
      0.10569342684904816,
      0.10565391342691301,
      0.1030478670489733,
      0.10059808113976831,
      0.10113184919734684,
      0.09985610178689458,
      0.09736002938465438,
      0.09686253348670291,
      0.09644360251996137,
      0.09624855588450684,
      0.09639934094870256,
      0.09490961101710826,
      0.09650289485581781,
      0.09237230082103202,
      0.09187628807793402,
      0.09167376349848806,
      0.089900157149172,
      0.08768741951241378,
      0.08864970932623373,
      0.0895825259505999,
      0.08839153525552852,
      0.08873096999906772,
      0.08821673902289692,
      0.0886006616763178,
      0.08909871739231666,
      0.08583604365113211,
      0.08531580266737217,
      0.08566425440249044,
      0.08572832678467142,
      0.08437214826561966,
      0.08499570202757115,
      0.08589906598311807,
      0.08355052607863178,
      0.0832036836880363,
      0.08252173028370244,
      0.0814985710460446,
      0.08199460004356471,
      0.08132657675925985,
      0.0819818816998789,
      0.08214707732995759,
      0.08104637468194521,
      0.0807620974619796,
      0.08028824098327944,
      0.07986760400178311,
      0.08028571794297892,
      0.07959532333665044,
      0.0804755534764557,
      0.07821022206320097,
      0.07824214295187383,
      0.07739344062240629,
      0.07619345561434453,
      0.07741284232802609,
      0.07828062724966217,
      0.07769661315507984,
      0.07708194103376752,
      0.07876878122814868,
      0.07725933242327375,
      0.0759960705191738,
      0.07672337819943983,
      0.07514279910490843,
      0.0761910233744112,
      0.0759381551702644,
      0.0754342142161863,
      0.07745448121463659,
      0.07528133989297897,
      0.07524515320668776,
      0.07560952839605499,
      0.07473828246565646,
      0.07578704493161408,
      0.07512717121393024,
      0.07360078040042127,
      0.07494748890277604,
      0.07438437197798946,
      0.07342528879810689,
      0.07301435177106928,
      0.07267112558226882,
      0.07283441099854786,
      0.0728196652521073,
      0.07550843933519796,
      0.07352502245729309,
      0.07336016567380933,
      0.07221501906822436,
      0.0733902882660365,
      0.07257177064309003,
      0.07201905873890349,
      0.07308868203730752
    ],
    "val_loss": [
      0.40174518266837755,
      0.49716582439259854,
      0.5307208781470796,
      0.5749828914503852,
      0.55153658004578,
      0.6459293431507613,
      0.5017817661969247,
      0.4725288108080447,
      0.5729222182563679,
      0.5020886994229106,
      0.5946835650655324,
      0.5032869775495129,
      0.4737791032669787,
      0.4673120238466891,
      0.4768582561058912,
      0.48501942275526994,
      0.4655182814883615,
      0.5821242574267759,
      0.5391853461543957,
      0.4345344471895766,
      0.44559791139856786,
      0.43934433010523904,
      0.4594043627113639,
      0.4973911924098066,
      0.4738977374787816,
      0.49395057719624685,
      0.5181827388123837,
      0.5368179157822431,
      0.49377854641326174,
      0.427414428866552,
      0.4819383804134266,
      0.5017859202302145,
      0.5079640130439919,
      0.498997987387423,
      0.5052202947125464,
      0.4661482113028715,
      0.5319985293164224,
      0.45763744770766734,
      0.4514641222839584,
      0.5041582092732012,
      0.4532421194686147,
      0.49317739002718897,
      0.49858166152488687,
      0.48330533879245824,
      0.43121212667333864,
      0.5019031290165679,
      0.45739295561156584,
      0.4547166585208413,
      0.4508156015309031,
      0.4822349004045932,
      0.43520089921480165,
      0.44284942023411483,
      0.43922723535292163,
      0.4385579243570031,
      0.47985187859949235,
      0.4897045596630987,
      0.4774259145031432,
      0.42568035307758584,
      0.4665482974873332,
      0.47609334764723293,
      0.46034171659789397,
      0.4120314719077356,
      0.45000007712912415,
      0.5995332818188354,
      0.48620749983245026,
      0.4905966218717084,
      0.48508062842720284,
      0.4657179399164851,
      0.4666636547821011,
      0.44891457563031933,
      0.5109690218093152,
      0.4915141815732339,
      0.522717328039472,
      0.46603615465992226,
      0.49919466870630574,
      0.4760921808952343,
      0.4595146578942944,
      0.46706566616089756,
      0.4541570322956154,
      0.47461498640254585,
      0.49970495825756095,
      0.45133486515033744,
      0.4878296409538406,
      0.486505859715496,
      0.4853183370150492,
      0.46994011737629326,
      0.48739695968385227,
      0.4874324619234679,
      0.4790471413892186,
      0.4471103797951144,
      0.6322810262620092,
      0.6181442451155829,
      0.5536093004270942,
      0.5029407105224575,
      0.5225275912863052,
      0.5487681247160107,
      0.5423786711550045,
      0.4692870026041648,
      0.5693946221988359,
      0.621344783259723,
      0.5873972690569427,
      0.5456406605279375,
      0.49040691099480954,
      0.5057397020791106,
      0.5061821975929295,
      0.5168417472682313,
      0.46766006473652616,
      0.5812994931450861,
      0.5120995727306354,
      0.5244201494012765,
      0.4835492724073147,
      0.5371681198388517
    ],
    "best_epoch": 62,
    "best_val_loss": 0.4120314719077356,
    "test_loss": 0.48559751361608505,
    "tracker": {
      "initial_train_loss": 0.3471259502889928,
      "train_threshold": 0.11570865009633093,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4120314719077356,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_49_49b182/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_49_49b182/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_49_49b182/config.yaml"
}