{
  "model_name": "mlp_with_history-other-value/trial_28_b4594b",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 102,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.27019276238801054,
    "mid_layer_count": 3,
    "mid_layer_size": 271
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 346,
    "learning_rate": 0.0011990337470438822,
    "weight_decay": 0.0017500359352892547,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7695,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 1020,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.8849891697144338,
      0.42411397160687486,
      0.3749078940307265,
      0.3658701101125565,
      0.35376995194260374,
      0.4474169770489272,
      0.45887363744758025,
      0.359005949983665,
      0.340792409156808,
      0.3186855240213631,
      0.29129699992041375,
      0.27994826595220884,
      0.2777611800724225,
      0.26925489046768836,
      0.2631636497376413,
      0.25581622746100746,
      0.25608718782915085,
      0.2560356182022634,
      0.25818146844433837,
      0.2542762258286752,
      0.24888238766659693,
      0.24841931089516814,
      0.24699311801719542,
      0.24954476828231217,
      0.24160034448934734,
      0.2405256432612427,
      0.24070465981456812,
      0.23974950928011057,
      0.24317732416553262,
      0.23849320285036782,
      0.22947189250574862,
      0.22694553384500482,
      0.25760463389814325,
      0.7027179871851008,
      0.5467517065064639,
      0.5064625400819897,
      0.4175774301198336,
      0.3238328401805365,
      0.2926309263419609,
      0.2782323495570214,
      0.26448734801570034,
      0.2687570786615561,
      0.2558904789731904,
      0.25156825539777616,
      0.24782555563408032,
      0.24631509916049618,
      0.2422822758681283,
      0.24224127520981975,
      0.3265928459136497,
      0.3008812064451394,
      0.2661416204274669,
      0.2519238725933957,
      0.2424561097046398,
      0.23900125980609574,
      0.23509465513715813,
      0.22907440427296188,
      0.22597984547077488,
      0.2245571414358512,
      0.22661048579982848,
      0.21179438402236012,
      0.21009939573584166,
      0.19674118146677927,
      0.19803771872153292,
      0.19928411132062387,
      0.1908592806186205,
      0.18236610663061098,
      0.1911004745646527,
      0.18258509527095498,
      0.18271372152893012,
      0.18769284217600857,
      0.18092683538397542,
      0.17735355079096582,
      0.18220738446154788,
      0.17801219665283813,
      0.1822779002071124,
      0.17310514459949256,
      0.17267845735834975,
      0.1767078236219866,
      0.17465672201348095,
      0.16581415160473792
    ],
    "val_loss": [
      0.6441700989614704,
      0.4767587704394392,
      0.5238917550819363,
      0.500031062942779,
      0.5596678205414447,
      1.4307090655772272,
      0.5481479575712523,
      0.5007981904609474,
      0.5328668854283002,
      0.5284557905828882,
      0.6014980102281371,
      0.48225163865589094,
      0.6679885137491597,
      0.5296147592231899,
      0.4755629428667936,
      0.5259085479699923,
      0.45418170035599237,
      0.4906181993331024,
      0.49201104043129673,
      0.42250103916593656,
      0.40902113478162333,
      0.41043243944466473,
      0.5358965822679554,
      0.4419374042820788,
      0.4957073707914281,
      0.3944905838745083,
      0.436510771468371,
      0.49303793125523776,
      0.4305338329986898,
      0.4255764197625086,
      0.44939790756224157,
      0.4490284436031016,
      1.5079605792453903,
      0.5719585341429282,
      1.9514347693163479,
      0.9609923621494613,
      0.6511821878170538,
      0.5068111643462838,
      0.5462016724005431,
      0.4806078342798941,
      0.46676704001105473,
      0.44873778409586695,
      0.43390838618050076,
      0.5747013269650365,
      0.4969471875868158,
      0.4872515693306923,
      0.4771106941792779,
      0.5223431966351177,
      0.7146974208826077,
      0.5891774043173134,
      0.47951206223158066,
      0.4290368128233327,
      0.450917190237495,
      0.4333161718652634,
      0.46457917270903104,
      0.4269139349014459,
      0.4385925783279413,
      0.5150066410442312,
      0.4847850013725058,
      0.4510989158096428,
      0.45554703290234067,
      0.45320990298857944,
      0.4867331038781269,
      0.4704060928907223,
      0.476548712812141,
      0.5815472360053462,
      0.483839493838256,
      0.49437390982569335,
      0.49324317869401263,
      0.4693239082744022,
      0.47668483244801707,
      0.46952053478021105,
      0.5096184518701302,
      0.5324114471317052,
      0.4789642570439927,
      0.46884369315679914,
      0.4751174651220173,
      0.5125955462634206,
      0.46049556585842977,
      0.5268661611005218
    ],
    "best_epoch": 26,
    "best_val_loss": 0.3944905838745083,
    "test_loss": 0.5334211308776476,
    "tracker": {
      "initial_train_loss": 0.8849891697144338,
      "train_threshold": 0.29499638990481125,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3944905838745083,
      "patience_no_improve_epochs": 54,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-value/trial_28_b4594b/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-value/trial_28_b4594b/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-value/trial_28_b4594b/config.yaml"
}