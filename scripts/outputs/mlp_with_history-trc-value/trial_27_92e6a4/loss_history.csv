epoch,train_loss,val_loss
1,0.777742,0.311429
2,0.406463,0.232397
3,0.209587,0.236392
4,0.303470,0.217677
5,0.206980,0.531438
6,0.175250,0.212557
7,0.169208,0.231422
8,0.161023,0.868456
9,0.260570,0.230808
10,0.220433,0.264512
11,0.181820,0.249758
12,0.188061,0.274036
13,0.168294,0.218980
14,0.156426,0.237998
15,0.144955,0.224194
16,0.140256,0.237327
17,0.142836,0.370807
18,0.164143,0.250552
19,0.138801,0.245961
20,0.134332,0.289503
21,0.132999,0.293309
22,0.163661,0.286561
23,0.171404,0.274102
24,0.146452,3.082444
25,0.240043,0.261954
26,0.155524,0.277806
27,0.154446,0.295835
28,0.143106,0.307821
29,0.147577,0.298421
30,0.117106,0.322575
31,0.138335,0.303373
32,0.116288,0.272847
33,0.111032,0.482058
34,0.133308,0.264623
35,0.116957,0.299706
36,0.106444,0.270493
37,0.162945,0.295129
38,0.116300,0.255923
39,0.114043,0.291702
40,0.163090,0.261239
41,0.136075,0.268921
42,0.137855,0.333660
43,0.149142,0.292231
44,0.147585,0.295238
45,0.113887,0.316033
46,0.103866,0.295097
47,0.143273,0.295613
48,0.116952,0.408626
49,0.125048,0.556785
50,0.127878,1.107683
51,0.190422,2.321934
52,0.233755,0.288714
53,0.138642,0.291914
54,0.121909,0.292723
55,0.109171,0.271896
56,0.128412,0.328965
57,0.117982,0.272897
58,0.109979,0.329576
59,0.106499,0.335170
60,0.130357,0.307078
61,0.138542,0.297891
62,0.119588,0.601675
63,0.108252,0.302117
64,0.088372,0.319644
65,0.088850,0.305559
66,0.085144,0.388563
67,0.087460,0.421236
68,0.086144,0.297630
69,0.084886,0.439088
70,0.079563,0.399387
71,0.092857,0.565632
72,0.081588,0.291839
73,0.277009,0.315002
74,0.193182,0.302732
75,0.133950,0.290472
76,0.124941,0.298356
77,0.138016,0.292556
78,0.114405,0.299116
79,0.153460,0.263400
80,0.110773,0.274491
