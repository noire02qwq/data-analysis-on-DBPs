{
  "model_name": "mlp_with_history-other-value/trial_18_7b082c",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 126,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.18780694453680358,
    "mid_layer_count": 12,
    "mid_layer_size": 710
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 507,
    "learning_rate": 0.0007118096956870068,
    "weight_decay": 0.0038641232204603814,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7671,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 1260,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108
    ],
    "train_loss": [
      0.8509010194240252,
      0.44030237488090224,
      0.37098267381900824,
      0.3574745866718076,
      0.35469774290552164,
      0.34684537692045764,
      0.3450183705352087,
      0.3392345663225646,
      0.3296586021949968,
      0.3124530774380576,
      0.2857260001815293,
      0.2735490850116482,
      0.27565176699326566,
      0.2585750354725633,
      0.25433848001642717,
      0.25600158864625694,
      0.2492120520626608,
      0.264699684906901,
      0.24926347553287115,
      0.24647706270357758,
      0.24715235952898354,
      0.24493573018592646,
      0.2504641560893717,
      0.25880372298733534,
      0.2424947686863449,
      0.23990799849113542,
      0.2510471252675722,
      0.2497438049183537,
      0.23966183023010795,
      0.2385283370804964,
      0.23749279349424618,
      0.23823120212783375,
      0.2364174697634108,
      0.23759722146127296,
      0.2515607895996126,
      0.24330003714020662,
      0.23172996481927896,
      0.22921630997745424,
      0.22970867999069944,
      0.23414162359039067,
      0.24089332982623862,
      0.6265387879739202,
      0.8665386349440647,
      0.6188143472863586,
      0.5544859447141713,
      0.40920821807791957,
      0.34677664964144056,
      0.30315258167756926,
      0.3286091526901065,
      0.27539340492613296,
      0.26154538746056355,
      0.2557055883730208,
      0.25239285814445095,
      0.25611068382946645,
      0.24979579296016954,
      0.2530372631843546,
      0.2430798295633281,
      0.2421075412548283,
      0.24270741667162873,
      0.24465438580205304,
      0.23795987630104898,
      0.2397224460384274,
      0.2371391807105516,
      0.24807442932749896,
      0.23765758468412915,
      0.2357613190012049,
      0.23192101976323232,
      0.23241628093974964,
      0.23079609734544915,
      0.23129591038090017,
      0.22957541849821117,
      0.22879562061607814,
      0.2284484694584021,
      0.22697083624047043,
      0.22290781819242306,
      0.22124021279774564,
      0.22210410874268482,
      0.2203278771638404,
      0.22045576082900206,
      0.27705070888059047,
      0.2512255324124357,
      0.2347964947117368,
      0.22516299732317904,
      0.21956854238727386,
      0.2171287140461165,
      0.21481755485420914,
      0.21770400259939543,
      0.21053874977501194,
      0.21974602279879407,
      0.21217249204485875,
      0.21065748244302554,
      0.21279604869938754,
      0.21311176358767678,
      0.21648378016359413,
      0.20798709475765667,
      0.2087751767005499,
      0.2048429219772632,
      0.2097516215588835,
      0.2063668808598606,
      0.20358142061512313,
      0.20735565426413044,
      0.20480638887554023,
      0.20204548931093855,
      0.20482302140947148,
      0.22288527130194832,
      0.6684715927090084,
      0.7105868349305624,
      0.6215403434420919
    ],
    "val_loss": [
      0.7284590597638113,
      0.4696826843087545,
      0.5006079985353047,
      0.48591852909076716,
      0.5342540485594801,
      0.5483172562307941,
      0.5409376685133951,
      0.49680416483186673,
      0.5012076658760002,
      0.5150031092638028,
      0.5844668549825688,
      0.5651080707946937,
      0.5586524778274362,
      0.483490234470653,
      0.4695230329375781,
      0.4731134906232714,
      0.46178755491615053,
      0.5071642791261216,
      0.4848965099561,
      0.484754422155326,
      0.48527065851909673,
      0.4722013054939801,
      0.49624746929921076,
      0.5435722642137619,
      0.44602130579198906,
      0.5074358581961272,
      0.46854026612942806,
      0.46521601500268467,
      0.6049959290259612,
      0.4262095508818141,
      0.5154396005867127,
      0.43370205716280164,
      0.42842974826068936,
      0.4645858148168661,
      0.4702504337413939,
      0.4263849218448479,
      0.4188428069749278,
      0.5214456299464859,
      0.40336680637148326,
      0.4144623185256998,
      1.0277144778988319,
      0.8013314764924392,
      0.4906254573318059,
      0.5003345003028116,
      0.7451626846711793,
      0.7041137092484685,
      0.5051639359868215,
      0.5330253102554533,
      0.6072251413709032,
      0.45528649846147634,
      0.46207655578137874,
      0.45421146703605164,
      0.41558861766835886,
      0.4218695854667775,
      0.424104307150234,
      0.4570993222920838,
      0.4428438027640303,
      0.4023930325390336,
      0.5313512754565227,
      0.4080985549324287,
      0.43622309374595114,
      0.44854364388895607,
      0.4270095293928763,
      0.4444350489866948,
      0.42088363469539286,
      0.45933451729263375,
      0.4287088926056188,
      0.45952128822396615,
      0.4374643676206023,
      0.4457164481728377,
      0.4504496815051147,
      0.4473781239665197,
      0.448159412575696,
      0.45778040404091336,
      0.46466179499904553,
      0.4738447508947578,
      0.4629347583937074,
      0.48046402435102864,
      0.4819665756678867,
      0.5960887394087043,
      0.5150995881525342,
      0.48180243550928054,
      0.4623217860203303,
      0.5027949064970016,
      0.468102351776854,
      0.4875572710783182,
      0.48575530601832684,
      0.4837903270553686,
      0.5040966854480926,
      0.5041309719046433,
      0.5200220068057854,
      0.5140816978708712,
      0.5707160571199691,
      0.530994495901162,
      0.48690250226837434,
      0.535480042426529,
      0.5436831810472611,
      0.48202326661812334,
      0.5189477362943267,
      0.5552974968970179,
      0.48980343696064577,
      0.47195931527607454,
      0.5063341967092303,
      0.5054449009770405,
      0.5643565620312434,
      1.0417172613793504,
      0.5269517431002178,
      0.592801237900457
    ],
    "best_epoch": 58,
    "best_val_loss": 0.4023930325390336,
    "test_loss": 0.5441497526439041,
    "tracker": {
      "initial_train_loss": 0.8509010194240252,
      "train_threshold": 0.28363367314134175,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4023930325390336,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-value/trial_18_7b082c/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-value/trial_18_7b082c/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-value/trial_18_7b082c/config.yaml"
}