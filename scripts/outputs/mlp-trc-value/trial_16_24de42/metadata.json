{
  "model_name": "mlp-trc-value/trial_16_24de42",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.39890980731015785,
    "mid_layer_count": 12,
    "mid_layer_size": 444
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 242,
    "learning_rate": 0.0014020754478846248,
    "weight_decay": 0.00030121482101967207,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.33484171051866524,
      0.13512690116260956,
      0.1076808403288633,
      0.09763807216979345,
      0.09532572219330815,
      0.09127902425921165,
      0.08244964683389223,
      0.07838263825201389,
      0.07698719249058682,
      0.07487578304334443,
      0.07321278271043129,
      0.07144556714440689,
      0.06815661368972831,
      0.07073310501644127,
      0.06556637323590013,
      0.06502235301312971,
      0.06445139744870934,
      0.0632495650598228,
      0.06201112907515574,
      0.05999507022789345,
      0.0616450707789887,
      0.06117926565036674,
      0.061303014416398606,
      0.061226957665422806,
      0.05846848876992974,
      0.05783852841275022,
      0.053988995001851565,
      0.05465366397953266,
      0.05556877901258684,
      0.0556728454548512,
      0.05496971353815879,
      0.05465572513162081,
      0.05514357738644114,
      0.054321096365217245,
      0.05311805470772527,
      0.05170714568103993,
      0.05274614271898494,
      0.05309189764019188,
      0.05133850194357064,
      0.05068918546635931,
      0.05230405434427077,
      0.051756644472403364,
      0.05189206325217294,
      0.04952313364309002,
      0.05067899446167996,
      0.05223501710103621,
      0.052781367370559655,
      0.0518513789277174,
      0.04996090293075868,
      0.04872639200675481,
      0.04762481735314908,
      0.0514857478262049,
      0.050581963982274436,
      0.04885221025564843,
      0.05025133655132729,
      0.04755079875360427,
      0.048898380373023055,
      0.04725778186020024,
      0.05135925982879516,
      0.04712504991882119,
      0.047753934200380994,
      0.04740050997682539,
      0.048696176938831104,
      0.048568544819522906,
      0.046149305508052955,
      0.04744213054758454,
      0.047373118203012925,
      0.04845203815067255,
      0.04781525406323224,
      0.04778116333918152,
      0.046199804350634366,
      0.047996733325216756,
      0.04877224716125175,
      0.04699358415946158,
      0.0486870157896035,
      0.04851619771974646,
      0.046719253394827284,
      0.049957108727368166,
      0.047963752438543145,
      0.04719573658355356
    ],
    "val_loss": [
      0.26438758181865346,
      0.20971283549944797,
      0.21113368109047057,
      0.22574401481333606,
      0.2201427251970518,
      0.23657907323164498,
      0.23382071298351903,
      0.24458854301960883,
      0.24067949199167912,
      0.26124629208784617,
      0.26735884413167743,
      0.25456130711618297,
      0.26027232763206887,
      0.284027109852808,
      0.28175960592702476,
      0.2791383546024204,
      0.28504110742025746,
      0.29016158754775623,
      0.2860249289428581,
      0.3149583639677413,
      0.29688759106629625,
      0.3145385523934564,
      0.2920887746541443,
      0.31329728747734764,
      0.30415408509354036,
      0.30428186732673357,
      0.3052483275599644,
      0.2924447641646612,
      0.3002305727095126,
      0.29846646826335055,
      0.2975061938791218,
      0.300849585451498,
      0.3046854423035583,
      0.3127437935840941,
      0.30420316209470083,
      0.3075723146562448,
      0.3050635577073533,
      0.302689933011721,
      0.30274970449596467,
      0.30567870273249237,
      0.304061147182466,
      0.3033453926265597,
      0.305866817083812,
      0.30717216190731456,
      0.3099728333423595,
      0.3034147087685362,
      0.2980541780903311,
      0.30487703777135844,
      0.3070230431653961,
      0.3047755482400249,
      0.3086839318431602,
      0.30621284847398716,
      0.2987171356147992,
      0.3043140466810165,
      0.30389749479151057,
      0.3063427490053955,
      0.3013616064373783,
      0.3039502575770467,
      0.30563851939123904,
      0.30631865384559076,
      0.3056237800727169,
      0.3088877932464113,
      0.3041887587639029,
      0.30261100772656724,
      0.3096198670008404,
      0.3074570124310826,
      0.30701829627334715,
      0.29949859730274736,
      0.304419512312837,
      0.30509453667048925,
      0.3063843578947875,
      0.3105532839425845,
      0.3107662259060109,
      0.3036808741083759,
      0.3026592705019577,
      0.3100359140153595,
      0.30465832286386074,
      0.30658732150753815,
      0.30906917863932554,
      0.30305830197196876
    ],
    "best_epoch": 3,
    "best_val_loss": 0.21113368109047057,
    "test_loss": 4.686511775380687,
    "tracker": {
      "initial_train_loss": 0.33484171051866524,
      "train_threshold": 0.11161390350622175,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.21113368109047057,
      "patience_no_improve_epochs": 78,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_16_24de42/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_16_24de42/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_16_24de42/config.yaml"
}