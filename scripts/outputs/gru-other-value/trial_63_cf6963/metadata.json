{
  "model_name": "gru-other-value/trial_63_cf6963",
  "model_type": "GRU",
  "model_format": "torch",
  "model_params": {
    "history_length": 133,
    "units": 320,
    "num_layers": 2,
    "dropout": 0.2603003842461335
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 178,
    "learning_rate": 0.0019845570897021173,
    "weight_decay": 0.001857257569693661,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7664,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 133,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86
    ],
    "train_loss": [
      0.32795206229892676,
      0.23471116084830995,
      0.21878162662193396,
      0.20164728226890644,
      0.17538256418846532,
      0.17984070554997827,
      0.15888958510462514,
      0.14343889150574088,
      0.14299902328463088,
      0.12843703361916392,
      0.14223322990138496,
      0.14817786764835703,
      0.1197844952780419,
      0.1120824698039908,
      0.11368316693507555,
      0.12214999896375023,
      0.10312359669247724,
      0.1052313826643786,
      0.10880134292802382,
      0.09509533222585854,
      0.09107943242882419,
      0.0950384934613625,
      0.12134085303961857,
      0.09975655044629268,
      0.08866144593470654,
      0.09149289783868075,
      0.09280264491821971,
      0.0866128085822738,
      0.08641211373540952,
      0.07687096549528563,
      0.07996218490155729,
      0.08136874024167128,
      0.08183654721258578,
      0.07610400144247988,
      0.07655628233766941,
      0.07699322275377982,
      0.0802761633337975,
      0.07144252324402954,
      0.07308625835062069,
      0.1062475134636079,
      0.0806840648534387,
      0.07252895627131915,
      0.0670160277773838,
      0.0688340959804121,
      0.08476536579445658,
      0.06511772969943745,
      0.06555665918822266,
      0.06717325335889589,
      0.06558643430879725,
      0.06557980954300978,
      0.06642418643965198,
      0.07951249624262242,
      0.06385382622896474,
      0.06111084654371182,
      0.06575287957549375,
      0.06936489270090092,
      0.061764027723082045,
      0.06536107948380435,
      0.05997658654802434,
      0.06577440257532238,
      0.06779665439263266,
      0.05891867540193438,
      0.06989222701876142,
      0.0795033839900661,
      0.05829615031499299,
      0.059567138466144094,
      0.05335657179281738,
      0.06375548973706763,
      0.058187391632285146,
      0.05995139577824599,
      0.06278327831294629,
      0.06735737288724593,
      0.06994676621658008,
      0.05713636576857161,
      0.051348083667138236,
      0.05407798146568472,
      0.055275615927858554,
      0.05575040183934171,
      0.05226133012704722,
      0.05525240495252678,
      0.05188549413892104,
      0.06679073813816606,
      0.05712464983946409,
      0.05537826428530127,
      0.05271202643714954,
      0.05325047263490631
    ],
    "val_loss": [
      0.58922685705973,
      0.5069579903058663,
      0.4196177867090631,
      0.5316802914538783,
      0.3841952911215628,
      0.44923518530266016,
      0.37462764289564715,
      0.4550431350034154,
      0.5140570945636241,
      0.44285344617095534,
      0.578877879291059,
      0.37844140484126026,
      0.3801378459452155,
      0.36332595353711866,
      0.38384158575606203,
      0.4257622778951051,
      0.3521266842941324,
      0.33216079276300475,
      0.3816398172767576,
      0.42409901110355014,
      0.3409968369199844,
      0.36490730341680033,
      0.34037987625527527,
      0.34804983802898204,
      0.33054445087017414,
      0.3318103774043614,
      0.3885320615804124,
      0.3655503890828458,
      0.31894110284165705,
      0.37902665391653595,
      0.4120362108071407,
      0.3640795869920068,
      0.3728896240185121,
      0.34494404537592105,
      0.319382721738901,
      0.30720153148481233,
      0.36646936892749304,
      0.3590798432598571,
      0.38018191471963586,
      0.3922073660139552,
      0.40944542308410486,
      0.3622464157328634,
      0.3839472095677239,
      0.39093057250012897,
      0.3379960853361084,
      0.40090092989855897,
      0.43116243911717467,
      0.3540308560172241,
      0.3544443853422553,
      0.36483677801436293,
      0.3979252452621917,
      0.4470827543360744,
      0.4470272177172278,
      0.4571014671357806,
      0.42330827751380956,
      0.4389778921614864,
      0.39963376334684336,
      0.4067099495919165,
      0.47380281424451015,
      0.40904572787220606,
      0.38113294321441366,
      0.46801049850301113,
      0.33557147946721777,
      0.47366529726339673,
      0.4471017590718355,
      0.39122571174256104,
      0.44938303578399613,
      0.3955573241867705,
      0.41672686552573107,
      0.41832741761278963,
      0.4257014403086223,
      0.48582537720303337,
      0.4251889094174979,
      0.4672088876991215,
      0.4263256464443521,
      0.42137078861455,
      0.4676677962530873,
      0.42692122626268936,
      0.4789781681434837,
      0.4518298268050491,
      0.49889066560182743,
      0.46372815920207316,
      0.49228971475612615,
      0.49515958481027694,
      0.47982123569100205,
      0.48870070997826354
    ],
    "best_epoch": 36,
    "best_val_loss": 0.30720153148481233,
    "test_loss": 0.3267857464894866,
    "tracker": {
      "initial_train_loss": 0.32795206229892676,
      "train_threshold": 0.10931735409964226,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.30720153148481233,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/gru-other-value/trial_63_cf6963/best_model.pt",
    "last": "scripts/outputs/gru-other-value/trial_63_cf6963/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/gru-other-value/trial_63_cf6963/config.yaml"
}