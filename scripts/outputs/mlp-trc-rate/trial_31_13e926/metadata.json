{
  "model_name": "mlp-trc-rate/trial_31_13e926",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.4968252545216673,
    "mid_layer_count": 7,
    "mid_layer_size": 388
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 336,
    "learning_rate": 0.0005615409175750561,
    "weight_decay": 0.00019593509570602237,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.6063281275205823,
      0.24216403691752744,
      0.18949148969475338,
      0.16600871047892896,
      0.14981176927800421,
      0.14143534386200804,
      0.13339968345268008,
      0.12520748456742226,
      0.12330868170850395,
      0.11307794360272881,
      0.10848855691698651,
      0.1079991896521623,
      0.10247518886368112,
      0.10213928659369605,
      0.10090459536105441,
      0.09942523835025242,
      0.09913914242788974,
      0.09933690547469091,
      0.09469676734148508,
      0.09382571878266249,
      0.09219261496808052,
      0.0905470216944011,
      0.08966127310183307,
      0.0869211496038887,
      0.08706509081858008,
      0.08289894758661079,
      0.08703951656115,
      0.08395601001273308,
      0.08211482685152967,
      0.08435353191771099,
      0.08283833086322429,
      0.08183989247996236,
      0.0805812329818433,
      0.081517080547505,
      0.07897586138845407,
      0.07700887049862273,
      0.0765726754433256,
      0.07892457323923914,
      0.07773752155412215,
      0.07678305242246942,
      0.07648150160671688,
      0.07477704712164408,
      0.0723725311523098,
      0.07314567370727283,
      0.07367279669943683,
      0.07391603981427133,
      0.0702454001112832,
      0.07253350423751212,
      0.07046114285216079,
      0.07133553825651394,
      0.07193006990642778,
      0.06942004574154083,
      0.0679966076107561,
      0.07251122914227906,
      0.06730541789673915,
      0.06829712919130149,
      0.06736068732237559,
      0.06744960723220232,
      0.0640632830265854,
      0.06758075161980873,
      0.06721240950087941,
      0.06629752590984733,
      0.06549619844688888,
      0.06524755205173502,
      0.06710485934737158,
      0.06802137052901223,
      0.06528416589445307,
      0.06462670153550701,
      0.0657706971907689,
      0.06482208003908808,
      0.06385967672910979,
      0.06408779546733145,
      0.06342301828133992,
      0.06275110179343366,
      0.06344346005016563,
      0.06186374314721882,
      0.06376215954119575,
      0.06238188516977446,
      0.06274429027883746,
      0.0636896905572889
    ],
    "val_loss": [
      0.4559466873814246,
      0.2685026183099804,
      0.258014547503637,
      0.24491232240985253,
      0.24162245435629062,
      0.22899261998559187,
      0.22280181018178336,
      0.21898618656361174,
      0.21561346983838225,
      0.21223347404759801,
      0.21480336075057527,
      0.22093469561217075,
      0.22295194662616638,
      0.21759427739474588,
      0.2232445266075477,
      0.2262920443169371,
      0.22896541910257168,
      0.22987699139260961,
      0.23076181440296287,
      0.22957905600527803,
      0.23171663359253705,
      0.2343509439579741,
      0.23670936109063154,
      0.23672894294747335,
      0.23991573524332332,
      0.24622365996509255,
      0.24563237826624315,
      0.24651808374656176,
      0.2586613256774263,
      0.2561925270064862,
      0.25385549771571586,
      0.2581981469414191,
      0.26482046428554784,
      0.2614187479554536,
      0.26516863398566215,
      0.269985163604428,
      0.27208914103622206,
      0.27316643749168534,
      0.27684242411287957,
      0.28131584086104067,
      0.2818119246802644,
      0.28118730890536736,
      0.2843464128093091,
      0.29263635327716075,
      0.28823633616912864,
      0.28914777618682314,
      0.29980964260900805,
      0.2958123760665962,
      0.30549567093749247,
      0.29981410376682965,
      0.30051735636003,
      0.303153407091866,
      0.30543285515493973,
      0.309960199348227,
      0.30406202909475316,
      0.31246474558364845,
      0.3081122113737518,
      0.30931468024225295,
      0.3043985876137625,
      0.3026856974927251,
      0.30354096316648815,
      0.3069183462751126,
      0.3085239758213123,
      0.30977602447578295,
      0.313436083308237,
      0.30938955729236145,
      0.3072390520644045,
      0.31211362108142077,
      0.3130931415957605,
      0.31459120412072733,
      0.31333656453800773,
      0.31581921643482713,
      0.3143295383560443,
      0.31232083532624616,
      0.3153335630893707,
      0.31666112099578997,
      0.3188605347436345,
      0.31483025723945596,
      0.3129518729662467,
      0.3117886486167679
    ],
    "best_epoch": 10,
    "best_val_loss": 0.21223347404759801,
    "best_val_abs_mse": 0.2773910462856293,
    "test_loss": 4.731686977108129,
    "test_abs_mse": 46.48271942138672,
    "tracker": {
      "initial_train_loss": 0.6063281275205823,
      "train_threshold": 0.2021093758401941,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.21223347404759801,
      "patience_no_improve_epochs": 70,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_31_13e926/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_31_13e926/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_31_13e926/config.yaml"
}