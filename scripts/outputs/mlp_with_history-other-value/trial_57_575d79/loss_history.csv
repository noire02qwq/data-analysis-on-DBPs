epoch,train_loss,val_loss
1,1.074683,1.345795
2,0.487766,0.541291
3,0.374486,0.474508
4,0.360140,0.462828
5,0.353457,0.476866
6,0.349043,0.466421
7,0.347218,0.496796
8,0.339862,0.532659
9,0.337063,0.479129
10,0.326995,0.602403
11,0.306123,0.525133
12,0.285479,0.554897
13,0.264315,0.620862
14,0.267388,0.572890
15,0.250000,0.553527
16,0.244820,0.529104
17,0.243081,0.547589
18,0.242027,0.448926
19,0.242219,0.612967
20,0.227901,0.452047
21,0.224793,0.481895
22,0.216560,0.535954
23,0.208119,0.535918
24,0.205096,0.538537
25,0.205102,0.558211
26,0.192908,0.592865
27,0.188324,0.601838
28,0.188143,0.568364
29,0.180662,0.598026
30,0.177167,0.586204
31,0.172252,0.579098
32,0.179851,0.520576
33,0.178795,0.582246
34,0.168693,0.558920
35,0.174587,0.549610
36,0.169616,0.606113
37,0.166367,0.592520
38,0.165854,0.540001
39,0.174834,0.607025
40,0.168091,0.567939
41,0.160255,0.547725
42,0.162081,0.552344
43,0.164064,0.507481
44,0.169607,0.578709
45,0.161061,0.605011
46,0.156861,0.509907
47,0.154771,0.543351
48,0.153494,0.504532
49,0.153848,0.551234
50,0.153836,0.584525
51,0.152363,0.485533
52,0.151584,0.519714
53,0.147822,0.525253
54,0.145351,0.561710
55,0.145739,0.506832
56,0.138972,0.502517
57,0.141103,0.495625
58,0.136323,0.505413
59,0.135535,0.527483
60,0.136932,0.507596
61,0.136719,0.543412
62,0.125496,0.535533
63,0.119307,0.558558
64,0.157679,0.508667
65,0.186009,0.525983
66,0.163995,0.576512
67,0.145005,0.541781
68,0.143393,0.510681
69,0.134426,0.530897
70,0.126538,0.535682
71,0.121294,0.507503
72,0.123140,0.550851
73,0.119092,0.507288
74,0.118748,0.493162
75,0.121751,0.561494
76,0.116280,0.535053
77,0.115304,0.523297
78,0.119981,0.542568
79,0.129236,0.576839
80,0.119666,0.572449
