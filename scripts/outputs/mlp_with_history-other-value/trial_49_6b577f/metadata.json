{
  "model_name": "mlp_with_history-other-value/trial_49_6b577f",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 112,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.2836542763314445,
    "mid_layer_count": 2,
    "mid_layer_size": 589
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 484,
    "learning_rate": 0.0004794092424678922,
    "weight_decay": 0.007533254480749752,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7685,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 1120,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90
    ],
    "train_loss": [
      1.0019083888172404,
      0.6679847015137012,
      0.43034838813035303,
      0.3893172238930992,
      0.3690576908335565,
      0.3622183810097875,
      0.35876124742439064,
      0.3572066872090431,
      0.3497953578335322,
      0.34790721547704434,
      0.34546512312600575,
      0.3456230466212246,
      0.3384524365369577,
      0.3399949510840526,
      0.3300967487446581,
      0.317195631566572,
      0.31850620163053217,
      0.2947205533125064,
      0.27848444853654214,
      0.26991279717769884,
      0.2631680509217311,
      0.25775830533571187,
      0.2572663103944695,
      0.25483442286663266,
      0.25736754421840335,
      0.30991420680699444,
      0.33486227898451904,
      0.2688627379062351,
      0.2565927604847165,
      0.25544874832160147,
      0.2538915717958551,
      0.26032773044176044,
      0.25966993075108946,
      0.2549255610404266,
      0.2540995023664749,
      0.2529171871340112,
      0.2502467181981967,
      0.2517380983005814,
      0.25186310938681267,
      0.24750524218313555,
      0.24636541195868206,
      0.25037860315033733,
      0.24831788691515727,
      0.24727381685762026,
      0.24757517580483435,
      0.2480562410826953,
      0.24734830998839227,
      0.24655274565761245,
      0.2482489100333228,
      0.24345396992713503,
      0.24366626047669251,
      0.24793229449586426,
      0.24828299828450556,
      0.24542942903766246,
      0.24548331959804467,
      0.2430154932751311,
      0.24370382646305963,
      0.2496029396237843,
      0.24470106170172806,
      0.24598248146847618,
      0.2444995564226214,
      0.24384262001235218,
      0.24246230012577855,
      0.2418769380917546,
      0.2442238083328608,
      0.25154914031885006,
      0.25005012123555276,
      0.24515759537339443,
      0.2418645497200624,
      0.2433341484451418,
      0.24233560783954589,
      0.24677684573903824,
      0.24410424006008527,
      0.24028440207417476,
      0.24160812355980288,
      0.24060919376728826,
      0.2441351618833486,
      0.24325135242419346,
      0.2419809761319598,
      0.24291482179019075,
      0.24022683532461378,
      0.24204568958119596,
      0.24532309072158828,
      0.24472453849573142,
      0.24498380269023917,
      0.2425886804629396,
      0.24067830860847456,
      0.24119666130727346,
      0.24244594908257003,
      0.24125247315377016
    ],
    "val_loss": [
      1.3907099338348754,
      0.5219175986187187,
      0.527753040462197,
      0.49443268583206357,
      0.46198754182118856,
      0.4614387368727587,
      0.4725487144764312,
      0.46964751699727453,
      0.4866813680725897,
      0.48669503759481236,
      0.4831669515478397,
      0.47319205417604504,
      0.48620037539990363,
      0.501921865861573,
      0.503843282832357,
      0.5659831162341341,
      0.5273116936583719,
      0.5134380006147716,
      0.5001913911568191,
      0.49622706767327773,
      0.4650211915998402,
      0.5166368151674727,
      0.5241950481416222,
      0.5092683710380943,
      0.5278960407672528,
      0.6295310350056894,
      0.5186407459710173,
      0.5727229242374797,
      0.5183148229907373,
      0.5016175530627816,
      0.5023384372631233,
      0.5200754654978563,
      0.509057114045777,
      0.5189900332225297,
      0.5068864398016901,
      0.4917161304972129,
      0.4489668301122631,
      0.469510220660421,
      0.4556819628098768,
      0.44831540638101314,
      0.5125645745657161,
      0.5497939913037294,
      0.4908337487788971,
      0.48723483503221754,
      0.4648127907764412,
      0.5118588720610042,
      0.5451464805774346,
      0.4705729649095478,
      0.48959980774782375,
      0.45283427938015874,
      0.48196799951399155,
      0.5265517649536361,
      0.5689469654938418,
      0.4837316287848764,
      0.5453459026927719,
      0.49896555021851363,
      0.501713919425439,
      0.48361796543983643,
      0.48379233875674404,
      0.47713094228755926,
      0.4835929698572901,
      0.4971829196650111,
      0.45412010957380966,
      0.5118908399236416,
      0.5981965482413412,
      0.5137304452008116,
      0.5304344314301085,
      0.5141250257542034,
      0.47726473829703414,
      0.5365963656923728,
      0.4928848189151216,
      0.5339710824146956,
      0.5063756510883034,
      0.5554614325126488,
      0.49726951207943304,
      0.4834161123829687,
      0.5611264421375926,
      0.48289745692721386,
      0.5978852182983638,
      0.5855559357804453,
      0.5177374680420596,
      0.5640905114704977,
      0.5076325586099111,
      0.5037288377028025,
      0.6252883673963433,
      0.48588759185311325,
      0.5166019620652684,
      0.6031745996839272,
      0.5294782628377754,
      0.5140125992055424
    ],
    "best_epoch": 40,
    "best_val_loss": 0.44831540638101314,
    "test_loss": 0.5657501965761185,
    "tracker": {
      "initial_train_loss": 1.0019083888172404,
      "train_threshold": 0.33396946293908014,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.44831540638101314,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-value/trial_49_6b577f/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-value/trial_49_6b577f/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-value/trial_49_6b577f/config.yaml"
}