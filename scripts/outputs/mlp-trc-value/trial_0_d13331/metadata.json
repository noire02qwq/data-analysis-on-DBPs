{
  "model_name": "mlp-trc-value/trial_0_d13331",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.4794354714229012,
    "mid_layer_count": 3,
    "mid_layer_size": 468
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 144,
    "learning_rate": 0.00054250636060764,
    "weight_decay": 0.0005621230720963537,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.4217613689437042,
      0.17812515966108727,
      0.14288708949514142,
      0.1310733351464636,
      0.11703316729731778,
      0.11754642355864081,
      0.11355130538428485,
      0.10332630194337507,
      0.09983414074185262,
      0.0966436567531374,
      0.09587701713965452,
      0.09232388973511324,
      0.09227562524481514,
      0.08853253129661358,
      0.09012017478204006,
      0.08584969606214209,
      0.08202302019723934,
      0.08157284232310419,
      0.0798068031584562,
      0.07919896333996855,
      0.07953452589941246,
      0.07522115352950137,
      0.07458127609594105,
      0.07366144425857367,
      0.07194824822977178,
      0.07140832928976014,
      0.07413002811162028,
      0.07365886133838886,
      0.07053112455396666,
      0.06973425866992979,
      0.07062159030635642,
      0.0689544345764945,
      0.06762594515204491,
      0.07330409996307098,
      0.06644047337993712,
      0.06898516655472868,
      0.06567857072250453,
      0.0667375027254155,
      0.06845187030354177,
      0.06382345517532467,
      0.06414122237279636,
      0.06457598080209673,
      0.0646676305641328,
      0.06408513848287072,
      0.06327565099610127,
      0.06374207878721379,
      0.06332868859439461,
      0.06341461157220764,
      0.06336730035101223,
      0.06283750334203152,
      0.061365068666044416,
      0.06002105502798779,
      0.06076172005295325,
      0.06145692753938604,
      0.06092102846093457,
      0.05932582944646868,
      0.06108657513224754,
      0.05996748986818841,
      0.06097096773203732,
      0.06259819574696153,
      0.06059928389200191,
      0.059499558867965985,
      0.058302874621930886,
      0.060601253995242764,
      0.06042036011226364,
      0.05939730919855506,
      0.059237894834831106,
      0.0612041645914148,
      0.05849563114234213,
      0.06030853987007706,
      0.06048683427836175,
      0.05907914482856054,
      0.05901016947120933,
      0.05781275984291666,
      0.058262788760870036,
      0.05767651262567434,
      0.056917123076027636,
      0.05701821229744104,
      0.05711759680001903,
      0.056455129576897606
    ],
    "val_loss": [
      0.25375337565016604,
      0.22322415538176804,
      0.21244178146659257,
      0.2373693743865647,
      0.207312157732284,
      0.2178169468027389,
      0.21813655222604375,
      0.2222632664406371,
      0.23285414299922075,
      0.2298021102379896,
      0.23246754191949695,
      0.24798874855041503,
      0.24109625818129785,
      0.25738821199197254,
      0.2542113684787008,
      0.2577500799458898,
      0.2602083195826251,
      0.27357567827144785,
      0.27244874744001263,
      0.2754140421302019,
      0.2765963872214277,
      0.2754731313197199,
      0.2756645866496834,
      0.2927738940109036,
      0.3018826292125051,
      0.29961000770151974,
      0.2929765018695843,
      0.2924352027698905,
      0.31112670075750637,
      0.309036208198456,
      0.30424624387018695,
      0.30792404927179484,
      0.3018728248908848,
      0.3070134410779633,
      0.3135155369600136,
      0.31032841899794733,
      0.3114187063392765,
      0.31736898614974796,
      0.3062224960434223,
      0.3125645619131134,
      0.3157016087434963,
      0.30825455816919933,
      0.3207690998108801,
      0.31468202569884457,
      0.32031068305769367,
      0.31932402265642934,
      0.3214842138711564,
      0.31814273745713834,
      0.324935274263342,
      0.32273996948838946,
      0.32397150088570076,
      0.32190555655313824,
      0.32582323497640875,
      0.3292237174546647,
      0.31731287064309605,
      0.31865659605957075,
      0.32420546490989044,
      0.3221143005850786,
      0.3209869642636019,
      0.3191300837758059,
      0.3239850025690958,
      0.32366445576716324,
      0.31890625411164975,
      0.3175518512547373,
      0.32033940277056777,
      0.32436272505514635,
      0.3221417292149481,
      0.3218939940551084,
      0.32054766548607877,
      0.3190467946365208,
      0.3225777857317896,
      0.3182931954632262,
      0.3197977160086889,
      0.3183294872859281,
      0.31856861398248615,
      0.3239634199056797,
      0.3198046341270744,
      0.31732730139158444,
      0.31878590710505755,
      0.3175127587454048
    ],
    "best_epoch": 5,
    "best_val_loss": 0.207312157732284,
    "test_loss": 4.669079771452544,
    "tracker": {
      "initial_train_loss": 0.4217613689437042,
      "train_threshold": 0.14058712298123474,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.207312157732284,
      "patience_no_improve_epochs": 75,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_0_d13331/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_0_d13331/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_0_d13331/config.yaml"
}