epoch,train_loss,val_loss
1,0.307922,0.298000
2,0.093200,0.196546
3,0.073011,0.222695
4,0.064639,0.269852
5,0.058422,0.235589
6,0.056314,0.284378
7,0.053806,0.256589
8,0.052022,0.262609
9,0.050182,0.288551
10,0.050149,0.294034
11,0.049264,0.274777
12,0.046687,0.332993
13,0.045873,0.272033
14,0.045149,0.291769
15,0.044423,0.297201
16,0.043920,0.314848
17,0.043655,0.311741
18,0.042972,0.326053
19,0.042766,0.319851
20,0.041333,0.321636
21,0.041534,0.305398
22,0.040515,0.303082
23,0.040516,0.295201
24,0.041226,0.306380
25,0.040969,0.301252
26,0.039536,0.330432
27,0.039210,0.321432
28,0.038534,0.315951
29,0.039129,0.327623
30,0.037602,0.336890
31,0.037542,0.319466
32,0.038534,0.310035
33,0.037938,0.331185
34,0.037441,0.337932
35,0.036330,0.320616
36,0.034619,0.307700
37,0.035565,0.328055
38,0.035977,0.329668
39,0.035902,0.310359
40,0.035346,0.320517
41,0.037059,0.353886
42,0.036400,0.336112
43,0.035055,0.342822
44,0.035551,0.349910
45,0.035454,0.331760
46,0.034833,0.347553
47,0.034234,0.341490
48,0.034163,0.318049
49,0.035380,0.355442
50,0.035161,0.305043
51,0.034582,0.367502
52,0.034263,0.333223
53,0.034173,0.333665
54,0.034416,0.326090
55,0.034988,0.319758
56,0.033594,0.324834
57,0.033458,0.357445
58,0.032431,0.347374
59,0.034374,0.336493
60,0.033843,0.362269
61,0.032375,0.322687
62,0.032952,0.354406
63,0.033330,0.371555
64,0.034222,0.325876
65,0.032129,0.339550
66,0.033152,0.316286
67,0.032791,0.330169
68,0.033364,0.322430
69,0.032812,0.341452
70,0.032238,0.307014
71,0.033229,0.354145
72,0.033550,0.311894
73,0.031776,0.315394
74,0.032089,0.322973
75,0.032599,0.308214
76,0.032064,0.329521
77,0.032823,0.313469
78,0.032899,0.319661
79,0.031584,0.314050
80,0.031449,0.329435
