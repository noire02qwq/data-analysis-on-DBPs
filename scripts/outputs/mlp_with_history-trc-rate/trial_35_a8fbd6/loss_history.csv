epoch,train_loss,val_loss
1,1.043586,0.309235
2,0.951302,0.301118
3,0.592166,0.180236
4,0.288585,0.236507
5,0.212422,0.358110
6,0.201007,0.262097
7,0.174628,0.291440
8,0.168545,0.290880
9,0.167274,0.296261
10,0.182878,0.283416
11,0.163430,0.262819
12,0.168974,0.268964
13,0.158865,0.282551
14,0.154008,0.266453
15,0.158310,0.523111
16,0.157273,0.283077
17,0.155531,0.273717
18,0.164013,0.287587
19,0.147532,0.276048
20,0.144405,0.306661
21,0.168278,0.286259
22,0.185144,0.281197
23,0.156038,0.284021
24,0.142821,0.281485
25,0.153632,0.314888
26,0.149033,0.292093
27,0.144643,0.288357
28,0.139174,0.273802
29,0.151913,0.294340
30,0.160507,0.291911
31,0.142840,0.286734
32,0.139282,0.288698
33,0.171232,0.303382
34,0.166743,0.297975
35,0.144742,0.297731
36,0.139233,0.276388
37,0.138263,0.290631
38,0.138453,0.286983
39,0.158159,0.289328
40,0.139412,0.295275
41,0.154281,0.281468
42,0.147994,0.266817
43,0.149291,0.284336
44,0.156653,0.292053
45,0.139879,0.289607
46,0.160738,0.301997
47,0.218530,0.307378
48,0.715856,0.437070
49,1.135907,0.363235
50,0.997218,0.438346
51,0.899615,0.415101
52,1.273655,0.261393
53,0.819217,0.309545
54,0.678397,0.284851
55,0.437402,0.272231
56,0.360833,0.282607
57,0.388189,0.332896
58,0.282260,0.290216
59,0.239502,0.292463
60,0.198714,0.276537
61,0.211741,0.272482
62,0.191113,0.309065
63,0.188215,0.271906
64,0.180883,0.306144
65,0.177032,0.310676
66,0.161928,0.282247
67,0.174075,0.292609
68,0.174284,0.294365
69,0.164637,0.287392
70,0.182396,0.283727
71,0.159117,0.371622
72,0.200616,0.291578
73,0.150550,0.273255
74,0.144913,0.615617
75,0.164367,0.561584
76,0.146316,0.315662
77,0.150249,0.286905
78,0.161890,0.293402
79,0.140568,0.297671
80,0.132698,0.286643
