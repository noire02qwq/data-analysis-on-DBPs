{
  "model_name": "gru-other-rate/trial_43_16a65c",
  "model_type": "GRU",
  "model_format": "torch",
  "model_params": {
    "history_length": 141,
    "units": 354,
    "num_layers": 5,
    "dropout": 0.4015897485338561
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 336,
    "learning_rate": 0.001285038433368271,
    "weight_decay": 0.00041044206885850116,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7656,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 141,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116
    ],
    "train_loss": [
      0.4120356148126357,
      0.2467640563612074,
      0.22268229797716052,
      0.20114798110480592,
      0.1803430392637522,
      0.16413807481247056,
      0.1526210571531218,
      0.13670907611009844,
      0.12800178543714147,
      0.12892322529539418,
      0.10538182260474441,
      0.09726698147746089,
      0.09044499029653573,
      0.08598540048333918,
      0.09090969351858928,
      0.08495949701549117,
      0.06888594569457362,
      0.060887210141155036,
      0.06466432735557466,
      0.06482458728888192,
      0.06481977809092095,
      0.05335298152552877,
      0.0519263836377093,
      0.07335122699227453,
      0.0646294824965882,
      0.05351047095226644,
      0.05436977943796723,
      0.04995968018813193,
      0.0572831301152893,
      0.043681977766341175,
      0.04636614038652761,
      0.044672561184646194,
      0.04041246109901925,
      0.03904132311433834,
      0.03848649069760287,
      0.04457423642137581,
      0.042524425295359665,
      0.03417237044595252,
      0.03721652411181351,
      0.035717734290421195,
      0.04444118883449082,
      0.05603985747666942,
      0.047851323392417364,
      0.04293624669033158,
      0.037289080539934315,
      0.03435546103689738,
      0.03238935844511447,
      0.03587318730298254,
      0.04025393590144229,
      0.05174953539543391,
      0.04998832657279266,
      0.05227103837558468,
      0.040177040234161396,
      0.03309945741136994,
      0.03249535531529625,
      0.032327075772057505,
      0.03519291654929846,
      0.03250336078897726,
      0.03105036238190896,
      0.03443186779194117,
      0.03355292365141797,
      0.0344911398990868,
      0.03288815238259055,
      0.15402852526652774,
      0.1174850803931305,
      0.06186088072982701,
      0.04360756663412883,
      0.04041598424268741,
      0.04282100513857734,
      0.036985117299803374,
      0.034492633290892485,
      0.033294649041465084,
      0.030353613483915135,
      0.030544666526693163,
      0.030127416904957318,
      0.029817801038953578,
      0.03728102119551931,
      0.0343290581178142,
      0.0323270947138157,
      0.0321145455548569,
      0.03269104444681664,
      0.03001422762613872,
      0.03088294684326387,
      0.03152127295358801,
      0.04145104748701974,
      0.03306508876476729,
      0.03047287231749128,
      0.030912901423754736,
      0.030643084521484225,
      0.03233540922893813,
      0.032062750309705734,
      0.02966854535627141,
      0.03098281013391048,
      0.034171764531572786,
      0.044994389924416345,
      0.03940378608281336,
      0.03004903053181672,
      0.028854745308807276,
      0.030934978714417142,
      0.029504672195003325,
      0.029982385975907216,
      0.04127159159992556,
      0.3386462466049717,
      0.33921224009654366,
      0.21339177716301527,
      0.15810519690423924,
      0.1443303093828004,
      0.12451874679625968,
      0.11629366919071323,
      0.1120974073729545,
      0.10170205911405408,
      0.09468906781516478,
      0.08924369014168981,
      0.0940432528670305,
      0.08487047432545211,
      0.06535120859602028
    ],
    "val_loss": [
      0.39298275659184256,
      0.3845089388464739,
      0.5347161278753223,
      0.47774556996579653,
      0.49597428301851193,
      0.3776520936075085,
      0.38508398311580727,
      0.3830255670461826,
      0.40150984204457907,
      0.41814173988239495,
      0.4199313839038689,
      0.42747235676485623,
      0.4054723945920339,
      0.4950118213356612,
      0.40189896607827286,
      0.39732704148321096,
      0.41034396465666995,
      0.3924568895094409,
      0.3923143455368316,
      0.37593039666821143,
      0.4374271377831876,
      0.4175536693213229,
      0.43168648866836185,
      0.39126773951296323,
      0.49183683516736515,
      0.42029540567340967,
      0.3827404209953582,
      0.4161719757639719,
      0.42946958156402953,
      0.3783993396216524,
      0.42406064914372155,
      0.4230943305763656,
      0.45709961288703416,
      0.4167924357031634,
      0.4332810471871656,
      0.43593717520822306,
      0.42388129762546745,
      0.43633164874093977,
      0.41904769079413956,
      0.3989857071174119,
      0.375624212533414,
      0.4216739488932901,
      0.423839461517905,
      0.39601054469982305,
      0.43640340580911696,
      0.43122866360727186,
      0.4101453212206949,
      0.39871554296173733,
      0.42037866015634134,
      0.4370110773040863,
      0.422640981717024,
      0.42324188033977667,
      0.411674598733822,
      0.40889445564704024,
      0.40619265297929685,
      0.41932426848097476,
      0.3877112559929579,
      0.418230509972144,
      0.42229787261186247,
      0.4263158344936942,
      0.3967777565567793,
      0.42576859575545717,
      0.4356764133105021,
      0.6215390085460183,
      0.3946454915457857,
      0.3642542566367966,
      0.39991356241488885,
      0.41621799090665257,
      0.38900971277031354,
      0.3933914193136249,
      0.4385386060811802,
      0.4195007606180842,
      0.4267424103742588,
      0.42572992212044264,
      0.4224489888031326,
      0.43711073641291637,
      0.4151801216388177,
      0.41828960779898183,
      0.4159728479956438,
      0.41909567253318375,
      0.41863514556142384,
      0.433663476726966,
      0.4451625311446047,
      0.4450717162943172,
      0.3937570880273145,
      0.427091792386449,
      0.41327737998105807,
      0.4358119460636984,
      0.42309288693045427,
      0.42222971173817525,
      0.45583738317032774,
      0.4415374398945334,
      0.42218472957611086,
      0.4228643774986267,
      0.47933941529896446,
      0.41989064152369243,
      0.41191190930897603,
      0.4117924204129659,
      0.4406156731222918,
      0.43859617089083097,
      0.42243718265773295,
      0.4183885764932918,
      0.6897226850429695,
      0.5471011532994802,
      0.556360285153646,
      0.5248141404397474,
      0.6027166048209824,
      0.5302886508895965,
      0.5906615741238622,
      0.631057941842222,
      0.6785023173886144,
      0.7176352660813018,
      0.6126152452594505,
      0.5732348490617947,
      0.6240849641982666,
      0.646366692874246
    ],
    "best_epoch": 66,
    "best_val_loss": 0.3642542566367966,
    "best_val_abs_mse": 0.3893853425979614,
    "test_loss": 0.38086841957706014,
    "test_abs_mse": 0.7868417501449585,
    "tracker": {
      "initial_train_loss": 0.4120356148126357,
      "train_threshold": 0.13734520493754523,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3642542566367966,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/gru-other-rate/trial_43_16a65c/best_model.pt",
    "last": "scripts/outputs/gru-other-rate/trial_43_16a65c/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/gru-other-rate/trial_43_16a65c/config.yaml"
}