{
  "model_name": "rnn-trc-value/trial_61_ae016f",
  "model_type": "RNN",
  "model_format": "torch",
  "model_params": {
    "history_length": 131,
    "units": 162,
    "num_layers": 8,
    "dropout": 0.2281260230660087
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 123,
    "learning_rate": 0.00037162453471014474,
    "weight_decay": 0.0005606948386293372,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7666,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 131,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149,
      150,
      151,
      152,
      153
    ],
    "train_loss": [
      0.29120923130110415,
      0.10625624326620219,
      0.07853952357815197,
      0.06038737462815544,
      0.05545719871197859,
      0.05022985953959121,
      0.055355325919504796,
      0.04602053169182463,
      0.03998760623260147,
      0.03837247881304571,
      0.0349942159418871,
      0.037031093383187996,
      0.03808672618127712,
      0.03401860322277461,
      0.035253207954441305,
      0.03231120736919151,
      0.03014752000717054,
      0.033403547614338565,
      0.03331142259086707,
      0.03169387426619007,
      0.03218963947375527,
      0.031097514814598316,
      0.028651091108084534,
      0.0303339243047921,
      0.03212747798988169,
      0.027986794802246768,
      0.029085342344912262,
      0.02799497657724477,
      0.03282329756640211,
      0.031767353286955506,
      0.03180543141682046,
      0.02836494663078605,
      0.02470080693539824,
      0.03137693894838007,
      0.028832754552725895,
      0.024806488339346754,
      0.027248404311935134,
      0.02466506237116031,
      0.02578299050577745,
      0.02453005872423861,
      0.023933410653764295,
      0.024934192689341227,
      0.02817723561445688,
      0.024656670486582204,
      0.023194891521150764,
      0.02795335074447867,
      0.02539493565666549,
      0.024385952508330207,
      0.025090000262698257,
      0.027332311683715152,
      0.02324004263388459,
      0.027822737997514894,
      0.023849423361969872,
      0.022035777238371353,
      0.02351363289672682,
      0.02537859828222787,
      0.03075417462894788,
      0.026005741769820647,
      0.025262371217309572,
      0.023924448547198177,
      0.02605595653879092,
      0.021452236437318205,
      0.02713060327736331,
      0.04033867821550279,
      0.028476844675121685,
      0.02134422819328633,
      0.021213647550588608,
      0.02172702134574965,
      0.023216849477743468,
      0.023035770727522203,
      0.022932083113422725,
      0.0227373097905393,
      0.030185493404430087,
      0.1351276805139388,
      0.04692505192601538,
      0.057258781338702935,
      0.04733655370719402,
      0.0376153121219582,
      0.0314789080519512,
      0.03017316317827699,
      0.027201224018122534,
      0.026622720387833036,
      0.023676352133693068,
      0.023868818068330168,
      0.022506221109102685,
      0.022237473573732975,
      0.02584357509725311,
      0.021523272612334044,
      0.022196120137876998,
      0.021940236978238693,
      0.02141078336428226,
      0.022355093958938508,
      0.025032824790749107,
      0.022171367203028074,
      0.021116535309794487,
      0.022458450533177517,
      0.026067490540269907,
      0.022472404084464076,
      0.021484342558970814,
      0.020755529128153052,
      0.02249941778165878,
      0.024160452731567934,
      0.02355508691007541,
      0.020796081892166363,
      0.020340192171181545,
      0.021976085729846485,
      0.0238434067163631,
      0.3116079348608649,
      0.08109110749591246,
      0.05623425943196255,
      0.0523848463993781,
      0.04955249443502517,
      0.05133069435971822,
      0.04882391861756788,
      0.04550136720429753,
      0.03871224826080795,
      0.038380200328330144,
      0.03321392020147936,
      0.034667487917606446,
      0.03556963679775063,
      0.032376662106392916,
      0.03113589379372755,
      0.029046629915126163,
      0.03795379116507274,
      0.030326726313796067,
      0.03059170615295385,
      0.028540689292143446,
      0.028764000210834254,
      0.028397288491248212,
      0.026825649915770876,
      0.02969820048449138,
      0.028173545722434423,
      0.028576534798579228,
      0.02698391516338922,
      0.03242778695561915,
      0.027401375740051206,
      0.026814023175410696,
      0.02762408387314401,
      0.025168371396302056,
      0.02863980215936977,
      0.025891647097564013,
      0.026614166932030364,
      0.02623844454966402,
      0.02678661396813951,
      0.02568829218020428,
      0.026788763123878588,
      0.03016228315573766,
      0.02347437914231529,
      0.025219174935595425,
      0.02548237116154533,
      0.02931397357781119,
      0.02878895509422424,
      0.028454407480050403
    ],
    "val_loss": [
      0.4005047775581925,
      0.34451613623403504,
      0.28428438521007043,
      0.28308116156540947,
      0.30684122464167857,
      0.2979405188364183,
      0.3002232927170967,
      0.30988878666083075,
      0.3064594555367342,
      0.3202837601237133,
      0.29705380164756034,
      0.3038925797148736,
      0.3708023817964389,
      0.32414832468964383,
      0.3385066509057216,
      0.32066603505504343,
      0.31053207935040406,
      0.30159773660076417,
      0.30851957959953896,
      0.32214342341451585,
      0.3200975890165407,
      0.30756594623232675,
      0.31972889877342714,
      0.31896417842742925,
      0.3269584778551302,
      0.30588791532006987,
      0.2866125808002617,
      0.29201092304115345,
      0.3156478699653627,
      0.3080507291347056,
      0.3118947848945321,
      0.30543069502751446,
      0.295677270822807,
      0.30700811823595786,
      0.30902260221027866,
      0.30122800014667706,
      0.304064107128603,
      0.30739415784305085,
      0.30047045867823197,
      0.29598551628899256,
      0.29101340564380507,
      0.30834779128387657,
      0.2853486739099026,
      0.33456542717103294,
      0.3050483375341592,
      0.2839328594293869,
      0.3037164198045067,
      0.29703197715034385,
      0.29536961108825344,
      0.28888032821057263,
      0.28215004512315206,
      0.28823627865354634,
      0.2896042481789778,
      0.28038794647478416,
      0.29711763474108754,
      0.2870770249716536,
      0.2721707001417697,
      0.2878757950241962,
      0.2703781123278651,
      0.29178191359060074,
      0.299033446403633,
      0.28393143304026947,
      0.2846733072036487,
      0.2903532665735947,
      0.2694112048947258,
      0.28330131556258764,
      0.2792720442370116,
      0.28645761557436455,
      0.4602024433420536,
      0.27423003659455364,
      0.27666102169851164,
      0.27574965090875675,
      0.27942492468115276,
      0.2892438096546395,
      0.29545073571341657,
      0.3795748071622349,
      0.28362383286463105,
      0.33394396832982404,
      0.2981474825621633,
      0.2942123165800275,
      0.27145819610798966,
      0.27897578947814905,
      0.2778747681238337,
      0.28581028262119806,
      0.275387673444689,
      0.28300453648640367,
      0.26736193107563755,
      0.2792601691726261,
      0.28260729438820464,
      0.2778280801859177,
      0.2707167954881213,
      0.2734891567507502,
      0.2749477690754982,
      0.27113110818816516,
      0.28413837847640055,
      0.26743839562363075,
      0.27744625066546447,
      0.2755785170686013,
      0.2816333814607766,
      0.28008678788486535,
      0.287040546731633,
      0.2979541816107349,
      0.26474914620267953,
      0.2697565336828817,
      0.28116519581303445,
      0.2705724138509995,
      0.26614669790591844,
      0.3231466574070161,
      0.30310976334853085,
      0.3008334676484148,
      0.3027747036643817,
      0.31448807393585493,
      0.29744232479304433,
      0.33441564729604534,
      0.3391112282749511,
      0.3296686601228343,
      0.35286224890991064,
      0.34555925871886894,
      0.3328871555514857,
      0.3431502518907725,
      0.3579273136020331,
      0.3430475167428216,
      0.33971196577109086,
      0.32706362977400866,
      0.354835164391932,
      0.3512546962930146,
      0.3306478229468454,
      0.33915387578977796,
      0.34245464988052843,
      0.3487742277620706,
      0.3577510496266855,
      0.35127577090602435,
      0.3523042945403182,
      0.3246825510937118,
      0.3400930427193285,
      0.3870497814842505,
      0.3610388518327814,
      0.40347130351259325,
      0.3912058216056781,
      0.3619965287360424,
      0.3419743196313788,
      0.3497005986339764,
      0.3317024956942497,
      0.3476779992162378,
      0.3500979115662282,
      0.3201663054202399,
      0.34780926098099013,
      0.3543114873318526,
      0.32337837913603396,
      0.33885774133604263,
      0.34604533976891977,
      0.33587440023432946,
      0.33403173333513525
    ],
    "best_epoch": 103,
    "best_val_loss": 0.26474914620267953,
    "test_loss": 4.654960352196648,
    "tracker": {
      "initial_train_loss": 0.29120923130110415,
      "train_threshold": 0.09706974376703471,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.26474914620267953,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/rnn-trc-value/trial_61_ae016f/best_model.pt",
    "last": "scripts/outputs/rnn-trc-value/trial_61_ae016f/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/rnn-trc-value/trial_61_ae016f/config.yaml"
}