{
  "model_name": "mlp_with_history-other-value/trial_45_a4a05d",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 119,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.3409612346981218,
    "mid_layer_count": 14,
    "mid_layer_size": 386
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 403,
    "learning_rate": 0.0012012974220430993,
    "weight_decay": 0.008415988366524586,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7678,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 1190,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100
    ],
    "train_loss": [
      1.0060037986845298,
      1.0057968232867058,
      1.005804403642094,
      1.0056174618404774,
      1.0056684083633045,
      1.0057229704691053,
      1.0056300646518475,
      1.0055589940933611,
      1.0055696431952053,
      1.0056392076689926,
      1.0056118880376494,
      1.0055681173846138,
      1.0055297541491033,
      1.0055656241824087,
      1.0055301423245464,
      1.0055471377762135,
      1.005577972761881,
      1.0055243080949126,
      1.0055014056117935,
      1.0055301849902312,
      1.0055584397422177,
      1.005563600621021,
      1.005568205161342,
      1.005548611496786,
      1.0055088458830692,
      1.0055181554407775,
      1.0055052495990207,
      1.0055286748144086,
      1.005549463646025,
      1.0055079858465783,
      1.005480534608366,
      1.0055555483812961,
      1.0055727613456673,
      1.0055044059580769,
      1.005504667650259,
      1.0055014100910693,
      1.005518891648968,
      1.0055410716955349,
      1.005514655744511,
      1.005504097516849,
      1.0054920605925044,
      1.0054963509547086,
      1.0054925793966734,
      1.0054940910319483,
      1.0055269759733498,
      1.0055174302017666,
      1.0055069652315414,
      1.005520291946679,
      1.0055395790486634,
      1.0054897093841202,
      1.005535540946544,
      1.005493335765487,
      1.0055149360757596,
      1.0055073729543271,
      1.0054960994864541,
      1.0054944347096284,
      1.005508265595599,
      1.005519707389535,
      1.0055184949729927,
      1.0055391433711598,
      1.00553152668473,
      1.005529888698166,
      1.0055511370398285,
      1.0055507625428672,
      1.0055650787044237,
      1.0055158717786312,
      1.0055286874992209,
      1.005535426340739,
      1.005514198625482,
      1.0055321543733413,
      1.0055487030230639,
      1.0054858263177342,
      1.005502799543809,
      1.0055193404693037,
      1.005514575070967,
      1.0055299102095583,
      1.0055148623967176,
      1.0055115979051303,
      1.0055209011670108,
      1.005515495294331,
      1.0055058141430395,
      1.005524259878652,
      1.005494034416075,
      1.005499466248371,
      1.0055018535393792,
      1.0054984362711041,
      1.0055219368268251,
      1.005542046407698,
      1.0055096217526467,
      1.005494667989073,
      1.005510716698821,
      1.0054985992561936,
      1.0055053135509695,
      1.0055238846985428,
      1.0055390160184379,
      1.005546180833656,
      1.0055574612261635,
      1.0055457217272883,
      1.0055361731299575,
      1.0055307058360807
    ],
    "val_loss": [
      1.4317432895392002,
      1.4401486020959067,
      1.4294892433517707,
      1.4329634606838226,
      1.4161446307590622,
      1.417425401267891,
      1.4241644968886575,
      1.4365735927027856,
      1.4320764333902005,
      1.436978606942171,
      1.4321204463164963,
      1.4276829174178802,
      1.4253752220890479,
      1.4257840324661688,
      1.432572679177016,
      1.4386530203376702,
      1.439132735864845,
      1.4351797876957648,
      1.4365227561510965,
      1.440349280584358,
      1.448426219410525,
      1.444296762257993,
      1.4296011294790372,
      1.4295513863335112,
      1.4347544144013684,
      1.4344523848530775,
      1.4345730278663293,
      1.434155483231573,
      1.4317533476267033,
      1.4350161189090707,
      1.4438723237571602,
      1.4433984881032726,
      1.4466164097457588,
      1.4406580850392758,
      1.4355110056742937,
      1.4302272161323868,
      1.4252292093759524,
      1.4303081711252292,
      1.4272982396765383,
      1.4316631802541766,
      1.4308810314732396,
      1.4312703887145677,
      1.4302442583495272,
      1.4339800356390948,
      1.4401918499412651,
      1.439775121140623,
      1.438560275367634,
      1.4391945083698112,
      1.4265555364286113,
      1.4327154546083805,
      1.4307788328496283,
      1.4314977366767243,
      1.4320439966138965,
      1.4340372838659914,
      1.431278716839716,
      1.4293144605473844,
      1.4271181715105823,
      1.429136439390525,
      1.4232064873872403,
      1.4221062442499721,
      1.423752725017285,
      1.4266611053201252,
      1.4212461345923875,
      1.4190830309947808,
      1.419760152893866,
      1.4264922184144666,
      1.4359924750770638,
      1.4399872484321365,
      1.442291452677664,
      1.445318771515064,
      1.4401939234333838,
      1.4358233760216992,
      1.4386507451891186,
      1.4324164945208384,
      1.4335519224226831,
      1.4293877978167848,
      1.4271376252888206,
      1.4280708083135638,
      1.4291353183235238,
      1.4267663647314746,
      1.4248350109525783,
      1.4246100063452463,
      1.427167624128079,
      1.427601153479365,
      1.4291894021505367,
      1.4251871992014125,
      1.4227114614612328,
      1.4210709626803142,
      1.427854370214268,
      1.4329393644532757,
      1.4335314367345706,
      1.4345254403388428,
      1.4375902573505561,
      1.446918643448881,
      1.4430433198006567,
      1.4464480546063292,
      1.444422560216424,
      1.4395478556256094,
      1.4335941388578473,
      1.4374052744068786
    ],
    "best_epoch": 100,
    "best_val_loss": 1.4374052744068786,
    "test_loss": 1.465492052574192,
    "tracker": {
      "initial_train_loss": 1.0060037986845298,
      "train_threshold": 0.33533459956150996,
      "best_tracking": false,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 1.4190830309947808,
      "patience_no_improve_epochs": 36,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": true
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-value/trial_45_a4a05d/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-value/trial_45_a4a05d/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-value/trial_45_a4a05d/config.yaml"
}