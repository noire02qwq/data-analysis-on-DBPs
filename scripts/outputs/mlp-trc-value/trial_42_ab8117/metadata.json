{
  "model_name": "mlp-trc-value/trial_42_ab8117",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.17359706504867925,
    "mid_layer_count": 12,
    "mid_layer_size": 234
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 185,
    "learning_rate": 0.0004972275374377814,
    "weight_decay": 0.0009407311189947416,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.3601482914232211,
      0.10581785987101193,
      0.07831076376394332,
      0.0679631956841982,
      0.061183488793506755,
      0.0592913659315283,
      0.05568903539446362,
      0.054615269239233086,
      0.055386931219713054,
      0.05117134428059844,
      0.05042111721528209,
      0.049306599699962345,
      0.048378690807727005,
      0.0486926189931984,
      0.047056672745324546,
      0.04966029280623667,
      0.046015367637258914,
      0.04469450149186273,
      0.04356254753166893,
      0.04508827055678758,
      0.044582980911913074,
      0.04486914996770695,
      0.04176528879626248,
      0.042278888162747295,
      0.041717949277005055,
      0.041135000162927565,
      0.0415281920164361,
      0.041019272333008165,
      0.040806111311726366,
      0.04144534600393062,
      0.03941784125096664,
      0.03915632249029585,
      0.04100793728479717,
      0.0389765683177375,
      0.03929570907074146,
      0.0398598271080428,
      0.038647422318768734,
      0.03822198495977946,
      0.038780886503323536,
      0.0376283416214885,
      0.03841647767572219,
      0.04024278683986433,
      0.03792188596482145,
      0.037621513821649105,
      0.03765216386953934,
      0.036522551452604364,
      0.0369746715693867,
      0.03667386186563851,
      0.03700358524757044,
      0.03779521648637786,
      0.03618091073034359,
      0.035706748444541116,
      0.03508117848867718,
      0.03610104431334659,
      0.03655166236904491,
      0.036591594828041384,
      0.03678760534962816,
      0.036519673045126363,
      0.035263861930203276,
      0.03570548907923907,
      0.036651243129100036,
      0.036909767009151585,
      0.035831406150584715,
      0.03700689590603434,
      0.035425436017598066,
      0.03491824672291253,
      0.033944949197113175,
      0.03487167155810691,
      0.034589881726085236,
      0.03517464814557593,
      0.03547301063822509,
      0.03549412286254062,
      0.035145282591972644,
      0.03429379831667915,
      0.03497868153663699,
      0.03445631185147038,
      0.03380489286337298,
      0.03403881458582795,
      0.034417822949393335,
      0.034201655685261324
    ],
    "val_loss": [
      0.2897069026342409,
      0.20412957920374986,
      0.29065095052725365,
      0.3442125463311722,
      0.24986876958903081,
      0.26643461373238686,
      0.2724987064226123,
      0.34679788022586505,
      0.30857264136192863,
      0.300214581977866,
      0.2995970034469923,
      0.2809617337798644,
      0.27740237216638053,
      0.3515509529775399,
      0.35635042202263,
      0.29327317770057454,
      0.31753193255803897,
      0.34825837589287295,
      0.30677433017485156,
      0.35232677925824224,
      0.32445434228277314,
      0.34463642197967825,
      0.302996702570312,
      0.35582388515868585,
      0.3206747018224643,
      0.3230692940892395,
      0.3608231752229754,
      0.34421968990434965,
      0.383042511875981,
      0.37912509178263165,
      0.35701526426515,
      0.3215688048544044,
      0.3564545739341728,
      0.39618138261808605,
      0.3599904843600478,
      0.390793777723423,
      0.38083931641418955,
      0.37004746482735446,
      0.38109823039169616,
      0.4244955962601893,
      0.32824317989368995,
      0.3415643447943166,
      0.36325277003297907,
      0.373195992475989,
      0.42249594445892436,
      0.4059665057261636,
      0.4204197127238184,
      0.34662437740111063,
      0.37149997881451946,
      0.39632181881252165,
      0.38848095734096216,
      0.3420342990715882,
      0.32011118251272663,
      0.38029697850837324,
      0.3846099904018962,
      0.33031658766913913,
      0.356899094371917,
      0.36255639302404874,
      0.3704273767579726,
      0.3759047863837666,
      0.3944496676035805,
      0.45460245846408215,
      0.4299603589548322,
      0.430321151563552,
      0.341246317575747,
      0.38135364789426507,
      0.34402553433228933,
      0.3344533599210446,
      0.3629728961167132,
      0.3287587193716429,
      0.4263793545423778,
      0.3191949122691315,
      0.3418835062578231,
      0.3953301055568778,
      0.31031218726009485,
      0.3357189496655664,
      0.30763331930080573,
      0.3948777567840622,
      0.3937369001817382,
      0.3263218653929269
    ],
    "best_epoch": 2,
    "best_val_loss": 0.20412957920374986,
    "test_loss": 5.307863887132069,
    "tracker": {
      "initial_train_loss": 0.3601482914232211,
      "train_threshold": 0.12004943047440703,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.20412957920374986,
      "patience_no_improve_epochs": 79,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_42_ab8117/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_42_ab8117/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_42_ab8117/config.yaml"
}