epoch,train_loss,val_loss
1,1.045417,0.327493
2,1.000709,0.347185
3,0.999384,0.353387
4,1.000050,0.353741
5,0.999647,0.351961
6,0.999444,0.352827
7,0.999903,0.354436
8,0.999997,0.346780
9,0.999870,0.351374
10,0.999552,0.349356
11,0.999476,0.351420
12,0.999430,0.358213
13,0.999907,0.353250
14,0.999508,0.353397
15,0.999837,0.353551
16,0.999781,0.355551
17,0.999399,0.350737
18,0.999944,0.348491
19,0.999612,0.349304
20,0.999616,0.349026
21,0.999838,0.353872
22,0.999669,0.354237
23,0.999738,0.352692
24,0.999524,0.352709
25,0.999491,0.350292
26,0.999768,0.349152
27,0.999914,0.354246
28,0.999631,0.355675
29,0.999766,0.359831
30,0.999732,0.357169
31,0.999823,0.356284
32,0.999630,0.349636
33,0.999722,0.345669
34,0.999630,0.348137
35,0.999589,0.348202
36,0.999649,0.351004
37,0.999525,0.350709
38,0.999693,0.352187
39,0.999770,0.348263
40,0.999497,0.348551
41,0.999351,0.348800
42,0.999735,0.353712
43,0.999580,0.354345
44,0.999518,0.353266
45,0.999554,0.351904
46,0.999646,0.351181
47,0.999587,0.352501
48,0.999605,0.350677
49,0.999659,0.350285
50,0.999448,0.348328
51,0.999839,0.349153
52,0.999555,0.349497
53,0.999448,0.347979
54,0.999685,0.347649
55,0.999463,0.348868
56,0.999612,0.348535
57,0.999678,0.351279
58,0.999524,0.352643
59,0.999547,0.353429
60,0.999556,0.352717
61,0.999472,0.349650
62,0.999530,0.350490
63,0.999530,0.350549
64,0.999630,0.351778
65,0.999541,0.352833
66,0.999471,0.348852
67,0.999565,0.347052
68,0.999568,0.348212
69,0.999616,0.350150
70,0.999551,0.349428
71,0.999642,0.349201
72,0.999528,0.350891
73,0.999564,0.351062
74,0.999560,0.349697
75,0.999623,0.348966
76,0.999624,0.352793
77,0.999522,0.351439
78,0.999578,0.348632
79,0.999547,0.351349
80,0.999574,0.353066
81,0.999571,0.353786
82,0.999649,0.355994
83,0.999617,0.352162
