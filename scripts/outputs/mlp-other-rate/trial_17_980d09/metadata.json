{
  "model_name": "mlp-other-rate/trial_17_980d09",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.10288375771786244,
    "mid_layer_count": 11,
    "mid_layer_size": 296
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 319,
    "learning_rate": 0.0010903743889249154,
    "weight_decay": 0.0020493539726834714,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103
    ],
    "train_loss": [
      0.4245723954465464,
      0.24861331856697264,
      0.21670702231685707,
      0.20094845037985729,
      0.19069928005567083,
      0.18553870730006494,
      0.17810547032253507,
      0.17385536785299133,
      0.1678972524643831,
      0.16332210805085515,
      0.16091481762713136,
      0.15758606786908952,
      0.15488234781237245,
      0.1515797483995213,
      0.15306678290678147,
      0.14992767403818755,
      0.14742753988255164,
      0.14561391083773068,
      0.14628390097974386,
      0.1442047574224305,
      0.14391758787102152,
      0.14357872985746845,
      0.1414172995286975,
      0.1410584541332988,
      0.13897706090012474,
      0.1382649074284204,
      0.1379808163420398,
      0.13659006626889483,
      0.13695886148366335,
      0.13479635792819275,
      0.13647415705518334,
      0.1353775859729656,
      0.13265682927396372,
      0.1306992867037371,
      0.13185271287978215,
      0.13155308755648906,
      0.13025477049387743,
      0.13044370116504447,
      0.13091685025240288,
      0.12871088310904139,
      0.1276482563779301,
      0.129212709065391,
      0.12608797430491345,
      0.1260785727683797,
      0.12522237729845045,
      0.12350323146879061,
      0.12289087188498463,
      0.12645928683251587,
      0.12567748317926006,
      0.12281719854091026,
      0.1237924755376507,
      0.1204904677330102,
      0.12332099181752348,
      0.12379832517904248,
      0.12359555041261702,
      0.12073731026098537,
      0.12026448740029928,
      0.12099475140615021,
      0.12045919749715685,
      0.11998505600507807,
      0.1166173202994391,
      0.11817474343578377,
      0.11809944075409451,
      0.11937968546821864,
      0.11861486370943337,
      0.11692604201995391,
      0.11770513453155282,
      0.11690194965012872,
      0.11704935188600656,
      0.11733041704178866,
      0.11599487213636742,
      0.11626819200936099,
      0.11365745370474578,
      0.11443853490111949,
      0.11600847133058288,
      0.11332122567542215,
      0.11468682507327302,
      0.11389305548557965,
      0.1136723634270352,
      0.11374141016985558,
      0.1143469558259412,
      0.11649120087640263,
      0.11088289949601433,
      0.11398895301513484,
      0.11363833314863886,
      0.11206430008395046,
      0.11138171364881554,
      0.1124833632994533,
      0.11076675281846077,
      0.1116622773851108,
      0.11185894005207021,
      0.11323227732704658,
      0.11259555668040169,
      0.11377271822916049,
      0.11233649058520732,
      0.11167549523785367,
      0.11252255058283987,
      0.11354874795720386,
      0.11231730130810258,
      0.11198694053836637,
      0.11088983515892015,
      0.11243404394513586,
      0.11074752162849524
    ],
    "val_loss": [
      0.3734521925092457,
      0.4014012328745005,
      0.44315254751169036,
      0.47068538440023355,
      0.49135790127747786,
      0.5703466865741564,
      0.48754326098871803,
      0.5129260430168249,
      0.5889135086429333,
      0.6354888722523601,
      0.6010473894323417,
      0.6190936664532045,
      0.6797253722648421,
      0.6258030884994005,
      0.5908040617620517,
      0.5473463468030542,
      0.5536390331423211,
      0.5998804066352501,
      0.6904332770915802,
      0.579058099582702,
      0.5207848722527841,
      0.505714694950395,
      0.623417250196377,
      0.5576175520341553,
      0.5592930139092628,
      0.5827400774031342,
      0.6976319569938197,
      0.6266962916372779,
      0.603500095536252,
      0.5257249453021381,
      0.4765396248526916,
      0.6118847809062746,
      0.6557664532593624,
      0.5161705409784517,
      0.5137265976139171,
      0.5738129395746185,
      0.5069507031026714,
      0.5408775538473786,
      0.6055222346575674,
      0.6693423266896231,
      0.533422541511273,
      0.549566144554201,
      0.5888515620352979,
      0.6370925148804031,
      0.6090868898851429,
      0.5856337922061988,
      0.5052994480479264,
      0.4776442747451588,
      0.5144532096600104,
      0.6068402119471641,
      0.6193226504111718,
      0.5708653748660031,
      0.4608366821340458,
      0.5426844554657708,
      0.558445840110322,
      0.5053803488701404,
      0.6277699224070874,
      0.5825134713225022,
      0.5439152508126405,
      0.6048522868199263,
      0.5705705675313216,
      0.5707343565846632,
      0.4940313890308677,
      0.5318663867023177,
      0.5366873202388158,
      0.5103278609985363,
      0.5239046461835593,
      0.5521218163346102,
      0.5173797401750159,
      0.5465275432446046,
      0.647266935106523,
      0.6053056819710189,
      0.5615829126028243,
      0.49757772462810584,
      0.6947713670973292,
      0.5621255099238036,
      0.6354408960722521,
      0.5375794083727691,
      0.5132221885783944,
      0.5370532571466383,
      0.6198743005891046,
      0.5677445774842165,
      0.6192134409072156,
      0.5720899585389092,
      0.5216941237092731,
      0.5293003888945736,
      0.5484634696812687,
      0.501625760747287,
      0.4694730445028779,
      0.5425856620162547,
      0.5908188481887657,
      0.5420852147622737,
      0.4911228181537754,
      0.5185545669968971,
      0.5458472434676693,
      0.5618021496577177,
      0.5937549808960475,
      0.542477081100384,
      0.509589489156793,
      0.4807476380717255,
      0.5967432544795339,
      0.5749894901663958,
      0.5062575353833729
    ],
    "best_epoch": 53,
    "best_val_loss": 0.4608366821340458,
    "best_val_abs_mse": 0.5664225816726685,
    "test_loss": 0.5070301975662771,
    "test_abs_mse": 1.2040529251098633,
    "tracker": {
      "initial_train_loss": 0.4245723954465464,
      "train_threshold": 0.14152413181551546,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4608366821340458,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-rate/trial_17_980d09/best_model.pt",
    "last": "scripts/outputs/mlp-other-rate/trial_17_980d09/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-rate/trial_17_980d09/config.yaml"
}