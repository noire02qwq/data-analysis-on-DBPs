{
  "model_name": "gru-other-value/trial_20_090a6c",
  "model_type": "GRU",
  "model_format": "torch",
  "model_params": {
    "history_length": 125,
    "units": 338,
    "num_layers": 3,
    "dropout": 0.255216000383074
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 307,
    "learning_rate": 0.0013489014295159146,
    "weight_decay": 0.000817310516149255,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7672,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 125,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89
    ],
    "train_loss": [
      0.4078489480670289,
      0.24132647904119725,
      0.2215843109221696,
      0.204954882769052,
      0.19177333377806685,
      0.17059159705976687,
      0.15342040586637817,
      0.1398835129447367,
      0.12915109402895347,
      0.11964025218874931,
      0.11375767688875837,
      0.1151909900166879,
      0.11108630665454614,
      0.09317672879136982,
      0.09955046857620771,
      0.09272316506285923,
      0.08671213210122397,
      0.08419861247116259,
      0.08249755312200166,
      0.07368169514155472,
      0.07053593689637944,
      0.08796385259341305,
      0.07228511083012638,
      0.06441468213528503,
      0.08600663673229772,
      0.07922608413314981,
      0.06030557609558478,
      0.05577701564569403,
      0.06599278648590769,
      0.0673320692851246,
      0.057532870301023144,
      0.07038798065743447,
      0.05672973586048259,
      0.049700235784329604,
      0.052811527217818933,
      0.05366945068951117,
      0.05010394099662789,
      0.05466279761508356,
      0.05446170715370426,
      0.051092128838461995,
      0.046041768326349285,
      0.04337226899148463,
      0.05961450800198646,
      0.0510334025614927,
      0.049465172064157514,
      0.04484515378107943,
      0.0423288499179944,
      0.04673406416676527,
      0.05155796483129931,
      0.04833551810042422,
      0.048345788416954784,
      0.039477964005179556,
      0.042751896395653924,
      0.04886962936771597,
      0.04218587175262189,
      0.04983139480585553,
      0.06293791560728075,
      0.04682024412305794,
      0.06921307054640603,
      0.10161424668193081,
      0.06040672880643056,
      0.05371970681054081,
      0.05477670385289599,
      0.04876932753754995,
      0.044246198899356395,
      0.04255842081075913,
      0.040731205714709194,
      0.03833295659446648,
      0.046205192762091986,
      0.04409463129106354,
      0.04061297743607456,
      0.06408336353260048,
      0.07271512764738144,
      0.04933645673304004,
      0.04918910478891434,
      0.039261767485327594,
      0.03670141728239462,
      0.03669678732389594,
      0.047643978123449185,
      0.03992711517588858,
      0.03697748352386003,
      0.03556847050533522,
      0.044354490123444446,
      0.09709473696903435,
      0.060791040405561145,
      0.04264420872540587,
      0.0401418914744578,
      0.03774318980282256,
      0.03598048489218397
    ],
    "val_loss": [
      0.39042947415463225,
      0.4060536323282533,
      0.4580335380342192,
      0.6132218660708673,
      0.6003470773379246,
      0.7067220752556881,
      0.7510379518934353,
      0.6741209168544786,
      0.8948967990894875,
      0.6720497601804976,
      0.5916460527185194,
      0.7013774829621087,
      0.637716510521616,
      0.6661014224865479,
      0.582890682386424,
      0.44739357670713326,
      0.34421465942959584,
      0.5505788579583168,
      0.4507255754338767,
      0.3834859614020693,
      0.40413643749888073,
      0.4599512697604602,
      0.4515885165039294,
      0.4295071575857565,
      0.3790568473765593,
      0.3711372975728469,
      0.4081371143549502,
      0.3781133256004956,
      0.44518727587904044,
      0.39063199328448245,
      0.48082001099507965,
      0.3752542222688298,
      0.37233354637544314,
      0.35562978133469997,
      0.45505642297560583,
      0.37782342640939587,
      0.40318504598683225,
      0.5214589893639444,
      0.30246140082885403,
      0.3623385076037424,
      0.35426665762227455,
      0.4211569891986019,
      0.37893343815011177,
      0.39930380581024877,
      0.43352842351455173,
      0.3960551718662599,
      0.4224460637854959,
      0.4279561298871469,
      0.492019043215913,
      0.3879015772731718,
      0.40667602386838664,
      0.4461994534748757,
      0.4751267058406761,
      0.476664147182496,
      0.4374906702580566,
      0.3361987426073965,
      0.37718089661020004,
      0.39168390654875135,
      0.3470494071612815,
      0.4582690142853531,
      0.5243389033539566,
      0.3972591098732577,
      0.40421953442210923,
      0.36073388904333115,
      0.43381805587671474,
      0.40823735740191924,
      0.39240642094505046,
      0.3964310052241394,
      0.3489903238005267,
      0.42915825395883916,
      0.4331896343006345,
      0.3254196344244623,
      0.38151629642990537,
      0.37223885575097476,
      0.37410651419512525,
      0.43887787666506395,
      0.42463979515843764,
      0.4489942537810274,
      0.3742229339962234,
      0.40023574616737706,
      0.3891612642628704,
      0.4269880564180677,
      0.48928737719794235,
      0.3475741998521154,
      0.4071721371954787,
      0.42591618180810337,
      0.42034078857855883,
      0.41511095742622534,
      0.35983200448894215
    ],
    "best_epoch": 39,
    "best_val_loss": 0.30246140082885403,
    "test_loss": 0.3632998338601949,
    "tracker": {
      "initial_train_loss": 0.4078489480670289,
      "train_threshold": 0.1359496493556763,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.30246140082885403,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/gru-other-value/trial_20_090a6c/best_model.pt",
    "last": "scripts/outputs/gru-other-value/trial_20_090a6c/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/gru-other-value/trial_20_090a6c/config.yaml"
}