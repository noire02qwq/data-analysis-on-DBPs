epoch,train_loss,val_loss
1,1.045250,0.319431
2,0.845218,0.267547
3,0.322399,0.191510
4,0.233055,0.349942
5,0.228599,0.263613
6,0.223846,0.206266
7,0.210909,0.746815
8,0.210543,0.222247
9,0.183576,0.903268
10,0.200633,0.911131
11,0.205306,0.299641
12,0.183276,0.285845
13,0.179849,0.275798
14,0.168221,0.278197
15,0.169030,0.345021
16,0.164745,0.275684
17,0.168412,0.528042
18,0.174072,0.507412
19,0.164042,0.281078
20,0.156832,0.669993
21,0.167788,0.342509
22,0.174167,0.289559
23,0.159547,0.321295
24,0.153708,0.316074
25,0.160628,0.281715
26,0.154821,0.566143
27,0.152579,0.297618
28,0.191257,0.279186
29,0.157608,0.283650
30,0.168228,0.395164
31,0.153593,0.250686
32,0.157950,0.287010
33,0.199629,0.272402
34,0.168713,0.291712
35,0.153099,0.297390
36,0.150514,0.273194
37,0.190764,0.279108
38,0.157049,0.286646
39,0.188605,0.296261
40,0.161000,0.274248
41,0.176649,0.276537
42,0.164157,0.304898
43,0.153891,0.296018
44,0.150507,0.295803
45,0.156022,0.293153
46,0.150633,0.290978
47,0.149095,0.286773
48,0.149960,0.320456
49,0.148194,0.309931
50,0.142417,0.298875
51,0.152080,0.277232
52,0.137720,0.621354
53,0.156360,0.300001
54,0.143653,0.270186
55,0.157754,0.287014
56,0.149525,0.282525
57,0.141347,0.268620
58,0.141152,0.262856
59,0.144136,0.268610
60,0.135750,0.278454
61,0.133817,0.260791
62,0.135975,0.324130
63,0.173291,0.282639
64,0.149676,0.294188
65,0.135968,0.295741
66,0.148631,0.285662
67,0.145193,0.451481
68,0.134676,0.273327
69,0.143230,0.273526
70,0.134532,0.275969
71,0.132250,0.270279
72,0.130462,0.278536
73,0.136063,0.361470
74,0.128065,0.276220
75,0.125519,0.263158
76,0.132889,0.292960
77,0.133736,0.275744
78,0.130226,0.291387
79,0.130668,0.291021
80,0.142333,0.231564
