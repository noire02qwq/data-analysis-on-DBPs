epoch,train_loss,val_loss
1,0.422739,0.297369
2,0.091342,0.189555
3,0.048729,0.220605
4,0.040580,0.230706
5,0.038429,0.231701
6,0.034703,0.261253
7,0.032111,0.304802
8,0.030267,0.269466
9,0.029944,0.286738
10,0.030389,0.304790
11,0.029438,0.298254
12,0.027778,0.283368
13,0.027218,0.305257
14,0.030142,0.322097
15,0.033222,0.372843
16,0.027002,0.308659
17,0.026388,0.277898
18,0.027242,0.271785
19,0.024133,0.269724
20,0.023234,0.277960
21,0.023370,0.277131
22,0.022572,0.284728
23,0.024344,0.275310
24,0.022966,0.281369
25,0.022778,0.276288
26,0.021748,0.282935
27,0.021305,0.276242
28,0.023119,0.281840
29,0.021490,0.282320
30,0.022537,0.289959
31,0.021779,0.292036
32,0.022120,0.288243
33,0.021151,0.288894
34,0.021234,0.304121
35,0.023393,0.299954
36,0.020815,0.312558
37,0.021541,0.307580
38,0.020807,0.301196
39,0.020096,0.317513
40,0.021154,0.323774
41,0.021075,0.321997
42,0.020239,0.319691
43,0.021857,0.312565
44,0.020589,0.325137
45,0.020692,0.330624
46,0.022126,0.321138
47,0.021142,0.333198
48,0.020277,0.328063
49,0.020408,0.320819
50,0.019895,0.336226
51,0.019887,0.334847
52,0.019508,0.335415
53,0.021423,0.327376
54,0.021685,0.371065
55,0.020127,0.328095
56,0.019769,0.331663
57,0.019852,0.340653
58,0.020049,0.335457
59,0.020468,0.337005
60,0.019454,0.341992
61,0.018879,0.332686
62,0.036984,0.342046
63,0.028466,0.343111
64,0.023696,0.358532
65,0.023217,0.348539
66,0.022774,0.360373
67,0.022439,0.366665
68,0.021268,0.359140
69,0.021811,0.379920
70,0.022909,0.351125
71,0.022458,0.367795
72,0.021727,0.365396
73,0.020397,0.368181
74,0.020594,0.370795
75,0.020415,0.377789
76,0.020027,0.374563
77,0.019807,0.376933
78,0.020435,0.400290
79,0.020197,0.375399
80,0.019336,0.400962
