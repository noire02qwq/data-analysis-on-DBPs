epoch,train_loss,val_loss
1,2.317568,0.322888
2,0.997091,0.403420
3,1.574617,0.362200
4,0.989107,0.358373
5,0.820709,0.593940
6,0.822263,0.264819
7,0.407796,0.381078
8,0.318522,0.414060
9,0.237668,0.395078
10,0.225392,0.364953
11,0.193243,0.316464
12,0.193807,0.330998
13,0.177169,0.396129
14,0.186146,0.420523
15,0.168427,0.631460
16,0.170407,0.370679
17,0.165214,0.398360
18,0.155023,0.411522
19,0.169049,0.349351
20,0.168819,0.328072
21,0.162193,0.479096
22,0.151915,0.379788
23,0.155732,0.474606
24,0.156388,0.341466
25,0.145731,0.545058
26,0.157262,0.560693
27,0.146744,0.404832
28,0.144887,0.651365
29,0.153287,0.390915
30,0.151153,0.348394
31,0.132921,0.489196
32,0.132499,0.486457
33,0.138423,0.454444
34,0.156587,0.445838
35,0.149938,0.334946
36,0.170184,0.381672
37,0.142222,0.352389
38,0.135435,0.424273
39,0.117433,0.426743
40,0.142986,0.422830
41,0.117962,0.436113
42,0.121892,0.483893
43,0.110594,0.591025
44,0.112858,0.330033
45,0.118556,0.355305
46,0.126026,0.477180
47,0.108163,0.535150
48,0.113718,0.353568
49,0.118373,0.386742
50,0.130805,0.595079
51,0.142982,0.427029
52,0.131503,0.562838
53,0.138719,0.407140
54,0.109069,0.351242
55,0.110405,0.716187
56,0.108303,0.407535
57,0.119468,0.361836
58,0.118805,0.350993
59,0.113058,0.690810
60,0.118713,0.495485
61,0.103680,0.491852
62,0.102937,0.479664
63,0.111993,0.632612
64,0.133264,1.076557
65,0.125787,0.518766
66,0.108122,0.454709
67,0.100541,0.368243
68,0.115396,0.390246
69,0.112479,0.416761
70,0.107200,0.350360
71,0.105520,0.501096
72,0.125649,0.328266
73,0.133329,0.382935
74,0.124420,0.478176
75,0.103532,0.566656
76,0.107189,0.494769
77,0.121577,0.357190
78,0.130099,0.448175
79,0.116481,0.637375
80,0.104465,0.672697
