epoch,train_loss,val_loss
1,0.893046,0.370632
2,0.241200,0.187854
3,0.142496,0.170745
4,0.125275,0.225627
5,0.122962,0.665481
6,0.129118,0.220635
7,0.134772,0.274449
8,0.121110,0.284243
9,0.112971,0.378341
10,0.122143,0.642292
11,0.119582,0.298193
12,0.105358,0.302785
13,0.106917,0.291127
14,0.114345,0.274512
15,0.116699,0.266518
16,0.103332,0.280658
17,0.104896,0.597859
18,0.124864,0.279978
19,0.113819,0.268667
20,0.108707,0.276680
21,0.120059,0.287510
22,0.116664,0.289514
23,0.116421,0.276513
24,0.114957,0.310962
25,0.117889,0.284009
26,0.107043,0.270719
27,0.101493,0.297024
28,0.101542,0.274948
29,0.103081,1.267185
30,0.319402,0.208237
31,0.214580,0.226741
32,0.126004,0.316595
33,0.120636,0.221105
34,0.114073,0.217278
35,0.112473,0.225090
36,0.104823,0.238880
37,0.106280,0.240193
38,0.106048,0.269363
39,0.103486,0.279342
40,0.106198,0.284944
41,0.108251,0.279333
42,0.119155,0.379182
43,0.108647,0.362286
44,0.103231,0.274241
45,0.102706,0.279679
46,0.104612,0.371935
47,0.101396,0.268854
48,0.109210,0.281262
49,0.099808,0.389327
50,0.110590,0.269685
51,0.102909,0.428188
52,0.102287,0.328748
53,0.099639,0.294575
54,0.102903,0.548867
55,0.104880,0.412453
56,0.107765,0.264078
57,0.099417,0.340120
58,0.100048,0.511831
59,0.101820,0.506272
60,0.109930,0.556611
61,0.106186,0.261505
62,0.100156,0.330364
63,0.098404,0.281322
64,0.107912,0.306584
65,0.104382,0.255107
66,0.106224,0.508137
67,0.107991,0.357792
68,0.113008,0.324545
69,0.107554,0.298923
70,0.100113,0.280328
71,0.098609,0.431788
72,0.100354,0.353926
73,0.108736,1.239017
74,0.162019,0.250885
75,0.105678,0.311976
76,0.110796,0.290727
77,0.127197,0.344699
78,0.107400,0.367377
79,0.105928,0.261538
80,0.104881,0.288291
