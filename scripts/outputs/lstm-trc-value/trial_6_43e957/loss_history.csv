epoch,train_loss,val_loss
1,1.003835,0.346010
2,1.003821,0.343901
3,1.003839,0.346733
4,1.003835,0.345664
5,1.003748,0.345737
6,1.003824,0.346349
7,1.003913,0.347725
8,1.003735,0.345084
9,1.003737,0.344933
10,1.003755,0.345673
11,1.003867,0.345474
12,1.003713,0.347526
13,1.003717,0.346027
14,1.003707,0.346584
15,1.003986,0.343591
16,1.003724,0.347257
17,1.003742,0.346271
18,1.003722,0.346075
19,1.003702,0.346543
20,1.003720,0.344729
21,1.003701,0.346186
22,1.003734,0.347461
23,1.003699,0.345079
24,1.003741,0.344687
25,1.003740,0.346935
26,1.003729,0.345896
27,1.003696,0.346011
28,1.003726,0.346575
29,1.003795,0.345843
30,1.003705,0.345357
31,1.003713,0.345641
32,1.003721,0.346089
33,1.003682,0.345912
34,1.003696,0.345163
35,1.003722,0.346146
36,1.003728,0.345430
37,1.003687,0.345532
38,1.003719,0.345713
39,1.003707,0.345347
40,1.003690,0.346199
41,1.003688,0.346219
42,1.003684,0.345818
43,1.003712,0.345204
44,1.003684,0.345697
45,1.003683,0.345921
46,1.003696,0.346519
47,1.003738,0.346201
48,1.003688,0.346049
49,1.003702,0.346152
50,1.003721,0.344963
