epoch,train_loss,val_loss
1,0.873221,1.155805
2,0.315783,0.200802
3,0.219191,0.233085
4,0.181962,0.208410
5,0.189484,0.257211
6,0.164042,0.363210
7,0.189968,0.277128
8,0.162501,0.264623
9,0.150861,0.540348
10,0.154933,0.278242
11,0.170145,0.325327
12,0.148092,0.287947
13,0.144100,0.371012
14,0.149604,0.282351
15,0.183521,0.277215
16,0.153683,0.278516
17,0.164533,0.319609
18,0.140861,0.297032
19,0.141870,0.333156
20,0.145376,0.261304
21,0.142074,0.282115
22,0.139851,0.324776
23,0.155630,0.277755
24,0.139151,0.272110
25,0.136675,0.271830
26,0.137768,0.287975
27,0.144168,0.282585
28,0.141548,0.284254
29,0.139349,0.284825
30,0.140910,0.288592
31,0.136773,0.367813
32,0.140128,0.281636
33,0.135962,0.287869
34,0.144587,0.328700
35,0.134292,0.284752
36,0.137701,0.278056
37,0.132278,0.267820
38,0.212896,0.311744
39,0.249824,0.287705
40,0.179171,0.329820
41,0.156859,0.305500
42,0.143570,0.397229
43,0.139481,0.269872
44,0.141128,0.300060
45,0.146784,0.283437
46,0.145495,0.270521
47,0.137880,0.295745
48,0.137679,0.264288
49,0.140243,0.276202
50,0.133916,0.270849
51,0.134705,0.293166
52,0.141476,0.272409
53,0.134760,0.302031
54,0.131219,0.302924
55,0.131892,0.302894
56,0.129902,0.254073
57,0.130854,0.282289
58,0.130871,0.289793
59,0.126995,0.265005
60,0.128464,0.320047
61,0.137140,0.368759
62,0.149281,0.284238
63,0.150186,0.269401
64,0.126484,0.260701
65,0.126254,0.288613
66,0.126312,0.272919
67,0.128379,0.269310
68,0.121645,0.465153
69,0.122553,0.387430
70,0.131222,0.279703
71,0.123692,0.275117
72,0.121585,0.333476
73,0.120769,0.263755
74,0.126585,0.253429
75,0.124803,0.257732
76,0.127072,0.294216
77,0.122029,0.279000
78,0.117177,0.379785
79,0.120224,0.285562
80,0.118421,0.280464
