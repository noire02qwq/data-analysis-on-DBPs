epoch,train_loss,val_loss
1,0.989289,0.286187
2,0.552696,0.208552
3,0.168233,0.191569
4,0.135448,0.163284
5,0.116919,0.174149
6,0.104466,0.199309
7,0.092083,0.205183
8,0.076462,0.201715
9,0.067544,0.198081
10,0.061046,0.278528
11,0.054799,0.291674
12,0.053747,0.253321
13,0.055327,0.427454
14,0.049951,0.466846
15,0.042315,0.476155
16,0.042797,0.466125
17,0.041952,0.502766
18,0.053128,0.453354
19,0.049764,0.513682
20,0.042988,0.422960
21,0.040654,0.480439
22,0.042073,0.443781
23,0.041511,0.407391
24,0.037159,0.493563
25,0.038834,0.469365
26,0.046989,0.447612
27,0.040398,0.481638
28,0.063416,0.572551
29,0.044675,0.491084
30,0.032982,0.449558
31,0.031472,0.470641
32,0.031805,0.472875
33,0.032317,0.430582
34,0.033152,0.444272
35,0.031833,0.463775
36,0.032349,0.428033
37,0.031366,0.433928
38,0.030023,0.443264
39,0.031164,0.359773
40,0.030684,0.398897
41,0.030661,0.395523
42,0.029981,0.524850
43,0.029980,0.519026
44,0.031806,0.423984
45,0.035207,0.477442
46,0.054523,0.371182
47,0.031915,0.415304
48,0.028731,0.509878
49,0.028446,0.315277
50,0.028213,0.368462
51,0.027910,0.319781
52,0.025762,0.346520
53,0.026358,0.342549
54,0.029609,0.393840
55,0.026136,0.342086
56,0.026897,0.323228
57,0.027710,0.298859
58,0.033565,0.328057
59,0.031662,0.325335
60,0.026142,0.338650
61,0.025761,0.307885
62,0.025671,0.302224
63,0.025774,0.303782
64,0.026584,0.308887
65,0.028292,0.322440
66,0.024695,0.345915
67,0.025282,0.340266
68,0.028652,0.421750
69,0.025878,0.345462
70,0.025294,0.392144
71,0.025553,0.429048
72,0.024558,0.338207
73,0.022411,0.313282
74,0.022061,0.354415
75,0.024975,0.317807
76,0.022050,0.366610
77,0.024864,0.352888
78,0.025736,0.380641
79,0.022954,0.345688
80,0.023002,0.320741
