{
  "model_name": "mlp-other-rate/trial_30_7f1ebd",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.21366514728712518,
    "mid_layer_count": 15,
    "mid_layer_size": 345
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 329,
    "learning_rate": 0.0013002970214298015,
    "weight_decay": 0.001456322337128491,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113
    ],
    "train_loss": [
      0.430219059895099,
      0.26288468476524407,
      0.23179707038534061,
      0.21424339789841773,
      0.20399516862575795,
      0.198873344189528,
      0.18925225971722492,
      0.18478403771425161,
      0.17829668276076932,
      0.17491477563128585,
      0.17238100485856134,
      0.16789361515706963,
      0.1660893294423161,
      0.161384915201908,
      0.16279196277406047,
      0.15977683509310556,
      0.1589765946044868,
      0.15300830712818134,
      0.15468530929917368,
      0.15254831683557726,
      0.15123915960539178,
      0.14952659100989857,
      0.14840095300225492,
      0.14903203917121569,
      0.14569772733112615,
      0.1442899003074437,
      0.14354197980846548,
      0.1435072056197964,
      0.1411447010632354,
      0.14086419196580544,
      0.14513540996373342,
      0.14108954800179122,
      0.1407016984671125,
      0.13880635083597126,
      0.13525968815475747,
      0.13631940879340568,
      0.1363268502901431,
      0.13661863542558017,
      0.13671604736018572,
      0.13302320932511674,
      0.13221889046456123,
      0.13347080243649148,
      0.13196042880775258,
      0.13222812929153901,
      0.1325620046117677,
      0.13036326255330127,
      0.12955069012095097,
      0.13080847838185364,
      0.12930617870914898,
      0.1292942128951287,
      0.12854620557815494,
      0.12617135972354185,
      0.1276241000655708,
      0.1288380508438678,
      0.12679025711058775,
      0.12734710576615774,
      0.12624875548127953,
      0.12412952174508553,
      0.12445493088246706,
      0.12633987323783832,
      0.12276515207148748,
      0.12155523946200077,
      0.12407671287369122,
      0.12556505892110398,
      0.12382574565613068,
      0.12346504833845526,
      0.12317334750180767,
      0.12268459461457366,
      0.12258227790522845,
      0.12386285603665706,
      0.12012197877475854,
      0.12132253504815531,
      0.12101913425973924,
      0.119355731355595,
      0.12191440945079292,
      0.12071102119030373,
      0.12233670155162717,
      0.12036339297179628,
      0.11914971933674819,
      0.12003168632577878,
      0.11877967539664383,
      0.11997442060231918,
      0.11992241309075523,
      0.11976939621928595,
      0.11740931939752271,
      0.11794076973391747,
      0.11829277326765275,
      0.11918135931196427,
      0.12018756980335425,
      0.11868591508085052,
      0.11693903876553596,
      0.11642132315396682,
      0.11685361285211797,
      0.11800980035037857,
      0.11661159606787136,
      0.11569793221888143,
      0.11764860663538165,
      0.11810558823235008,
      0.11639537541181415,
      0.11635285745321818,
      0.11662364001359586,
      0.11638554465838002,
      0.11550805520069422,
      0.1154685062076753,
      0.11588019424004851,
      0.11489516097656606,
      0.11454809503701481,
      0.114469001840909,
      0.1169039117723795,
      0.1154519345959206,
      0.11451123511966312,
      0.11613248826399744,
      0.11461150450770552
    ],
    "val_loss": [
      0.3744117704604914,
      0.4109606714885749,
      0.4810185858054075,
      0.48098580286709847,
      0.4378376836280623,
      0.4918178170384047,
      0.5296275187573747,
      0.49065401354235805,
      0.5519361291816849,
      0.6363752595991075,
      0.5469908010683017,
      0.5778615371686613,
      0.5418638972732835,
      0.529341645833261,
      0.5585835275803498,
      0.5434122355086004,
      0.562809539327543,
      0.5188714335153917,
      0.5907567819792353,
      0.5578776694120404,
      0.5402801284889975,
      0.5041189689657646,
      0.6059271513344999,
      0.5563752203733622,
      0.5512959744134349,
      0.5117386340202685,
      0.5868739127532807,
      0.5543211627149296,
      0.5319438070148051,
      0.5102746270820052,
      0.48437256851417576,
      0.5891923668364921,
      0.6008854276048923,
      0.5356377366015654,
      0.5153567297774517,
      0.49884662323012324,
      0.4893054791820977,
      0.5473986447125138,
      0.526043480201931,
      0.5606018052085074,
      0.4967792779519529,
      0.49443523767822517,
      0.5427722869072845,
      0.5311167551148794,
      0.5400679880005871,
      0.5236654384184384,
      0.5228546995156539,
      0.5247836363083588,
      0.5335120198344756,
      0.5579995451751584,
      0.550756134021425,
      0.49769570041380956,
      0.46561981172797207,
      0.5108913795409088,
      0.528737344784651,
      0.49868948903983223,
      0.5397886163103366,
      0.5073715906389459,
      0.5022781676250303,
      0.5378206735287241,
      0.5142407517322524,
      0.512122906334029,
      0.4460798537838245,
      0.4988477859445318,
      0.4756800438472611,
      0.48157055035322727,
      0.49318606286437927,
      0.5030364559617585,
      0.47280062599899525,
      0.4980594888106435,
      0.5286513525122654,
      0.4960012765612431,
      0.48668387945362196,
      0.4992941443702418,
      0.5835245059457368,
      0.48431915523941643,
      0.5099751649279437,
      0.49856293084557185,
      0.49587504595161197,
      0.5301170301160769,
      0.5413953823243787,
      0.5006549237909431,
      0.5086683948507565,
      0.46372658886952317,
      0.5222794002535457,
      0.4982240284720581,
      0.5160294525816055,
      0.48163756076804176,
      0.48081038872638865,
      0.5239560940397714,
      0.5086039577415603,
      0.475215254527723,
      0.48390849255426915,
      0.5213930892105588,
      0.47556850866464795,
      0.47987884522198204,
      0.5259021919198379,
      0.48268043787001136,
      0.454672606690915,
      0.4881572905860975,
      0.5157820332996146,
      0.5437328860966745,
      0.4982148808499653,
      0.565692507542536,
      0.4568649095734079,
      0.46634170222960547,
      0.46102453237343693,
      0.5295693843798366,
      0.5156844527109298,
      0.49744970741386185,
      0.4698289064143946,
      0.5514207505269679,
      0.4761727528479285
    ],
    "best_epoch": 63,
    "best_val_loss": 0.4460798537838245,
    "best_val_abs_mse": 0.5666128396987915,
    "test_loss": 0.51935396823836,
    "test_abs_mse": 1.2166332006454468,
    "tracker": {
      "initial_train_loss": 0.430219059895099,
      "train_threshold": 0.14340635329836635,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4460798537838245,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-rate/trial_30_7f1ebd/best_model.pt",
    "last": "scripts/outputs/mlp-other-rate/trial_30_7f1ebd/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-rate/trial_30_7f1ebd/config.yaml"
}