{
  "model_name": "gru-other-value/trial_39_8871a1",
  "model_type": "GRU",
  "model_format": "torch",
  "model_params": {
    "history_length": 127,
    "units": 251,
    "num_layers": 2,
    "dropout": 0.3193760297730812
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 169,
    "learning_rate": 0.0012124268556679056,
    "weight_decay": 0.0006620419083285256,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7670,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 127,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124
    ],
    "train_loss": [
      0.3316499566627761,
      0.22745816232794422,
      0.19910433421195564,
      0.17343912319106572,
      0.14398866715067524,
      0.1361724881044889,
      0.12450498371558674,
      0.12131556266192663,
      0.09819999914300644,
      0.08531706579408403,
      0.08555178473056373,
      0.07947416363631264,
      0.07138499939593218,
      0.07782654307024964,
      0.0664665454083075,
      0.06063510121430381,
      0.0707714051197646,
      0.06292960003523504,
      0.05517741172116692,
      0.05526767213339523,
      0.05371980419603445,
      0.04684206393184298,
      0.05346261507247464,
      0.06018366818710909,
      0.0550357799093097,
      0.04507010382742195,
      0.0436926914789414,
      0.04306970750755173,
      0.04502969554672807,
      0.03933276051686982,
      0.04253652676687402,
      0.04326048964413546,
      0.04175416097928912,
      0.05339035519982799,
      0.04096288491608733,
      0.058314262709375154,
      0.03889677242328555,
      0.04033369392282882,
      0.03832994961195578,
      0.039108007893723956,
      0.03815595154034889,
      0.03644807854572595,
      0.03930590067500785,
      0.04476820891565186,
      0.03673154153561188,
      0.03788962500895989,
      0.04366312228395777,
      0.0398771716944747,
      0.036536151060234695,
      0.03534092634474322,
      0.04172330117326672,
      0.04092865286679086,
      0.03856907606882564,
      0.037128940300416136,
      0.03539684503576008,
      0.03248791005462408,
      0.03528759539506193,
      0.03961467704404208,
      0.033807823162967876,
      0.03449310277099327,
      0.044505141915406214,
      0.03586421140422255,
      0.03524141430033971,
      0.03184448900490494,
      0.1276364353564331,
      0.10744930969203932,
      0.07081614067241297,
      0.05648894561296802,
      0.060084744220820524,
      0.04268423431253029,
      0.040187580763535985,
      0.04677786419199685,
      0.04139790629683915,
      0.07388969425553993,
      0.042505309115148195,
      0.0342312713611429,
      0.03764864594943948,
      0.0329488207633465,
      0.03554533473137072,
      0.03704515203075894,
      0.03417830604870441,
      0.03259694306337732,
      0.06255894095273846,
      0.059272049310601364,
      0.03980476999560655,
      0.03397456688837985,
      0.03366386280789719,
      0.0322016619366862,
      0.031576033751085655,
      0.03228007694232767,
      0.03458536195931798,
      0.031989894677900664,
      0.03372854950948287,
      0.03293425495720516,
      0.029978752941272016,
      0.03237845191763619,
      0.029880566560363364,
      0.035018290045781664,
      0.030328938207131322,
      0.05384605428424932,
      0.03259612758154586,
      0.029131581457489626,
      0.028961212491079913,
      0.03021166774175935,
      0.029147915087514003,
      0.02948899534925566,
      0.029936147923186673,
      0.02957793988792573,
      0.029756261922924195,
      0.02993541298023725,
      0.0333282046146312,
      0.029948178786089866,
      0.030374825610068896,
      0.0325840952095844,
      0.03194424430445089,
      0.029758141360293002,
      0.03107803371119297,
      0.030793992344732003,
      0.031351760478090435,
      0.029154773763680863,
      0.029481885692704532,
      0.028943857462224314,
      0.03051113712017314,
      0.02901184409225391
    ],
    "val_loss": [
      0.38165499473403314,
      0.6141088783428698,
      0.573507147670506,
      0.7135217072007185,
      0.8243037297072525,
      0.798495340588207,
      0.43635516702058075,
      0.46745179199173065,
      0.4127099803063327,
      0.4861070091473664,
      0.5002262744807198,
      0.5002939232050658,
      0.5395349813703292,
      0.5267696407272252,
      0.41362505373126734,
      0.46800012565301563,
      0.47318157503258684,
      0.4194201377114493,
      0.5253207828158033,
      0.41657129218523015,
      0.42322106534938614,
      0.46813415107791295,
      0.46069741740733566,
      0.38575131020056985,
      0.4182091432774138,
      0.48571045048044115,
      0.4507084735808615,
      0.41313206558366733,
      0.4506787838603922,
      0.4461763766086744,
      0.43720852634953167,
      0.4975500011961617,
      0.43044063735775606,
      0.44600139465517624,
      0.44471985140960374,
      0.3970111899568649,
      0.4302028348792099,
      0.48259184658081233,
      0.4312932109136781,
      0.4535726129741012,
      0.4061662558756189,
      0.49699347817790723,
      0.4069922547274364,
      0.4413950867549388,
      0.4696951323149804,
      0.44198538047110963,
      0.46648661264937796,
      0.4279837646214905,
      0.5112635073993734,
      0.4755119121092522,
      0.45466388309162536,
      0.4518694197480193,
      0.49055388638091657,
      0.4153998810820237,
      0.4990517587138864,
      0.5225735881996012,
      0.5170087840118094,
      0.4604052160002157,
      0.48564945882308985,
      0.526794683817261,
      0.46462139781720624,
      0.5051772034498389,
      0.5145339897917416,
      0.4874044344632212,
      0.4167148516831284,
      0.4317566640362768,
      0.39519444691563793,
      0.3746704696092063,
      0.40388087004780054,
      0.3846247968113351,
      0.3904599964975597,
      0.404329951285959,
      0.38952986225485803,
      0.3628676668657157,
      0.40047749755179096,
      0.3969744973375412,
      0.37976768884562445,
      0.3831505831353322,
      0.4248892658574139,
      0.3646562167627369,
      0.3957972843891489,
      0.39012610834694195,
      0.3629433247411322,
      0.37223571310500186,
      0.40577104940653563,
      0.4413189181823752,
      0.43146177113814627,
      0.457222096724603,
      0.4496124317813776,
      0.42719250432031597,
      0.41047539490157975,
      0.44940818043169145,
      0.5139925803922251,
      0.4301807527413625,
      0.43446155981924717,
      0.4017846158655461,
      0.44494541071712257,
      0.43087638894954844,
      0.4351331456781861,
      0.43035647267263805,
      0.43238426814313063,
      0.4430613243249719,
      0.4484430109401663,
      0.44377220057977174,
      0.41636597874635706,
      0.4338316773939989,
      0.4052079789518953,
      0.4209857693020098,
      0.4179491214588017,
      0.40849488345894985,
      0.40848981301316956,
      0.4413428031443479,
      0.4038627359592272,
      0.42207662932976275,
      0.4169179429060328,
      0.4475563033389117,
      0.4217376003543774,
      0.4479417154531993,
      0.43182770262310605,
      0.4089111429265516,
      0.41581279447157227,
      0.41858726668054475,
      0.4159917900037623,
      0.427809568784551
    ],
    "best_epoch": 74,
    "best_val_loss": 0.3628676668657157,
    "test_loss": 0.4531205641105771,
    "tracker": {
      "initial_train_loss": 0.3316499566627761,
      "train_threshold": 0.1105499855542587,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3628676668657157,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/gru-other-value/trial_39_8871a1/best_model.pt",
    "last": "scripts/outputs/gru-other-value/trial_39_8871a1/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/gru-other-value/trial_39_8871a1/config.yaml"
}