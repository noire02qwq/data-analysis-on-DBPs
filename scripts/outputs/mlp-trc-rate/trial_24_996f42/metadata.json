{
  "model_name": "mlp-trc-rate/trial_24_996f42",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.16732638153243085,
    "mid_layer_count": 3,
    "mid_layer_size": 289
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 216,
    "learning_rate": 0.0009199434600101783,
    "weight_decay": 0.0005823734930545665,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.297677604425192,
      0.09166417866677673,
      0.07090717943632768,
      0.06186861674630562,
      0.0582121468013895,
      0.053913734390712384,
      0.054440988962652745,
      0.052684983201305824,
      0.05040415640387124,
      0.04900384390331984,
      0.0476753624751514,
      0.047862058043816325,
      0.04672445286124593,
      0.04776414669381159,
      0.04390430097979971,
      0.04759666931864664,
      0.04274944864737186,
      0.04183282629190622,
      0.0400002238523691,
      0.04305384856476241,
      0.041235692211340304,
      0.04399053027242682,
      0.04102754553425398,
      0.03875827773824418,
      0.03903558109626518,
      0.04177493198161678,
      0.039917458445139574,
      0.037689189698495516,
      0.037817983620973536,
      0.039631564367950546,
      0.03960274681525392,
      0.03887063088425922,
      0.03763482253664026,
      0.03928817879253776,
      0.037167558957822144,
      0.036393857097540866,
      0.03727932008945709,
      0.03781946079032338,
      0.037173905984721714,
      0.03471127366422536,
      0.03790188931299516,
      0.03624532405590938,
      0.035173944614755,
      0.035685164931341586,
      0.03647424873937516,
      0.035634723976025094,
      0.035242667414053026,
      0.034598218526532554,
      0.03462548409442892,
      0.03523244088149609,
      0.03482356100028267,
      0.03394509544008325,
      0.034882365930930595,
      0.03515648665054753,
      0.03541440961011836,
      0.03413290841425609,
      0.03399413370891924,
      0.03667034425907957,
      0.034761731815321315,
      0.03247371341568681,
      0.03437215456592847,
      0.03461555641750423,
      0.033486237755191516,
      0.03644884672644751,
      0.03323047175590597,
      0.03347891318459368,
      0.03303671753719227,
      0.03289161611820503,
      0.03319709328289458,
      0.033261105645660136,
      0.032331219721889425,
      0.032312712630686115,
      0.03550140134581179,
      0.03406519671589549,
      0.032725579851235774,
      0.032469199870016834,
      0.03368965179022457,
      0.03372408515401471,
      0.032994288103459064,
      0.03226195673925134
    ],
    "val_loss": [
      0.22740330007261858,
      0.2133169790584884,
      0.27122522033974084,
      0.2879586957261234,
      0.2880176430244646,
      0.29683918359572303,
      0.2783375574800069,
      0.3554369479417801,
      0.2811550036786559,
      0.33337308518187014,
      0.26486725067485595,
      0.27608384216081594,
      0.28093618737187925,
      0.3301755722679064,
      0.42621304128698245,
      0.2951207877365415,
      0.3075965676657454,
      0.3399817721750922,
      0.3173857347961671,
      0.39985357293647206,
      0.33887293312007083,
      0.31256883975988375,
      0.3184634235893895,
      0.3528375951115957,
      0.3693460604744757,
      0.36217092922526206,
      0.32435661744393274,
      0.3694883709271511,
      0.3341987663043473,
      0.31525144781359654,
      0.38451923674452093,
      0.29805461087983526,
      0.35161934415558854,
      0.3391413680450645,
      0.33092104478510553,
      0.3100035047995116,
      0.32099480978743045,
      0.3536984761764189,
      0.3329920972000339,
      0.3383586794851783,
      0.30954520364186006,
      0.3152500382708218,
      0.328003980710121,
      0.322999461673334,
      0.32399903987339157,
      0.3259766737590293,
      0.3732132612409706,
      0.32582301347555515,
      0.33034170725031525,
      0.3332375935273256,
      0.3748090239074416,
      0.318618439236087,
      0.3275731683223547,
      0.3032637894956652,
      0.35376176842137014,
      0.32401628702165125,
      0.3406593734989623,
      0.34079599786482884,
      0.31390219644872014,
      0.33456730217098474,
      0.36359476877186825,
      0.3414095244364824,
      0.3960547069232621,
      0.3393634821840389,
      0.3148389675303134,
      0.3407051715843692,
      0.34084452472761007,
      0.32221035966259276,
      0.29864818227148343,
      0.3125704042033521,
      0.35503378197283086,
      0.3029583513112125,
      0.29165173338915773,
      0.32946319728197454,
      0.34838734369078084,
      0.3039924660396433,
      0.294487871925631,
      0.3458772634496232,
      0.3030169693028142,
      0.30497457525151933
    ],
    "best_epoch": 2,
    "best_val_loss": 0.2133169790584884,
    "best_val_abs_mse": 0.16774998605251312,
    "test_loss": 5.3424048708956775,
    "test_abs_mse": 50.07268142700195,
    "tracker": {
      "initial_train_loss": 0.297677604425192,
      "train_threshold": 0.09922586814173066,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.2133169790584884,
      "patience_no_improve_epochs": 79,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_24_996f42/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_24_996f42/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_24_996f42/config.yaml"
}