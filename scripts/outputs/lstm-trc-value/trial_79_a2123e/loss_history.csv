epoch,train_loss,val_loss
1,1.000257,0.358129
2,0.999498,0.350729
3,0.999850,0.344044
4,0.999630,0.354475
5,0.999505,0.347175
6,0.999529,0.351681
7,0.999696,0.342889
8,0.999564,0.352079
9,0.999638,0.351990
10,0.999564,0.350406
11,0.999452,0.353758
12,0.999670,0.353752
13,0.999563,0.352560
14,0.999428,0.351514
15,0.999452,0.347857
16,0.999446,0.348113
17,0.999449,0.355407
18,0.999589,0.353687
19,0.999415,0.349667
20,0.999531,0.349661
21,0.999500,0.354223
22,0.999392,0.349502
23,0.999498,0.352145
24,0.999407,0.348142
25,0.999549,0.350844
26,0.999393,0.349558
27,0.999574,0.352427
28,0.999384,0.350495
29,0.999462,0.351074
30,0.999416,0.348837
31,0.999383,0.354173
32,0.999409,0.351283
33,0.999397,0.350806
34,0.999397,0.351713
35,0.999371,0.349936
36,0.999453,0.353431
37,0.999494,0.349520
38,0.999374,0.352819
39,0.999409,0.352495
40,0.999554,0.354217
41,0.999419,0.349074
42,0.999355,0.350219
43,0.999433,0.349964
44,0.999351,0.350347
45,0.999501,0.350974
46,0.999399,0.352359
47,0.999547,0.350297
48,0.999461,0.347577
49,0.999333,0.350682
50,0.999402,0.351237
