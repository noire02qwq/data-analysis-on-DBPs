epoch,train_loss,val_loss
1,1.001419,0.342921
2,0.999641,0.334479
3,1.000067,0.353336
4,0.999893,0.353294
5,0.999688,0.345841
6,0.999851,0.347926
7,0.999819,0.348242
8,0.999833,0.351180
9,0.999742,0.350952
10,0.999738,0.349746
11,0.999713,0.350870
12,0.999774,0.351285
13,0.999907,0.347158
14,0.999718,0.349800
15,0.999700,0.350785
16,0.999815,0.349512
17,0.999893,0.350151
18,0.999722,0.350584
19,0.999712,0.351634
20,0.999723,0.350071
21,0.999741,0.351142
22,0.999740,0.349486
23,0.999709,0.346503
24,0.999736,0.349583
25,0.999683,0.350485
26,0.999680,0.349788
27,0.999735,0.350105
28,0.999686,0.350136
29,0.999722,0.351551
30,0.999781,0.349914
31,0.999726,0.349969
32,0.999801,0.348889
33,0.999773,0.347179
34,0.999849,0.352214
35,0.999719,0.348596
36,0.999832,0.347683
37,0.999765,0.348637
38,0.999735,0.349978
39,0.999808,0.349810
40,0.999753,0.350077
41,0.999761,0.350556
42,0.999747,0.351901
43,0.999783,0.351183
44,0.999805,0.349111
45,0.999719,0.351221
46,0.999751,0.350722
47,0.999746,0.348505
48,0.999797,0.347874
49,0.999824,0.343382
50,0.999849,0.349286
