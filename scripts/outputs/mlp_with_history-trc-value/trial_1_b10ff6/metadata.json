{
  "model_name": "mlp_with_history-trc-value/trial_1_b10ff6",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 98,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.19851562950623675,
    "mid_layer_count": 11,
    "mid_layer_size": 766
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 289,
    "learning_rate": 0.0011112625378807623,
    "weight_decay": 0.004168759473714949,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7699,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 980,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122
    ],
    "train_loss": [
      0.6897653148075654,
      0.16603393509455633,
      0.1344043842587847,
      0.1341376955175666,
      0.12755537737494305,
      0.1362443887725993,
      0.11539019367198292,
      0.1118551709056907,
      0.11528846635642276,
      0.3095240291401092,
      0.5354466044619449,
      0.1798168266438125,
      0.1403940529180883,
      0.12848619098848515,
      0.12486400949941825,
      0.11667407371693113,
      0.12083666773198688,
      0.11246266022202628,
      0.11235186445924396,
      0.10911383632445183,
      0.11222216881959682,
      0.0878932473934042,
      0.08359713878147261,
      0.07597728180918605,
      0.07308974091492468,
      0.07154854343351737,
      0.10340626095545603,
      0.07762479856910295,
      0.07493264877309597,
      0.07687158983891267,
      0.06447033115009052,
      0.06588256819354418,
      0.06853153492763284,
      0.0750337690187555,
      0.06527136923371003,
      0.0646969789716776,
      0.3942757399361046,
      0.24158405283121712,
      0.12265309819750607,
      0.12073638447907424,
      0.10953962068861066,
      0.11690074536944074,
      0.16172404604978352,
      0.12893287126317954,
      0.10641043984703405,
      0.10585300506016762,
      0.10257468381970404,
      0.10321040995102576,
      0.10586914452353396,
      0.10534767157277561,
      0.10490865556198771,
      0.10161695629067971,
      0.10277223635809904,
      0.10684196975946829,
      0.16227301528065494,
      0.36719792522127126,
      0.12508615190343494,
      0.11063033949614252,
      0.10628660707787145,
      0.1064177247051961,
      0.10896819459202073,
      0.10257013713555578,
      0.10399711712786464,
      0.11243869348003703,
      0.11537541977839588,
      0.1064803888289429,
      0.10378660285437258,
      0.10128006345653769,
      0.10607559938220362,
      0.10242022447078038,
      0.2834561602034063,
      0.23952113889164547,
      0.1381417862013232,
      0.11367219711378931,
      0.11587622119441622,
      0.13794531893933,
      0.12550932506506032,
      0.1047093322095832,
      0.10293467053888308,
      0.10983726657091883,
      0.10171513638568863,
      0.10272584520140039,
      0.1084626323720947,
      0.10369425630655393,
      0.10243446256997818,
      0.286206792306979,
      0.4256643581884312,
      0.14322551475831294,
      0.12222210960521963,
      0.11428517540804302,
      0.10962206145194711,
      0.10722733195036445,
      0.10995177649603151,
      0.26774492447198806,
      0.1715219745782385,
      0.12579593532429004,
      0.11338374479794165,
      0.10826631738684644,
      0.10799234943709476,
      0.10609415359141873,
      0.10480517703386108,
      0.10546690339213115,
      0.10486185065855189,
      0.12739385221918492,
      0.10759260564082504,
      0.10142318175309416,
      0.09930315377039017,
      0.09968191970554416,
      0.09829575347213687,
      0.11611892581605372,
      0.09933280876405456,
      0.1010576253450835,
      0.09859072669115387,
      0.10373426039860084,
      0.10075538941448672,
      0.10145446395394801,
      0.09734694654000302,
      0.10116699777503868,
      0.10115849704483233,
      0.11263961119185115,
      0.20159880763711147,
      0.11526623961871003
    ],
    "val_loss": [
      0.4013644528826197,
      0.8739631933544925,
      0.3048536561317965,
      0.3003091153984298,
      0.27937115664164464,
      0.24953328622560836,
      0.5877699267609926,
      0.2915196006069194,
      0.4586716422331547,
      0.2734822857645368,
      0.2978590937164015,
      0.7885643451513644,
      0.30379590590423095,
      0.2478547117868048,
      0.5967317309699016,
      0.343937153192962,
      0.29418666860211395,
      0.4116765614866675,
      0.365062214052695,
      0.37050223427149886,
      0.403734969168143,
      0.34661128578517963,
      0.29172616706056864,
      0.47516642014557375,
      0.5188787544280022,
      0.5025094026688509,
      0.28226155659440394,
      0.2592183712535276,
      0.6918782235474554,
      0.31241648378307946,
      0.41933689505687194,
      0.43406910767366075,
      0.2888628029158551,
      0.3167930334482989,
      0.6184016633544586,
      0.3150224182252845,
      0.2783634040761226,
      0.331001718879906,
      0.4164768630426801,
      0.4148399613318061,
      0.3319246928469685,
      0.33705648758119633,
      0.6074548461480055,
      0.2899038533362264,
      0.30385519682491074,
      0.3677111535539438,
      0.45449804869887533,
      0.32313401950579024,
      0.30381292917369723,
      0.29485296678177253,
      0.385345008938077,
      0.5148786071252948,
      0.43892467403840163,
      0.34897566483227793,
      0.31549810296270303,
      0.2640817138650817,
      0.3023221984070664,
      0.2985711497014868,
      0.3304538006576414,
      0.35159844282099945,
      0.346976265805344,
      0.40797718160055174,
      0.3007452545665249,
      0.31060386963500947,
      0.29494130992202344,
      0.29300184269173596,
      0.37275810802835013,
      0.32999543271133464,
      0.32808908177483936,
      0.6394100541170843,
      0.28247669864066705,
      0.2293329790736476,
      0.48125615886406986,
      0.2725038551864867,
      0.2524756917261524,
      0.2731377891895032,
      0.2722437888997311,
      0.2776132775637918,
      0.2870240552975478,
      0.28212039449592374,
      0.37390627190470693,
      0.3045909866936014,
      0.3137183775166105,
      0.3028911896027669,
      0.3510522819174353,
      0.2827063130694414,
      0.2747327010364768,
      0.29315567193943226,
      0.379130260489078,
      0.28318475326244347,
      0.29676367187772146,
      0.30274797122657837,
      0.30452868643880426,
      0.2909960400212757,
      0.5311642119582899,
      0.4579381352234743,
      0.40575820681399216,
      0.4682495739255212,
      0.41278391587520075,
      0.31242257709542437,
      0.3021475616318291,
      0.3048207872530479,
      0.8139745319050229,
      0.4867225173436953,
      0.2963071601967255,
      0.3012771279645894,
      0.31746721317779697,
      0.2917644109365023,
      0.3145849093136762,
      0.2997782104118855,
      0.2960587218481891,
      0.37572984728337583,
      0.29188905807803134,
      0.28540951666829295,
      0.2966185018007538,
      0.2860547429820645,
      0.29179642967389013,
      0.31730468548432794,
      0.2941043562384066,
      0.32842531631405125,
      0.26315597821540104,
      0.3020121098713514
    ],
    "best_epoch": 72,
    "best_val_loss": 0.2293329790736476,
    "test_loss": 4.763511118563739,
    "tracker": {
      "initial_train_loss": 0.6897653148075654,
      "train_threshold": 0.2299217716025218,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.2293329790736476,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_1_b10ff6/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_1_b10ff6/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_1_b10ff6/config.yaml"
}