{
  "model_name": "gru-other-value/trial_30_4d7c16",
  "model_type": "GRU",
  "model_format": "torch",
  "model_params": {
    "history_length": 101,
    "units": 347,
    "num_layers": 4,
    "dropout": 0.4387103648669492
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 315,
    "learning_rate": 0.0017232133051092405,
    "weight_decay": 0.0063384410093246125,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7696,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 101,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92
    ],
    "train_loss": [
      0.35259624437202475,
      0.26226782145485933,
      0.2572600594673329,
      0.24637870313580343,
      0.24151785757485583,
      0.24356926294148215,
      0.23503981618958056,
      0.23581935508707208,
      0.24452075463857137,
      0.23246117500809027,
      0.2315970441876386,
      0.22899126496336378,
      0.2331455208248848,
      0.23074489857676186,
      0.24505334330447745,
      0.2333199260175507,
      0.22654319998736566,
      0.23378808418842587,
      0.23075218734732228,
      0.22444815921893424,
      0.23099829935373858,
      0.2248198755352667,
      0.2268134536523674,
      0.22474122629258897,
      0.22204194259161822,
      0.22819192979577735,
      0.2221436998196984,
      0.22143387219243202,
      0.21960599665682987,
      0.21920961038772938,
      0.22128939870241526,
      0.2178206215312476,
      0.21478189916588103,
      0.21824721260898575,
      0.21576800796623474,
      0.21126905825616416,
      0.21461786694336768,
      0.21458157227256502,
      0.21758012907684096,
      0.21282568100545549,
      0.21191661674994008,
      0.21026840888684045,
      0.20742501299867017,
      0.2060852983768975,
      0.21691810840783396,
      0.20874275872774284,
      0.20907997666410869,
      0.20355430316458806,
      0.20804941713453703,
      0.20099008184995137,
      0.2000798744550304,
      0.2064350982527723,
      0.19815020584607818,
      0.19662538275370478,
      0.20173644148231545,
      0.19831766495423048,
      0.19873494142956893,
      0.19603465516468715,
      0.19760814488414297,
      0.19763552514630953,
      0.1974850427669138,
      0.19740207941346877,
      0.19748301092504278,
      0.20339512922985017,
      0.19359461498677172,
      0.19211852679652572,
      0.1910328214074216,
      0.19143210681012043,
      0.18633430705767845,
      0.1894091078798575,
      0.18926885044453917,
      0.1959891071825786,
      0.20266382256619586,
      0.19378647246357372,
      0.1895013043478813,
      0.18600357702416281,
      0.18551987537769543,
      0.19371657807325746,
      0.1858441019914812,
      0.1864640990295399,
      0.18706862240053884,
      0.19216011661122284,
      0.18700365278203807,
      0.18845066172990507,
      0.18880990797192973,
      0.18394716173069642,
      0.1881517705056437,
      0.18390934073643103,
      0.1816849913157662,
      0.18346145649957557,
      0.18111645385018876,
      0.18254837075639477
    ],
    "val_loss": [
      0.45732803218914364,
      0.3611253934973728,
      0.38150381038110415,
      0.3633795009401744,
      0.3939626334670061,
      0.39067116794650425,
      0.35897113744191783,
      0.57991448758605,
      0.4043360382407725,
      0.40945611064305565,
      0.4464701336925615,
      0.4021038786022963,
      0.38316889334760024,
      0.5650819589768699,
      0.3760894242964105,
      0.4035599348609319,
      0.3830820570315073,
      0.4507896656583169,
      0.42041053877262297,
      0.3880209519031519,
      0.3909301678399126,
      0.41540194922935464,
      0.4095386690097655,
      0.3941123842479226,
      0.39556463656132806,
      0.38680538196049763,
      0.40689136723647573,
      0.3734730776109381,
      0.4104926019103941,
      0.37620699436900146,
      0.37902193177424504,
      0.43412210912761573,
      0.37447032345804626,
      0.378020943237279,
      0.3783577750632149,
      0.36854875270656484,
      0.34910032240127375,
      0.3762470744327157,
      0.37396031292434223,
      0.3721280403569073,
      0.35873098568823525,
      0.3476788384650282,
      0.3861214591045223,
      0.39268355914754066,
      0.5501512552271346,
      0.37652903563248186,
      0.39227351358907664,
      0.38165147709632347,
      0.422896995962023,
      0.4319126300379902,
      0.3956869946357733,
      0.4332445432504494,
      0.3834103547081262,
      0.39754749954995994,
      0.47159521830474543,
      0.36970321222872077,
      0.4737304578016618,
      0.4709436080145265,
      0.5138487113405488,
      0.7139346555633816,
      0.48916253554606864,
      0.5584668020556073,
      0.3913591519711974,
      0.40835702347898195,
      0.5321103284012771,
      0.5494791061846082,
      0.5653499978968126,
      0.6803767622677152,
      0.6031384833915505,
      0.6717322143073567,
      0.49041729210736507,
      0.49798831423956474,
      0.6782725396493595,
      0.461710732497141,
      0.5181456963102261,
      0.6699045359820663,
      0.5241368454016612,
      0.49915441598542437,
      0.5783785618172435,
      0.6395623666529884,
      0.7111022327162192,
      0.6387441228339058,
      0.6069365304387259,
      0.582362677522762,
      0.7048974774197904,
      0.5793433417370933,
      0.6343136180392996,
      0.5816803690112994,
      0.5641172656755962,
      0.582399830445201,
      0.5647771474040911,
      0.6855928749292196
    ],
    "best_epoch": 92,
    "best_val_loss": 0.6855928749292196,
    "test_loss": 0.6282652500909909,
    "tracker": {
      "initial_train_loss": 0.35259624437202475,
      "train_threshold": 0.11753208145734158,
      "best_tracking": false,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3476788384650282,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/gru-other-value/trial_30_4d7c16/best_model.pt",
    "last": "scripts/outputs/gru-other-value/trial_30_4d7c16/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/gru-other-value/trial_30_4d7c16/config.yaml"
}