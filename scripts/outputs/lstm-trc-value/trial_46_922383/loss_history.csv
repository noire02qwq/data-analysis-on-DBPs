epoch,train_loss,val_loss
1,0.411573,0.704906
2,0.102584,0.260139
3,0.057229,0.275683
4,0.049798,0.245200
5,0.041140,0.240586
6,0.038622,0.281524
7,0.036053,0.267893
8,0.044362,0.263018
9,0.043264,0.266660
10,0.033208,0.294741
11,0.028837,0.265477
12,0.038378,0.355680
13,0.042265,0.277248
14,0.034060,0.288781
15,0.031994,0.316935
16,0.027292,0.347383
17,0.037159,0.340067
18,0.031026,0.332443
19,0.026667,0.304231
20,0.026997,0.298306
21,0.024133,0.296132
22,0.024390,0.318545
23,0.024168,0.310954
24,0.026357,0.316913
25,0.023602,0.330253
26,0.024396,0.332568
27,0.026091,0.334430
28,0.022713,0.329739
29,0.024657,0.367479
30,0.025283,0.348198
31,0.022713,0.338765
32,0.029583,0.365664
33,0.026278,0.347396
34,0.021215,0.395958
35,0.029855,0.349868
36,0.022329,0.348718
37,0.023302,0.384685
38,0.023090,0.369089
39,0.026223,0.373985
40,0.023542,0.356727
41,0.023428,0.353687
42,0.021024,0.346477
43,0.022744,0.370971
44,0.021674,0.381079
45,0.021320,0.468235
46,0.036403,0.375310
47,0.022907,0.359037
48,0.025173,0.375880
49,0.021534,0.406708
50,0.021290,0.412062
51,0.020962,0.391406
52,0.021337,0.381649
53,0.024222,0.403518
54,0.022394,0.378088
55,0.025747,0.379346
56,0.022910,0.404874
57,0.019533,0.391591
58,0.027921,0.373580
59,0.024181,0.399471
60,0.022561,0.395706
61,0.019923,0.376553
62,0.020005,0.378795
63,0.024322,0.415821
64,0.023145,0.421977
65,0.021368,0.391427
66,0.022402,0.385723
67,0.019943,0.366639
68,0.022627,0.400977
69,0.019913,0.406209
70,0.020021,0.401983
71,0.021815,0.397036
72,0.021087,0.456249
73,0.020817,0.400090
74,0.019748,0.396890
75,0.019257,0.402885
76,0.026666,0.376620
77,0.019557,0.399453
78,0.019561,0.394504
79,0.021541,0.384020
80,0.020555,0.379347
