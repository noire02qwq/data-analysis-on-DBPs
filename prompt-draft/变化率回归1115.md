# 变化率回归

基于原来的回归实验与调参脚本，作如下改动尝试，用于与原有的直接回归效果进行对比：原始模型输出目标由数值变为**对RT阶段的变化率**，但程序最终输出目标还是数值，详细来说如下：

- 输入不变 模型输出由TRC-PPL1, TRC-PPL2, TOC-PPL1 ... 变为 (TRC-PPL1 - TRC-RT) / TRC-RT, (TRC-PPL2 - TRC-RT) / TRC-RT, (TOC-PPL1 - TOC-RT) / TOC-RT ...
- 训练时 先计算出(TRC-PPL1 - TRC-RT) / TRC-RT等一系列变化率值作为输出目标进行训练
- 验证/测试时 先推理出(TRC-PPL1 - TRC-RT) / TRC-RT等一系列变化率值，再根据TRC-RT等RT阶段的数值计算出TRC-PPL1等最终数值，train loss, val loss指标使用(TRC-PPL1 - TRC-RT) / TRC-RT等变化率值计算的MSE，但同时还需要输出TRC-PPL1等最终目标的MSE
- 模型本体继续使用以前的lstm_regressor.py等文件，配置文件也使用原有的yaml，但训练、测试、调参脚本要根据我的要求生成新文件，前面加rate_，比如rate_train_regression.py，rate_autotune_lstm.py等。脚本的输出目录也是前面加rate_，比如rate_lstm_regressor。