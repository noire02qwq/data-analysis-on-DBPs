{
  "model_name": "mlp-other-value/trial_27_081ee0",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.27891970486444984,
    "mid_layer_count": 3,
    "mid_layer_size": 482
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 142,
    "learning_rate": 0.001810086288712085,
    "weight_decay": 0.0004978040185992375,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116
    ],
    "train_loss": [
      0.33333194511189956,
      0.23122955945484328,
      0.21066115747634542,
      0.19735104022590608,
      0.18585523806623216,
      0.1778112882189166,
      0.17508567084274945,
      0.1675444529790827,
      0.16307590609409675,
      0.15612948316604802,
      0.15280548725114718,
      0.15100278921536203,
      0.14937322934264707,
      0.14394795783571307,
      0.14379610744552956,
      0.13944836056434295,
      0.1396047380213373,
      0.13571754929008945,
      0.13093152310242404,
      0.1324234850238292,
      0.1301805125582885,
      0.13439188393003945,
      0.12579791141762803,
      0.1258706031391075,
      0.12451241282376342,
      0.12261715345371375,
      0.12175907242972463,
      0.12205151599063024,
      0.12147054923129669,
      0.11987602197899153,
      0.12049900563773037,
      0.11935214258504868,
      0.12025926654356574,
      0.11869027136823591,
      0.11681391862438482,
      0.11753452188689444,
      0.1158812983566489,
      0.11496521451492808,
      0.11496449346960416,
      0.11348915269828687,
      0.11307740182624895,
      0.1140223467629833,
      0.11104379341067443,
      0.11221467354944145,
      0.11133681527845916,
      0.11081819833204219,
      0.10906321087468887,
      0.10864136396707053,
      0.1091929097158625,
      0.11023234641356246,
      0.11013684080022001,
      0.109300599939521,
      0.10885516243517063,
      0.11061538609672718,
      0.107951475109517,
      0.10849350148390476,
      0.10786550316965354,
      0.10746898816534346,
      0.10739887907925234,
      0.1085247620213882,
      0.10876548054196579,
      0.10668493794127266,
      0.10708856279495865,
      0.10653553530573845,
      0.10753691104121732,
      0.10538820150366131,
      0.10566494500158444,
      0.10816041489880535,
      0.10520252570693403,
      0.10473898176071336,
      0.10476611815717907,
      0.10621587238850319,
      0.10640909358392685,
      0.10495371775383397,
      0.10605065570451346,
      0.10254951229862766,
      0.1046498590968492,
      0.10343187464818764,
      0.10453041258333523,
      0.10481140266180711,
      0.10298088128908345,
      0.10570414856137404,
      0.10484239585762638,
      0.10177518887442463,
      0.10412241448731897,
      0.1045671166300682,
      0.10191365548162475,
      0.10378056447694949,
      0.10254023065852653,
      0.10503760200584467,
      0.10375786512103859,
      0.10437631351885703,
      0.10290055074038537,
      0.10102377807087871,
      0.10326761542305755,
      0.10205182940410062,
      0.10508752970733112,
      0.1011454015071879,
      0.1034397510281277,
      0.10252642015108945,
      0.10205995549699659,
      0.10239927825819474,
      0.1018243138360604,
      0.10037575874108727,
      0.10275737311081314,
      0.10261264991009461,
      0.10168238403347286,
      0.10238355450741202,
      0.10018272949655035,
      0.10170201164191964,
      0.10160067808810046,
      0.10224806222626953,
      0.10069793307357656,
      0.1024062563519468,
      0.10085904996186541,
      0.10038139903129462
    ],
    "val_loss": [
      0.43120210962648875,
      0.4970470451220067,
      0.5214914961846289,
      0.5683179612466676,
      0.5812472723201363,
      0.6158828400030821,
      0.5047862751755172,
      0.601552858743482,
      0.5292682805282627,
      0.5470278260236728,
      0.5818485374936087,
      0.5110101970637629,
      0.4650138260361677,
      0.44192931565517435,
      0.4804707023911847,
      0.5225618213236689,
      0.4457088905180286,
      0.4898550218450809,
      0.47992043345274327,
      0.4489112718555028,
      0.4758594007727629,
      0.47113954956660015,
      0.4415394636417577,
      0.45989579657416146,
      0.4745754176092719,
      0.45774330897424037,
      0.47489697786862267,
      0.4283093289254668,
      0.45682108195242055,
      0.4076116549040743,
      0.4146780087027007,
      0.4323561023452325,
      0.4571939903283547,
      0.40446645799511205,
      0.4344345077961505,
      0.41892639969637296,
      0.42816990421203793,
      0.42465022274120123,
      0.42242691153716183,
      0.4932103187470379,
      0.4589103590317829,
      0.45338939148151947,
      0.4262763828485312,
      0.4503073415534939,
      0.48663832569372156,
      0.4946059463266841,
      0.4299506867181755,
      0.39210031069145945,
      0.47300365718895804,
      0.458335123982972,
      0.39422442959454246,
      0.42755899567625477,
      0.44099074263058735,
      0.48643945857079446,
      0.4801306989378558,
      0.41869379821830166,
      0.4317822950239667,
      0.4601619774442233,
      0.45647173567624866,
      0.42119019400038404,
      0.4229630503111971,
      0.46830536134228734,
      0.3952816582636205,
      0.4381622468193848,
      0.4156627798687198,
      0.3907825608274894,
      0.41120288040109737,
      0.41916417587481575,
      0.4155509558712651,
      0.42471157597032133,
      0.45095451870364345,
      0.445670091954177,
      0.4426899209172426,
      0.44113737644549617,
      0.4647166808386763,
      0.40713486252073755,
      0.4364153678724152,
      0.42170111742205246,
      0.42178776472985385,
      0.4032373718961984,
      0.4248784358094552,
      0.4324691947259589,
      0.4283085271359204,
      0.41758039417024145,
      0.42045470504703636,
      0.4120020233942363,
      0.4183570180110589,
      0.44684734558630845,
      0.4599244446365419,
      0.4405436446120639,
      0.45456305931428237,
      0.41911336221916234,
      0.40378205393424293,
      0.4379510059238908,
      0.4311781768670339,
      0.4477695193476306,
      0.44785233305064504,
      0.4002234410650716,
      0.42796161598609594,
      0.39189145061784164,
      0.43919764325290384,
      0.41299019254253294,
      0.3976144572574935,
      0.40738799688880317,
      0.4038723942851592,
      0.4325821799075532,
      0.4911259324072364,
      0.42711002650018226,
      0.42625003625711283,
      0.44052833275880643,
      0.4351688581669402,
      0.47936264139984897,
      0.44594805602898857,
      0.47719338893176555,
      0.41510980015921733,
      0.4549132049529852
    ],
    "best_epoch": 66,
    "best_val_loss": 0.3907825608274894,
    "test_loss": 0.5162334074600462,
    "tracker": {
      "initial_train_loss": 0.33333194511189956,
      "train_threshold": 0.11111064837063318,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3907825608274894,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_27_081ee0/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_27_081ee0/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_27_081ee0/config.yaml"
}