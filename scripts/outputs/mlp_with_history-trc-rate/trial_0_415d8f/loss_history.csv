epoch,train_loss,val_loss
1,1.015935,0.342028
2,0.999483,0.350610
3,0.999034,0.353214
4,0.999087,0.359255
5,0.998866,0.350535
6,0.998583,0.353882
7,0.998809,0.352530
8,0.998940,0.351297
9,0.998629,0.353782
10,0.998692,0.357515
11,0.998527,0.352634
12,0.998654,0.347551
13,0.999092,0.353579
14,0.998903,0.357723
15,0.998971,0.354717
16,0.998869,0.356021
17,0.998789,0.354608
18,0.998802,0.356079
19,0.999402,0.360910
20,0.998814,0.356722
21,0.998846,0.355830
22,0.998656,0.353494
23,0.998933,0.358740
24,0.998859,0.356152
25,0.998842,0.359190
26,0.998870,0.355221
27,0.999022,0.359974
28,0.998789,0.355354
29,0.998686,0.351259
30,0.998613,0.351520
31,0.998807,0.350578
32,0.998730,0.354895
33,0.998849,0.358433
34,0.998694,0.353876
35,0.998733,0.352952
36,0.998710,0.351308
37,0.998700,0.353258
38,0.998702,0.351404
39,0.998706,0.349894
40,0.998751,0.347351
41,0.998803,0.349521
42,0.998737,0.348725
43,0.998761,0.349990
44,0.998695,0.354122
45,0.998784,0.350467
46,0.998790,0.351139
47,0.998730,0.353721
48,0.999131,0.361311
49,0.998744,0.350518
50,0.998769,0.350732
