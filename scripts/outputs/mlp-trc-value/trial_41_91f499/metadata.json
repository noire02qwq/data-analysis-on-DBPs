{
  "model_name": "mlp-trc-value/trial_41_91f499",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.20186940145001928,
    "mid_layer_count": 14,
    "mid_layer_size": 243
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 158,
    "learning_rate": 0.0005182422177367303,
    "weight_decay": 0.004523794575236709,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.33627147265944557,
      0.10881632848190247,
      0.08514909732851723,
      0.075711889755365,
      0.07031256384792053,
      0.06748382752811896,
      0.06356088941837501,
      0.061534621612789574,
      0.06219945072634609,
      0.05993662474953162,
      0.060383428321083794,
      0.057680872198731366,
      0.05592828451929611,
      0.05531808010002874,
      0.05568149185936808,
      0.05544931596558849,
      0.05416602699928035,
      0.053431457871921925,
      0.0535100634410985,
      0.05410609314798269,
      0.05354071263722758,
      0.05296170989528352,
      0.052408581670314425,
      0.050724754727356186,
      0.05191306465842009,
      0.05014703979858103,
      0.049871518430020516,
      0.05079081777259593,
      0.049975902570355175,
      0.05138866407839747,
      0.04937354445824445,
      0.05007221089201043,
      0.04962355318097441,
      0.0502113880357371,
      0.0505431813076559,
      0.0493220971708973,
      0.04972750944046714,
      0.05013145895348933,
      0.050081445076232876,
      0.050206817266052965,
      0.048523242874458056,
      0.04983997161668836,
      0.04986407763954002,
      0.049471772702581886,
      0.049331204154327506,
      0.04825229785587159,
      0.04896556456052933,
      0.049627128515436505,
      0.04937496471131319,
      0.048515136087511124,
      0.04791636084358835,
      0.048090162571842635,
      0.049391088190141125,
      0.04763950389538012,
      0.047028801304069834,
      0.0474398081253482,
      0.04799832270245114,
      0.047541070371109315,
      0.048069206430070704,
      0.04766007914676643,
      0.04717053514090546,
      0.04807708149115479,
      0.04802115142475403,
      0.04956274545952685,
      0.04764649781731534,
      0.04868767988615277,
      0.05001614600221214,
      0.04727449671882828,
      0.04925900646960846,
      0.04814817386465754,
      0.04739219299386164,
      0.04973577310246587,
      0.047887554997172094,
      0.04761892619742039,
      0.047419081687193276,
      0.04750863102294807,
      0.04816785431622297,
      0.04739549873791456,
      0.048842977048143964,
      0.04674582237644401
    ],
    "val_loss": [
      0.32631818834179177,
      0.21042599400538883,
      0.23458155171867617,
      0.28515699285857693,
      0.3006283936274801,
      0.25211059226693505,
      0.23381317341755964,
      0.30150646472762443,
      0.32706440307958395,
      0.34957901132544,
      0.3095703739159835,
      0.2807603400334448,
      0.26912440094806833,
      0.32208019785226105,
      0.32461250772822403,
      0.2918001144343686,
      0.323303332465316,
      0.3718079995743172,
      0.3124730465364849,
      0.30416087064958974,
      0.3385205913736613,
      0.33944926304731543,
      0.3025558194513628,
      0.31460809739540796,
      0.31793418052846084,
      0.33241289560487886,
      0.3382231814664103,
      0.32533246392083026,
      0.33441310874047037,
      0.32123217878272076,
      0.30302773215947393,
      0.3011328056655423,
      0.335513189506388,
      0.36244883522569776,
      0.341219768227039,
      0.3218146015850905,
      0.3603846374519928,
      0.30187889813573776,
      0.29720281230475376,
      0.3221212125266205,
      0.3208531395961603,
      0.2976015736421425,
      0.3125764304917016,
      0.28947167867895013,
      0.34281506910474,
      0.2841179431176293,
      0.37509565002056294,
      0.2851673605444724,
      0.30049985799113077,
      0.3326840067427315,
      0.31362877823189345,
      0.3201541537207044,
      0.28831663213134884,
      0.3265448873360714,
      0.2928067974054706,
      0.30586921314591775,
      0.2908873808888083,
      0.31829859302072466,
      0.35789185742775126,
      0.33804025942693927,
      0.3389040908770647,
      0.3454573971336473,
      0.328215549643079,
      0.32304004736824665,
      0.32760659582957535,
      0.30052129006582107,
      0.30138491488948554,
      0.3262019900772386,
      0.3248663933401158,
      0.3504975498815675,
      0.3369941550814463,
      0.29224803333510896,
      0.2843341072920911,
      0.3019755311845662,
      0.30669384742612965,
      0.3383744802303657,
      0.27238410400550167,
      0.31900904040538264,
      0.3224903008761163,
      0.33582933510982704
    ],
    "best_epoch": 2,
    "best_val_loss": 0.21042599400538883,
    "test_loss": 5.140114917281712,
    "tracker": {
      "initial_train_loss": 0.33627147265944557,
      "train_threshold": 0.11209049088648186,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.21042599400538883,
      "patience_no_improve_epochs": 79,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_41_91f499/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_41_91f499/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_41_91f499/config.yaml"
}