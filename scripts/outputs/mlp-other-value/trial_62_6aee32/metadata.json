{
  "model_name": "mlp-other-value/trial_62_6aee32",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.37589595797297376,
    "mid_layer_count": 7,
    "mid_layer_size": 454
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 146,
    "learning_rate": 0.0014416652775818802,
    "weight_decay": 0.000518256170024142,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138
    ],
    "train_loss": [
      0.37494687956226,
      0.2550327181816101,
      0.23374491657062088,
      0.21947299063266884,
      0.20950624323796468,
      0.20186155788283155,
      0.19337572128712183,
      0.1889159098504567,
      0.18318423639510825,
      0.17940357425706457,
      0.17262746135643534,
      0.17147201836384401,
      0.17039936038165168,
      0.1634199782487305,
      0.1616044060779633,
      0.16050142374342682,
      0.15768288049929077,
      0.15292671492171325,
      0.15327139956453265,
      0.15366347507215758,
      0.14761138107988883,
      0.1479092963792961,
      0.14560277397439014,
      0.14740721511918806,
      0.14454938345548127,
      0.14398343501189173,
      0.1403906256984967,
      0.14204929761967028,
      0.140400405397869,
      0.14117531507649198,
      0.13712739241450428,
      0.13570443020341272,
      0.13549564366518932,
      0.1376318921793296,
      0.1345273394609733,
      0.13377113086962283,
      0.13334201123391498,
      0.13334291541863857,
      0.13319403462192228,
      0.12882829679242155,
      0.12878039341444783,
      0.1337982837766363,
      0.12718989637767797,
      0.12784861141348447,
      0.12955348996045102,
      0.12848229607659895,
      0.12770014933251675,
      0.1285221889813843,
      0.12587621038528268,
      0.1276177640310491,
      0.12693593471386055,
      0.12717029574270308,
      0.12618025723537032,
      0.1245406710811766,
      0.12370741511076276,
      0.12382707679085146,
      0.12561895218742328,
      0.1223134266976181,
      0.1230934743887495,
      0.12337468825605602,
      0.12239125428512013,
      0.12304335056191043,
      0.12418450360468805,
      0.12185063278670492,
      0.12358588642183177,
      0.12284032061214384,
      0.1204019459819812,
      0.12313420870644794,
      0.11873444154086389,
      0.11979044184065771,
      0.12129054528748519,
      0.12162760584751357,
      0.1189808130719192,
      0.1204029318153583,
      0.11910299308074322,
      0.12195914495008123,
      0.1219578291427606,
      0.1185252188225628,
      0.11620741053314745,
      0.12316007261714487,
      0.11845311343960421,
      0.1204290191192331,
      0.11948363378208193,
      0.12061090413586123,
      0.11892825086577664,
      0.11936662169321492,
      0.11747598801364405,
      0.11804963753827723,
      0.11797824540601258,
      0.11913992099467763,
      0.1186975417013594,
      0.1178142050937728,
      0.11870836315933651,
      0.11803969644533786,
      0.1180303747043694,
      0.11852162620726459,
      0.11734132039976646,
      0.11631883741793662,
      0.11590180856836582,
      0.1162673423191931,
      0.11749537027473937,
      0.11693881935855252,
      0.11614201542251902,
      0.11632244722232445,
      0.12068769241706599,
      0.11692984265324517,
      0.1161729662582133,
      0.11651373345341788,
      0.11552014226727512,
      0.11623973810730866,
      0.11418465507900549,
      0.11480666722064449,
      0.11694118822076616,
      0.11588441417301662,
      0.1175376705121939,
      0.11496982939269923,
      0.1169443370200017,
      0.11728295166066452,
      0.11573843363617065,
      0.11592216596290232,
      0.11622523808285112,
      0.11441246095018365,
      0.11433174306112966,
      0.11729605268857123,
      0.11493043112962781,
      0.11450466884633649,
      0.11381764298045922,
      0.11522515328565643,
      0.11740977449744955,
      0.11629104399035807,
      0.11458783895694763,
      0.11192310064564674,
      0.1152593114892601,
      0.11473713857071592,
      0.11345949882365239,
      0.11379019636230753,
      0.11488799618728164,
      0.1142142103739339
    ],
    "val_loss": [
      0.38720612367113194,
      0.46282371317376636,
      0.5060407163184917,
      0.5139715405459889,
      0.4525329538715814,
      0.5353531120423072,
      0.47658295259325806,
      0.5553104913252557,
      0.599208815217375,
      0.5647076524571031,
      0.6441566715875785,
      0.5135572389838938,
      0.44013409860833674,
      0.5129525870977047,
      0.4761732090822237,
      0.47899656729426926,
      0.4790497606029054,
      0.5057047212552168,
      0.5748982324750124,
      0.4679837958006088,
      0.48265128694251624,
      0.4529874346302655,
      0.47624787335802693,
      0.4742871314911785,
      0.47477909406859004,
      0.4565960558856319,
      0.4705127862756124,
      0.46332951142580925,
      0.489441273419443,
      0.4299109572243548,
      0.4328764911718711,
      0.4150057303780567,
      0.46838648854615444,
      0.4289377725766804,
      0.4417796227924838,
      0.4530413691244439,
      0.44143230800857086,
      0.4466242896582552,
      0.4141470581471563,
      0.42459215346032275,
      0.4329474775377148,
      0.44710383895271555,
      0.4454277898469371,
      0.4326520552535257,
      0.42186144146019827,
      0.4164007997173749,
      0.39667480521930193,
      0.37930333155714824,
      0.42295588291512276,
      0.432057084428693,
      0.405976605790104,
      0.3981001537360117,
      0.4234305792582963,
      0.3974723055780291,
      0.4530583184547053,
      0.3915585901387437,
      0.41296780764342783,
      0.41890940289654416,
      0.41732735094909895,
      0.4221597676148672,
      0.418891986945789,
      0.42644844234525087,
      0.41668764099389494,
      0.4311916517551074,
      0.3803786719809035,
      0.38379145472527976,
      0.4036558070582544,
      0.42027269433180015,
      0.40073384487343405,
      0.4136508101653196,
      0.41003201215745444,
      0.4154980811441016,
      0.4065869832110262,
      0.4007598443837937,
      0.44852052820835286,
      0.4172883474898196,
      0.433550048213519,
      0.4006120739225856,
      0.42361207085098335,
      0.42402308524368765,
      0.39874927835193225,
      0.42796455578889675,
      0.42492392251413025,
      0.41293784746688283,
      0.37810213038485924,
      0.3924501493127046,
      0.4116035000560526,
      0.37792649732199973,
      0.40426390487812236,
      0.41245358564004214,
      0.43393796052404504,
      0.4479421550909916,
      0.4141804808538831,
      0.3978152281866816,
      0.43839399298864923,
      0.43685292157227407,
      0.42823160749352623,
      0.412029413682615,
      0.40810012737969437,
      0.3824316083849547,
      0.4327626496285735,
      0.41286501707788,
      0.40127364521968867,
      0.4256078830557669,
      0.3896626236106821,
      0.436576590745035,
      0.3883573899904411,
      0.41082006242282376,
      0.40555937295545363,
      0.4001702485773378,
      0.40783474799580205,
      0.42568620174766303,
      0.40227855149500386,
      0.409541730109803,
      0.43273880934108516,
      0.41684565340687413,
      0.38495271589584695,
      0.4215453202139118,
      0.41696630513775135,
      0.38277868373308355,
      0.3811585852129017,
      0.44935584163772846,
      0.44644885063171386,
      0.4521735487851554,
      0.4983259235938152,
      0.40220226928324043,
      0.43178687115272363,
      0.4471524650732914,
      0.5198869357922834,
      0.4455826077186419,
      0.3788200303733706,
      0.38478723793864966,
      0.42009784215224716,
      0.43900328821050905,
      0.412517911374212,
      0.3997762722437253,
      0.40070198825198017,
      0.3942571089653198
    ],
    "best_epoch": 88,
    "best_val_loss": 0.37792649732199973,
    "test_loss": 0.5160915387090313,
    "tracker": {
      "initial_train_loss": 0.37494687956226,
      "train_threshold": 0.12498229318742,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.37792649732199973,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_62_6aee32/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_62_6aee32/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_62_6aee32/config.yaml"
}