{
  "model_name": "mlp-trc-value/trial_35_d99b34",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.21244692578357988,
    "mid_layer_count": 11,
    "mid_layer_size": 184
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 348,
    "learning_rate": 0.0004919963503587856,
    "weight_decay": 0.0006817517354858598,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.5264193769401009,
      0.16695096903791667,
      0.11524835897522623,
      0.09139759980788165,
      0.07866559934163472,
      0.07278125819531754,
      0.06841963443192169,
      0.06523371016508252,
      0.06388685471541213,
      0.06183219784770396,
      0.06003213905298814,
      0.05877226312239088,
      0.05813674210523446,
      0.05593438817330542,
      0.05349026542021226,
      0.053291133131398,
      0.05233835305095392,
      0.051143343000839524,
      0.0516993401121977,
      0.050381382777254784,
      0.050368599580259674,
      0.050007696586994096,
      0.049924829616385766,
      0.04761968751276928,
      0.04816182953744683,
      0.04893924543426672,
      0.04656287633062265,
      0.045229556913434575,
      0.04587201477855581,
      0.04570003373002688,
      0.044943757985970376,
      0.043997008636356805,
      0.04405080924635364,
      0.04356367847074173,
      0.04399013106618985,
      0.04549263469901618,
      0.04320030266838602,
      0.04228917743653258,
      0.042444234420514336,
      0.042245301143244755,
      0.041126948484568916,
      0.042194775002255935,
      0.04079718749039353,
      0.041610382059603365,
      0.040616804358285165,
      0.040752301259246344,
      0.041031178975790325,
      0.040905535305200816,
      0.04104057249119491,
      0.0401069260846963,
      0.03985303743389278,
      0.03920465502687269,
      0.039203668652573506,
      0.04037974509346051,
      0.039461661218113626,
      0.03930049747220977,
      0.03929287437569367,
      0.04032204762051477,
      0.03830185478286538,
      0.03843934984620624,
      0.03801755495885509,
      0.03753757083825786,
      0.03876738093521975,
      0.03803458960278637,
      0.037450949778506055,
      0.036934790092058335,
      0.03667405517767062,
      0.03926940423065176,
      0.038151453201849685,
      0.03947233792495703,
      0.03771202526738119,
      0.037543303121536926,
      0.03669040321657724,
      0.0371781601811859,
      0.037468578385474925,
      0.03829972431438283,
      0.038022560390021144,
      0.03708446934712184,
      0.03541295278077709,
      0.03641599574613229
    ],
    "val_loss": [
      0.41949071821695316,
      0.35882757812916877,
      0.2483870788784084,
      0.23014742630327534,
      0.2039147673475885,
      0.206809693329527,
      0.22480922219103683,
      0.21386085021013984,
      0.2207360311851887,
      0.21874492571293236,
      0.22562379630918275,
      0.2429945335639808,
      0.25084720162485175,
      0.24893715939300504,
      0.25897483598150894,
      0.25279243846317967,
      0.25304201434918505,
      0.25618962886001534,
      0.26984510778220827,
      0.28342567076850794,
      0.27353247714613727,
      0.27795763646146493,
      0.2759408794789614,
      0.2820750681939953,
      0.28421739330013357,
      0.29359300190103266,
      0.29120025552675394,
      0.3110672925180661,
      0.3386307269468636,
      0.29761636389675966,
      0.3105931633023802,
      0.3032208273332276,
      0.3410971866440987,
      0.31564910902591525,
      0.3045579263906993,
      0.36625184121424564,
      0.3505468461417153,
      0.3378504318971477,
      0.33170346669005063,
      0.34590249128059714,
      0.3756600837195348,
      0.3164776263122787,
      0.36484697516896053,
      0.33428804273912294,
      0.37306917353483016,
      0.35664169017426267,
      0.3784123037835795,
      0.3156487798084042,
      0.3512353148690598,
      0.35059780285743897,
      0.4249075866477218,
      0.4029868470426805,
      0.32794926781318856,
      0.38180346883788796,
      0.38101288713737874,
      0.4105043858691247,
      0.40470477341713307,
      0.39783071466459485,
      0.3864008651834405,
      0.4223513382146815,
      0.40029113457766835,
      0.4078877253000608,
      0.4098064039727885,
      0.36888027431186804,
      0.4062077234382044,
      0.3885695490294588,
      0.3928841316682136,
      0.365984291471764,
      0.3416581304888882,
      0.4202190766032941,
      0.40456480658250654,
      0.3684403131554227,
      0.39301974462445627,
      0.375164112015934,
      0.3881359657618457,
      0.3866345493736381,
      0.3856918321308975,
      0.4108820050687133,
      0.3900056685917749,
      0.3560723792382343
    ],
    "best_epoch": 5,
    "best_val_loss": 0.2039147673475885,
    "test_loss": 5.078702956295469,
    "tracker": {
      "initial_train_loss": 0.5264193769401009,
      "train_threshold": 0.17547312564670028,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.2039147673475885,
      "patience_no_improve_epochs": 75,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_35_d99b34/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_35_d99b34/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_35_d99b34/config.yaml"
}