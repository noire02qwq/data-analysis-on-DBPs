{
  "model_name": "mlp_with_history-other-rate/trial_19_36b744",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 120,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.10160331089148525,
    "mid_layer_count": 7,
    "mid_layer_size": 267
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 482,
    "learning_rate": 0.0010407828703356986,
    "weight_decay": 0.006780297413325945,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7677,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 1200,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120
    ],
    "train_loss": [
      0.9984209727880715,
      0.7544734051245582,
      0.3802142597951351,
      0.3501328339066778,
      0.3443756559809096,
      0.34355528912181515,
      0.3379614656288611,
      0.3382754750871031,
      0.32544277362468205,
      0.31213321698756985,
      0.30165143813552125,
      0.2841589894668345,
      0.339807294345048,
      0.2814155562293239,
      0.26285117425551496,
      0.25728970510241916,
      0.25278611047761396,
      0.2484522287355234,
      0.245479279354368,
      0.24253113492129602,
      0.8922340542415754,
      0.9090599833373929,
      0.4385880562528372,
      0.3607401438712515,
      0.34620637655786135,
      0.33540538824503663,
      0.32126762221936245,
      0.31099016327200824,
      0.2920016716649884,
      0.2768072159251183,
      0.261933687058715,
      0.25911830325478824,
      0.2588325483818857,
      0.25499831014263674,
      0.2481066963705868,
      0.24848032869972164,
      0.24858717081353304,
      0.24989364595793337,
      0.2550120180405039,
      0.31089767916556277,
      0.5461519204251885,
      0.734821953825673,
      0.6378527990119818,
      0.3905577661120924,
      0.32432841538792867,
      0.30971814271402776,
      0.29029508123519565,
      0.2657111392067608,
      0.2605657831011021,
      0.26204373589387486,
      0.2546830811145111,
      0.24978587130938437,
      0.24696481168867943,
      0.2447499507834114,
      0.24287716762324213,
      0.242673774909675,
      0.24370464723728527,
      0.24170511072969567,
      0.24343195808373252,
      0.2419855224114929,
      0.24692048473261569,
      0.24156489337470455,
      0.24049143049848007,
      0.23984085408306158,
      0.24063863610210434,
      0.23827119782068185,
      0.24558274987713813,
      0.23696855773866154,
      0.2364800889615173,
      0.23669138970599599,
      0.2343281592663741,
      0.23432143827007668,
      0.8994105655660662,
      0.9900039408811604,
      0.9021456636021624,
      0.6215846480429755,
      0.4481099278095785,
      0.3744455926878247,
      0.3503685755602034,
      0.3426639891212707,
      0.328871351714182,
      0.3141117129992644,
      0.2970134192485432,
      0.27969686799765536,
      0.27230778801980016,
      0.2636119277158628,
      0.2572659580863142,
      0.25844687779728936,
      0.2511245709340119,
      0.24988330781490864,
      0.2526164529487244,
      0.25058077836900045,
      0.24596634317542235,
      0.2463938759180567,
      0.24741735695332961,
      0.24473149497030428,
      0.24413777461380515,
      0.24282605799905674,
      0.24201653652612284,
      0.24527962918671,
      0.24199612222838032,
      0.24038808580191476,
      0.23926665326169153,
      0.23649982576400053,
      0.2464340076877283,
      0.49651022258720406,
      0.42072418686917196,
      0.37643775417265274,
      0.3346977631445119,
      0.29933852430540275,
      0.27032569748389157,
      0.2635491998269096,
      0.2610646162657156,
      0.2527574730486986,
      0.2534062119570346,
      0.24608552396895286,
      0.24461094336117153,
      0.24464660136824212,
      0.2454360224189152,
      0.24425423343471675
    ],
    "val_loss": [
      1.3265969185058228,
      0.4800232913322791,
      0.46543555040202456,
      0.45270919853341796,
      0.47342178271916097,
      0.4806110301774419,
      0.47910787650568043,
      0.5226854375557985,
      0.5308154566202336,
      0.5261154555096598,
      0.6520232101221999,
      0.6970573439212616,
      0.5594097615715986,
      0.4921516905287783,
      0.5202672929999357,
      0.48415975613508394,
      0.5187864407361624,
      0.4371254025908287,
      0.47918850005922203,
      0.43820615511632965,
      1.0480973889727792,
      0.7047149738330327,
      0.5044166103451552,
      0.5118766364044772,
      0.5472425581273919,
      0.555420405190148,
      0.5514127905318837,
      0.517522171924928,
      0.5276114510561891,
      0.4891864960600516,
      0.47259537716825567,
      0.4534529403119744,
      0.436573176201946,
      0.48116368276630334,
      0.47108248811282083,
      0.493973187165346,
      0.48822272157597685,
      0.5494978122100859,
      0.4464089610084088,
      0.7603005514530364,
      0.8768102121567298,
      0.6333382087017961,
      0.5085462682975267,
      0.5428970274632562,
      0.5190395772457123,
      0.5891935282660101,
      0.520482440426678,
      0.46745880713719806,
      0.44673512019440087,
      0.4876929487832292,
      0.5210071185927191,
      0.4623807383065452,
      0.4537214651436149,
      0.45142690355549314,
      0.42456187052641087,
      0.4605305269806685,
      0.47161873800311976,
      0.4469213099804467,
      0.4263259991378841,
      0.45951539020160004,
      0.4409109402648703,
      0.43438336060432614,
      0.4294059598517275,
      0.434307603796799,
      0.42501042126538513,
      0.4406649418041378,
      0.4462101601019591,
      0.43703384283417,
      0.421767444364325,
      0.4190463362161271,
      0.4376041728133213,
      0.4318502829995698,
      4.773240324979771,
      6.184262351647108,
      0.9322507604867398,
      0.9533035933257576,
      0.8369554260176812,
      0.5548599968056479,
      0.7999250668965414,
      0.5445212900103209,
      0.5265359723639346,
      0.5167289696410744,
      0.5664123771968715,
      0.5092874025691769,
      0.5030079187390333,
      0.5432640123777761,
      0.46916112746307237,
      0.4464886242044186,
      0.5352107827356476,
      0.5278769249152281,
      0.4522132993815188,
      0.48709262131216996,
      0.4870088883235069,
      0.4663998517804517,
      0.43683758286123503,
      0.4484470318891331,
      0.4661507664237194,
      0.4601429965324744,
      0.4694784123115911,
      0.4532140322609576,
      0.45363728389768543,
      0.48596161537898513,
      0.48445277042731555,
      0.4468425008351217,
      0.5227621529809016,
      0.9096461190434987,
      0.547797866103178,
      0.6790365398643974,
      0.5373534175628674,
      0.5225690789386898,
      0.5639345908593275,
      0.4889885839052543,
      0.48517718780897334,
      0.5176470500623395,
      0.45352141370851834,
      0.469331138523039,
      0.533476314091397,
      0.4726848472199754,
      0.4648608283189956,
      0.44056242450982513
    ],
    "best_epoch": 70,
    "best_val_loss": 0.4190463362161271,
    "best_val_abs_mse": 0.4863930940628052,
    "test_loss": 0.6258993358774618,
    "test_abs_mse": 1.4375272989273071,
    "tracker": {
      "initial_train_loss": 0.9984209727880715,
      "train_threshold": 0.33280699092935717,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4190463362161271,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-rate/trial_19_36b744/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-rate/trial_19_36b744/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-rate/trial_19_36b744/config.yaml"
}