{
  "model_name": "mlp-trc-value/trial_63_1cc827",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.2670088168970514,
    "mid_layer_count": 15,
    "mid_layer_size": 142
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 187,
    "learning_rate": 0.0004282089993974979,
    "weight_decay": 0.0003732130250149989,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.4155768727919057,
      0.13277507182296697,
      0.09890986976140642,
      0.08518034416232248,
      0.07882344918999307,
      0.07349205300022679,
      0.0702579980228706,
      0.0669419606144097,
      0.0651546842334988,
      0.06354043710252424,
      0.06255857985545085,
      0.061156622924029125,
      0.06009261605839673,
      0.057562897631228585,
      0.056142879437355124,
      0.055178455265861036,
      0.0543659785007432,
      0.052168884809645495,
      0.052135027497299605,
      0.051975317977907845,
      0.05149063075046361,
      0.05117620237452623,
      0.05208609937300754,
      0.04997981881905345,
      0.04908128347670255,
      0.047064212299481975,
      0.046418408279318174,
      0.04783069611641231,
      0.046440653415973095,
      0.04623406465137124,
      0.04663094530085636,
      0.04497053473996712,
      0.045944694110912475,
      0.044422261390630526,
      0.04476905278116082,
      0.04396843623796171,
      0.043699910277916476,
      0.04370655888226122,
      0.042930427730358704,
      0.04439235170189771,
      0.04366730226193287,
      0.04328369610862144,
      0.042170133922877925,
      0.042115242715032364,
      0.04211130921034598,
      0.040995284346811066,
      0.04070596197326636,
      0.04153822275550473,
      0.04261141828045807,
      0.04114046569563842,
      0.04039656986965544,
      0.039587243762117676,
      0.04006793933933464,
      0.03953343969060174,
      0.04054226096444264,
      0.03892548666505278,
      0.040359384985234475,
      0.039860852679123995,
      0.03911363020832682,
      0.04025339815988296,
      0.03862442283328716,
      0.03822113399328392,
      0.03830042932652751,
      0.039176454152835445,
      0.0377308729928027,
      0.039397152415737165,
      0.03934480629196193,
      0.03982608675958638,
      0.037995043993397606,
      0.03805624260512176,
      0.03862864449940404,
      0.038255584571011685,
      0.037518271410397194,
      0.03747444385218278,
      0.0382876706516524,
      0.037545964123491,
      0.0373471656567171,
      0.03746272862533833,
      0.03745902883793954,
      0.03690367680723435
    ],
    "val_loss": [
      0.2698573728476813,
      0.19183028411499398,
      0.20091820437862665,
      0.20736036203177033,
      0.2094156251684902,
      0.2395868222881666,
      0.22024100027688429,
      0.2218209917919186,
      0.22855718122226393,
      0.23111682018477045,
      0.24760028980783896,
      0.24509137952532953,
      0.23893752166343307,
      0.2564784733678945,
      0.25300704619016295,
      0.2442812567498691,
      0.25550813036385234,
      0.2558990891643627,
      0.2689934081570831,
      0.2672220437335754,
      0.2683725733008838,
      0.27029063657126917,
      0.2673060496175985,
      0.28777190536974434,
      0.2796059962663197,
      0.2812033891622089,
      0.2811641004906889,
      0.27961905647381513,
      0.2883134117283061,
      0.2901606579941368,
      0.29035149422769774,
      0.2926840786716181,
      0.31513812105634254,
      0.30145832025362346,
      0.31072441758643726,
      0.2972364528405809,
      0.2923054581876108,
      0.31675790740835097,
      0.3071150318858866,
      0.32133610755829756,
      0.31114966963267254,
      0.29230599793309936,
      0.3155760203069912,
      0.2985402520411386,
      0.31929519945967516,
      0.31331691805295603,
      0.3254601761598341,
      0.3005821831067076,
      0.33069051996564974,
      0.3256426607966869,
      0.3645299937743359,
      0.30591457500317676,
      0.3292895636404167,
      0.32089280671925247,
      0.31533893344667324,
      0.3303124733904968,
      0.32025284788900327,
      0.3233083500565883,
      0.31313087192369615,
      0.331250784102225,
      0.325189388845629,
      0.3445166418830792,
      0.3374573145429799,
      0.31469848558061314,
      0.3314133503089497,
      0.31561819016821907,
      0.3176712278912435,
      0.31997803271954467,
      0.32822042478661156,
      0.30618026868780396,
      0.3286018914191755,
      0.32287556611916085,
      0.3214483879227749,
      0.31463915097811623,
      0.3245588859409362,
      0.3268910896300734,
      0.3325723613885616,
      0.3393018191312245,
      0.30894811907950454,
      0.3044647848992023
    ],
    "best_epoch": 2,
    "best_val_loss": 0.19183028411499398,
    "test_loss": 4.896035858675053,
    "tracker": {
      "initial_train_loss": 0.4155768727919057,
      "train_threshold": 0.13852562426396856,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.19183028411499398,
      "patience_no_improve_epochs": 79,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_63_1cc827/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_63_1cc827/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_63_1cc827/config.yaml"
}