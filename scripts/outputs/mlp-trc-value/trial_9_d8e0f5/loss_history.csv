epoch,train_loss,val_loss
1,0.600534,0.555184
2,0.218468,0.217568
3,0.161783,0.236469
4,0.133206,0.216523
5,0.118072,0.202844
6,0.109015,0.210845
7,0.103063,0.197993
8,0.097488,0.201779
9,0.093507,0.206541
10,0.089600,0.208772
11,0.086750,0.216148
12,0.085071,0.217506
13,0.081898,0.219000
14,0.078688,0.217044
15,0.077939,0.221871
16,0.079026,0.224363
17,0.077032,0.229116
18,0.078589,0.231740
19,0.074064,0.239553
20,0.072366,0.233663
21,0.072221,0.234325
22,0.070131,0.242807
23,0.070462,0.244604
24,0.069632,0.244666
25,0.067507,0.242269
26,0.067600,0.252204
27,0.066032,0.259462
28,0.065754,0.253537
29,0.065076,0.265921
30,0.067024,0.264122
31,0.065075,0.270473
32,0.063851,0.276095
33,0.062793,0.276751
34,0.061646,0.270466
35,0.061228,0.271429
36,0.060721,0.265290
37,0.059547,0.270633
38,0.061411,0.283625
39,0.061596,0.287616
40,0.059112,0.298127
41,0.057893,0.297584
42,0.059802,0.283087
43,0.056610,0.302150
44,0.055639,0.287633
45,0.056975,0.288512
46,0.057759,0.287643
47,0.057242,0.298330
48,0.056334,0.286761
49,0.055038,0.306041
50,0.054119,0.310737
51,0.054590,0.315053
52,0.053929,0.308577
53,0.053099,0.304480
54,0.053347,0.313332
55,0.052949,0.311588
56,0.053702,0.312968
57,0.052560,0.321743
58,0.053469,0.321900
59,0.054560,0.323773
60,0.051012,0.318539
61,0.051671,0.332803
62,0.051690,0.309900
63,0.050387,0.327082
64,0.050395,0.326119
65,0.050601,0.338385
66,0.051354,0.320599
67,0.051564,0.323183
68,0.050658,0.336445
69,0.052347,0.326977
70,0.049406,0.330055
71,0.050208,0.337194
72,0.049159,0.335713
73,0.049392,0.330436
74,0.049542,0.343505
75,0.049434,0.351408
76,0.049248,0.349409
77,0.048827,0.346159
78,0.048165,0.332718
79,0.048285,0.333489
80,0.048338,0.324538
