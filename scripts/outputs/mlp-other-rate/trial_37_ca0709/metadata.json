{
  "model_name": "mlp-other-rate/trial_37_ca0709",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.302916788717684,
    "mid_layer_count": 15,
    "mid_layer_size": 412
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 236,
    "learning_rate": 0.0009095494718359389,
    "weight_decay": 0.00043549682569741935,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149,
      150,
      151,
      152,
      153,
      154,
      155,
      156,
      157,
      158,
      159,
      160
    ],
    "train_loss": [
      0.4360989175465487,
      0.2731634503284927,
      0.2447526649351668,
      0.22835526672340528,
      0.21678271092256562,
      0.2096222785113713,
      0.2016091089238871,
      0.1956538162578859,
      0.19174628737279853,
      0.19022797270577158,
      0.1840077928162771,
      0.17856102103817578,
      0.174740302793609,
      0.17219278220949324,
      0.17075518790485308,
      0.16628110679435143,
      0.16329317021944878,
      0.1612044187724254,
      0.15896697634455484,
      0.16000031568626064,
      0.15731542789520148,
      0.1545183486116428,
      0.15361351527850894,
      0.14919144573457552,
      0.14762091396587698,
      0.1491047151352333,
      0.14380580170788235,
      0.14351273011540436,
      0.14453939856505504,
      0.1413374688569982,
      0.1410517925678491,
      0.14032269895780142,
      0.13837410876572345,
      0.13674941616923214,
      0.13806124583551857,
      0.13431415469478863,
      0.13355879265033263,
      0.13357472725178168,
      0.1303167419174563,
      0.12916361936595025,
      0.13022948314878743,
      0.12992508996138516,
      0.1279413947398813,
      0.12785580263054022,
      0.12645001007600465,
      0.1263472498220135,
      0.1309198848272422,
      0.1264034388362291,
      0.12444377910362996,
      0.12282306969685698,
      0.12389434941720816,
      0.12246899074349665,
      0.1221630088889397,
      0.12134333672417684,
      0.12114894359524034,
      0.11919288536779327,
      0.12190653024009095,
      0.1213261092386532,
      0.12453322118676706,
      0.11829686016150166,
      0.11710797072511994,
      0.11762820019087099,
      0.12463352650694506,
      0.1244059634123049,
      0.11871477000877881,
      0.1150856245291912,
      0.11561792266634931,
      0.11442558432600937,
      0.11605494136058593,
      0.11819872933283655,
      0.11374193593943774,
      0.11377846778754151,
      0.11180335553931603,
      0.11286735602713292,
      0.1130233777944035,
      0.11349776798544815,
      0.10995548146238322,
      0.11056619526301364,
      0.11404474437420278,
      0.10900713904369422,
      0.10975083097884324,
      0.11025554959348313,
      0.10909310050534247,
      0.11372204054206259,
      0.11057699654822842,
      0.11128985289275921,
      0.10890897170756644,
      0.10983902660545904,
      0.10600546877420272,
      0.10725941582023332,
      0.10726666428328417,
      0.1092265130366161,
      0.11552004197305628,
      0.10623190531735545,
      0.1051147423719002,
      0.10426546706640763,
      0.10457977628466286,
      0.10356869045864808,
      0.10596985088564788,
      0.10892145053171512,
      0.10972559116417595,
      0.10913763723965483,
      0.10498694280375573,
      0.10239341639827128,
      0.10389554514724086,
      0.10103475862111477,
      0.09964244392986724,
      0.10067508898373442,
      0.10457239729692044,
      0.10245491766880695,
      0.10475828259296452,
      0.10465824661375989,
      0.10221412362365492,
      0.10114511576461571,
      0.10140170140135527,
      0.10028574505238853,
      0.10458723135701567,
      0.1008658367832726,
      0.0992861374134648,
      0.10126405880199206,
      0.10175439279589547,
      0.10502816013812162,
      0.10062473033363235,
      0.10181144293896537,
      0.10263462202588126,
      0.09892206696775278,
      0.10191832565004365,
      0.10117804312580607,
      0.10077046894259548,
      0.09966174187783769,
      0.10715619726570036,
      0.10023351298839145,
      0.10136524801180263,
      0.10113851654569328,
      0.0988990765670864,
      0.10008701099500465,
      0.09962672796798033,
      0.09875757861911119,
      0.09851483107683535,
      0.09731069983978526,
      0.09825757893615653,
      0.09825169583691763,
      0.10063843656925742,
      0.10165001382012438,
      0.10387684516474918,
      0.09895402941950289,
      0.09674172664205498,
      0.10779516273137543,
      0.10284418638331147,
      0.0979838682106362,
      0.10110978433922538,
      0.09845729923021983,
      0.09594581329697154,
      0.09606985832679693,
      0.09779035531294046,
      0.09620210789086697,
      0.09527426225258914,
      0.09922840459995724,
      0.09704701876551632,
      0.09630508343185015
    ],
    "val_loss": [
      0.3629475322312224,
      0.4000093892662825,
      0.45992892202502955,
      0.4679445802451608,
      0.4515497898448727,
      0.5711362841778886,
      0.47599384035179,
      0.5079859902937255,
      0.4623029930862838,
      0.5532356867890158,
      0.5012716939706289,
      0.5543790198371796,
      0.48135458873417564,
      0.5381481502941269,
      0.5242836244092016,
      0.5202163365965118,
      0.5010411965632867,
      0.5586746501708459,
      0.5108489250351569,
      0.4543311047696782,
      0.4977811223018669,
      0.48392914754901817,
      0.5928315275443529,
      0.5039388095190425,
      0.49590520623201384,
      0.46774796932757257,
      0.48459788271766935,
      0.5111486234350833,
      0.4678019493282912,
      0.4670013374554183,
      0.4243873356345171,
      0.44837109373358197,
      0.5083355242263771,
      0.4410635596263908,
      0.4930465277440534,
      0.4751282553294462,
      0.43218602588076793,
      0.4520041070476977,
      0.5166900758793254,
      0.48297083711552763,
      0.44530757779846647,
      0.45315741325566866,
      0.47560374958072593,
      0.45593662936530427,
      0.46568317722060726,
      0.49941925959672756,
      0.4461660120123161,
      0.4869159917810006,
      0.4128375023781896,
      0.47818254021827333,
      0.44625223321829016,
      0.42442660274619826,
      0.4527422897116153,
      0.45371213608873107,
      0.42097995952217876,
      0.4875148293679346,
      0.450444200474345,
      0.44803882255525646,
      0.45241743074562735,
      0.46005460348671784,
      0.45552607507048964,
      0.4524591792129471,
      0.40554363873904337,
      0.4791163182544137,
      0.4304465026912575,
      0.4221277309392027,
      0.44516979472009005,
      0.4161050182259725,
      0.4506497406317088,
      0.4395937636048494,
      0.4481664937413381,
      0.41835216066080655,
      0.41918792376618186,
      0.43005832285581236,
      0.4405803498750675,
      0.4571740662266394,
      0.4481464808929466,
      0.44290723532973647,
      0.45526082529993117,
      0.4680897163059897,
      0.44291393828249265,
      0.42954819648565645,
      0.4797656169551575,
      0.4251644402920843,
      0.47290290793972817,
      0.429477102064087,
      0.4409643275295189,
      0.41687142927489595,
      0.4473214135912364,
      0.4343245153655549,
      0.4403792959487367,
      0.4017910969471503,
      0.40726039263302694,
      0.426676543529876,
      0.42342678824227725,
      0.42791991062506946,
      0.4605806483836945,
      0.42870173614895984,
      0.39562742942107654,
      0.43406932992849523,
      0.4180476469015647,
      0.4431640952290175,
      0.42638210183132197,
      0.40831766298074207,
      0.4347224089378368,
      0.4071943582888849,
      0.4201387988949964,
      0.4261206909211096,
      0.43692650827105173,
      0.3801811096554031,
      0.4170049068813552,
      0.43185579314560235,
      0.42359182811425833,
      0.42727990457397735,
      0.4301368332908539,
      0.41085456541912285,
      0.4252660802024567,
      0.396233970533588,
      0.42978907452372017,
      0.39715094809046764,
      0.4110121275315028,
      0.42114086590127314,
      0.4141587417996572,
      0.4255440873300244,
      0.3903716921092507,
      0.3883336428575173,
      0.4175607108070465,
      0.40423168300868506,
      0.4122806760722292,
      0.40680561722395664,
      0.4112301791499475,
      0.3915589926842444,
      0.4110844857678442,
      0.42739822393405935,
      0.42067313931302397,
      0.44123527725299677,
      0.4248080393868292,
      0.43838510349125204,
      0.43832970297265195,
      0.413186762147321,
      0.41331828243718177,
      0.42526047743723067,
      0.4055332857691599,
      0.4275137197650121,
      0.3841361959180432,
      0.4064628421189542,
      0.39256270192340464,
      0.41983448117079136,
      0.4083050707500138,
      0.39967827004586864,
      0.4146873599397922,
      0.42438860999609895,
      0.4200246310341144,
      0.41951497475544136,
      0.41697949274571355,
      0.4408960680047909,
      0.4146506340917713,
      0.4253555442758663,
      0.40865468090165874,
      0.407071586711678
    ],
    "best_epoch": 110,
    "best_val_loss": 0.3801811096554031,
    "best_val_abs_mse": 0.4811573624610901,
    "test_loss": 0.5130562731666428,
    "test_abs_mse": 1.2581020593643188,
    "tracker": {
      "initial_train_loss": 0.4360989175465487,
      "train_threshold": 0.14536630584884958,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3801811096554031,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-rate/trial_37_ca0709/best_model.pt",
    "last": "scripts/outputs/mlp-other-rate/trial_37_ca0709/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-rate/trial_37_ca0709/config.yaml"
}