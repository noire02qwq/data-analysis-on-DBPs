epoch,train_loss,val_loss
1,1.005402,0.345803
2,1.004082,0.354558
3,1.003930,0.349549
4,1.003952,0.348473
5,1.004054,0.350835
6,1.003954,0.344305
7,1.004022,0.344718
8,1.003785,0.345397
9,1.003717,0.345173
10,1.003764,0.343837
11,1.004043,0.345444
12,1.003887,0.345541
13,1.003702,0.343851
14,1.003733,0.345874
15,1.003840,0.345717
16,1.003729,0.343455
17,1.004032,0.346051
18,1.003794,0.345321
19,1.003667,0.345322
20,1.003720,0.346212
21,1.003698,0.346826
22,1.003755,0.345851
23,1.003786,0.344895
24,1.003795,0.344428
25,1.003796,0.344463
26,1.003749,0.346939
27,1.003767,0.346238
28,1.003681,0.346659
29,1.003706,0.346902
30,1.003705,0.344902
31,1.003707,0.345899
32,1.003698,0.347819
33,1.003675,0.346413
34,1.003725,0.346549
35,1.003789,0.345894
36,1.003686,0.345515
37,1.003772,0.343385
38,1.003721,0.348238
39,1.003820,0.345064
40,1.003713,0.344941
41,1.003713,0.345504
42,1.003710,0.346534
43,1.003687,0.346347
44,1.003846,0.346814
45,1.003732,0.345977
46,1.003790,0.347048
47,1.003718,0.346202
48,1.003656,0.344548
49,1.003670,0.346103
50,1.003675,0.345031
