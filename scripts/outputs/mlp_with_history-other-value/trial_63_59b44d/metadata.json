{
  "model_name": "mlp_with_history-other-value/trial_63_59b44d",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 103,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.2777641109522041,
    "mid_layer_count": 9,
    "mid_layer_size": 963
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 273,
    "learning_rate": 0.0006673129666832308,
    "weight_decay": 0.0003299770923489891,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7694,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 1030,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.7797216786861357,
      0.3909348552765275,
      0.3792334734262477,
      0.36114068694213225,
      0.3471616360896093,
      0.3307544462303388,
      0.2826009418864761,
      0.2650920922841566,
      0.26250048413241345,
      0.2488420030239157,
      0.24504399681350056,
      0.2423716538450394,
      0.23369260158845906,
      0.23405761284110205,
      0.20949343960293554,
      0.19592969329489773,
      0.21014707112137238,
      0.17940900388021483,
      0.1755240590662376,
      0.17198652913733398,
      0.16126918087175737,
      0.14799360353485125,
      0.14712874001036813,
      0.13481964860987844,
      0.12583545305963953,
      0.12142424141319504,
      0.12358823336790623,
      0.1179008371944021,
      0.11588331021238743,
      0.11007211166975063,
      0.10772790668582123,
      0.10988156991149656,
      0.1127479386522936,
      0.10857434259073469,
      0.10391739680433477,
      0.09866324403040713,
      0.09332063174190415,
      0.093921903281637,
      0.08992450319817384,
      0.08528598496452659,
      0.08758261521698625,
      0.0846209373409357,
      0.08287981797463868,
      0.09151035509684007,
      0.08276818214700474,
      0.0823654492400453,
      0.0828330642789455,
      0.07849965748951625,
      0.07910965086443411,
      0.07775302485700611,
      0.07424661865075874,
      0.07819616994843534,
      0.07690504260800832,
      0.07426048050147234,
      0.07951761601376076,
      0.07711041885376566,
      0.07427463701809726,
      0.07514969506529762,
      0.07582868097438607,
      0.07273585586182818,
      0.07169676208561168,
      0.07026639619606376,
      0.0751558943260156,
      0.07714881763164334,
      0.07617864952852874,
      0.07512854372495206,
      0.07202894409839088,
      0.07072750715069688,
      0.06872118194908299,
      0.06785213350300699,
      0.07265441511567146,
      0.06868270206068332,
      0.06744097755974474,
      0.07097437738992655,
      0.09318726906063404,
      0.07674681042227337,
      0.07154867032308965,
      0.06864093677127457,
      0.06905930662444885,
      0.06658309454513286
    ],
    "val_loss": [
      0.49125796715299525,
      0.5075374807247859,
      0.4737210245457238,
      0.47602020969647846,
      0.5688348182928776,
      0.7946177083039712,
      0.40542439686324067,
      0.45602114673057004,
      0.4988181361493593,
      0.3661431857881075,
      0.4419059767248388,
      0.5678284682980376,
      0.6561431994962835,
      0.4730674008141735,
      0.44804733582510203,
      0.5749361662896807,
      0.5268739428884255,
      0.49025825255377564,
      0.6673401785735599,
      0.6926530325484133,
      0.8562592819377691,
      0.5693457725251506,
      0.49129059215237997,
      0.6468493387727681,
      0.4898773150708147,
      0.5158602473710825,
      0.5457374875684698,
      0.5095944516494603,
      0.522080023345833,
      0.5566892478637353,
      0.6541033564302736,
      0.6358492726248182,
      0.4714471921503187,
      0.4911528081058742,
      0.5620990698030609,
      0.6112417927848365,
      0.5579775208440012,
      0.6542465083568753,
      0.47319151341112076,
      0.5534604794741748,
      0.6609551915597773,
      0.455149716540368,
      0.4740304879978031,
      0.46499453199926966,
      0.48381377972528605,
      0.49983768405136236,
      0.4484841820990254,
      0.4791389425491501,
      0.5632462205822596,
      0.505585356757134,
      0.5384422620122661,
      0.588360937113712,
      0.5314318645901666,
      0.516562821095932,
      0.4209555675526579,
      0.5680046239477432,
      0.43269694791939445,
      0.4054007018040754,
      0.6457493827103855,
      0.4916900355748074,
      0.5155778934944889,
      0.5059379118466806,
      0.5047768819028746,
      0.4341783269481388,
      0.5926925024408066,
      0.4093073922092329,
      0.41141562394485504,
      0.44054237325748286,
      0.40837951381495613,
      0.46243960268929335,
      0.5290846244482224,
      0.468902190457918,
      0.5030328413594268,
      0.6908324879978945,
      0.4609504406903675,
      0.4826466943823292,
      0.45940702710590675,
      0.4899682816631066,
      0.443090589884334,
      0.4985387711244786
    ],
    "best_epoch": 10,
    "best_val_loss": 0.3661431857881075,
    "test_loss": 0.36153089905237895,
    "tracker": {
      "initial_train_loss": 0.7797216786861357,
      "train_threshold": 0.25990722622871193,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3661431857881075,
      "patience_no_improve_epochs": 71,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-value/trial_63_59b44d/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-value/trial_63_59b44d/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-value/trial_63_59b44d/config.yaml"
}