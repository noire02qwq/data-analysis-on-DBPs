{
  "model_name": "mlp-other-value/trial_4_9ad239",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.3965778439971561,
    "mid_layer_count": 11,
    "mid_layer_size": 218
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 218,
    "learning_rate": 0.0011843229109732866,
    "weight_decay": 0.00015434381207319236,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81
    ],
    "train_loss": [
      0.4269735036812543,
      0.2806290952921709,
      0.2529411733517468,
      0.2368873050039765,
      0.2278823716371961,
      0.2168017607994603,
      0.21047459962109286,
      0.20373399349253504,
      0.1955969554451932,
      0.18966338431425372,
      0.18590125930101337,
      0.18171877459479088,
      0.17712873430313852,
      0.17446062932906242,
      0.17225332188875386,
      0.1700245214806819,
      0.16360865813178732,
      0.161312317981238,
      0.1598535761229499,
      0.15915007879713855,
      0.157849711831898,
      0.15295528846024978,
      0.15303331795886824,
      0.1514265794457993,
      0.148807502679026,
      0.14699572568836733,
      0.14352341237673397,
      0.1436474751881785,
      0.14325950622917935,
      0.1407470041040184,
      0.14150547385292214,
      0.13757155445132457,
      0.13949110016815475,
      0.13469804019469858,
      0.13453406850119748,
      0.1317542006609041,
      0.13200569565309017,
      0.13299493028903203,
      0.13049835863481613,
      0.12922534607484623,
      0.12980591822864765,
      0.1267730897152008,
      0.1284635070426578,
      0.12627624502245924,
      0.12686640032595276,
      0.12339876824966023,
      0.12402297605331768,
      0.12190072178427779,
      0.1230090134832081,
      0.12108310287758103,
      0.12453145734113323,
      0.12062942418243532,
      0.1207364694415575,
      0.1195968368638779,
      0.11763582983005959,
      0.11811237667747924,
      0.11678366993805761,
      0.116733252864547,
      0.11779122668322752,
      0.11488083501147148,
      0.11527489917806749,
      0.11660780047012513,
      0.116170698783531,
      0.11583766222703512,
      0.1134578079222226,
      0.11361396580881006,
      0.11315644858142178,
      0.1116988668022338,
      0.11329995806765226,
      0.11154554884454543,
      0.10960256993931156,
      0.10980822324844554,
      0.11023039780767407,
      0.11163981031796576,
      0.11079533439055048,
      0.10980224305655847,
      0.10821225825389451,
      0.107482903521831,
      0.10924429491758653,
      0.1061773024606454,
      0.10750220695165502
    ],
    "val_loss": [
      0.3607413451560957,
      0.4107293268163761,
      0.49374157253675116,
      0.43746174257137105,
      0.4338522125503974,
      0.47506740267226794,
      0.49207571591445787,
      0.47644914955257656,
      0.47823197447254273,
      0.5083125358213207,
      0.4748972628912526,
      0.49653446268357204,
      0.4767528765037388,
      0.5005090757044489,
      0.48888361323736385,
      0.47516786499830066,
      0.4790367692619741,
      0.47848946682350363,
      0.5731395260837977,
      0.4691186492849967,
      0.49624339172583143,
      0.5023973230384067,
      0.4833279438539893,
      0.45739392659621325,
      0.462730697511199,
      0.40996384369042105,
      0.45707286837215194,
      0.4452922910630346,
      0.4722525508460884,
      0.45526023657022124,
      0.403002411992607,
      0.46047828237632077,
      0.46066049804944476,
      0.4230501280840999,
      0.4164176371104703,
      0.4257897942455229,
      0.44923446741468176,
      0.45662621346240984,
      0.43234923962882893,
      0.4327502120754676,
      0.44108897493092597,
      0.4540474235476134,
      0.41594066059518003,
      0.45549211771545295,
      0.4541071020914409,
      0.4594358004317312,
      0.4448190990411593,
      0.4497324539872701,
      0.4200029696176152,
      0.4398729909679847,
      0.44475561740869535,
      0.41507212285866996,
      0.4043441427681974,
      0.4185196038937854,
      0.4188154924237086,
      0.43002064290517816,
      0.44260181013695493,
      0.43768649126241305,
      0.41855830303923097,
      0.428766533268426,
      0.4605000755922523,
      0.4437971607564452,
      0.45169978541528394,
      0.44074034366957443,
      0.4163925937192883,
      0.43965289039526156,
      0.45044812483344965,
      0.4567260216988489,
      0.43766554467335433,
      0.4655330014889112,
      0.4382164676478523,
      0.42689325957598084,
      0.46146419392731375,
      0.4815732942280655,
      0.4533639769800409,
      0.4596856540637816,
      0.44031740156654825,
      0.43016910842971173,
      0.434931220658525,
      0.4386533872720724,
      0.4404386634419778
    ],
    "best_epoch": 31,
    "best_val_loss": 0.403002411992607,
    "test_loss": 0.49288924396679734,
    "tracker": {
      "initial_train_loss": 0.4269735036812543,
      "train_threshold": 0.14232450122708476,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.403002411992607,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_4_9ad239/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_4_9ad239/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_4_9ad239/config.yaml"
}