epoch,train_loss,val_loss
1,0.606328,0.455947
2,0.242164,0.268503
3,0.189491,0.258015
4,0.166009,0.244912
5,0.149812,0.241622
6,0.141435,0.228993
7,0.133400,0.222802
8,0.125207,0.218986
9,0.123309,0.215613
10,0.113078,0.212233
11,0.108489,0.214803
12,0.107999,0.220935
13,0.102475,0.222952
14,0.102139,0.217594
15,0.100905,0.223245
16,0.099425,0.226292
17,0.099139,0.228965
18,0.099337,0.229877
19,0.094697,0.230762
20,0.093826,0.229579
21,0.092193,0.231717
22,0.090547,0.234351
23,0.089661,0.236709
24,0.086921,0.236729
25,0.087065,0.239916
26,0.082899,0.246224
27,0.087040,0.245632
28,0.083956,0.246518
29,0.082115,0.258661
30,0.084354,0.256193
31,0.082838,0.253855
32,0.081840,0.258198
33,0.080581,0.264820
34,0.081517,0.261419
35,0.078976,0.265169
36,0.077009,0.269985
37,0.076573,0.272089
38,0.078925,0.273166
39,0.077738,0.276842
40,0.076783,0.281316
41,0.076482,0.281812
42,0.074777,0.281187
43,0.072373,0.284346
44,0.073146,0.292636
45,0.073673,0.288236
46,0.073916,0.289148
47,0.070245,0.299810
48,0.072534,0.295812
49,0.070461,0.305496
50,0.071336,0.299814
51,0.071930,0.300517
52,0.069420,0.303153
53,0.067997,0.305433
54,0.072511,0.309960
55,0.067305,0.304062
56,0.068297,0.312465
57,0.067361,0.308112
58,0.067450,0.309315
59,0.064063,0.304399
60,0.067581,0.302686
61,0.067212,0.303541
62,0.066298,0.306918
63,0.065496,0.308524
64,0.065248,0.309776
65,0.067105,0.313436
66,0.068021,0.309390
67,0.065284,0.307239
68,0.064627,0.312114
69,0.065771,0.313093
70,0.064822,0.314591
71,0.063860,0.313337
72,0.064088,0.315819
73,0.063423,0.314330
74,0.062751,0.312321
75,0.063443,0.315334
76,0.061864,0.316661
77,0.063762,0.318861
78,0.062382,0.314830
79,0.062744,0.312952
80,0.063690,0.311789
