epoch,train_loss,val_loss
1,0.974519,0.332253
2,0.999467,0.352142
3,0.991681,0.346300
4,0.944428,0.807525
5,0.679110,1.017365
6,0.271836,0.186980
7,0.160304,0.474923
8,0.124396,0.301428
9,0.124687,0.319835
10,0.121097,0.479133
11,0.115979,0.377415
12,0.113455,0.448531
13,0.112967,0.329049
14,0.116231,0.282729
15,0.111069,0.322203
16,0.112817,0.749684
17,0.124199,0.295659
18,0.134191,0.309431
19,0.114053,0.408331
20,0.127881,0.319948
21,0.175253,0.263791
22,0.115282,0.446574
23,0.117255,0.470540
24,0.110297,0.611582
25,0.108055,0.514931
26,0.108332,0.273740
27,0.106186,0.278255
28,0.108422,0.508949
29,0.103008,0.273809
30,0.111452,0.374516
31,0.104886,0.313287
32,0.104820,0.323849
33,0.104888,0.327134
34,0.104405,0.270150
35,0.110982,0.383867
36,0.131520,0.298992
37,0.676756,0.315400
38,0.596313,0.299473
39,0.234314,0.284702
40,0.134714,0.278283
41,0.123259,0.272336
42,0.128095,0.314669
43,0.117924,0.279133
44,0.121816,0.290485
45,0.123084,0.274595
46,0.217307,0.277673
47,0.148382,0.258102
48,0.126377,0.268247
49,0.119756,0.292259
50,0.110801,0.314373
51,0.112519,0.366401
52,0.112413,0.451263
53,0.110913,0.304520
54,0.107554,0.287043
55,0.109062,0.325293
56,0.114567,0.282724
57,0.127678,0.306363
58,0.109906,0.286108
59,0.111634,0.287103
60,0.119330,0.306428
61,0.109066,0.295375
62,0.109013,0.319442
63,0.107935,0.673479
64,0.107779,0.397343
65,0.105932,0.400135
66,0.106979,0.287077
67,0.108896,0.495378
68,0.108410,0.302968
69,0.130758,0.348818
70,0.376689,0.264380
71,0.207109,0.470065
72,0.131645,0.368932
73,0.125816,0.614899
74,0.118785,0.537131
75,0.123861,0.512874
76,0.224122,0.294600
77,0.120801,0.315642
78,0.113869,0.356935
79,0.112677,0.438603
80,0.110196,0.524463
