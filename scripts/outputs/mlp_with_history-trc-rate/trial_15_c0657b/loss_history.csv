epoch,train_loss,val_loss
1,0.964214,0.347715
2,0.416380,0.305267
3,0.214068,0.750561
4,0.163356,0.278684
5,0.167156,0.268037
6,0.157151,0.258587
7,0.156239,0.305551
8,0.147432,0.303330
9,0.149395,0.313434
10,0.147159,0.274785
11,0.145328,0.267715
12,0.144665,0.268145
13,0.132646,0.273972
14,0.146558,0.277008
15,0.143262,0.268403
16,0.138272,0.320781
17,0.137057,0.264350
18,0.135261,0.293119
19,0.136319,0.264568
20,0.129489,0.293143
21,0.140326,0.321295
22,0.141399,0.294024
23,0.136630,0.294069
24,0.139569,0.292261
25,0.133335,0.288639
26,0.132652,0.263386
27,0.136830,0.296179
28,0.133695,0.275364
29,0.133532,0.299425
30,0.132453,0.316614
31,0.185450,0.249186
32,0.139490,0.290408
33,0.132680,0.288308
34,0.145574,0.284710
35,0.128385,0.273638
36,0.128327,0.290758
37,0.127784,0.278477
38,0.132896,0.292081
39,0.127048,0.273695
40,0.128332,0.296461
41,0.127742,0.283387
42,0.129949,0.804601
43,0.139815,0.268848
44,0.131905,0.291054
45,0.122045,0.303430
46,0.154841,0.290888
47,0.127179,0.267884
48,0.121543,0.273319
49,0.124810,0.403030
50,0.130700,0.290630
51,0.230219,0.284964
52,0.330729,0.344840
53,0.194642,0.280264
54,0.155842,0.292274
55,0.135801,0.275566
56,0.138206,0.299514
57,0.130327,0.277073
58,0.143634,0.282622
59,0.138538,0.264835
60,0.126627,0.285921
61,0.137616,0.279340
62,0.133910,0.291620
63,0.132639,0.268228
64,0.126323,0.272253
65,0.127430,0.288934
66,0.126191,0.313192
67,0.139038,0.290599
68,0.132805,0.412123
69,0.130643,0.306813
70,0.147788,0.286736
71,0.187724,0.251440
72,0.141648,0.315145
73,0.131094,0.294191
74,0.128622,0.323248
75,0.133924,0.289668
76,0.132123,0.295982
77,0.130009,0.292894
78,0.136013,0.291931
79,0.134723,0.285307
80,0.129166,0.286355
81,0.134203,0.265761
