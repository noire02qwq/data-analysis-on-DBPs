{
  "model_name": "mlp-trc-rate/trial_57_4ed283",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.3264960904358068,
    "mid_layer_count": 11,
    "mid_layer_size": 447
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 359,
    "learning_rate": 0.0010793796273118345,
    "weight_decay": 0.0002878190649974947,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.403975514730409,
      0.14560650902708994,
      0.10677948402763636,
      0.09387900192135722,
      0.08569711803426615,
      0.08074546749371483,
      0.0759312416048861,
      0.07259041060043213,
      0.0703133482485054,
      0.0685189902751858,
      0.06700309535240961,
      0.06379770207528948,
      0.06655174385414116,
      0.06377528653240712,
      0.06050235748466863,
      0.061869975402588075,
      0.05798830868405844,
      0.05676599501131849,
      0.05604249635914875,
      0.05743846917508687,
      0.05506378390934756,
      0.05340174000553515,
      0.056737403847418606,
      0.05559043842905405,
      0.05197552045670578,
      0.053565172057096135,
      0.050902900533543266,
      0.052785849841880214,
      0.05053506147072461,
      0.04997807063865717,
      0.05264986921226049,
      0.04934614409944411,
      0.051079931895914234,
      0.04815746421159736,
      0.048922125467521185,
      0.04910309809671496,
      0.049623400667226425,
      0.048297418841471915,
      0.04793882893284677,
      0.04628152542605637,
      0.04753823716885359,
      0.04619709450585253,
      0.04707537669298541,
      0.04649976817934008,
      0.046666355457170274,
      0.04543699390217165,
      0.044487492992743856,
      0.0443178834656436,
      0.045970701394634196,
      0.047513123364663234,
      0.044688339100021957,
      0.041776865617056236,
      0.042983189934798695,
      0.04286823159570172,
      0.042700483133990594,
      0.043466103776884174,
      0.042360438882115714,
      0.043072138945947185,
      0.04089124702068171,
      0.04130217226546137,
      0.04247242848786897,
      0.04217138513827122,
      0.04136610059464219,
      0.04073292901094386,
      0.04107848678086203,
      0.040436643990508836,
      0.04126364070102152,
      0.04161798736398773,
      0.04026040334202896,
      0.04143938072180598,
      0.04213204952611518,
      0.04025829605626305,
      0.041384680638650764,
      0.040732194886009106,
      0.04182840667601929,
      0.040808560449979804,
      0.04175070083708244,
      0.040259268601210436,
      0.040060361965787356,
      0.039898403008980225
    ],
    "val_loss": [
      0.27569549021695905,
      0.21862878872159713,
      0.19665056460364136,
      0.21434758950002536,
      0.2337165174715801,
      0.22962122528317447,
      0.22520595786278833,
      0.22830812682224783,
      0.23269657733220006,
      0.24996657970021227,
      0.25962784756309615,
      0.2514521206344316,
      0.2520596317021165,
      0.26435756447228664,
      0.27532490588010783,
      0.2662686868955543,
      0.2749374554420035,
      0.2996928138558022,
      0.28639063467076437,
      0.2967608773456273,
      0.28517753510306515,
      0.2927406582512898,
      0.2854389140795091,
      0.2973335286568917,
      0.2977489630262295,
      0.28535062532849653,
      0.28779021594004184,
      0.299683210083066,
      0.32911004574222125,
      0.31742510673238666,
      0.31308126188480034,
      0.3142565442349561,
      0.3088620262789334,
      0.30820187660168386,
      0.30626956307089437,
      0.3203768081896141,
      0.31373775808954846,
      0.33683886966015586,
      0.324895011218722,
      0.3238325538202942,
      0.33049428985638174,
      0.3171590384107061,
      0.35087632281136905,
      0.323757290649423,
      0.3211843894292673,
      0.3213088585476497,
      0.332528565154818,
      0.3084577438549813,
      0.33621906712205113,
      0.3317309629194394,
      0.350278636810933,
      0.32867003203464484,
      0.31854407841975463,
      0.3463027836453772,
      0.3313211896395433,
      0.33561464061704044,
      0.3313903893093149,
      0.3403284017721604,
      0.32231215202322083,
      0.34281744860380353,
      0.31401945755086436,
      0.34609455983572734,
      0.3140846658308438,
      0.31451084407012975,
      0.32739153250628067,
      0.31693933996857104,
      0.31464584008706903,
      0.3155170795323695,
      0.32094778837803417,
      0.31662419715416645,
      0.32772819552414434,
      0.32180253679970067,
      0.3181124423424195,
      0.32272472632212373,
      0.3191507517544185,
      0.32113891133179745,
      0.31897878307782246,
      0.3182881961437221,
      0.319251640919529,
      0.31740945743698024
    ],
    "best_epoch": 3,
    "best_val_loss": 0.19665056460364136,
    "best_val_abs_mse": 0.2399217039346695,
    "test_loss": 4.774244242878051,
    "test_abs_mse": 46.48466491699219,
    "tracker": {
      "initial_train_loss": 0.403975514730409,
      "train_threshold": 0.13465850491013634,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.19665056460364136,
      "patience_no_improve_epochs": 78,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_57_4ed283/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_57_4ed283/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_57_4ed283/config.yaml"
}