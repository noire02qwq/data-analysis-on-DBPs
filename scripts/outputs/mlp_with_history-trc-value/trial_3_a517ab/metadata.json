{
  "model_name": "mlp_with_history-trc-value/trial_3_a517ab",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 30,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.4555022244424468,
    "mid_layer_count": 14,
    "mid_layer_size": 284
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 398,
    "learning_rate": 0.0017891008892460362,
    "weight_decay": 0.005963253485996019,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7767,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 300,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92
    ],
    "train_loss": [
      0.9807525777565063,
      0.9994121395177142,
      0.9994237360782999,
      0.99972111681982,
      0.9995874968737851,
      0.9989702633115735,
      0.9997182776680228,
      0.999563068761564,
      0.9996702675885701,
      0.9993733153374511,
      0.9994339445804681,
      0.9995191313975779,
      0.999386006246068,
      0.9992242556550227,
      0.9993781669652184,
      0.9995459564959694,
      0.9992868328272522,
      0.9992302074784767,
      0.9997505883813227,
      0.9993045028455932,
      0.9994083366231966,
      0.9993215974761326,
      0.9993607348359443,
      0.9993598770416886,
      0.9991731241861488,
      0.999351371649964,
      0.9993816591742662,
      0.999430844202701,
      0.9992702477024653,
      0.9993999440328977,
      0.9992580068637862,
      0.9993566467646268,
      0.999366828277026,
      0.9993469105028379,
      0.9993396775210182,
      0.9993030326514074,
      0.999284164838323,
      0.9993607981318257,
      0.999325662018695,
      0.9993204614578012,
      0.9993786154696421,
      0.9994265842855214,
      0.9992927482448306,
      0.9993229238962719,
      0.9993021132956145,
      0.9993260758055428,
      0.9992830768214147,
      0.9992851635748867,
      0.9992857788295778,
      0.9992936730799228,
      0.9992997014524088,
      0.9992899530809083,
      0.9992917498766233,
      0.9992937258929993,
      0.9993246308667819,
      0.9992793900742254,
      0.9992879606880275,
      0.9992881555177844,
      0.9993028929599759,
      0.9993910563564583,
      0.9993170674156925,
      0.9992546612835458,
      0.9992869933845301,
      0.9992771725926571,
      0.9993005254269567,
      0.9992711038928366,
      0.9993217047291925,
      0.999281117580596,
      0.9992760617913803,
      0.9992944194080441,
      0.999317871997819,
      0.999277299637191,
      0.9993007382294287,
      0.9992726898659944,
      0.9993053481617812,
      0.9993183394572411,
      0.9993045080793216,
      0.9992895293637901,
      0.9992961232782224,
      0.9992850513336694,
      0.9993075246790654,
      0.9992816376842648,
      0.999297799575401,
      0.9992916549021049,
      0.9992704994048915,
      0.9993032965556341,
      0.9993137887458291,
      0.9993260473730452,
      0.999313767051181,
      0.9992787193512233,
      0.9992973215103886,
      0.9992847372869489
    ],
    "val_loss": [
      0.3402174264817181,
      0.36314060391334,
      0.3634586014076621,
      0.3591422349080711,
      0.3583348013639093,
      0.3596199888802931,
      0.35843417120729376,
      0.355715184346466,
      0.3593476716718988,
      0.3559037295822612,
      0.35786385646391056,
      0.3589229961355289,
      0.3578674076783086,
      0.3577337335103643,
      0.3582180119961679,
      0.35829961888358264,
      0.35464424679200807,
      0.3559000758309207,
      0.3603958705674388,
      0.3530494713140819,
      0.3581789916325472,
      0.35665438874306793,
      0.35589809635888314,
      0.3585689730808407,
      0.3553906569625446,
      0.35602065695527785,
      0.3568092672767753,
      0.35442230993669904,
      0.3588283128724127,
      0.35826964509522846,
      0.3568457236145428,
      0.35693228418330947,
      0.3586041304522646,
      0.3573388832102636,
      0.35607965793795215,
      0.35664606943369626,
      0.35551532690307336,
      0.35653796946395655,
      0.3590513885065824,
      0.355521062444784,
      0.3571507082460169,
      0.3530467757430976,
      0.3554289729161534,
      0.356750355772451,
      0.35679366278523456,
      0.3577528604356472,
      0.35600433598110776,
      0.35650717121755293,
      0.35706121151497267,
      0.3559181991317672,
      0.35633417507577797,
      0.35458811598712814,
      0.3546602438533021,
      0.3568730851401112,
      0.3551103892752867,
      0.3557340723534901,
      0.35497835719299886,
      0.35566827033361986,
      0.3557477360089382,
      0.3578624678898357,
      0.3551328010678648,
      0.35681283216098114,
      0.35707732783017043,
      0.3567994084543811,
      0.3577730951061149,
      0.3556540543760011,
      0.3542974505372747,
      0.3561165526866199,
      0.35676534741135413,
      0.35638932485780317,
      0.3573519200175822,
      0.3557319756441131,
      0.3547229564341599,
      0.35593966394662857,
      0.35717102153572494,
      0.3580609589012083,
      0.3549793099125702,
      0.355227729049093,
      0.3562586708250874,
      0.35571491774060054,
      0.35636525935309377,
      0.356874687617232,
      0.35567987090991643,
      0.3557282094826955,
      0.35737964187018173,
      0.3568821791447922,
      0.3570992327646581,
      0.35758523413699544,
      0.3558485310323938,
      0.35624712592291974,
      0.3574695180588497,
      0.3578979348618827
    ],
    "best_epoch": 92,
    "best_val_loss": 0.3578979348618827,
    "test_loss": 5.723894552180641,
    "tracker": {
      "initial_train_loss": 0.9807525777565063,
      "train_threshold": 0.32691752591883544,
      "best_tracking": false,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3530467757430976,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_3_a517ab/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_3_a517ab/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_3_a517ab/config.yaml"
}