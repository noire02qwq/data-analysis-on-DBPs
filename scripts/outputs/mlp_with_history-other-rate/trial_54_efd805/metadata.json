{
  "model_name": "mlp_with_history-other-rate/trial_54_efd805",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 74,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.11838341628111401,
    "mid_layer_count": 15,
    "mid_layer_size": 525
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 158,
    "learning_rate": 0.0008466248357190051,
    "weight_decay": 8.075266981491026e-06,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7723,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 740,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149,
      150,
      151,
      152,
      153,
      154,
      155,
      156,
      157,
      158
    ],
    "train_loss": [
      0.5209688942743894,
      0.3471683025298365,
      0.30116786948143165,
      0.25363154249550623,
      0.23469036201862387,
      0.222907915200098,
      0.1988715224105985,
      0.18640328269771664,
      0.16805168325868924,
      0.1539434992200458,
      0.12817891789994584,
      0.10979745582963586,
      0.10839429824953944,
      0.09689706391070646,
      0.0922133707471899,
      0.09040686706469094,
      0.08115318919592658,
      0.07497130912923602,
      0.07062522067830582,
      0.06170219696298961,
      0.05610405772279986,
      0.05485030318362315,
      0.05328567345459875,
      0.05348429287043736,
      0.047626966886221395,
      0.0467104414511951,
      0.047253617053318715,
      0.04233033382242769,
      0.04276793174928957,
      0.04153247817889653,
      0.04073647392457142,
      0.03969397691103688,
      0.03915537795707705,
      0.04229378880660151,
      0.04064046723398384,
      0.04085421964968021,
      0.03677987575455757,
      0.036330656738543965,
      0.043901341169817865,
      0.04462364908280296,
      0.06027774238351419,
      0.043236199471191256,
      0.03887593907391054,
      0.03676626347145252,
      0.03622537288512341,
      0.03668125258995263,
      0.03389877295954833,
      0.03279912125723945,
      0.03383199766203018,
      0.08676206196267479,
      0.0591888586774316,
      0.04481555786016119,
      0.04732495718303391,
      0.04294611888796682,
      0.044442249338282336,
      0.036894000539944204,
      0.041701936743411626,
      0.04880762765784346,
      0.041563499545253776,
      0.03703340259407772,
      0.033877408470093594,
      0.03475516076171613,
      0.0388395277122196,
      0.03922108354011487,
      0.032542851881962064,
      0.03141811044789512,
      0.030385403020690177,
      0.032312444798435154,
      0.0310854227437066,
      0.03048111139067703,
      0.030119245376273418,
      0.030369321538190157,
      0.029139772864526747,
      0.030555486706089482,
      0.04767680926040774,
      0.08257298483319747,
      0.07016188283183793,
      0.05225459514271406,
      0.041311199849544525,
      0.03773006847243798,
      0.04457017202733419,
      0.03741285676542039,
      0.03831350982235485,
      0.03729526006784153,
      0.035095535990979004,
      0.03566426815829036,
      0.03998676329565592,
      0.039467939420102884,
      0.038584581084156785,
      0.0356986071491402,
      0.030566121237508053,
      0.031061949612116713,
      0.030333754591953487,
      0.029058739448417952,
      0.029315834395634715,
      0.028819678879953042,
      0.02886796506078583,
      0.030699717589267775,
      0.036392140718714557,
      0.03233218337570187,
      0.05273519733745354,
      0.04143058453403991,
      0.041838249645786675,
      0.03382072018206922,
      0.03260818315653253,
      0.044939538040676526,
      0.037432210108212946,
      0.04556154486871933,
      0.03936441611268507,
      0.03848445872198219,
      0.05840168577244704,
      0.04038857709832039,
      0.032170711088818034,
      0.031059476904977207,
      0.030376865299763217,
      0.031511645145722966,
      0.028820633637898174,
      0.027958923139215427,
      0.02760444551843305,
      0.027413030452500518,
      0.028772243106489074,
      0.027553381604048063,
      0.02764100030331812,
      0.04691973015392026,
      0.04441593458800524,
      0.04182722882906591,
      0.048837906809671545,
      0.053214878299689954,
      0.04406818051181061,
      0.045721428287696084,
      0.03778972956141505,
      0.035732112949848883,
      0.04982237632829075,
      0.044981386694368825,
      0.03620768167878253,
      0.04214328574239783,
      0.038640131790658346,
      0.03550718138342916,
      0.029965625441797532,
      0.030212125732865757,
      0.029554306496299875,
      0.02780537597355595,
      0.027436770636467264,
      0.027589185772844506,
      0.027597746987266737,
      0.028165653084839978,
      0.030293593716412246,
      0.034996167778444,
      0.03424790826900225,
      0.0688939990137396,
      0.06878176132062934,
      0.043019770510869984,
      0.03808516802809622,
      0.03747081816260114,
      0.035670239098247555,
      0.03434416991984707,
      0.03160580622822637,
      0.029878331777844328
    ],
    "val_loss": [
      0.4596573619696194,
      0.49031983650551586,
      0.5299374686922141,
      0.6760862983272461,
      0.762937616097356,
      0.9901446214336121,
      0.4876835472747951,
      1.0886105654125442,
      0.5273912081996838,
      0.6878084211470838,
      0.7587721315508117,
      1.05899074173973,
      0.8296956702799141,
      0.7336410736787818,
      0.910791351730952,
      0.7230004861861646,
      0.6245880524376909,
      0.7503906262313534,
      0.5759626354375286,
      0.7576516360222937,
      0.5824952475325076,
      0.70020529195934,
      0.7629681513694946,
      0.8066603108615933,
      0.6261245956856334,
      0.5557244090887601,
      0.5451444373025509,
      0.5438172636453263,
      0.5891390173378105,
      0.5938990913108437,
      0.6246250135099103,
      0.5613504902777557,
      0.6041497966129623,
      0.6242013693212749,
      0.6330202583959716,
      0.5405629097790775,
      0.6034687488378879,
      0.5573295161574187,
      0.6253607597358213,
      0.5460046116017296,
      0.5205646157532395,
      0.6542776608181571,
      0.5608069319121852,
      0.5382168999332154,
      0.5891481618681353,
      0.5929034094878299,
      0.5448288405459084,
      0.55210972610348,
      0.603377163633258,
      0.5422702438817053,
      0.6086560508626664,
      0.5505731787331803,
      0.597007403669957,
      0.5491861935504182,
      0.5461472230578611,
      0.5336906239747288,
      0.6000085101691549,
      0.5485563062800619,
      0.5835416567539741,
      0.5388915922738121,
      0.548654565741559,
      0.5847274727673231,
      0.5570834526223337,
      0.612431799169786,
      0.5872580877499666,
      0.5508596848406477,
      0.5586470779544579,
      0.5357962080104622,
      0.5788310158038568,
      0.5807969190135688,
      0.5758464554648199,
      0.5290322899550735,
      0.5723398210759648,
      0.5670286198129911,
      0.6101787636870752,
      0.5649740518477863,
      0.46846793002175713,
      0.5470401554407474,
      0.5247806839689523,
      0.5373574380389231,
      0.5169564162899634,
      0.49944996073574366,
      0.523580325417176,
      0.5719011173812215,
      0.5368303097650676,
      0.49025487754337804,
      0.508523062241827,
      0.49777189422242657,
      0.5037773540321582,
      0.5320690538890348,
      0.5514965654490237,
      0.5396681612970943,
      0.512468623704539,
      0.5323875136985751,
      0.5117051051985361,
      0.5184031868587711,
      0.5261597970199442,
      0.49889376437860333,
      0.5170069893052478,
      0.52720775266072,
      0.522306763046159,
      0.508090540976403,
      0.5346150772924909,
      0.5178261992281783,
      0.6012282129667119,
      0.5450544493284054,
      0.5497674252994046,
      0.435484136792714,
      0.5239398752233225,
      0.4932082089656841,
      0.5280403446651505,
      0.5570694642375686,
      0.5884149507312717,
      0.5757673483765767,
      0.543174585048667,
      0.5809589308714438,
      0.5750600460492922,
      0.5647874272869019,
      0.5473447154203575,
      0.524019026791978,
      0.4995756934949024,
      0.5300654751811913,
      0.4855566021211133,
      0.49756405870179216,
      0.5371229721222095,
      0.4950642446290233,
      0.4757801742253903,
      0.5306696260760644,
      0.6541499044188482,
      0.5484883553878276,
      0.5433836865389419,
      0.5016384781299237,
      0.5044779607546543,
      0.54235643701639,
      0.6267365184015856,
      0.4942810541676904,
      0.541350424851843,
      0.5763547612343006,
      0.5627255841554282,
      0.5638980095793387,
      0.5789756137096953,
      0.5341425804722452,
      0.5413959913357289,
      0.5282685812183483,
      0.5546048808329833,
      0.5489752562281615,
      0.5357213028890644,
      0.5104710719096447,
      0.5712302180464396,
      0.5579149161270278,
      0.5762635612737633,
      0.5888636274073652,
      0.6444148563160867,
      0.5332890099929478,
      0.5839852976584863,
      0.5899615860270883,
      0.5786771013886629,
      0.5706765259989721
    ],
    "best_epoch": 108,
    "best_val_loss": 0.435484136792714,
    "best_val_abs_mse": 0.4604222774505615,
    "test_loss": 0.5402711796881765,
    "test_abs_mse": 0.9707889556884766,
    "tracker": {
      "initial_train_loss": 0.5209688942743894,
      "train_threshold": 0.17365629809146313,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.435484136792714,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-rate/trial_54_efd805/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-rate/trial_54_efd805/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-rate/trial_54_efd805/config.yaml"
}