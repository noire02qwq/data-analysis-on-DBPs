epoch,train_loss,val_loss
1,1.004392,0.353338
2,1.003867,0.348903
3,1.004143,0.350641
4,1.003789,0.350589
5,1.003837,0.349788
6,1.003769,0.344058
7,1.003888,0.351211
8,1.003759,0.347034
9,1.003643,0.346916
10,1.003703,0.346772
11,1.003769,0.349668
12,1.003628,0.346805
13,1.003692,0.345908
14,1.003687,0.347028
15,1.003683,0.347228
16,1.003644,0.346525
17,1.003733,0.348424
18,1.003779,0.345693
19,1.003739,0.347927
20,1.003746,0.347241
21,1.003640,0.345988
22,1.003602,0.348435
23,1.003605,0.346505
24,1.003603,0.345648
25,1.003634,0.345906
26,1.003611,0.346227
27,1.003698,0.347185
28,1.003687,0.347519
29,1.003669,0.346130
30,1.003613,0.345888
31,1.003626,0.345995
32,1.003662,0.344186
33,1.003763,0.339955
34,1.003728,0.347591
35,1.003683,0.346745
36,1.003615,0.345901
37,1.003599,0.346475
38,1.003689,0.347979
39,1.003628,0.343147
40,1.003696,0.344942
41,1.003641,0.345517
42,1.003611,0.346733
43,1.003650,0.347447
44,1.003636,0.345707
45,1.003663,0.344866
46,1.003597,0.345543
47,1.003615,0.348024
48,1.004098,0.342567
49,1.003875,0.342364
50,1.003683,0.347172
