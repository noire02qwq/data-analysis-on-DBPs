{
  "model_name": "mlp-trc-value/trial_24_401727",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.22320238723823185,
    "mid_layer_count": 12,
    "mid_layer_size": 307
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 277,
    "learning_rate": 0.0005911967497675618,
    "weight_decay": 0.0014398249475025353,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.4247124982551467,
      0.13652305520417263,
      0.0980168440053789,
      0.08199241226457782,
      0.07395289060380167,
      0.07030265480174797,
      0.06655153023578865,
      0.06209680622777094,
      0.06176291098708278,
      0.06095243626780208,
      0.057150430713095474,
      0.058445383690913066,
      0.05807829404076807,
      0.05377394466036372,
      0.0556198851692334,
      0.054245387585790665,
      0.05277134395520341,
      0.053701622841192585,
      0.05128448558450433,
      0.051126383155156184,
      0.05124972120267633,
      0.05049338845489284,
      0.04923882871376912,
      0.05090822152537282,
      0.05028692295745191,
      0.04804157855236695,
      0.04747245987239802,
      0.048313706182421264,
      0.0482412526664014,
      0.04669445082344585,
      0.046893495589441184,
      0.04656778149815203,
      0.04673203625016224,
      0.04750829870038962,
      0.04676982128668697,
      0.045954261894976714,
      0.04605951298911291,
      0.04633288849584793,
      0.044908582051310895,
      0.04532168459447303,
      0.04657000637665322,
      0.046624958385193024,
      0.04287132717527568,
      0.04347549086812216,
      0.04388382525616667,
      0.042512931327706824,
      0.04305156358370052,
      0.04289554695518981,
      0.04350933652722863,
      0.043782425622884404,
      0.04257752510191937,
      0.043484970565030916,
      0.04264873193826368,
      0.04313232794904813,
      0.04324728882168656,
      0.043996266543333835,
      0.04315863659852908,
      0.0434986598108283,
      0.04395024664365539,
      0.0419584068174872,
      0.04186069561200089,
      0.04122111513415565,
      0.04345572488014517,
      0.04209317832902311,
      0.04267810403549515,
      0.04177193916242679,
      0.04144234746491958,
      0.04291163702777803,
      0.04161519325147643,
      0.04086796964985582,
      0.040517720614123676,
      0.04106165209174416,
      0.040303651966429814,
      0.04119311479479839,
      0.04090037466284402,
      0.0406021900970074,
      0.04024256750264646,
      0.04114938471437632,
      0.04064401473349229,
      0.04143082295874637
    ],
    "val_loss": [
      0.2896401600209539,
      0.23565335126515635,
      0.21808443242449782,
      0.25736891926673355,
      0.24453696894409235,
      0.22303021142738844,
      0.23141961969033686,
      0.22905868212218414,
      0.22888140761053669,
      0.259599829005624,
      0.2558187400721415,
      0.23981208424836753,
      0.23866069473571586,
      0.30536231709766887,
      0.3309613706544042,
      0.2740154883539873,
      0.28683224935084584,
      0.3161980518167783,
      0.26794624949532175,
      0.28644946530505927,
      0.2784296559872563,
      0.2897619009709465,
      0.26872126330024826,
      0.27967785582347904,
      0.301671569789955,
      0.2939988720437099,
      0.2879224247148562,
      0.3009581641277332,
      0.3317338371560156,
      0.31710781968215446,
      0.321673963280272,
      0.2838861265994921,
      0.2995807507716699,
      0.30321778083320505,
      0.30045369648915565,
      0.30316473459657617,
      0.32561067165974195,
      0.3016942592650027,
      0.28764951510946013,
      0.2950764379692738,
      0.28570640552231297,
      0.2949779742759859,
      0.32696851593090925,
      0.30910937716504056,
      0.3181131712222349,
      0.30431638129256267,
      0.3378130180560454,
      0.2949125514505152,
      0.3118548212885232,
      0.31898164867150214,
      0.3512306720096462,
      0.28903926674633507,
      0.3096368358275312,
      0.3564158896185056,
      0.30479111372532247,
      0.3019343021833254,
      0.2932339662106005,
      0.35549550326485296,
      0.3044443689766312,
      0.34503438846280654,
      0.3407406953760161,
      0.30534070454270185,
      0.3304660636697433,
      0.29300212457017627,
      0.3111376046621335,
      0.30687803850581724,
      0.30589251794523287,
      0.29386852246201683,
      0.3037696133161376,
      0.29654090612524464,
      0.3195668716574768,
      0.2891781413760371,
      0.31187881347305046,
      0.2913433008353243,
      0.3043144476404804,
      0.27607959156443257,
      0.2837072105130214,
      0.3296793475200584,
      0.3461447724849432,
      0.3007415041572855
    ],
    "best_epoch": 3,
    "best_val_loss": 0.21808443242449782,
    "test_loss": 5.400519354491713,
    "tracker": {
      "initial_train_loss": 0.4247124982551467,
      "train_threshold": 0.14157083275171556,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.21808443242449782,
      "patience_no_improve_epochs": 77,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_24_401727/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_24_401727/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_24_401727/config.yaml"
}