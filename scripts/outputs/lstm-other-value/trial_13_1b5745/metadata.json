{
  "model_name": "lstm-other-value/trial_13_1b5745",
  "model_type": "LSTM",
  "model_format": "torch",
  "model_params": {
    "history_length": 123,
    "units": 205,
    "num_layers": 3,
    "dropout": 0.4410302543543363
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 140,
    "learning_rate": 0.0013596564530723731,
    "weight_decay": 0.00015253144908286627,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7674,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 123,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119
    ],
    "train_loss": [
      0.373508548088797,
      0.22032920224361505,
      0.16323817375894945,
      0.14716951617209403,
      0.1294269559320945,
      0.1100600573846161,
      0.11176396950065763,
      0.10413662274507672,
      0.09097026931236024,
      0.13095217562992498,
      0.11020796375137025,
      0.09588205191246818,
      0.10710943894155453,
      0.07322941359801469,
      0.0627984214988667,
      0.07546712053468335,
      0.06451402042631,
      0.052810006258207774,
      0.04777224360731452,
      0.045214613386475234,
      0.0428933280920389,
      0.06087337545943751,
      0.05438295098694936,
      0.0483981227632811,
      0.04332976002932558,
      0.036656779670834944,
      0.07142233963039259,
      0.06396076448333583,
      0.04147528766700306,
      0.04095532321331089,
      0.06373978863284088,
      0.07849045179964882,
      0.04390050369856847,
      0.03647029481037911,
      0.040799783572364294,
      0.035987355545598114,
      0.064757223564579,
      0.04864481392376958,
      0.03262547611537811,
      0.04631805678080512,
      0.04042153827387792,
      0.03283078095504074,
      0.028847197207612765,
      0.02726550233847218,
      0.027308329229153536,
      0.027205258189897878,
      0.034907177034333436,
      0.031798812560008965,
      0.027224687381740005,
      0.03424136667030069,
      0.02638089525129123,
      0.02539299997936275,
      0.024893119234124725,
      0.042417388419085,
      0.12704215613323666,
      0.09306702930222957,
      0.055962942946476024,
      0.05523758625297581,
      0.05252228939314978,
      0.036259754126658966,
      0.032027307480325104,
      0.03666392783980243,
      0.031484562469171085,
      0.02983870003823893,
      0.027372998503663745,
      0.027751366664884394,
      0.02663176865306005,
      0.02828880355824227,
      0.030147661012494227,
      0.027241669369025064,
      0.03493783077439169,
      0.04982033794940466,
      0.030689125619430636,
      0.026769117195647552,
      0.025906214921606344,
      0.02567493371230521,
      0.024951292011582946,
      0.024488881356569514,
      0.030351507102942946,
      0.06146162377069914,
      0.041675051308222695,
      0.030407810083218842,
      0.03178015916691042,
      0.02835594101621827,
      0.02737653944986016,
      0.026395467956833677,
      0.028181311689707524,
      0.024965108806014463,
      0.023808192460758163,
      0.02456062291655374,
      0.02408127942245579,
      0.08074507863494547,
      0.1430323105077275,
      0.10855103509948687,
      0.07439467073232518,
      0.05601079151003287,
      0.05210764390111342,
      0.05072422487749108,
      0.09361905963731706,
      0.057699485214226624,
      0.04968452382932767,
      0.04702329640086193,
      0.034687344260573974,
      0.03154603406740316,
      0.03022977324716741,
      0.028981562320833286,
      0.029537854698220362,
      0.03206082317781054,
      0.047138849799058885,
      0.10821320728372402,
      0.08292930415553104,
      0.05361967575769111,
      0.03667860062186579,
      0.03058288997033859,
      0.03014536616425201,
      0.027912902790671497,
      0.026852164703431245,
      0.026109854034654233,
      0.026535088431351286
    ],
    "val_loss": [
      0.6784048129520016,
      0.7095644744391927,
      0.6717087564889542,
      0.735435092520571,
      0.7653813124773745,
      0.7355182684824139,
      0.724720242405366,
      0.6876185533707727,
      0.7357001123492589,
      0.6465361907096681,
      0.7192527977470866,
      0.5724481105090615,
      0.6676942070801101,
      0.6493947580902876,
      0.472622385192774,
      0.4821817327045395,
      0.5343669519096077,
      0.4940303957569385,
      0.48577457327328755,
      0.45950108481024554,
      0.4369398372437426,
      0.49821776223039915,
      0.5294760351409455,
      0.503376621686056,
      0.5244177148013771,
      0.5648703764298719,
      0.4938177967856744,
      0.5183675953014169,
      0.526645460885442,
      0.502295917558099,
      0.45204421342489964,
      0.46931294802420154,
      0.4875078795555823,
      0.46961491211445744,
      0.4613997338417761,
      0.47642666511906834,
      0.5231486310858926,
      0.5061602381888978,
      0.5554355033143552,
      0.45470561113900054,
      0.5370622516392234,
      0.551017481409861,
      0.5279885628623163,
      0.5854516828845361,
      0.5848165513155703,
      0.584238324336663,
      0.5073814142250015,
      0.5390694177079344,
      0.5684946432798922,
      0.5849940526985122,
      0.5711287634815284,
      0.5850876377014342,
      0.59305375207684,
      0.5200959015749171,
      0.43493119524624535,
      0.46870623328193217,
      0.43543941005618275,
      0.4074544678191225,
      0.4281868691037515,
      0.43050296836627455,
      0.45214467058460156,
      0.40714774258479386,
      0.43076799854546965,
      0.4358730795319209,
      0.44880483411029426,
      0.4088233343498436,
      0.42593222338996245,
      0.4106578930855511,
      0.39936084786575,
      0.435042703446157,
      0.4035347862514907,
      0.45237816763138344,
      0.4382348795850834,
      0.4352888577355596,
      0.4608583578806437,
      0.4450443677916498,
      0.4787934025426111,
      0.5182891225743437,
      0.5317957859910177,
      0.4432483212855048,
      0.48054578436348966,
      0.47307720476995685,
      0.41457161726708897,
      0.4720567330093441,
      0.5524246649827785,
      0.5513516956282233,
      0.5710161494280763,
      0.5315421572523916,
      0.6336254104525744,
      0.5233718326348744,
      0.6763347687121637,
      0.5714712142944336,
      0.48728787631331805,
      0.45534949513252626,
      0.4159195137594988,
      0.4462556872896092,
      0.5249246917441933,
      0.5490982225555145,
      0.5007828486536792,
      0.464448710758529,
      0.44062732409931227,
      0.4953815117924513,
      0.47878439019540114,
      0.4528183673848649,
      0.5087521923873239,
      0.4735004273717275,
      0.5070124388098003,
      0.5090287591882808,
      0.538056699369482,
      0.44761498102884806,
      0.4407549423728874,
      0.441671204781104,
      0.43988357734180494,
      0.46671563386917114,
      0.44588647738188325,
      0.4655076830151552,
      0.4948699913338987,
      0.4959615551069111,
      0.4717936795093342
    ],
    "best_epoch": 69,
    "best_val_loss": 0.39936084786575,
    "test_loss": 0.46811435034757026,
    "tracker": {
      "initial_train_loss": 0.373508548088797,
      "train_threshold": 0.12450284936293234,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.39936084786575,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/lstm-other-value/trial_13_1b5745/best_model.pt",
    "last": "scripts/outputs/lstm-other-value/trial_13_1b5745/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/lstm-other-value/trial_13_1b5745/config.yaml"
}