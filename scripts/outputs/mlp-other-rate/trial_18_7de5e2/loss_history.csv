epoch,train_loss,val_loss
1,0.472801,0.375819
2,0.304873,0.380294
3,0.270255,0.457947
4,0.251561,0.437999
5,0.238899,0.455867
6,0.230476,0.557540
7,0.223157,0.538581
8,0.216549,0.499868
9,0.213010,0.483087
10,0.207447,0.546760
11,0.202301,0.452119
12,0.196845,0.520210
13,0.192622,0.490930
14,0.189209,0.502516
15,0.185479,0.437003
16,0.183992,0.488640
17,0.182411,0.498525
18,0.176467,0.522391
19,0.175639,0.503401
20,0.171105,0.499678
21,0.170937,0.502961
22,0.168692,0.472277
23,0.165593,0.508591
24,0.163926,0.507128
25,0.161885,0.461175
26,0.162816,0.458357
27,0.159066,0.460889
28,0.156727,0.470176
29,0.155364,0.472099
30,0.153290,0.431486
31,0.155157,0.439799
32,0.152411,0.456996
33,0.151619,0.483758
34,0.148796,0.443864
35,0.149659,0.475741
36,0.150778,0.480738
37,0.146163,0.441491
38,0.145911,0.486899
39,0.144855,0.488822
40,0.142907,0.451015
41,0.141213,0.480483
42,0.141833,0.441372
43,0.141490,0.448740
44,0.139937,0.463208
45,0.139305,0.474586
46,0.138715,0.447939
47,0.139328,0.460526
48,0.138175,0.475363
49,0.135147,0.457971
50,0.135877,0.489342
51,0.136477,0.456547
52,0.135441,0.450987
53,0.134316,0.444678
54,0.134052,0.472247
55,0.133900,0.480081
56,0.131559,0.462388
57,0.130572,0.475011
58,0.131830,0.451408
59,0.131269,0.455008
60,0.131943,0.475349
61,0.128906,0.441053
62,0.128255,0.447218
63,0.127578,0.438002
64,0.130403,0.466589
65,0.127622,0.449545
66,0.129600,0.441304
67,0.126847,0.455793
68,0.128438,0.457795
69,0.126168,0.449561
70,0.123900,0.451126
71,0.125501,0.451932
72,0.125581,0.473131
73,0.123289,0.448272
74,0.124341,0.442019
75,0.126617,0.434344
76,0.121861,0.461426
77,0.122497,0.447847
78,0.122744,0.460815
79,0.125490,0.455578
80,0.122250,0.498785
