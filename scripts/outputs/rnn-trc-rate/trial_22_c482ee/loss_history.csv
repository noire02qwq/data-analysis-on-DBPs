epoch,train_loss,val_loss
1,0.350143,0.361589
2,0.148097,0.306450
3,0.100972,0.285356
4,0.091759,0.298136
5,0.087645,0.286143
6,0.082420,0.291699
7,0.076152,0.336064
8,0.297699,0.531149
9,0.333667,0.729193
10,0.528225,0.637148
11,0.697980,1.667032
12,0.721672,1.850336
13,0.715909,1.747219
14,0.716762,1.651152
15,0.717019,1.982555
16,0.721242,1.697316
17,0.722750,1.822866
18,0.720239,1.731663
19,0.719861,1.661679
20,0.723602,1.840418
21,0.976398,0.355014
22,1.004018,0.332718
23,1.004014,0.380687
24,1.004169,0.452354
25,1.005571,0.334175
26,1.005189,0.329384
27,1.007549,0.366552
28,1.003756,0.340789
29,1.002485,0.353086
30,1.004838,0.321007
31,1.003491,0.336003
32,1.003411,0.334168
33,1.002763,0.396883
34,1.002998,0.331071
35,1.002415,0.347673
36,1.002065,0.346046
37,1.001568,0.480429
38,1.003588,0.349550
39,1.001353,0.360362
40,1.002006,0.368104
41,1.002405,0.341092
42,1.000752,0.360619
43,1.001206,0.369424
44,1.000489,0.364464
45,1.000684,0.369403
46,1.000210,0.332423
47,0.999494,0.371888
48,0.999440,0.351019
49,0.999608,0.333058
50,0.999776,0.359115
51,0.999474,0.349924
52,0.999244,0.347039
53,0.999913,0.363265
54,0.998577,0.366787
55,0.998842,0.334719
56,0.999119,0.384192
57,0.999192,0.348947
58,0.999605,0.352793
59,0.999764,0.367401
60,0.999684,0.363948
61,0.999651,0.358372
62,0.999267,0.353367
63,0.999590,0.346733
64,0.998942,0.337028
65,0.999858,0.353477
66,1.000253,0.361988
67,0.999046,0.403279
68,1.000267,0.371696
69,0.998928,0.346535
70,0.999412,0.345199
71,0.998720,0.367443
72,0.998989,0.359234
73,0.999129,0.355783
74,0.999029,0.349415
75,0.998902,0.371200
76,0.999863,0.339710
77,0.999424,0.360239
78,0.999202,0.360724
79,0.999106,0.360401
80,0.998964,0.353643
