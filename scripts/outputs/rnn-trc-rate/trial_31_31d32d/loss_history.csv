epoch,train_loss,val_loss
1,0.303782,0.301749
2,0.157297,0.669861
3,0.119678,0.394717
4,0.120303,0.313798
5,0.097510,0.358478
6,0.109720,0.313858
7,0.137628,0.308834
8,0.086044,0.360294
9,0.205902,0.521563
10,0.596998,0.443577
11,0.508850,0.300803
12,0.776760,0.299065
13,0.605543,0.957175
14,0.796134,0.557619
15,0.859537,0.688847
16,0.833260,1.395995
17,0.825686,0.320803
18,0.980995,0.315376
19,0.876341,0.291311
20,0.779485,0.386514
21,0.655641,0.982937
22,0.643628,0.799200
23,0.658347,1.624002
24,0.746531,1.260245
25,0.565145,1.414569
26,0.573642,0.291903
27,0.611414,0.305646
28,0.602456,0.284088
29,0.657718,0.288136
30,0.689324,0.382457
31,0.625675,0.963753
32,0.485431,0.398724
33,0.541377,0.333248
34,0.673728,0.285702
35,0.899973,0.398277
36,1.007428,0.446177
37,1.006981,0.353149
38,1.003666,0.382629
39,1.002230,0.386698
40,1.004141,0.350927
41,1.004492,0.321145
42,1.002377,0.344646
43,1.004719,0.352647
44,1.001763,0.373915
45,1.000733,0.360649
46,1.002039,0.376108
47,0.999902,0.349673
48,1.001268,0.353102
49,1.001966,0.344017
50,1.000183,0.351697
51,1.001132,0.343919
52,1.001673,0.336963
53,1.002113,0.372574
54,1.000654,0.337308
55,1.002436,0.338955
56,0.998958,0.356324
57,0.999034,0.359330
58,0.998897,0.356685
59,0.998982,0.360157
60,0.999161,0.353310
61,0.999134,0.358264
62,0.999076,0.351124
63,0.999045,0.348084
64,0.998849,0.349533
65,0.998815,0.354550
66,0.998834,0.359229
67,0.999161,0.357042
68,0.998781,0.357582
69,0.998874,0.358089
70,0.998850,0.359204
71,0.998907,0.356989
72,0.998742,0.358888
73,0.998795,0.357700
74,0.998994,0.355906
75,0.998828,0.351630
76,0.998762,0.356268
77,0.998853,0.359443
78,0.998815,0.351747
79,0.998748,0.358090
80,0.998765,0.354649
