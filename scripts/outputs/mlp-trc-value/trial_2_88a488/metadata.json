{
  "model_name": "mlp-trc-value/trial_2_88a488",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.2679521073908248,
    "mid_layer_count": 14,
    "mid_layer_size": 204
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 351,
    "learning_rate": 0.0014421480183847075,
    "weight_decay": 0.00012786829078233663,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.3497046654658815,
      0.11987820965333007,
      0.08766147122742764,
      0.07872352141384255,
      0.07600308354015058,
      0.07085575121266145,
      0.06717064905158598,
      0.06648438632786427,
      0.062333347926202064,
      0.06071333721301123,
      0.059016659733036075,
      0.05802278458621026,
      0.055794262287114725,
      0.05387584888029857,
      0.053627672542140785,
      0.0524197513363747,
      0.0508083185805089,
      0.05052365471975445,
      0.05079966555590841,
      0.048769407671015653,
      0.04806164084762151,
      0.04822757583409701,
      0.04708643755486083,
      0.046654615498192345,
      0.04622388929472696,
      0.04548306485877901,
      0.043759473878555784,
      0.046129339209744845,
      0.046017186555164694,
      0.042225666555373895,
      0.0441703064889939,
      0.04206848827134789,
      0.042223856206209213,
      0.041339418495799286,
      0.042504364536217906,
      0.040944389543047376,
      0.04092890303056322,
      0.041091532172638064,
      0.041071273892039885,
      0.03913874261696685,
      0.04136067525932366,
      0.039111107346979763,
      0.038023737915770066,
      0.03839218401072452,
      0.03942639699560318,
      0.03876531994225445,
      0.039067926505564295,
      0.038667674823398925,
      0.03937906044138249,
      0.03808206987121415,
      0.03810703480380156,
      0.03660181503439023,
      0.03739725499953396,
      0.03741121572562292,
      0.03677390947012855,
      0.03680275833896486,
      0.036126142241091314,
      0.037500704630058716,
      0.03771137239042576,
      0.03584004546577286,
      0.03891139697396278,
      0.036598325380649305,
      0.03603175633910445,
      0.03656834336246181,
      0.035231345640175264,
      0.034930887169277766,
      0.035390857872569896,
      0.03668449666248821,
      0.03553746831916338,
      0.034690830445135934,
      0.03483764002560277,
      0.03517394632281685,
      0.034599917045550245,
      0.03500833112713984,
      0.03429293482081287,
      0.035689804287031945,
      0.03587202624962108,
      0.0355865334291078,
      0.03517628807059392,
      0.034335887809310316
    ],
    "val_loss": [
      0.26075423874719417,
      0.20443601026060337,
      0.21650420643924595,
      0.2405454366373088,
      0.2476138207849539,
      0.24391412803914375,
      0.28123133943198686,
      0.25942361261918695,
      0.2789979359715017,
      0.2905973686652626,
      0.2840777488425374,
      0.3237551180590056,
      0.26331368910628344,
      0.3111429397284449,
      0.35827731589736517,
      0.3123190843784613,
      0.3498056820956265,
      0.33244374306749797,
      0.3348479351352253,
      0.3485301934104569,
      0.3301730680864996,
      0.3720364292670867,
      0.4348245069685721,
      0.3483528659974565,
      0.3828731059760391,
      0.38770701374613237,
      0.37138583156542326,
      0.3450516985562033,
      0.4174959693706321,
      0.46042734438519994,
      0.46006456520073785,
      0.4421851583505551,
      0.42898456086990183,
      0.4931895952883684,
      0.42673709506090884,
      0.46966849148920375,
      0.4319308332530057,
      0.46130515952109397,
      0.36659778053844405,
      0.435825968598445,
      0.41270345633035294,
      0.38265881419494124,
      0.48197940084971713,
      0.4287187239367091,
      0.36732669290779774,
      0.40365287978871317,
      0.41774515779410115,
      0.41772371773011313,
      0.5153209444938484,
      0.36312616740403597,
      0.4259378316070505,
      0.3388164945537905,
      0.36551771590229637,
      0.42103943786399806,
      0.40572966551798545,
      0.4121341275865446,
      0.4389350206697148,
      0.4320771036379619,
      0.3564915212417791,
      0.3531439843671229,
      0.37972056365900947,
      0.390819420526083,
      0.34899332334404576,
      0.33775756363784837,
      0.37960539036123697,
      0.3400977405881186,
      0.3195213576845691,
      0.34360118617532315,
      0.3388185825555803,
      0.3443592581641442,
      0.3726648483548068,
      0.333138372141221,
      0.3160467058654406,
      0.328911911118441,
      0.33240470456818266,
      0.3272299970048452,
      0.3151186218931379,
      0.320329384678629,
      0.3090987416307726,
      0.3180816115844928
    ],
    "best_epoch": 3,
    "best_val_loss": 0.21650420643924595,
    "test_loss": 4.882312396354082,
    "tracker": {
      "initial_train_loss": 0.3497046654658815,
      "train_threshold": 0.11656822182196051,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.21650420643924595,
      "patience_no_improve_epochs": 78,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_2_88a488/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_2_88a488/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_2_88a488/config.yaml"
}