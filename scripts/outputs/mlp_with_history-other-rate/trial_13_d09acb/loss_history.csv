epoch,train_loss,val_loss
1,1.937104,1.430958
2,0.736947,1.950528
3,0.545862,0.472355
4,0.473407,0.924760
5,0.424186,0.483822
6,0.404159,0.494079
7,0.400667,0.518232
8,0.375172,0.577943
9,0.361954,0.548646
10,0.359742,0.583977
11,0.361867,0.565927
12,0.336368,0.546362
13,0.327568,1.195600
14,0.369041,0.520782
15,0.323777,0.518810
16,0.305835,0.520412
17,0.303994,0.358604
18,0.283691,0.409043
19,0.286491,0.482973
20,0.270468,0.512891
21,0.262902,0.564558
22,0.254859,0.420726
23,0.267423,0.449708
24,0.243694,0.500662
25,0.246174,0.387383
26,0.238635,0.458945
27,0.235877,0.530670
28,0.235026,0.403053
29,0.238340,0.439958
30,0.233338,0.529195
31,0.227413,0.418381
32,0.221290,0.455247
33,0.219431,0.447448
34,0.218863,0.434597
35,0.213638,0.431698
36,0.212651,0.550594
37,0.216379,0.410654
38,0.216180,0.449979
39,0.210012,0.458089
40,0.202372,0.442353
41,0.203140,0.449668
42,0.198878,0.487165
43,0.193641,0.437344
44,0.198077,0.454962
45,0.188336,0.489756
46,0.179948,0.461160
47,0.181926,0.430691
48,0.183863,0.447730
49,0.186490,0.448996
50,0.184879,0.482301
51,0.173522,0.436297
52,0.166385,0.481690
53,0.159520,0.474418
54,0.164888,0.552401
55,0.159663,0.573824
56,0.160813,0.449846
57,0.153277,0.543893
58,0.148700,0.467536
59,0.140189,0.490937
60,0.143808,0.482413
61,0.141289,0.531116
62,0.134799,0.499721
63,0.139279,0.519030
64,0.135076,0.488650
65,0.132197,0.467434
66,0.127363,0.620069
67,0.127595,0.506474
68,0.141315,0.550454
69,0.135350,0.521147
70,0.124121,0.494776
71,0.121782,0.640186
72,0.122372,0.580786
73,0.126961,0.473297
74,0.134669,0.460768
75,0.123936,0.590738
76,0.126064,0.582992
77,0.120670,0.470548
78,0.115576,0.497919
79,0.122098,0.480895
80,0.116032,0.509879
