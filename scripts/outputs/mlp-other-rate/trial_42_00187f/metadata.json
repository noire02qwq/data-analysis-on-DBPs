{
  "model_name": "mlp-other-rate/trial_42_00187f",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.35289232742162013,
    "mid_layer_count": 14,
    "mid_layer_size": 148
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 142,
    "learning_rate": 0.00053600086490836,
    "weight_decay": 0.0009480089862184153,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149,
      150,
      151,
      152,
      153,
      154,
      155,
      156,
      157,
      158,
      159,
      160,
      161,
      162,
      163,
      164,
      165,
      166,
      167,
      168,
      169,
      170,
      171,
      172,
      173,
      174,
      175,
      176,
      177,
      178,
      179,
      180,
      181,
      182
    ],
    "train_loss": [
      0.43870092349642054,
      0.28025728402197697,
      0.2513703325081936,
      0.23539336878575076,
      0.22702466534797566,
      0.2189643830328553,
      0.21388434921857208,
      0.20779904372619323,
      0.20257144576543537,
      0.1978683972615594,
      0.1932249976433871,
      0.18950875319460223,
      0.18775473699440035,
      0.18399107957372549,
      0.1809127840240715,
      0.17689189239533637,
      0.17583720489243107,
      0.17382243219065385,
      0.16956856219492672,
      0.1697952271601125,
      0.1667596141441227,
      0.16813990778804375,
      0.1640876471354082,
      0.1635214356106327,
      0.16130274692297042,
      0.1603332888268091,
      0.15922041193010136,
      0.15758959532716812,
      0.15724477719318689,
      0.15514256973383425,
      0.15538940449489452,
      0.15565788798634367,
      0.1530669514928921,
      0.15299849912692426,
      0.15079816016227604,
      0.1507699896947979,
      0.14987630347576492,
      0.1474646316442721,
      0.14855401389771025,
      0.1479636884025423,
      0.14702350028306474,
      0.1463719511900638,
      0.1438611050491427,
      0.1445055652568437,
      0.1431656055641731,
      0.1425648297007846,
      0.142347916121618,
      0.14022748425732887,
      0.1390876764495627,
      0.13981853846963274,
      0.13974745485027548,
      0.13668788998569814,
      0.13849368134848947,
      0.13769296101992592,
      0.13731989836374756,
      0.13644769134476833,
      0.13648875529044954,
      0.13579587499611556,
      0.1335725917620895,
      0.135562007632269,
      0.13357059407564478,
      0.13406949438510216,
      0.13336929558690785,
      0.13183823644946696,
      0.13224219758657996,
      0.13226138754127084,
      0.1299706386213978,
      0.13143257815304812,
      0.13028812970203457,
      0.1310364262794855,
      0.1297592152332483,
      0.13046657661976663,
      0.13097559406076595,
      0.12888942968163386,
      0.13118388523477173,
      0.1285317495843733,
      0.12979321496770466,
      0.12823362516792633,
      0.12858894566363588,
      0.12732388422451243,
      0.12683266930362394,
      0.1275168927878585,
      0.1268539308465677,
      0.12614918872714043,
      0.12642347184380182,
      0.12671777469346376,
      0.12598033357371483,
      0.12615233603358392,
      0.1253339261000067,
      0.12598605167642504,
      0.12250772425345789,
      0.12446453113045798,
      0.12709663160577256,
      0.12582374390705908,
      0.12465958489346896,
      0.12537048900239037,
      0.12420274899090297,
      0.12313459995176439,
      0.1242321725340303,
      0.1240022458048158,
      0.12246363074650148,
      0.12149256413727005,
      0.1224265552869878,
      0.12260025935969089,
      0.1240724664737684,
      0.12188098387168639,
      0.12086102080504181,
      0.12349335005790714,
      0.12053597695158347,
      0.1215093318027004,
      0.12139512676307945,
      0.12146585289792197,
      0.12072378054849914,
      0.12090289999676888,
      0.12004988189459825,
      0.12044192131144257,
      0.12191284248550896,
      0.11943014344537851,
      0.12133196585373489,
      0.1203919009211401,
      0.12076531773411109,
      0.11984158970373542,
      0.11955605254051256,
      0.11918778357795105,
      0.12028816815995143,
      0.12020347915157836,
      0.11858956275336739,
      0.1177028288358508,
      0.1195728187207964,
      0.11955464156530893,
      0.11771184764515748,
      0.11859395073056833,
      0.11843741977976309,
      0.11855317871461409,
      0.11730175337091417,
      0.11764555558822228,
      0.1170102457351994,
      0.11882914088784945,
      0.11868686829547873,
      0.11920751347801452,
      0.11739501016278521,
      0.11799652412870164,
      0.11840243494590165,
      0.11740767511574043,
      0.11740494896970755,
      0.11726087795473968,
      0.11802250007143567,
      0.1169232518902921,
      0.11569215546339644,
      0.11813769118526828,
      0.1179538478414452,
      0.11652892601488492,
      0.1150190449941458,
      0.11718797687538592,
      0.11607536098983362,
      0.11725864359863358,
      0.11754972903796683,
      0.11564459956765726,
      0.11622913613563748,
      0.11851120628550335,
      0.11740225180410127,
      0.11642501044496627,
      0.11546657006593164,
      0.11750327151798175,
      0.11557086010875917,
      0.11633104532995305,
      0.11527556014281165,
      0.11672246187214304,
      0.11478896076294506,
      0.11574979652275545,
      0.11509080631816124,
      0.11555555645374532,
      0.1153734610394492,
      0.11533262369807346,
      0.11527223916406079,
      0.1148551987964811,
      0.11576855195071711,
      0.11444235169135221,
      0.11402803351323748,
      0.11417911914279975,
      0.11498427669732249,
      0.11588915542586146
    ],
    "val_loss": [
      0.3709820312297273,
      0.38697797255423255,
      0.45312717292390897,
      0.4779563686091029,
      0.4748797698559875,
      0.4933421367656685,
      0.5102209183716488,
      0.48143384544970746,
      0.5265739207585415,
      0.5831462708151269,
      0.5398745614343774,
      0.5542126912199808,
      0.5373376721482791,
      0.5341268317785092,
      0.535667963888117,
      0.5817340339104572,
      0.5233336433232901,
      0.5032962057137204,
      0.5707601275897312,
      0.48643431401181364,
      0.4992052372433468,
      0.4895066661659829,
      0.5544422967705184,
      0.5462828068943795,
      0.50269409333339,
      0.4859665647684457,
      0.5006409181627685,
      0.5369829730448609,
      0.5103369699891456,
      0.46231937062240647,
      0.47352111670606867,
      0.5460335261896698,
      0.5385245500210516,
      0.4547420738699907,
      0.47821861225330903,
      0.47518216466118474,
      0.46130680847846106,
      0.48224063029367764,
      0.4816127099409075,
      0.5452894251235945,
      0.4847382701977998,
      0.49968787224706773,
      0.4811260461004194,
      0.5013710245311617,
      0.4721788877766289,
      0.4758818657098416,
      0.46823179886012734,
      0.476286577446732,
      0.4831079834414099,
      0.4951117367801552,
      0.46169747732535094,
      0.4722966253668248,
      0.4459061462008311,
      0.5063921775646553,
      0.4995628283676987,
      0.4883625801005763,
      0.49878297439235414,
      0.47968099740986336,
      0.498888396966957,
      0.508870236905749,
      0.4826208991918735,
      0.45331507740085,
      0.4531609485160091,
      0.4662843380859512,
      0.44746162416692264,
      0.46070021473005146,
      0.4706452949318343,
      0.4850116719921192,
      0.4672932331790467,
      0.46595997541785955,
      0.4790271089284006,
      0.4454738759887433,
      0.45982060364620414,
      0.4513000495062617,
      0.48964099047069776,
      0.44795874216242465,
      0.46048532364789596,
      0.4809186553972924,
      0.4805256197552481,
      0.4354314458138215,
      0.4846050678077572,
      0.46818678794863694,
      0.47013373369585254,
      0.45781939807766214,
      0.45712076795850687,
      0.4775349439707345,
      0.44717930790906896,
      0.47445343084142594,
      0.4287657406604932,
      0.4483874920242561,
      0.47378370749379345,
      0.4473107499901406,
      0.44650916816767106,
      0.4471958685777858,
      0.4655072637214632,
      0.48014109542448363,
      0.47822695235292356,
      0.4551023521198484,
      0.43176699988320916,
      0.43637500672997115,
      0.4745458987658609,
      0.4641469101884408,
      0.4390284426733405,
      0.47261128949369496,
      0.46297250685399166,
      0.43278359196143235,
      0.42879286937549443,
      0.48281227259221904,
      0.4547113073175539,
      0.47099510024407665,
      0.4572162251986429,
      0.4730211723172022,
      0.4587242044285386,
      0.46152601921986675,
      0.4411669379133664,
      0.4423056963318122,
      0.47280955284298537,
      0.43109051432616696,
      0.47321073352219817,
      0.4516969792054085,
      0.4498120358158014,
      0.46936041934939915,
      0.4395353325112851,
      0.47708317400987993,
      0.4947423027304118,
      0.47176674791795764,
      0.46067565129010263,
      0.4647881979178526,
      0.45476623753944556,
      0.47336308518034254,
      0.4344028014711991,
      0.40864756221542814,
      0.4400993638945197,
      0.4596378460258781,
      0.4342278085604399,
      0.4616542059504343,
      0.4382848675201039,
      0.45421394269444987,
      0.44056635517738535,
      0.4419889335146921,
      0.43724099386059595,
      0.456402706475315,
      0.4626470438466814,
      0.431202293504141,
      0.4564921057688262,
      0.4162542141929358,
      0.42696968767635834,
      0.42235067796385933,
      0.4270205185085,
      0.42601559393241734,
      0.44878760229149267,
      0.41741316214114604,
      0.4558179314175766,
      0.4363788694589438,
      0.4666652383204706,
      0.4255772415392413,
      0.46253657188422664,
      0.4876658364684282,
      0.42699240761067336,
      0.44100752581736286,
      0.44641755293764757,
      0.43335460065724607,
      0.43606659181103735,
      0.4462884940430076,
      0.4586124496188706,
      0.42934948011429724,
      0.45930408160843533,
      0.46461906284093857,
      0.4570282959295604,
      0.4261922504641339,
      0.43749223925217895,
      0.44850519842016484,
      0.4428281976255828,
      0.44266820857803263,
      0.443160598783079,
      0.4604024891457158,
      0.4243591342857498,
      0.44847824263893915,
      0.44796348939577263,
      0.4439643196716994,
      0.45135440969181634,
      0.4545766118222368
    ],
    "best_epoch": 132,
    "best_val_loss": 0.40864756221542814,
    "best_val_abs_mse": 0.5080512762069702,
    "test_loss": 0.5204497491807173,
    "test_abs_mse": 1.197150468826294,
    "tracker": {
      "initial_train_loss": 0.43870092349642054,
      "train_threshold": 0.14623364116547352,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.40864756221542814,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-rate/trial_42_00187f/best_model.pt",
    "last": "scripts/outputs/mlp-other-rate/trial_42_00187f/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-rate/trial_42_00187f/config.yaml"
}