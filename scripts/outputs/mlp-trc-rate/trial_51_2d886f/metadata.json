{
  "model_name": "mlp-trc-rate/trial_51_2d886f",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.3520940866832995,
    "mid_layer_count": 9,
    "mid_layer_size": 314
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 382,
    "learning_rate": 0.00046597067967916154,
    "weight_decay": 0.00010161751356398268,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.6092036711353104,
      0.21736049532064602,
      0.1584768778104058,
      0.12817414247719003,
      0.11206844512883549,
      0.10405414278741798,
      0.09657395797174304,
      0.09059580983742192,
      0.08657574199480299,
      0.08572205793152655,
      0.0843313893751495,
      0.08086362981517967,
      0.07759348971682245,
      0.07634914527838814,
      0.07544999506196466,
      0.07263690163273882,
      0.07087043443338237,
      0.07233499559268486,
      0.0696628636619857,
      0.06868368836684585,
      0.06739244382998587,
      0.06657781777736191,
      0.06733593580840092,
      0.06512925074291939,
      0.06328719909880606,
      0.0612317402051497,
      0.06152679415093806,
      0.06214402373373631,
      0.061249255240460494,
      0.06241470953022412,
      0.06114287350829471,
      0.060361577898432134,
      0.05974842088364864,
      0.05891685426644235,
      0.05777568670095787,
      0.0581163432020952,
      0.058027007663407466,
      0.057106723314129186,
      0.055842326722729506,
      0.056117626671617675,
      0.05403937937060095,
      0.05391735564621061,
      0.05305221836522734,
      0.053543430044406065,
      0.05445551713608423,
      0.05419061432141962,
      0.053728690334600995,
      0.05241404343711804,
      0.053395904731550176,
      0.05155972289107835,
      0.05172453022606407,
      0.051918829234556825,
      0.05182524580984405,
      0.051882240255141085,
      0.04978511642651291,
      0.05114818832862371,
      0.05099283114435001,
      0.050990271062354604,
      0.050649536398930876,
      0.04884312630250186,
      0.049551596757064664,
      0.0495661310316386,
      0.0497892141560061,
      0.0491550073807456,
      0.04796620375601496,
      0.04791686854388789,
      0.04925875203553042,
      0.04633548611984337,
      0.04631697516859709,
      0.04625972465307606,
      0.04649114133307511,
      0.04566675700102023,
      0.04634844293753846,
      0.047036541676509065,
      0.04534674872223263,
      0.04546384379103313,
      0.04496899739733533,
      0.04524324187151648,
      0.04609294269060006,
      0.04727316824762316
    ],
    "val_loss": [
      0.5627346239582507,
      0.26184141893765167,
      0.2315704603528905,
      0.21783674865247246,
      0.19341220033026027,
      0.20334371120674524,
      0.21493298949863382,
      0.19839126299732102,
      0.21187871029366276,
      0.2048947420015842,
      0.21605298731721448,
      0.218043295693344,
      0.21482798585857818,
      0.2156181016948052,
      0.21934062745756733,
      0.22809132914878652,
      0.23764699195584138,
      0.2388211030847655,
      0.24971667265597575,
      0.2392696545665671,
      0.23940537716903373,
      0.25413565952442363,
      0.24668411210982386,
      0.2509704410025995,
      0.24855332715648734,
      0.25588981513223963,
      0.2507226349484778,
      0.2569917382036676,
      0.27435818819139535,
      0.2689715115966911,
      0.2600024181880994,
      0.2736743967801689,
      0.27406634024740334,
      0.26709125895209296,
      0.2661459120960828,
      0.2696970966717083,
      0.2681423917435065,
      0.2781934555285348,
      0.28139883578938996,
      0.2809126432784303,
      0.27981583112906555,
      0.27525993710506463,
      0.27966342127608684,
      0.2818191434719605,
      0.2784666170840135,
      0.2804183702603607,
      0.288798096392326,
      0.2810193066468496,
      0.28821973000502515,
      0.29272061459006304,
      0.29010675139725206,
      0.2886243392919709,
      0.29405065564115246,
      0.2912946693197696,
      0.292259500055256,
      0.3005308859027967,
      0.3121105383144703,
      0.30663053384887246,
      0.3038321410199839,
      0.3028549400989167,
      0.30414688372148013,
      0.3046258318343919,
      0.2985575880766093,
      0.3122744655314677,
      0.3184849427934892,
      0.3210918583578157,
      0.3143165266487056,
      0.3094132068204487,
      0.30723406219643035,
      0.32466130166532037,
      0.3146954344730534,
      0.32072291463658126,
      0.319412215544792,
      0.3067435733617066,
      0.31386785309114856,
      0.3142757978044941,
      0.3245116042051308,
      0.3281989435191283,
      0.3155767701320841,
      0.30904099321561657
    ],
    "best_epoch": 5,
    "best_val_loss": 0.19341220033026027,
    "best_val_abs_mse": 0.2071150541305542,
    "test_loss": 4.922826346312983,
    "test_abs_mse": 47.65038299560547,
    "tracker": {
      "initial_train_loss": 0.6092036711353104,
      "train_threshold": 0.20306789037843678,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.19341220033026027,
      "patience_no_improve_epochs": 75,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_51_2d886f/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_51_2d886f/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_51_2d886f/config.yaml"
}