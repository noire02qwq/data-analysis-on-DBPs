{
  "model_name": "mlp-other-value/trial_45_bbc2bc",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.21039654368383529,
    "mid_layer_count": 10,
    "mid_layer_size": 234
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 215,
    "learning_rate": 0.0013199714326157538,
    "weight_decay": 0.00024241040769773715,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149,
      150,
      151,
      152,
      153,
      154,
      155,
      156,
      157,
      158,
      159,
      160
    ],
    "train_loss": [
      0.3766233036156004,
      0.23827868849115533,
      0.210124521847411,
      0.19551580378058447,
      0.182676678574073,
      0.17510808653758697,
      0.16712977318786057,
      0.15905070600944216,
      0.1528298670799687,
      0.14795799148180597,
      0.14242455134576348,
      0.14193864407380036,
      0.13955492645180978,
      0.13691204709367394,
      0.1337332874718096,
      0.13052483168208429,
      0.12784453181539393,
      0.12329246105292689,
      0.12435453028641277,
      0.12220631439378318,
      0.12028477647140615,
      0.11898112849926355,
      0.117340490396869,
      0.11696748060483453,
      0.11240348178585595,
      0.11289407712731868,
      0.1126381508344684,
      0.11005311942501152,
      0.10902164363158459,
      0.1081053327545409,
      0.10811738325727328,
      0.10584776360769037,
      0.10645046277882474,
      0.10376110825670444,
      0.1032845412556363,
      0.10289294534712158,
      0.10052636868223402,
      0.09959542781512147,
      0.10298756098880286,
      0.09832567238980468,
      0.09884989898787547,
      0.09742797186083063,
      0.09560849442370828,
      0.09502787662793301,
      0.09544081855880689,
      0.09360966323112725,
      0.09341365583202758,
      0.09221752869273957,
      0.09083907631798822,
      0.09334334268259996,
      0.09259368172187785,
      0.09155004040809733,
      0.08925388041423063,
      0.09130722443630997,
      0.08936275332581238,
      0.09146220413437557,
      0.09043894941250046,
      0.0884310974552654,
      0.08950605073139997,
      0.08774482260523636,
      0.08606677383983392,
      0.08565013955087769,
      0.08754580811797624,
      0.0864969979935331,
      0.08597959362146272,
      0.08746552596078003,
      0.08581623284976686,
      0.08522815691004232,
      0.08549465114712379,
      0.08352483244657731,
      0.08324059395128149,
      0.0842337013676709,
      0.08250610487370261,
      0.08408698010683183,
      0.0829784875165092,
      0.0818243407462272,
      0.0806333017208183,
      0.08172123445023048,
      0.08133531038316322,
      0.08381114807409956,
      0.08211760447021782,
      0.08205002434303235,
      0.08045405233274092,
      0.08020721812884951,
      0.0787074155493875,
      0.0800200253572141,
      0.08000122094569893,
      0.07949254608566392,
      0.0805278140382546,
      0.08135024436093435,
      0.0791699981958194,
      0.07938179642481948,
      0.07713744594400634,
      0.08129720051527757,
      0.07971597391215576,
      0.07764020935656658,
      0.07815782718069894,
      0.0789839274370866,
      0.08016405174993227,
      0.07860898057055235,
      0.07885309784033318,
      0.07848131808601874,
      0.07794502950543437,
      0.07633069029059729,
      0.07694980551729054,
      0.07705909689614074,
      0.07595428711557431,
      0.07730155540969492,
      0.07852667448550019,
      0.07589103842871871,
      0.07588629501122979,
      0.07581304728013849,
      0.07685293385872724,
      0.07699728184778638,
      0.07545226877636485,
      0.07698056923885906,
      0.07664004054920162,
      0.07392588701039904,
      0.07548985438179578,
      0.07467565831636055,
      0.07447696741376017,
      0.07367031892934568,
      0.07460403771427823,
      0.07494168340005344,
      0.07398766367669944,
      0.07430225718009542,
      0.07408170015663444,
      0.07277454889205984,
      0.07497118880113099,
      0.07417265200971211,
      0.07278715772530386,
      0.07316128030446109,
      0.0738630929991427,
      0.07402624638169132,
      0.0736613551536054,
      0.07311565577391327,
      0.07309689965116299,
      0.07447590414203394,
      0.07314442423984156,
      0.071201418233073,
      0.07304096259673691,
      0.0717592253829957,
      0.0725532159182492,
      0.07270223426017595,
      0.07331918935081695,
      0.07276738206714987,
      0.07334688291758329,
      0.07149330000099217,
      0.07215841955339498,
      0.0715391168656595,
      0.07188672218624677,
      0.07118855881719267,
      0.07385753494820697,
      0.07164467881510599,
      0.07242667847138573,
      0.07297449633087284,
      0.07114817860420161,
      0.07182216169546742,
      0.07231069445178073,
      0.071466011549511
    ],
    "val_loss": [
      0.39209193361555034,
      0.47992588833955946,
      0.56298462477719,
      0.512812096714795,
      0.5496230004745686,
      0.5283708709353458,
      0.5349677658812728,
      0.5749777980193407,
      0.5219940603180917,
      0.5580293888861905,
      0.615722126634178,
      0.48895148700939683,
      0.5043845006270323,
      0.5093873094789639,
      0.5605628509185985,
      0.49782948932069504,
      0.4751857334223693,
      0.512636608527806,
      0.5829368961339225,
      0.49172158860517834,
      0.4410358985473296,
      0.49686543527477517,
      0.5727284357264013,
      0.4660249318548305,
      0.5447577395571206,
      0.4949278429953638,
      0.5724174643526534,
      0.5623456751425823,
      0.523319502076703,
      0.5099619289715133,
      0.4682306411291311,
      0.5932151631502334,
      0.5537451939757713,
      0.5138853657879159,
      0.4526048659564492,
      0.46928830980183833,
      0.45397046096846017,
      0.4342797162111648,
      0.42172751294638583,
      0.4827241386526716,
      0.45857987994562366,
      0.48364174950444055,
      0.4937993581155817,
      0.47776968759334015,
      0.4896718240649757,
      0.459423784255803,
      0.4481140859201997,
      0.4362043585784421,
      0.44610693319115097,
      0.4500980568146277,
      0.4382409300142063,
      0.4286099206321611,
      0.41229239032564763,
      0.45362668506756515,
      0.5028315011166526,
      0.48070331558049795,
      0.48872995898573696,
      0.43972857956757805,
      0.48433050091662805,
      0.5118725880712807,
      0.4799095986935193,
      0.45162708057971773,
      0.4141264024698092,
      0.46777190187734047,
      0.40403766149353837,
      0.42287142985238285,
      0.4454254947022764,
      0.41115008948181203,
      0.42811383666124886,
      0.4524696119085044,
      0.4362232712303807,
      0.47309792157775626,
      0.42588726886196765,
      0.4300386469342751,
      0.43546338321384553,
      0.4310138499933089,
      0.43991042976964734,
      0.4240918281058708,
      0.4298914818394327,
      0.42007215111376994,
      0.4321302805921275,
      0.4333197489871593,
      0.45637766588590817,
      0.4295863125718639,
      0.43076981215955257,
      0.4319942873082832,
      0.4655842626701572,
      0.426744983113276,
      0.4301413266646291,
      0.44412589903006294,
      0.4454742476433337,
      0.43477582398378206,
      0.4510922428599732,
      0.4173182080650401,
      0.4137682121938574,
      0.43266307393055475,
      0.42345030855632826,
      0.43071804710937117,
      0.4292706340819062,
      0.4174338009453819,
      0.47692186532620184,
      0.4138846426399168,
      0.4329293521712283,
      0.46633215625575203,
      0.40419009073587236,
      0.4181508869825009,
      0.39715460915408446,
      0.44615228230992476,
      0.41618743984999057,
      0.3822277313221001,
      0.39861071645142787,
      0.43773776295031613,
      0.43801204960592494,
      0.42392858978873954,
      0.40831043522158067,
      0.4264499742738501,
      0.4342942720580244,
      0.43514948708568507,
      0.42806386758021253,
      0.42273994231830814,
      0.45305819862973906,
      0.42563775683680694,
      0.4263083785326181,
      0.42909364567366903,
      0.4445401722799518,
      0.4569950338430747,
      0.43785793256170735,
      0.4260325282142905,
      0.4297475549141447,
      0.46603305640067166,
      0.43565729108756174,
      0.3997875229862636,
      0.42491185058376746,
      0.46231145208734953,
      0.440094027021331,
      0.5197398406258243,
      0.43319444115201156,
      0.41142674000141866,
      0.4253171059096645,
      0.49959896922022284,
      0.44123146566980614,
      0.42727629211312995,
      0.45045914474183213,
      0.4440125555781547,
      0.42939528222837137,
      0.4240876625397962,
      0.39069021314739466,
      0.40829045611048886,
      0.40908815792042336,
      0.44623518616942587,
      0.4055769115597188,
      0.4060811017623205,
      0.4109515468115935,
      0.40906526308930563,
      0.4335782292137246,
      0.43253888359326803,
      0.4631880718746228,
      0.46414285411913236,
      0.40552317505022006,
      0.41776936017199906
    ],
    "best_epoch": 110,
    "best_val_loss": 0.3822277313221001,
    "test_loss": 0.4745969913953372,
    "tracker": {
      "initial_train_loss": 0.3766233036156004,
      "train_threshold": 0.12554110120520015,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3822277313221001,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_45_bbc2bc/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_45_bbc2bc/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_45_bbc2bc/config.yaml"
}