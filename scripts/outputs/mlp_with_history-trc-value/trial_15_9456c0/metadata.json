{
  "model_name": "mlp_with_history-trc-value/trial_15_9456c0",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 41,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.25061030986848776,
    "mid_layer_count": 2,
    "mid_layer_size": 839
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 435,
    "learning_rate": 0.0013363731196894754,
    "weight_decay": 0.00020996560236854027,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7756,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 410,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      1.1020247942166208,
      0.49539539133798466,
      0.23563323350351395,
      0.17029054956669165,
      0.13521426896910005,
      0.12902315115136329,
      0.1181277207494197,
      0.12737071282427725,
      0.11177167122056798,
      0.1089301842614017,
      0.10146836566730619,
      0.0868011262189057,
      0.08694212175924917,
      0.09645753524920847,
      0.10572065039316424,
      0.0725532973270677,
      0.06467323141943908,
      0.06320822057892991,
      0.06601404036957696,
      0.06349690282998809,
      0.06213601043590985,
      0.05805411895419086,
      0.060289911675550784,
      0.05673689658495647,
      0.05867769965991309,
      0.06240381888541873,
      0.059660352435579704,
      0.057888323954600016,
      0.05565579552126567,
      0.05147084610583765,
      0.054776892969466445,
      0.05036170590455659,
      0.06070934840136502,
      0.05073969894294858,
      0.04840072419046741,
      0.0478013045302928,
      0.051724569851848624,
      0.04970536419238978,
      0.04950301302813066,
      0.04485225217688738,
      0.05025676928091719,
      0.052205500550771756,
      0.051823215055759264,
      0.04351380023943926,
      0.04710359130460095,
      0.04530836264984687,
      0.04386211481846412,
      0.04200855136261566,
      0.043307880175027604,
      0.04852537070115228,
      0.0494588511127089,
      0.05456231450186509,
      0.050992484703513995,
      0.04161379270518776,
      0.041844241668831876,
      0.04471425445584168,
      0.045014310642104746,
      0.0431109414445049,
      0.03984686452126906,
      0.04195485638513154,
      0.042877644380192405,
      0.038934468139921685,
      0.04229180557175879,
      0.04078234065863937,
      0.041201864856248695,
      0.03962000827158524,
      0.038384025477933445,
      0.04161027548215081,
      0.04263270395611475,
      0.03991377821683023,
      0.04058427702973665,
      0.0385049545566843,
      0.036937472539943804,
      0.042187524340324425,
      0.041916617253807756,
      0.03810629298235182,
      0.037017904396844686,
      0.036560106022036555,
      0.036720136089020854,
      0.037915124633561295
    ],
    "val_loss": [
      0.8886458130921432,
      0.18490769892574072,
      0.1774749418464071,
      0.22761356181459513,
      0.29024588651285915,
      0.31346981986955613,
      0.29438923413078943,
      0.3618421710324948,
      0.24561020585814278,
      0.2780420165564753,
      0.27092350327303844,
      0.2804249855438749,
      0.3256647226227793,
      0.2669453663294187,
      0.397040376378346,
      0.3637486766789577,
      0.4719610127570208,
      0.42846181977562564,
      0.4111863044285756,
      0.5568899704355322,
      0.5595645887141456,
      0.3927598858731771,
      0.44784721372994835,
      0.47572805093947107,
      0.41700281047758586,
      0.34456644759898236,
      0.3793512179131458,
      0.4869611526889626,
      0.3986193227475721,
      0.37539161746194977,
      0.34403484461349465,
      0.380336426415977,
      0.34008091331799767,
      0.44901264205151153,
      0.5510086355184367,
      0.3909484543419348,
      0.49133060463218986,
      0.44671321331807773,
      0.4131196195672372,
      0.3672961098404077,
      0.4225220766286561,
      0.3693843254161452,
      0.46591775206302455,
      0.3933164944180739,
      0.3264447199180722,
      0.37791171128454504,
      0.4579881023124842,
      0.3736238046019466,
      0.3191490126996786,
      0.34491511375760425,
      0.5608584025350516,
      0.4111130670616459,
      0.3912015121296316,
      0.4359179222733229,
      0.44800763977635766,
      0.28006128358381416,
      0.35705677882216114,
      0.43105101486121467,
      0.37970528132031245,
      0.348280567469488,
      0.286373690116459,
      0.38343302480051084,
      0.3934443219436589,
      0.5200584035946759,
      0.38798909141364213,
      0.3678246985083658,
      0.37728403201382493,
      0.35237874732001456,
      0.27840376979375847,
      0.3481242604007175,
      0.33209462869287787,
      0.39387103198598067,
      0.4129537264844347,
      0.4671415612715001,
      0.40828649628305147,
      0.31734002868416245,
      0.41581251186703494,
      0.33760349778737314,
      0.3355827195692562,
      0.42588433500067024
    ],
    "best_epoch": 3,
    "best_val_loss": 0.1774749418464071,
    "test_loss": 4.36403681045514,
    "tracker": {
      "initial_train_loss": 1.1020247942166208,
      "train_threshold": 0.36734159807220695,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.1774749418464071,
      "patience_no_improve_epochs": 78,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_15_9456c0/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_15_9456c0/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_15_9456c0/config.yaml"
}