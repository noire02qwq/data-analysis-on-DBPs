epoch,train_loss,val_loss
1,1.000508,0.346077
2,0.999809,0.356349
3,0.999788,0.344420
4,1.000199,0.361563
5,0.999955,0.352717
6,0.999854,0.351083
7,0.999717,0.345873
8,0.999730,0.353307
9,0.999888,0.352500
10,0.999822,0.354236
11,1.000003,0.345663
12,0.999786,0.353796
13,0.999720,0.350382
14,0.999631,0.348359
15,0.999801,0.347663
16,0.999718,0.350993
17,0.999633,0.348721
18,0.999654,0.349803
19,0.999836,0.349248
20,0.999686,0.351175
21,0.999594,0.349178
22,0.999694,0.350955
23,0.999622,0.351431
24,0.999608,0.350126
25,0.999592,0.352255
26,0.999641,0.352004
27,0.999783,0.350047
28,0.999644,0.351836
29,0.999560,0.350242
30,0.999589,0.349970
31,0.999585,0.351746
32,0.999643,0.350001
33,0.999615,0.350157
34,0.999615,0.352169
35,0.999559,0.349535
36,0.999591,0.351445
37,0.999601,0.350798
38,0.999558,0.349667
39,0.999591,0.349334
40,0.999568,0.351850
41,0.999569,0.351484
42,0.999747,0.350223
43,0.999686,0.349734
44,0.999622,0.350017
45,0.999638,0.350162
46,0.999635,0.351634
47,0.999655,0.348458
48,0.999610,0.350532
49,0.999607,0.351089
50,0.999560,0.349949
