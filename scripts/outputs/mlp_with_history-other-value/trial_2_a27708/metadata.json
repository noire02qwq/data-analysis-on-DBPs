{
  "model_name": "mlp_with_history-other-value/trial_2_a27708",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 117,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.24469890622688514,
    "mid_layer_count": 6,
    "mid_layer_size": 696
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 360,
    "learning_rate": 0.0009390397159276301,
    "weight_decay": 0.007819409001808601,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7680,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 1170,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100
    ],
    "train_loss": [
      1.0075863897800446,
      1.0058102402836084,
      1.0056317560374737,
      1.005462085828185,
      1.0054852347820997,
      1.0054736584424973,
      1.0054967571049929,
      1.0054025538265705,
      1.0053769713267684,
      1.0053984895348549,
      1.005420072004199,
      1.005391745828092,
      1.0053649879992008,
      1.0054230643436313,
      1.005393316037953,
      1.0053522922098637,
      1.005382914096117,
      1.005358717404306,
      1.0053354362025857,
      1.0053704623132944,
      1.0053619854152203,
      1.0053331572562456,
      1.0053493967279792,
      1.005346667021513,
      1.005350673571229,
      1.0053339637815952,
      1.0053264051675797,
      1.0053489739075303,
      1.0053275870159268,
      1.0053295502439141,
      1.0053249364718795,
      1.0053262878209352,
      1.0053232703357935,
      1.0053258696570992,
      1.0053394921123981,
      1.0053272247314453,
      1.0053394567221403,
      1.005331190302968,
      1.0053522400557995,
      1.005345311947167,
      1.0053313365206122,
      1.0053480882197618,
      1.0053225476294756,
      1.0053399009630084,
      1.0053245071321726,
      1.0053344890475273,
      1.0053277658298612,
      1.00533417891711,
      1.0053733829408884,
      1.0053388644009829,
      1.0053575094789267,
      1.0053529292345047,
      1.0053461398929358,
      1.005338054150343,
      1.0053482074290514,
      1.005336044356227,
      1.0053326478227973,
      1.0053219106048346,
      1.0053333267569542,
      1.0053466046229005,
      1.0053449189290404,
      1.0053364178165793,
      1.0053270468488336,
      1.005326284095645,
      1.0053324736654758,
      1.0053424630314112,
      1.0053318003192544,
      1.0053210807964206,
      1.0053218761458993,
      1.0053852936252952,
      1.0053386287763715,
      1.0053304713219404,
      1.0053245117887855,
      1.0053426641970873,
      1.005321318283677,
      1.0053261760622263,
      1.0053264861926436,
      1.005325447767973,
      1.0053224777802825,
      1.0053258733823895,
      1.0053334375843406,
      1.0053258901461959,
      1.005332823842764,
      1.005324344150722,
      1.0053302813321352,
      1.0053466381505132,
      1.005358056165278,
      1.005327532067895,
      1.0053255939856172,
      1.0053407400846481,
      1.005335801281035,
      1.0053670424968004,
      1.0053250370547175,
      1.0053322967141867,
      1.005337324924767,
      1.0053571201860905,
      1.0053156362846494,
      1.00536223128438,
      1.0053246039897203,
      1.005328762345016
    ],
    "val_loss": [
      1.447239321862866,
      1.4398339237281663,
      1.4445887668404036,
      1.4367669285414462,
      1.4356946788148253,
      1.434085127836216,
      1.434305754964223,
      1.4425837865132771,
      1.4386256355011535,
      1.4419583346315488,
      1.4391303947585785,
      1.4334625769518092,
      1.435718543515234,
      1.4432955716184512,
      1.4347494562228997,
      1.4327192920410705,
      1.438043061844603,
      1.4378991341162584,
      1.437543396464365,
      1.432974909593959,
      1.4359454651792607,
      1.4349445054631034,
      1.4367349347668494,
      1.4367556357812026,
      1.4296972180554968,
      1.4302149204436891,
      1.4332702374030015,
      1.4353691503673256,
      1.4351303663082466,
      1.43322664249443,
      1.432803705066978,
      1.4331270106538327,
      1.4333769290033216,
      1.4307725629406776,
      1.429559305042564,
      1.42975634729077,
      1.4313809015079886,
      1.4332723860255259,
      1.4342847412931705,
      1.429559430676306,
      1.4350733714189359,
      1.4351458706541689,
      1.4367237176723824,
      1.4355570855968727,
      1.4328925481099568,
      1.4291609390053206,
      1.4315643039292205,
      1.4362146840124073,
      1.4325750944857112,
      1.4342124876147972,
      1.4301991833898122,
      1.4320048343635605,
      1.4334221585781988,
      1.4337699498958931,
      1.4316284428099673,
      1.434132079164425,
      1.4313529237301763,
      1.4347238255118182,
      1.4363661411993518,
      1.4326262673931922,
      1.4339468065136207,
      1.4338853287839604,
      1.4337271730343024,
      1.4339324571415335,
      1.432973687520284,
      1.4327588766634822,
      1.43134053453,
      1.4329913876013842,
      1.4335097581326603,
      1.4370057996875512,
      1.431936061310911,
      1.4318364594510928,
      1.4331842282575047,
      1.431743349143845,
      1.4348241868847145,
      1.4359328104350382,
      1.4354236468583523,
      1.4328294228650853,
      1.4329801676516047,
      1.4309546904649564,
      1.4317001054386893,
      1.4335908361537728,
      1.4343553845753927,
      1.4321713490400485,
      1.4335892029151232,
      1.430557844881526,
      1.4359224156705206,
      1.4325040628810128,
      1.4331610431214292,
      1.431190003891905,
      1.4325102075131353,
      1.4285923735110346,
      1.4337025916505002,
      1.4386382017306938,
      1.4377869217695591,
      1.4351484318693242,
      1.432209224758034,
      1.42868051843015,
      1.4327766766805135,
      1.4364612645017887
    ],
    "best_epoch": 100,
    "best_val_loss": 1.4364612645017887,
    "test_loss": 1.4626892608318602,
    "tracker": {
      "initial_train_loss": 1.0075863897800446,
      "train_threshold": 0.3358621299266815,
      "best_tracking": false,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 1.4285923735110346,
      "patience_no_improve_epochs": 8,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": true
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-value/trial_2_a27708/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-value/trial_2_a27708/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-value/trial_2_a27708/config.yaml"
}