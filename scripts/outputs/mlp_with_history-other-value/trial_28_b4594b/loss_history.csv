epoch,train_loss,val_loss
1,0.884989,0.644170
2,0.424114,0.476759
3,0.374908,0.523892
4,0.365870,0.500031
5,0.353770,0.559668
6,0.447417,1.430709
7,0.458874,0.548148
8,0.359006,0.500798
9,0.340792,0.532867
10,0.318686,0.528456
11,0.291297,0.601498
12,0.279948,0.482252
13,0.277761,0.667989
14,0.269255,0.529615
15,0.263164,0.475563
16,0.255816,0.525909
17,0.256087,0.454182
18,0.256036,0.490618
19,0.258181,0.492011
20,0.254276,0.422501
21,0.248882,0.409021
22,0.248419,0.410432
23,0.246993,0.535897
24,0.249545,0.441937
25,0.241600,0.495707
26,0.240526,0.394491
27,0.240705,0.436511
28,0.239750,0.493038
29,0.243177,0.430534
30,0.238493,0.425576
31,0.229472,0.449398
32,0.226946,0.449028
33,0.257605,1.507961
34,0.702718,0.571959
35,0.546752,1.951435
36,0.506463,0.960992
37,0.417577,0.651182
38,0.323833,0.506811
39,0.292631,0.546202
40,0.278232,0.480608
41,0.264487,0.466767
42,0.268757,0.448738
43,0.255890,0.433908
44,0.251568,0.574701
45,0.247826,0.496947
46,0.246315,0.487252
47,0.242282,0.477111
48,0.242241,0.522343
49,0.326593,0.714697
50,0.300881,0.589177
51,0.266142,0.479512
52,0.251924,0.429037
53,0.242456,0.450917
54,0.239001,0.433316
55,0.235095,0.464579
56,0.229074,0.426914
57,0.225980,0.438593
58,0.224557,0.515007
59,0.226610,0.484785
60,0.211794,0.451099
61,0.210099,0.455547
62,0.196741,0.453210
63,0.198038,0.486733
64,0.199284,0.470406
65,0.190859,0.476549
66,0.182366,0.581547
67,0.191100,0.483839
68,0.182585,0.494374
69,0.182714,0.493243
70,0.187693,0.469324
71,0.180927,0.476685
72,0.177354,0.469521
73,0.182207,0.509618
74,0.178012,0.532411
75,0.182278,0.478964
76,0.173105,0.468844
77,0.172678,0.475117
78,0.176708,0.512596
79,0.174657,0.460496
80,0.165814,0.526866
