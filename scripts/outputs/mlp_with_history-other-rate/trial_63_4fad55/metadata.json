{
  "model_name": "mlp_with_history-other-rate/trial_63_4fad55",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 55,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.1638855573636791,
    "mid_layer_count": 13,
    "mid_layer_size": 682
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 173,
    "learning_rate": 0.0008426747329464332,
    "weight_decay": 0.001273129130999813,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7742,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 550,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118
    ],
    "train_loss": [
      0.5084395369250656,
      0.3483302043223991,
      0.33844716005456504,
      0.28960065415080466,
      0.257427630706894,
      0.2502504579378357,
      0.240786752630592,
      0.23290590472082487,
      0.2264968704415889,
      0.2344706188998029,
      0.21429589709680352,
      0.20763531368244098,
      0.19997973533578697,
      0.19806167876741984,
      0.19535787199563495,
      0.18917001965733593,
      0.18807884325925092,
      0.18132451394906313,
      0.18353715213701355,
      0.18054099992645153,
      0.17606279348848217,
      0.1818686718223662,
      0.16917501958734274,
      0.17552025455647555,
      0.16072477058280626,
      0.15890742410133127,
      0.15814653976508364,
      0.1563536670646967,
      0.15011752828247354,
      0.15019950997233544,
      0.15472952280317712,
      0.1496191223642063,
      0.14463300512080135,
      0.14569214022292767,
      0.15250666839489485,
      0.14550472274172432,
      0.13720836480480392,
      0.135078972616928,
      0.13383515419361974,
      0.1386502409419774,
      0.13585144961389944,
      0.13271885549539406,
      0.13120950533265263,
      0.1274438892546257,
      0.1257610201722074,
      0.1250188507955763,
      0.12312148720145348,
      0.13019444161963012,
      0.13024352445286147,
      0.12947789621396263,
      0.12632556441999074,
      0.12961101748128173,
      0.11774789786495093,
      0.12231041359284749,
      0.12201717866522586,
      0.12995642188718018,
      0.11979196667074542,
      0.11784741199603994,
      0.12137425461366823,
      0.13943920250923342,
      0.12194624122831749,
      0.11593711009339072,
      0.11691397204860425,
      0.12019501736296667,
      0.11431884721067795,
      0.11634359143249011,
      0.11623153449917942,
      0.11497614023910108,
      0.11713903507608002,
      0.11790535643646742,
      0.11600197670734443,
      0.11445648838397576,
      0.12089824964547613,
      0.11409423443424058,
      0.11266816750715421,
      0.11282444603450537,
      0.1125472822026654,
      0.11238958159698839,
      0.1111204547630019,
      0.11178764807326454,
      0.1183675182105127,
      0.12011922868962313,
      0.11482923212758302,
      0.11044061745080767,
      0.11317843490082205,
      0.1128850737993214,
      0.11173474510929068,
      0.11014266959019824,
      0.10972221037678495,
      0.1116964320085117,
      0.10703639572934259,
      0.11166982329733241,
      0.11123917622237174,
      0.11005673996932869,
      0.10760383480869655,
      0.1081835711300296,
      0.10652142568260192,
      0.10585488743928013,
      0.10420351432844731,
      0.10578696069711094,
      0.10242643668473891,
      0.10489953792305363,
      0.11252338709167749,
      0.10397091309280859,
      0.10331724073763843,
      0.1053396762533725,
      0.12175510145456284,
      0.10109191585463999,
      0.09651711723545638,
      0.10028932141094392,
      0.09931268152961033,
      0.10032234997330972,
      0.09978851250336017,
      0.09962698169393276,
      0.10704771638324605,
      0.09993347621640011,
      0.09647540307647805,
      0.09868873992814046
    ],
    "val_loss": [
      0.4775127561729468,
      0.4879842955686018,
      0.48774839013279553,
      0.5491300684427787,
      0.4895305963110424,
      0.5458276004625294,
      0.4782345726862996,
      0.5672592553817584,
      0.4577776185008223,
      0.5462211215835131,
      0.5407930207555879,
      0.508388423723375,
      0.536837571096456,
      0.5339590904107707,
      0.5490890971602437,
      0.5613582054298081,
      0.572838413782284,
      0.5593391061230691,
      0.5335404479664243,
      0.5277165918114657,
      0.5519748204304072,
      0.5819767922966066,
      0.5324782043963135,
      0.5833449142867934,
      0.580525133566942,
      0.6344020271461881,
      0.5813520868738254,
      0.4795847832353529,
      0.5134128491143266,
      0.610590395019083,
      0.5317643611240173,
      0.5013938277513681,
      0.559309045122769,
      0.5743316560983658,
      0.5317910790800334,
      0.6245392457253026,
      0.5480241464015967,
      0.527922560756435,
      0.5701249378660839,
      0.49089590503784,
      0.5933653815019273,
      0.4949512990782718,
      0.5268428301249078,
      0.5469250826510841,
      0.5512541822152224,
      0.5190770647215273,
      0.5798243778930631,
      0.5317555641543544,
      0.5195449228883682,
      0.4963757605877465,
      0.5084314275376811,
      0.5363044123628182,
      0.5072239387981192,
      0.5677465922907441,
      0.5906967028395501,
      0.6313979473611909,
      0.5641180241714695,
      0.5926416508942663,
      0.6091497733408284,
      0.6029315484453461,
      0.6337445312988258,
      0.5930051644561355,
      0.5856741516711469,
      0.5126507328745133,
      0.5605210064280176,
      0.6103274826941911,
      0.5581673189105388,
      0.46997295639695164,
      0.6072340638092356,
      0.47211608313871717,
      0.5633757980105406,
      0.5525890925954916,
      0.5310726520677883,
      0.6667451355628624,
      0.5723525496746251,
      0.543146355383232,
      0.5333024673520805,
      0.5449562508992092,
      0.5384647729957175,
      0.6313098832875669,
      0.5397426504084093,
      0.5156813130719576,
      0.6576982328054791,
      0.4922455965312655,
      0.5667844896366496,
      0.5259506141354224,
      0.5184043329722153,
      0.5621984194584949,
      0.5694457831407735,
      0.5532592999453316,
      0.6144551274216103,
      0.6070419721573056,
      0.6042840592027782,
      0.5580234123159669,
      0.4984232567384571,
      0.5112784729790901,
      0.5642461338442957,
      0.6029744580477298,
      0.5781242786521862,
      0.5930360523571154,
      0.6505938598495757,
      0.5141985742185644,
      0.6381660456741285,
      0.5478938511210287,
      0.5297109745599017,
      0.5173202534011024,
      0.5481249675779285,
      0.5551191234526163,
      0.5702975111450264,
      0.5191701123279012,
      0.49511159173251984,
      0.551808517055954,
      0.606603164961952,
      0.6130033225624147,
      0.5961525913840996,
      0.6588204600496921,
      0.5139587918173767,
      0.5936040058107434
    ],
    "best_epoch": 68,
    "best_val_loss": 0.46997295639695164,
    "best_val_abs_mse": 0.5199230909347534,
    "test_loss": 0.4679943057775284,
    "test_abs_mse": 0.8766454458236694,
    "tracker": {
      "initial_train_loss": 0.5084395369250656,
      "train_threshold": 0.16947984564168853,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.46997295639695164,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-rate/trial_63_4fad55/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-rate/trial_63_4fad55/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-rate/trial_63_4fad55/config.yaml"
}