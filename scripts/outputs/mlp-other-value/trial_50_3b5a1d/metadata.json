{
  "model_name": "mlp-other-value/trial_50_3b5a1d",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.27082102295695976,
    "mid_layer_count": 8,
    "mid_layer_size": 393
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 150,
    "learning_rate": 0.000814802384920631,
    "weight_decay": 0.0008642899645223283,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149,
      150,
      151,
      152,
      153,
      154,
      155
    ],
    "train_loss": [
      0.38895279638518915,
      0.25129650796205955,
      0.22511711592794137,
      0.21032979164278282,
      0.20072919819570922,
      0.19397276030970942,
      0.18281566238498126,
      0.17714578451530452,
      0.17551862919419287,
      0.1720030608201345,
      0.16572602206756054,
      0.16367239869171502,
      0.15975270014716883,
      0.15902045370677362,
      0.15599514005764012,
      0.15346018998492308,
      0.15225211930785684,
      0.14817962307519275,
      0.14764132306912484,
      0.1451468098795891,
      0.1448853074751217,
      0.14297930363387926,
      0.14086707470591647,
      0.14116102077636491,
      0.1390094414196637,
      0.13805137096252915,
      0.13705645697721766,
      0.13553304020114712,
      0.13460750901558388,
      0.1339640486326017,
      0.13053294831266643,
      0.13239257830482315,
      0.13318132761084098,
      0.12829702865884757,
      0.12855945650073367,
      0.12858364444938974,
      0.1280980410428002,
      0.12838117270446117,
      0.12663524839864626,
      0.1253504183539034,
      0.12369356523834173,
      0.12441552765074909,
      0.12318068328937119,
      0.12236974083877271,
      0.12151018327523526,
      0.12181193877934737,
      0.12094434447253956,
      0.12099944676471833,
      0.1220317297773278,
      0.11957479651162965,
      0.12120281899775096,
      0.11848488342057074,
      0.11918179604060959,
      0.11802143562086244,
      0.11853861112650264,
      0.11479452892702136,
      0.11943605361939272,
      0.11862208736652347,
      0.1147179463682357,
      0.11705720730856053,
      0.11484282999359198,
      0.11609605907162927,
      0.11391928039487353,
      0.11462385174921073,
      0.11567651310514156,
      0.11486091949485276,
      0.11313242978464645,
      0.1144575991095825,
      0.11349798930668414,
      0.11421776068644869,
      0.11359114718244527,
      0.1127119972659662,
      0.11247857368568875,
      0.11269649400878956,
      0.11241453417933801,
      0.1117407806206202,
      0.11056630236558758,
      0.11216040136433064,
      0.10971285685468724,
      0.11100716916046245,
      0.10971116698158283,
      0.11096817899539325,
      0.11004731081055334,
      0.1097879897881435,
      0.10915648820248551,
      0.10858449844663544,
      0.10768793049096878,
      0.11009687329214803,
      0.10925909193120839,
      0.10915647594477043,
      0.10879315806312889,
      0.10786674403346093,
      0.10728010910254004,
      0.1072530091332588,
      0.1065168836526286,
      0.10804237189080056,
      0.10728886682996999,
      0.1068582963762282,
      0.10664822215289871,
      0.107672549375147,
      0.10417316412278907,
      0.10772398294256919,
      0.10742297017227202,
      0.10737630536444313,
      0.10647277569750935,
      0.10686359232460736,
      0.10535647556866176,
      0.10709707434167307,
      0.10648812359345149,
      0.10539448851114545,
      0.10657560164773079,
      0.10503520725391473,
      0.1067490246110601,
      0.10430437352043839,
      0.10526166185774884,
      0.10622902414266913,
      0.10488589756523357,
      0.1046802522724503,
      0.10522013308987854,
      0.10568118543808983,
      0.10446848051327201,
      0.10447972413704847,
      0.10372879360924323,
      0.1042772219743314,
      0.10439467461652606,
      0.10317198188641917,
      0.10403347185303029,
      0.1022310728687944,
      0.1055913129052087,
      0.10421011673182387,
      0.10343339347331691,
      0.10456127628469969,
      0.10457497345080065,
      0.10433645729929315,
      0.10232104199927486,
      0.10289010952387852,
      0.10407865828446941,
      0.10483407773738827,
      0.10473246754492595,
      0.10249848397742056,
      0.10365205555733746,
      0.10368682328074513,
      0.10243667004818241,
      0.1019316999066818,
      0.10193327161220174,
      0.1029091347477233,
      0.10230574206763993,
      0.10493840012276949,
      0.10301757364387143,
      0.1032710193043308,
      0.1026717235528701,
      0.10183707837602186,
      0.10361926164908125,
      0.10353277663027953,
      0.10248751937196217
    ],
    "val_loss": [
      0.3679909869403896,
      0.45804019129561807,
      0.5229178585870538,
      0.5352567097027144,
      0.5163330644993724,
      0.5511633864419903,
      0.5244184307709425,
      0.5350743910509669,
      0.5373813801718329,
      0.5702962261474062,
      0.6243751304235287,
      0.5379355799652146,
      0.5069184893976428,
      0.5077714754078917,
      0.5594110663779481,
      0.5505667888743435,
      0.5117470881717647,
      0.5523835664202353,
      0.6161231063529403,
      0.4899595000162096,
      0.5078518382624951,
      0.5062959146446097,
      0.5027942086854381,
      0.4936379667170747,
      0.5268637992129355,
      0.5156292757409775,
      0.4932761717877702,
      0.5238914061895388,
      0.567491475336566,
      0.4426503996113817,
      0.4681225825926501,
      0.47547552025246764,
      0.538204410118971,
      0.44826561689912203,
      0.45759857031042706,
      0.4585506142881102,
      0.47913293727857625,
      0.4584330192761507,
      0.46482350561254754,
      0.4977555975853326,
      0.5170902192235707,
      0.47671131414924556,
      0.4999194155910058,
      0.4918239073392874,
      0.4788295871126438,
      0.4909301012040612,
      0.45845953665093747,
      0.44541958893487554,
      0.45447792674966914,
      0.5026960707531718,
      0.47449553771290237,
      0.4569431239973285,
      0.4465083150628084,
      0.4496486556387233,
      0.5013101503788354,
      0.46626719239050757,
      0.46842560578070713,
      0.47150812217753807,
      0.4800461948720995,
      0.4841301236859339,
      0.4692997983294333,
      0.46140948370723667,
      0.4273822412876312,
      0.5017126075432686,
      0.45987117986479203,
      0.4576160289391786,
      0.45765539075800044,
      0.45897789629633556,
      0.43700488750449196,
      0.4503346447816152,
      0.503894230607384,
      0.48105573921860334,
      0.4858243644326747,
      0.4582688724566363,
      0.4721414833636341,
      0.4321218017421797,
      0.4258448091631164,
      0.42961549575992686,
      0.4530937535587899,
      0.44776089792836926,
      0.4611625776676361,
      0.43280441180139245,
      0.4306113220260529,
      0.43252037171118274,
      0.4493713716190018,
      0.4532872284511606,
      0.4355884332232133,
      0.42833367663764665,
      0.46014489157649574,
      0.42283021377589175,
      0.4329894254664461,
      0.42149411079412447,
      0.4308643024303242,
      0.4342983689850676,
      0.4591976676783162,
      0.4666817831154355,
      0.4334869672081428,
      0.42074041514696475,
      0.43192930452659456,
      0.42885456515286496,
      0.47073949864524567,
      0.4635220352939503,
      0.4335756436614933,
      0.4607205568494911,
      0.4010338971090174,
      0.43537186755391655,
      0.4416591915452552,
      0.451306697048113,
      0.41827848433199044,
      0.4460191014194917,
      0.4418099494037514,
      0.4573501137023914,
      0.48868516663055933,
      0.42927234338786074,
      0.4508891151604538,
      0.4521434850053873,
      0.4565405012247805,
      0.4574748902709898,
      0.4506332284497644,
      0.4432201214179307,
      0.44198266158025423,
      0.41687598052674424,
      0.4334117783579284,
      0.4576769597873002,
      0.43348907657012253,
      0.4831822030023187,
      0.45568944134576594,
      0.4787819526063468,
      0.4623202448208889,
      0.4645825526760724,
      0.42302678324683696,
      0.42065033102463817,
      0.4615553503264924,
      0.455144922354978,
      0.4100356206387103,
      0.4545174657316979,
      0.4710633644979157,
      0.40366702923874653,
      0.41373617732953166,
      0.44257397878312776,
      0.46634908770015854,
      0.43215388447760106,
      0.4551199098190148,
      0.427131754061776,
      0.4304716056603158,
      0.4097881065068131,
      0.41720689119336135,
      0.4177449654319329,
      0.42938972456369573,
      0.4416570529609383,
      0.4509155059199847,
      0.4185205082782728,
      0.41394907512707624,
      0.4153701441730568,
      0.4512518335602241
    ],
    "best_epoch": 105,
    "best_val_loss": 0.4010338971090174,
    "test_loss": 0.514219456980602,
    "tracker": {
      "initial_train_loss": 0.38895279638518915,
      "train_threshold": 0.12965093212839637,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4010338971090174,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_50_3b5a1d/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_50_3b5a1d/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_50_3b5a1d/config.yaml"
}