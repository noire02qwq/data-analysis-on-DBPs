{
  "model_name": "mlp-trc-value/trial_26_ae6fbb",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.31703673172228425,
    "mid_layer_count": 10,
    "mid_layer_size": 502
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 310,
    "learning_rate": 0.001180415209576066,
    "weight_decay": 0.0001909249165967815,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.3618107542181517,
      0.12825100686976457,
      0.1000290528339276,
      0.08689560130307343,
      0.07927033137921922,
      0.07629088718556881,
      0.07597122156563449,
      0.07110770016033231,
      0.07080866661154044,
      0.06712249544601584,
      0.06680341867903002,
      0.06416194617897349,
      0.060358001960927915,
      0.06068930431068892,
      0.05911155067682419,
      0.060981890316641654,
      0.05912972228260393,
      0.057866902528794194,
      0.05816618848846257,
      0.05544041355965748,
      0.0533721083273424,
      0.05214587931620151,
      0.052050288367142976,
      0.05193664583011032,
      0.05254027450418032,
      0.050278640600191805,
      0.0485553508094025,
      0.04901393381195413,
      0.04937071988350492,
      0.04731560426512365,
      0.049835975638845446,
      0.04795787958910888,
      0.047549308110898185,
      0.05091050038426702,
      0.04639340528674527,
      0.0466330230318243,
      0.046180005250771025,
      0.04530778415443776,
      0.04794009847460404,
      0.04547210243660068,
      0.04493576647468167,
      0.045011502973976165,
      0.04486217665146289,
      0.04405757252522589,
      0.044431175233814395,
      0.0445508199083065,
      0.04363000649230611,
      0.04411317709128083,
      0.045063725561324056,
      0.04314048596972713,
      0.04258324454451078,
      0.04433311501937441,
      0.04416863993574804,
      0.04154745594198395,
      0.04376467809620088,
      0.04316472334776737,
      0.04457860129224514,
      0.04460965744814639,
      0.042032562237827364,
      0.04295683289763865,
      0.03957565423634463,
      0.041707099208454404,
      0.04216251270859868,
      0.040898591379375564,
      0.04062854016668953,
      0.03892103596764873,
      0.04312799107369366,
      0.04224855743784394,
      0.04086675532754719,
      0.04123594971988188,
      0.04041179957173157,
      0.040953270253797504,
      0.040743470892478345,
      0.03887390905848798,
      0.04069836878945517,
      0.03892514590993944,
      0.03990986017417593,
      0.03926208303842776,
      0.04100235718841917,
      0.03904738249003949
    ],
    "val_loss": [
      0.22428181109403422,
      0.2059864545252152,
      0.20482500132820206,
      0.24862139116593462,
      0.24043510043380145,
      0.2301507031957725,
      0.2484159322488986,
      0.24159179941310496,
      0.2641618984478141,
      0.2608054370848005,
      0.2689938143029541,
      0.24953771281072837,
      0.24859923395344954,
      0.27361526815388015,
      0.2809693568168643,
      0.27363593784902623,
      0.2727070452790417,
      0.2887499509658107,
      0.2849337054293848,
      0.3133659975346691,
      0.2951757500985425,
      0.2976379601987536,
      0.3057784315555574,
      0.3035754769103613,
      0.29984172459267927,
      0.2986134633444205,
      0.29927102496434826,
      0.3059429933768725,
      0.3250933482261475,
      0.32518115747876153,
      0.3122522370878629,
      0.30229423865452854,
      0.3272896156629581,
      0.31558377912524577,
      0.31651833904405197,
      0.34269302417552044,
      0.32830404129972357,
      0.3348047142837219,
      0.3042611207835332,
      0.3213263273261443,
      0.33821379959940195,
      0.323073346290492,
      0.319646629387747,
      0.3260192147450533,
      0.3288391218325514,
      0.3163558662963841,
      0.32844069142809174,
      0.31807228920613223,
      0.35380206360833016,
      0.32634348665436586,
      0.3279550888514269,
      0.3256750609391107,
      0.31120967174584635,
      0.3278048506597737,
      0.31524007707209645,
      0.32611877620666324,
      0.3369886091391662,
      0.31796420155884975,
      0.32763493503862157,
      0.32470141198419167,
      0.3201173617432039,
      0.32041608687200235,
      0.31794648992265767,
      0.32386430564843965,
      0.31805263109460563,
      0.3209119550549163,
      0.3179989344256367,
      0.32083620326203144,
      0.3127561802390271,
      0.3182295884290141,
      0.32678390924489786,
      0.32270236465031515,
      0.3220251631326304,
      0.314531733164798,
      0.33462159086888776,
      0.3132607535442371,
      0.31632104230498126,
      0.33200198171024553,
      0.3168905346046486,
      0.32520169759180373
    ],
    "best_epoch": 3,
    "best_val_loss": 0.20482500132820206,
    "test_loss": 4.744862197118513,
    "tracker": {
      "initial_train_loss": 0.3618107542181517,
      "train_threshold": 0.12060358473938389,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.20482500132820206,
      "patience_no_improve_epochs": 78,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_26_ae6fbb/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_26_ae6fbb/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_26_ae6fbb/config.yaml"
}