{
  "model_name": "mlp_with_history-other-value/trial_10_301c40",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 17,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.4873371624271571,
    "mid_layer_count": 12,
    "mid_layer_size": 614
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 260,
    "learning_rate": 0.000411502475145728,
    "weight_decay": 0.0024828973607697574,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7780,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 170,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87
    ],
    "train_loss": [
      0.7534460796948264,
      0.4154989307214791,
      0.39444565221399147,
      0.38164977572264586,
      0.3740243241382442,
      0.3625624464073034,
      0.3444256889023327,
      0.3216273254477886,
      0.2982171346411913,
      0.2902609429353307,
      0.28474954781924544,
      0.2793679825750905,
      0.2731260255477116,
      0.2767705773326609,
      0.2678076349064746,
      0.2680497335744088,
      0.26628429632260436,
      0.2631858856558493,
      0.26512635278977587,
      0.25993999616652347,
      0.2623191699194111,
      0.25950382573285874,
      0.2592116339577501,
      0.25560530361295664,
      0.2542842667559425,
      0.2560597091223709,
      0.25450770671845707,
      0.2519000567936346,
      0.24932293946301723,
      0.24317781462460986,
      0.24626935658387475,
      0.24044617412942235,
      0.2436214453303722,
      0.23708663815704287,
      0.23534862348536906,
      0.23500175777928076,
      0.2334616612882418,
      0.23067956408222415,
      0.23153588918916365,
      0.23277981809141704,
      0.22698530018482846,
      0.22591425750433325,
      0.22585305353210028,
      0.23207950833370874,
      0.2224365495394312,
      0.2213640360492054,
      0.22354349007490054,
      0.2253160335717287,
      0.22152589878263695,
      0.21925830676347247,
      0.2277168677138179,
      0.22098486914579543,
      0.21740706475657484,
      0.2142776952994207,
      0.21422079952486375,
      0.2153572504118966,
      0.21911717288598304,
      0.21373115744259794,
      0.21357531933674162,
      0.20956500073784728,
      0.21070884547380678,
      0.20954449417352064,
      0.20918824759271273,
      0.2116318413255147,
      0.21153980642940207,
      0.21301916781765023,
      0.20647392297465267,
      0.20681274883391618,
      0.20643812854676136,
      0.20767213327565964,
      0.2092620507074199,
      0.20407159607330755,
      0.2047978390994599,
      0.20512280672558783,
      0.2065326290679162,
      0.2045969454365708,
      0.20424209094599158,
      0.20211114789955414,
      0.20310474342276322,
      0.2059717640702093,
      0.20480466325669178,
      0.2017613214591475,
      0.20052511032412168,
      0.2054534323877418,
      0.20167542622450998,
      0.2028717743017373,
      0.20213014469661567
    ],
    "val_loss": [
      0.44314963749782765,
      0.4601790578422432,
      0.4601421331217189,
      0.4685008397359334,
      0.4900789491073814,
      0.4994347773626179,
      0.5577755888065178,
      0.5668182808482004,
      0.550452744175574,
      0.52818126798033,
      0.5067018464118421,
      0.5210964314773411,
      0.5288065643367653,
      0.5169980046813359,
      0.48697615490702095,
      0.522241759353769,
      0.5570622169507478,
      0.5207610820938727,
      0.5114721307854453,
      0.5106662195064351,
      0.5577541175716652,
      0.5226319184203347,
      0.5582177433781995,
      0.560309252696123,
      0.5848460466918831,
      0.5109144308252963,
      0.46912414129979596,
      0.50112650173153,
      0.5348114314193497,
      0.4512231136688929,
      0.5158441661896106,
      0.453612053733386,
      0.5340547985480931,
      0.49467823025352226,
      0.5650070774519514,
      0.45157479543885787,
      0.4269522981729336,
      0.49860014342619274,
      0.44411180583302845,
      0.43776130801189445,
      0.45986890373472683,
      0.5313127431683912,
      0.529781123389027,
      0.485512151421901,
      0.48937909046332995,
      0.478839697238214,
      0.499615966024513,
      0.5052812120871629,
      0.4767378236719234,
      0.44754785442066763,
      0.4654736163730393,
      0.5138211177137797,
      0.4913220570651357,
      0.5659103571119423,
      0.4805530070544717,
      0.48268462583690347,
      0.524106054427381,
      0.5226713165551603,
      0.4997169244253707,
      0.4989204343386039,
      0.5625334704172111,
      0.4862830189173807,
      0.5146816238136349,
      0.5086186670079202,
      0.5408992965421276,
      0.5059034200664052,
      0.5245052890149419,
      0.5652329414012189,
      0.5235368503246479,
      0.5396605196470272,
      0.49902227770782515,
      0.5056576265724834,
      0.5279046451438687,
      0.5350582524687945,
      0.5216193863017831,
      0.49253878050935485,
      0.5302176276545325,
      0.525755860134513,
      0.5003175499910366,
      0.48282745873142857,
      0.49599128301272133,
      0.5646758077744238,
      0.5317865654736936,
      0.530466554050674,
      0.539784448857079,
      0.5339548361158657,
      0.5505606881872622
    ],
    "best_epoch": 37,
    "best_val_loss": 0.4269522981729336,
    "test_loss": 0.42258662562906457,
    "tracker": {
      "initial_train_loss": 0.7534460796948264,
      "train_threshold": 0.25114869323160877,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4269522981729336,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-value/trial_10_301c40/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-value/trial_10_301c40/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-value/trial_10_301c40/config.yaml"
}