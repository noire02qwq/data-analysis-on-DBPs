epoch,train_loss,val_loss
1,0.858372,1.698331
2,0.557918,0.476021
3,0.378295,0.459395
4,0.367205,0.479698
5,0.367116,0.485703
6,0.361897,0.598335
7,0.352993,0.472244
8,0.348702,0.485079
9,0.352694,0.483785
10,0.343435,0.493394
11,0.331681,0.715295
12,0.333939,0.576646
13,0.297715,0.528352
14,0.285999,0.400980
15,0.263533,0.303952
16,0.257817,0.332272
17,0.254051,0.482927
18,0.255728,0.574260
19,0.257287,0.363683
20,0.261794,0.455764
21,0.264811,0.471578
22,0.242680,0.418320
23,0.236071,0.537542
24,0.240681,0.762989
25,0.252673,0.598471
26,0.229182,0.403067
27,0.217531,0.538107
28,0.247989,0.397055
29,0.223435,0.446786
30,0.219675,0.510439
31,0.223514,0.554895
32,0.217947,0.456210
33,0.203225,0.639445
34,0.265560,0.395917
35,0.238571,0.447090
36,0.216603,0.581477
37,0.218526,0.444925
38,0.202056,0.510130
39,0.199188,0.589249
40,0.205275,0.594073
41,0.197099,0.564245
42,0.196208,0.474845
43,0.199618,0.481306
44,0.188203,0.423434
45,0.184433,0.443810
46,0.200445,0.459617
47,0.185976,0.588840
48,0.175973,0.524094
49,0.190864,0.444536
50,0.177803,0.441234
51,0.182736,0.525553
52,0.176699,0.467402
53,0.202727,0.492864
54,0.172601,0.508650
55,0.169659,0.486857
56,0.162009,0.499522
57,0.161416,0.661897
58,0.160339,0.498574
59,0.148053,0.561639
60,0.218822,1.061250
61,0.209252,0.455556
62,0.177355,0.463662
63,0.168597,0.487608
64,0.163588,0.509374
65,0.163808,0.502068
66,0.286901,0.425964
67,0.204333,0.411459
68,0.178829,0.466732
69,0.171732,0.450363
70,0.171622,0.433483
71,0.157337,0.447162
72,0.159239,0.439219
73,0.150288,0.463442
74,0.151292,0.517016
75,0.168816,0.394577
76,0.149856,0.519125
77,0.144332,0.529934
78,0.157205,0.465918
79,0.135689,1.027288
80,0.177143,0.536868
