{
  "model_name": "mlp-other-rate/trial_32_0d7af5",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.4354053550186815,
    "mid_layer_count": 15,
    "mid_layer_size": 222
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 171,
    "learning_rate": 0.0010533925652067564,
    "weight_decay": 0.0005177952038683428,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149
    ],
    "train_loss": [
      0.426819271739169,
      0.2877092916860588,
      0.25847945893694646,
      0.24341251795347865,
      0.2358065011078208,
      0.22440243305771274,
      0.21650522751012113,
      0.21086735055118172,
      0.20587372817882763,
      0.20264641605527844,
      0.19667057089006798,
      0.18995033229212385,
      0.19142116938816578,
      0.1846211729958279,
      0.18312345852090067,
      0.179765795766084,
      0.17625527767576335,
      0.17340018147035952,
      0.17238251438671165,
      0.1684753062416646,
      0.16812516061953242,
      0.16968503821279954,
      0.16478697515034016,
      0.163324981755847,
      0.15898701877908072,
      0.16076729716919458,
      0.16050239927443619,
      0.16033056997844597,
      0.15582788189736435,
      0.15646209228323202,
      0.15488742303777928,
      0.154878432052511,
      0.1532490555447392,
      0.15219319718634244,
      0.1488386284743458,
      0.15104058360620728,
      0.14748148349858725,
      0.1473189302805664,
      0.14788841359841023,
      0.14646248127968878,
      0.14632069750312904,
      0.14509444834502952,
      0.1450471731524947,
      0.14205786663792327,
      0.14312186966788285,
      0.14312001825021192,
      0.1410212421224951,
      0.1434694276353284,
      0.14191122118454366,
      0.14220660583442482,
      0.14213597620543514,
      0.137955760783977,
      0.13745617504021856,
      0.13716931993943596,
      0.13852510951734648,
      0.1384545170351779,
      0.13586855744164134,
      0.1351963376225937,
      0.13995763922770585,
      0.1358554518894852,
      0.13396191106045502,
      0.1354677834174858,
      0.1349077795232226,
      0.1344223119779129,
      0.13548549651247133,
      0.13465570635317595,
      0.13459642720970208,
      0.13397134807994882,
      0.13445681615853505,
      0.1316757479442686,
      0.12937582014037774,
      0.1335452718124092,
      0.13174209653711919,
      0.13039009724425896,
      0.13111750587339338,
      0.1318242679832225,
      0.12943781836922655,
      0.13111196389912091,
      0.12939552310041857,
      0.12851778274854064,
      0.12954127036509083,
      0.13025687205647737,
      0.12722326815892882,
      0.13067563151077713,
      0.12779303589666605,
      0.128287101463592,
      0.1278580573753952,
      0.12638803346014715,
      0.12704938773893434,
      0.1282228269590865,
      0.13055023100473687,
      0.1291541175667355,
      0.12603579105387872,
      0.12750258362479794,
      0.12627068424493212,
      0.12381464841772251,
      0.12586127140923853,
      0.12768817840840738,
      0.12736228812656047,
      0.12561019016606584,
      0.12449762984448944,
      0.1263642677078726,
      0.12576421039544997,
      0.12463990579898722,
      0.12466427363386486,
      0.12624988090504952,
      0.12317909297555792,
      0.1255996582313814,
      0.12598582851070206,
      0.12553751864697518,
      0.1258008972139099,
      0.12540505712841368,
      0.12465639787225799,
      0.12561979443847887,
      0.12592977948635892,
      0.12482821951314937,
      0.12191477772985715,
      0.12231148382015201,
      0.12161824644556132,
      0.12449048618652718,
      0.12092154598739925,
      0.123705822860716,
      0.12261303550654065,
      0.12541734515806385,
      0.12118541674278466,
      0.12168038500928768,
      0.12222546685664791,
      0.12306878783129893,
      0.12489523081679477,
      0.12268567083259159,
      0.12372293788605222,
      0.12241227566725692,
      0.12245464686872012,
      0.12200137645411394,
      0.12256488126782407,
      0.12114153743333056,
      0.1259835488700512,
      0.12188838387893493,
      0.12343515031968648,
      0.12203019651072554,
      0.1194828324193845,
      0.12111394931053339,
      0.12106543579920094,
      0.12091674546344638,
      0.12176321461995544,
      0.12257777009084783,
      0.12377050012376842,
      0.11906066381603311,
      0.12207317071894672
    ],
    "val_loss": [
      0.3587647207661303,
      0.4053098937976146,
      0.47544933436159603,
      0.4583190788453568,
      0.46137677271387534,
      0.46846391455142083,
      0.4930856306752759,
      0.4852978947276841,
      0.5380060797590696,
      0.5312568930273285,
      0.5413226778011122,
      0.5283604801191898,
      0.4514310261535787,
      0.534993503104427,
      0.5092181834542823,
      0.5107909070160574,
      0.554223547643887,
      0.5163765536989281,
      0.5637883313580188,
      0.5046513345784056,
      0.5005474903849427,
      0.4724116753050667,
      0.5700547985955626,
      0.5039191719122276,
      0.5045218858444048,
      0.48358574827274164,
      0.5064696711426724,
      0.5002282162894032,
      0.4953655552632081,
      0.4997781910849902,
      0.48108781324086075,
      0.4958568729058711,
      0.5131990023091167,
      0.44471027793106205,
      0.47768842167483117,
      0.47333485207514847,
      0.4586430526199098,
      0.47167085717895074,
      0.48533083672919675,
      0.5019682688404343,
      0.5290203326476548,
      0.4901438948190855,
      0.4876227210069488,
      0.47575236880136823,
      0.4720862085144677,
      0.4894565285189066,
      0.46527855283396685,
      0.4575071866373102,
      0.46114701215556997,
      0.4977623977436277,
      0.47599542653132343,
      0.4595432693283715,
      0.45007608579304403,
      0.49774849207815297,
      0.485124638788179,
      0.5101814988442881,
      0.5211749383967793,
      0.490395035010255,
      0.44155054868695265,
      0.44858123549444234,
      0.47132166367091105,
      0.43373604776884267,
      0.45740208674422994,
      0.4444645515369798,
      0.46016798456628877,
      0.4543473377913058,
      0.46845642925201064,
      0.4555703725286587,
      0.4576747055539114,
      0.4682734365413289,
      0.45991887124534137,
      0.4599750219169491,
      0.4479711832355953,
      0.4648128368094296,
      0.48095105908320335,
      0.4521433863409622,
      0.4542836456063265,
      0.4468550659537672,
      0.4556726483706229,
      0.4511853648606175,
      0.4686445674050354,
      0.4454662404820591,
      0.47036693098837745,
      0.4517475523099214,
      0.4406419002590422,
      0.4716826508546661,
      0.4399586076864939,
      0.4431756793738839,
      0.4441496843706348,
      0.46330404889262367,
      0.46456627299685677,
      0.4596855944680597,
      0.4233237501166895,
      0.4412750309902037,
      0.45261236538965544,
      0.4493565800125727,
      0.454593099225424,
      0.4353152857658392,
      0.39704121351242067,
      0.4095400066298996,
      0.4707740097791849,
      0.44967154542843024,
      0.4478378845055303,
      0.47972221137163884,
      0.456718481282988,
      0.44514279935709733,
      0.42362616925004,
      0.44738264522420434,
      0.4243307298662777,
      0.4283349221025755,
      0.42560590583674923,
      0.468785653111642,
      0.43146595460569076,
      0.4150633347471674,
      0.42162519684897926,
      0.43303367810959587,
      0.42320718318223954,
      0.44298913429329495,
      0.42748015879424744,
      0.4141438937115812,
      0.4322017398958435,
      0.41166030239916135,
      0.40827795059202676,
      0.4054987579450279,
      0.4694659044954948,
      0.47490360842136564,
      0.4374259134966456,
      0.4787916903634985,
      0.43470198786008857,
      0.45726997748374226,
      0.41092010954183017,
      0.3997204243958353,
      0.42534224669376536,
      0.41023474081369216,
      0.4117822836616082,
      0.4154771213715305,
      0.4166607942052944,
      0.44133554903154604,
      0.4220341779514701,
      0.4820943231800359,
      0.4380577537292492,
      0.42851100578279555,
      0.4459066758300373,
      0.41880372904107244,
      0.44020290286419633,
      0.4179092134990378,
      0.41258652899079695,
      0.42676225164514814,
      0.43081667284944103
    ],
    "best_epoch": 99,
    "best_val_loss": 0.39704121351242067,
    "best_val_abs_mse": 0.5214570164680481,
    "test_loss": 0.5179667086763815,
    "test_abs_mse": 1.2543878555297852,
    "tracker": {
      "initial_train_loss": 0.426819271739169,
      "train_threshold": 0.142273090579723,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.39704121351242067,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-rate/trial_32_0d7af5/best_model.pt",
    "last": "scripts/outputs/mlp-other-rate/trial_32_0d7af5/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-rate/trial_32_0d7af5/config.yaml"
}