{
  "model_name": "mlp-trc-value/trial_18_b3d452",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.41261008492384216,
    "mid_layer_count": 5,
    "mid_layer_size": 193
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 308,
    "learning_rate": 0.0007811781871834898,
    "weight_decay": 0.00015076929381247474,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.452705173942907,
      0.18419231076831388,
      0.13749213194452597,
      0.11400231116548326,
      0.11005514415947212,
      0.09981596433180549,
      0.09971958733693706,
      0.09583879330636538,
      0.08892496319735216,
      0.08655959931610792,
      0.08407996810127859,
      0.08409615288015021,
      0.0822370156125878,
      0.07916713114913884,
      0.07632956890462912,
      0.07511707485150287,
      0.07425680004056445,
      0.07042810785511996,
      0.07371471749055747,
      0.07175212582260783,
      0.06915648789811649,
      0.06932799593799233,
      0.06872417654492355,
      0.06670168268299824,
      0.06571860266815949,
      0.06606037740243466,
      0.06453303516239861,
      0.06377602768646197,
      0.06289474218663281,
      0.06153029340843533,
      0.060782235289702606,
      0.06166289651574325,
      0.060202717282195284,
      0.060389873194673115,
      0.059474331035774264,
      0.05969593022735441,
      0.058931647752602324,
      0.0585123028237279,
      0.05811592301553552,
      0.057424155524093225,
      0.05736744897358842,
      0.05620247154487531,
      0.055831469796127756,
      0.0559897757168303,
      0.05573793821010056,
      0.05602468418893048,
      0.05416673713154888,
      0.054376573458107515,
      0.05365308996513601,
      0.0550784717016247,
      0.05314224997220925,
      0.053213824792786586,
      0.05427402932256108,
      0.05346716489124873,
      0.05119295730965146,
      0.05156802518695608,
      0.05128829684844379,
      0.0512049104664771,
      0.05020915399023115,
      0.05380539381432191,
      0.05054565617530819,
      0.051613617602405085,
      0.05022593286976012,
      0.050579106111199874,
      0.048478859286084426,
      0.05049949824014892,
      0.050528006478111946,
      0.05021795885242701,
      0.04818944308071518,
      0.05012341542862329,
      0.049620561987895606,
      0.048973267828197956,
      0.04873029287692337,
      0.048903292271496396,
      0.048699845008938175,
      0.047955571735452666,
      0.048517394528029945,
      0.046846359186428765,
      0.04849142287253355,
      0.04835608348884969
    ],
    "val_loss": [
      0.274066351363045,
      0.23611374067332216,
      0.21051442529894634,
      0.20943079820114696,
      0.20301475413366707,
      0.21005436883804326,
      0.21490969437057386,
      0.22208575273523787,
      0.2303783995171864,
      0.23868865534484743,
      0.2302073263836478,
      0.23432228152534204,
      0.23858846727156355,
      0.25171389607433786,
      0.23665095052408602,
      0.2485879356900375,
      0.2442429026934558,
      0.2512403838202625,
      0.25557571816854846,
      0.26030988317139137,
      0.2687431179477783,
      0.26348445626522254,
      0.26027954947091864,
      0.27420610341572477,
      0.2862721123693589,
      0.2918845236301422,
      0.2802852091496576,
      0.30581040866896064,
      0.3120382286206691,
      0.3036373922835567,
      0.30121864581893304,
      0.3054992362767636,
      0.30694369147726874,
      0.3089701064689431,
      0.30785004254319,
      0.3199669340993473,
      0.3207574001061702,
      0.31552514124237846,
      0.3054100542189832,
      0.30603456954488495,
      0.31268766659819436,
      0.3059636807994928,
      0.31873658217355877,
      0.3271662841790807,
      0.3274731984975452,
      0.3379890445463672,
      0.3258937478645476,
      0.319371639513327,
      0.333129799415073,
      0.3166211065908749,
      0.3327560457774622,
      0.34711427152781427,
      0.33090918094455124,
      0.3225916177168221,
      0.32722312320402996,
      0.32753059328226986,
      0.3215407132343975,
      0.31595270991057695,
      0.31825865022168903,
      0.32033963721401676,
      0.3233901899553345,
      0.32893479448592594,
      0.3182631687132898,
      0.31562915762473726,
      0.3154576866346562,
      0.3109615330032246,
      0.3209810740398076,
      0.3136284432100679,
      0.3186764035083933,
      0.3211375875164292,
      0.3151426060470992,
      0.3150005812461148,
      0.32345678274056866,
      0.3147626930635846,
      0.3146298155233175,
      0.32185066460581596,
      0.31222949265362976,
      0.30929695495856024,
      0.30996728013910935,
      0.30876633623492217
    ],
    "best_epoch": 5,
    "best_val_loss": 0.20301475413366707,
    "test_loss": 4.780715735335099,
    "tracker": {
      "initial_train_loss": 0.452705173942907,
      "train_threshold": 0.15090172464763565,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.20301475413366707,
      "patience_no_improve_epochs": 75,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_18_b3d452/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_18_b3d452/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_18_b3d452/config.yaml"
}