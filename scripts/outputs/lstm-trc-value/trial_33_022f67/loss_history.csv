epoch,train_loss,val_loss
1,0.999725,0.368513
2,0.999524,0.356691
3,0.999653,0.360275
4,0.999077,0.348918
5,0.999179,0.354769
6,0.998913,0.354121
7,0.998932,0.353666
8,0.998975,0.353895
9,0.998956,0.355594
10,0.998874,0.354774
11,0.998872,0.353379
12,0.998948,0.351181
13,0.998943,0.348342
14,0.999029,0.357300
15,0.998823,0.349582
16,0.998866,0.353793
17,0.999046,0.353253
18,0.998955,0.351086
19,0.998881,0.351859
20,0.998851,0.354521
21,0.998953,0.355433
22,0.998945,0.353146
23,0.998929,0.352791
24,0.998825,0.354907
25,0.998907,0.355943
26,0.998851,0.354484
27,0.998876,0.351488
28,0.998822,0.353951
29,0.998838,0.353751
30,0.998901,0.352783
31,0.998807,0.355202
32,0.998898,0.355746
33,0.998853,0.352352
34,0.998878,0.353027
35,0.998946,0.353782
36,0.998906,0.355669
37,0.998926,0.351770
38,0.998866,0.353439
39,0.998816,0.355684
40,0.998879,0.355098
41,0.998790,0.352130
42,0.998885,0.353278
43,0.998820,0.353082
44,0.998895,0.354006
45,0.998800,0.353537
46,0.998900,0.351612
47,0.998859,0.352785
48,0.998884,0.354862
49,0.998844,0.352006
50,0.998817,0.354404
