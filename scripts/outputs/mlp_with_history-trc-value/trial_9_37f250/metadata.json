{
  "model_name": "mlp_with_history-trc-value/trial_9_37f250",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 81,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.22225443710780676,
    "mid_layer_count": 7,
    "mid_layer_size": 900
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 232,
    "learning_rate": 0.0013685306484753851,
    "weight_decay": 0.004824963900699821,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7716,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 810,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90
    ],
    "train_loss": [
      1.0125081389292712,
      0.7239064899610694,
      0.2323309107494824,
      0.15087411498980177,
      0.14403831876887752,
      0.14063787767002162,
      0.1407379025140533,
      0.13207304102652057,
      0.12975012354973747,
      0.13310821236972056,
      0.11933271234643589,
      0.12959239633822453,
      0.12482831876255676,
      0.47493431346752657,
      0.23307265749151934,
      0.14915640412710565,
      0.14686112735418536,
      0.14993805639125202,
      0.13350213697965185,
      0.12867998966378458,
      0.12490422195600932,
      0.13082227520277737,
      0.1435274267255364,
      0.13721413487841763,
      0.12524345374635737,
      0.12273994400255293,
      0.12516440155284894,
      0.2433951075766728,
      0.14447807133228685,
      0.12213435457771216,
      0.12313306031911839,
      0.13041283506967663,
      0.11831963521526415,
      0.12062976745325645,
      0.1415442311204487,
      0.16900784277032235,
      0.12541274879728345,
      0.11851545038959904,
      0.12835736479272244,
      0.17903873775523213,
      0.12007910030579678,
      0.119554872569054,
      0.12378861478970668,
      0.1169193831401331,
      0.11688027930667574,
      0.1408557090937257,
      0.16989020448218609,
      0.11979224316161677,
      0.1276456753768224,
      0.21318314749382516,
      0.13144316077386858,
      0.13541433652365623,
      0.12129551813029575,
      0.12322306187273988,
      0.1578833978215668,
      0.1236542261221546,
      0.1202333340949503,
      0.11820340211787578,
      0.11679572199156026,
      0.12330840103146695,
      0.11898110694932221,
      0.1823369046299491,
      0.14281650825740144,
      0.12657841033905265,
      0.11665135486454097,
      0.11111760460045005,
      0.21247018717650368,
      0.24131510065295894,
      0.137669543757409,
      0.12989394896663242,
      0.1235911411408503,
      0.12181378496224674,
      0.1253502213194804,
      0.21560779138202182,
      0.143695371989267,
      0.12622956762417664,
      0.11990625553794819,
      0.11875739728789554,
      0.11414715197340944,
      0.1933197396415821,
      0.30179966229147837,
      0.1586250812510495,
      0.15932385256526507,
      0.12904582134394402,
      0.12995460352142466,
      0.1348949212942054,
      0.21174330461312602,
      0.13201822443228425,
      0.1215834485443223,
      0.11552175040563936
    ],
    "val_loss": [
      0.3516074726859966,
      0.5342414481911116,
      0.3426565889826792,
      0.3968846790537149,
      0.3529195634904736,
      0.30042033656807005,
      0.39672366446720625,
      0.3201303195007547,
      0.3069612327360821,
      0.33213255263552693,
      0.3665708538033291,
      0.289981805243178,
      0.3556251872888582,
      0.6155148152105823,
      0.276068585076018,
      0.2754659737030903,
      0.3028750793751842,
      0.29619243766019443,
      0.28733580008952203,
      0.30542682803676513,
      0.46881552822218686,
      0.352480849213229,
      0.3492744235132269,
      0.2772370244393092,
      0.5452943167732861,
      0.3249525199304084,
      0.30109912437236236,
      0.2991241043734693,
      0.31894568538594387,
      0.35470578132453795,
      0.39696130816808006,
      0.2773052034888439,
      0.309196272956397,
      0.2772306618219364,
      0.3021964036240549,
      0.3063866142830449,
      0.33614657533739856,
      0.3551113952598172,
      0.2847085970782948,
      0.27375374023250476,
      0.3062911617809427,
      0.2879636668694947,
      0.32156517940188595,
      0.3030205222393224,
      0.3337746853778462,
      1.0284117413316658,
      0.3898311210071255,
      0.27886416257141594,
      0.4805293760256853,
      0.3468660016795118,
      0.30695848434628126,
      0.30972395812322995,
      0.3623241665388296,
      0.32401703058067194,
      0.29094209075866345,
      0.31218617680722366,
      0.2950919255435824,
      0.44600904526824725,
      0.3322115868865373,
      0.2750782278661956,
      0.282065749105936,
      0.2829257628696407,
      0.348285578271586,
      0.3484101500875222,
      0.3275245219022928,
      0.3212442870179336,
      1.3899613434683062,
      0.33807209392864546,
      0.4173530190647719,
      0.6726953421524184,
      0.29185185338744146,
      0.28825171020573487,
      0.3129723521585236,
      0.5060563173122749,
      0.281463594779283,
      0.2918842176388124,
      0.3148667868293688,
      0.3022163596784997,
      0.3811283276466552,
      0.6087651919818924,
      0.44603257847581795,
      0.378896231494264,
      0.3168130025802972,
      0.34900185439936415,
      0.371407451815234,
      0.45195112858346836,
      0.3189479303395677,
      0.322164396093991,
      0.43904928689945244,
      0.3156164996727498
    ],
    "best_epoch": 40,
    "best_val_loss": 0.27375374023250476,
    "test_loss": 4.842906569750115,
    "tracker": {
      "initial_train_loss": 1.0125081389292712,
      "train_threshold": 0.3375027129764237,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.27375374023250476,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_9_37f250/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_9_37f250/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_9_37f250/config.yaml"
}