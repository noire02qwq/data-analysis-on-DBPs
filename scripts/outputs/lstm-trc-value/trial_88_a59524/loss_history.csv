epoch,train_loss,val_loss
1,1.000685,0.352117
2,0.999855,0.352162
3,0.999545,0.354420
4,0.999519,0.347393
5,0.999671,0.348549
6,0.999753,0.346927
7,0.999701,0.348642
8,0.999817,0.350474
9,0.999811,0.350169
10,0.999500,0.348820
11,0.999532,0.351289
12,0.999574,0.349473
13,0.999605,0.352788
14,0.999431,0.349104
15,0.999520,0.348789
16,0.999631,0.347280
17,0.999446,0.350987
18,0.999497,0.349367
19,0.999569,0.346910
20,0.999613,0.350909
21,0.999449,0.347461
22,0.999534,0.349669
23,0.999480,0.352103
24,0.999541,0.348784
25,0.999459,0.351126
26,0.999507,0.351076
27,0.999559,0.347859
28,0.999542,0.352337
29,0.999485,0.351064
30,0.999449,0.351336
31,0.999511,0.349634
32,0.999555,0.345847
33,0.999349,0.352504
34,0.999549,0.350857
35,0.999493,0.351389
36,0.999556,0.351606
37,0.999553,0.347315
38,0.999592,0.353720
39,0.999452,0.352150
40,0.999432,0.350428
41,0.999593,0.348847
42,0.999505,0.351533
43,0.999484,0.350521
44,0.999540,0.349944
45,0.999444,0.352827
46,0.999498,0.351401
47,0.999451,0.349986
48,0.999467,0.350844
49,0.999447,0.349621
50,0.999429,0.351050
