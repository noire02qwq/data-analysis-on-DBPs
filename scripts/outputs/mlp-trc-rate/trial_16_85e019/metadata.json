{
  "model_name": "mlp-trc-rate/trial_16_85e019",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.23550120377712366,
    "mid_layer_count": 6,
    "mid_layer_size": 356
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 216,
    "learning_rate": 0.0005884154757907818,
    "weight_decay": 0.0016959033948711645,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.37367877543828865,
      0.11683617400367667,
      0.08980809694577511,
      0.07691460574908768,
      0.07304170127554757,
      0.06614093009999863,
      0.06606592797220763,
      0.0643210978447443,
      0.061594344983273985,
      0.06114264663543959,
      0.0600352529159199,
      0.05780939381281005,
      0.05832520722501886,
      0.05804535368120077,
      0.056216833043581646,
      0.05757894231462368,
      0.053046533152682776,
      0.05246990292178722,
      0.051328307692403055,
      0.05180637572646875,
      0.05014625145624148,
      0.05217268848156183,
      0.04992032183641009,
      0.04934742219512924,
      0.05113278753508844,
      0.04947078839066764,
      0.048727198278845855,
      0.048531401938753535,
      0.04849314950922626,
      0.04873691981666941,
      0.048412408406395616,
      0.04700304012174115,
      0.04634502746849075,
      0.048944573899135646,
      0.04750389314656566,
      0.045794095193681474,
      0.04622451911153336,
      0.04578185257329398,
      0.046915006228919025,
      0.04454484636039536,
      0.047038561980378146,
      0.051341232487701526,
      0.045041057209041314,
      0.04475871285470465,
      0.045731546528343055,
      0.04473813791869695,
      0.04576467232575106,
      0.0444240872468656,
      0.04462648094801367,
      0.04721623286031466,
      0.0436560175051409,
      0.044009405343562534,
      0.04479835846061398,
      0.04450454743719517,
      0.04477184064774222,
      0.043406454170588166,
      0.043881098250966,
      0.0443422150682981,
      0.04496244888460257,
      0.043124245566670986,
      0.04332954406531852,
      0.04559069093012883,
      0.04425357474829369,
      0.04635358751470031,
      0.04381170470732001,
      0.04217398538707678,
      0.04246396784899539,
      0.04345375008540865,
      0.04294231424481824,
      0.04335565731625119,
      0.04337318267973342,
      0.04259008409817626,
      0.04339948422124962,
      0.043585406126059774,
      0.042166937092914525,
      0.04237221236345002,
      0.04300333178191689,
      0.04283662265947441,
      0.04309095429297653,
      0.04267917383269141
    ],
    "val_loss": [
      0.2135108575135648,
      0.18699157553875517,
      0.24156513416660047,
      0.24061197840168091,
      0.24805313194404818,
      0.24926398793558874,
      0.24676475324138195,
      0.26798577818149577,
      0.26624911737120793,
      0.2948967688276382,
      0.2771368515527177,
      0.24547816465000907,
      0.25617131074210125,
      0.28949222886812187,
      0.34670097913570747,
      0.257388791468686,
      0.2800545051783145,
      0.31941709355144443,
      0.2873294724408024,
      0.3244606400589029,
      0.29712216543580244,
      0.28188191846816124,
      0.30335767938348346,
      0.2985830362863883,
      0.31267257059762577,
      0.3140528497403253,
      0.29642320495701124,
      0.3369396950134974,
      0.3214420880832358,
      0.32800034942205797,
      0.3257060815028088,
      0.3096537884659396,
      0.345097191390877,
      0.4055254024124431,
      0.3295709816995495,
      0.3829748216414166,
      0.3639422446935477,
      0.3973300118289308,
      0.33910828637862633,
      0.34985500426884897,
      0.30057051764455384,
      0.34015224706270025,
      0.3679532495890549,
      0.34469441811660095,
      0.383150076982147,
      0.36797977618114674,
      0.3635207531962566,
      0.34093173236368657,
      0.33717007205157934,
      0.37820151900638366,
      0.377491103630223,
      0.3546197364251771,
      0.3316194715971004,
      0.37175525311759844,
      0.33815080456569524,
      0.33252524613084905,
      0.3860134583301173,
      0.386806798712936,
      0.35041129342810123,
      0.3835701447225616,
      0.3627822638450269,
      0.3552969775424746,
      0.38523349655780964,
      0.31414805427639786,
      0.3578219577045498,
      0.35957923047913765,
      0.3417407996104863,
      0.32730740199902814,
      0.35041164556841653,
      0.3208864788184623,
      0.3693599842801065,
      0.341491530924857,
      0.31891739103430045,
      0.34867098247576617,
      0.3559752926676573,
      0.3212887203800464,
      0.33204003344039,
      0.3609825395895335,
      0.32568970967731076,
      0.32639325379789946
    ],
    "best_epoch": 2,
    "best_val_loss": 0.18699157553875517,
    "best_val_abs_mse": 0.18987832963466644,
    "test_loss": 5.058807841328343,
    "test_abs_mse": 47.95487594604492,
    "tracker": {
      "initial_train_loss": 0.37367877543828865,
      "train_threshold": 0.12455959181276288,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.18699157553875517,
      "patience_no_improve_epochs": 79,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_16_85e019/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_16_85e019/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_16_85e019/config.yaml"
}