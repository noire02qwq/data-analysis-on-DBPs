epoch,train_loss,val_loss
1,0.755069,0.262603
2,0.250166,0.219386
3,0.176280,0.215399
4,0.157425,0.302203
5,0.143110,0.197814
6,0.172010,0.371697
7,0.140719,0.260266
8,0.130219,0.645438
9,0.128864,0.251324
10,0.129062,0.460523
11,0.123146,0.399513
12,0.124073,0.492656
13,0.135198,0.461110
14,0.124284,0.325665
15,0.122644,0.241076
16,0.131870,0.385077
17,0.115909,0.421916
18,0.118424,0.273246
19,0.117529,0.241875
20,0.121758,0.331211
21,0.112390,0.307360
22,0.115720,0.449372
23,0.113053,0.267372
24,0.116997,0.926895
25,0.129989,0.285803
26,0.122184,0.465942
27,0.112540,0.289151
28,0.111705,0.449957
29,0.113167,0.475457
30,0.109316,0.501176
31,0.114081,0.260264
32,0.113051,0.312867
33,0.113919,0.463186
34,0.114068,0.265491
35,0.127150,0.293661
36,0.145984,0.262316
37,0.118077,0.289348
38,0.114437,0.306510
39,0.112139,0.253818
40,0.107984,0.253576
41,0.110394,0.334654
42,0.111654,0.278407
43,0.107453,0.452942
44,0.108557,0.368729
45,0.113683,0.301705
46,0.109977,0.339374
47,0.106815,0.345050
48,0.107586,0.371072
49,0.117632,0.444506
50,0.109490,0.544039
51,0.104720,0.332405
52,0.108721,0.370255
53,0.114774,0.254375
54,0.110243,0.428462
55,0.111410,0.279162
56,0.108349,0.339818
57,0.106839,0.235216
58,0.111180,0.371969
59,0.107741,0.282556
60,0.109177,0.247212
61,0.106901,0.267526
62,0.115473,0.440012
63,0.111153,0.257661
64,0.113095,0.248973
65,0.106409,0.296921
66,0.107165,0.407736
67,0.105925,0.253830
68,0.106958,0.443982
69,0.103200,0.256655
70,0.106698,0.273497
71,0.111737,0.438585
72,0.107859,0.270166
73,0.108586,0.497114
74,0.107101,0.274467
75,0.107588,0.432708
76,0.109198,0.372450
77,0.104730,0.269368
78,0.108863,0.363802
79,0.106367,0.619556
80,0.103752,0.357903
