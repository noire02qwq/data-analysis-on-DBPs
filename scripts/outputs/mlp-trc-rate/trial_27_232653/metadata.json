{
  "model_name": "mlp-trc-rate/trial_27_232653",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.14618818080472704,
    "mid_layer_count": 3,
    "mid_layer_size": 303
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 182,
    "learning_rate": 0.0006698249830179234,
    "weight_decay": 0.0005941762100156611,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.303800304828851,
      0.09010044279952212,
      0.0652683803906283,
      0.06019643211155258,
      0.05759200101681035,
      0.05323166277387651,
      0.04991610970189475,
      0.048949131783214576,
      0.04824198814937553,
      0.046117321707560596,
      0.04674316101204346,
      0.04452871214244811,
      0.04306776720214312,
      0.043769166051286376,
      0.042077608358759094,
      0.0401931605514439,
      0.03975202035820212,
      0.03993951428486651,
      0.03966703995911279,
      0.03950154666419501,
      0.040280834446279376,
      0.03905265822360582,
      0.038166884612435406,
      0.03804763661159452,
      0.0374353996966858,
      0.03747152554357722,
      0.035932433315045774,
      0.036130698937244174,
      0.03705928161770885,
      0.037220293879145806,
      0.036331838833071624,
      0.035478200581882356,
      0.0354124803780332,
      0.035552092477117304,
      0.035646607493432195,
      0.03566435254582721,
      0.035061653353667614,
      0.03447420476076158,
      0.03472338434262894,
      0.03332497344078499,
      0.03414574246270617,
      0.03342797089628053,
      0.03359364819597776,
      0.0327188875693436,
      0.033062038804118205,
      0.033409786656242786,
      0.03370258700209605,
      0.032458337511257554,
      0.0332285109931281,
      0.03260716918536704,
      0.03206906235872889,
      0.03289925474472814,
      0.03224513883926567,
      0.032708898692245116,
      0.03159206812382279,
      0.03224973379753304,
      0.0321537071194838,
      0.031908616641504815,
      0.03178919492582822,
      0.03185264731046785,
      0.030702418890452464,
      0.0327931997619986,
      0.03164372019987723,
      0.03150231756648386,
      0.0314815080891425,
      0.031298326790474236,
      0.03158265538083599,
      0.03142466237687297,
      0.030828172364403585,
      0.03227470168129963,
      0.031477487295304064,
      0.03133459229417921,
      0.029963756154547935,
      0.030393041774970774,
      0.03127744852858149,
      0.030533632759545754,
      0.030220520049008638,
      0.03073366865584519,
      0.030332429559109086,
      0.02998322494645312
    ],
    "val_loss": [
      0.33651096979658046,
      0.20980016996269812,
      0.2701274451158361,
      0.27118704623492534,
      0.22452674481326235,
      0.28804193845766035,
      0.243114976067386,
      0.28036059269871183,
      0.31310093418031393,
      0.3129047819463436,
      0.29199075525080015,
      0.2901386610628245,
      0.2748462155505926,
      0.32474178585285196,
      0.3526801641428185,
      0.30386239462894593,
      0.31945638788451336,
      0.36596710971015656,
      0.30554886486180527,
      0.31183480195210367,
      0.3352117174199063,
      0.3137754026934237,
      0.2862917522604237,
      0.31044153383972045,
      0.3142984254809911,
      0.3494395303132827,
      0.3288757996756338,
      0.3195289883383377,
      0.3786861865173378,
      0.3366349893527295,
      0.37952735472894356,
      0.33792440416570196,
      0.36459983879711455,
      0.3523214226978982,
      0.3924237760575767,
      0.34500705090066985,
      0.3279932614995869,
      0.3567122865178271,
      0.33629901192993106,
      0.3521955717198863,
      0.37652650014636757,
      0.3481531517033627,
      0.4103502849105768,
      0.38165950462177484,
      0.41612846692522126,
      0.36414332867204074,
      0.36262719614910865,
      0.34241763838973943,
      0.3606980463768729,
      0.3595875616135176,
      0.43182113739901673,
      0.33356200481603243,
      0.3150374372807627,
      0.4081073137412885,
      0.32249611988886745,
      0.3418444081650166,
      0.33136192330432507,
      0.3767950374343081,
      0.3892585366183591,
      0.3498010504433138,
      0.3409182949426645,
      0.39116364394476316,
      0.42496226384209657,
      0.34236234056423165,
      0.3703201980558698,
      0.32583329950621026,
      0.3196185211243922,
      0.328350787257363,
      0.3832406174859958,
      0.3068927901836034,
      0.34808410404997314,
      0.30751325330156054,
      0.3316352777316899,
      0.3680535079141755,
      0.3161298997789443,
      0.37944112574670485,
      0.29514742395701166,
      0.36213223812376666,
      0.35071473431266,
      0.34692598720733636
    ],
    "best_epoch": 2,
    "best_val_loss": 0.20980016996269812,
    "best_val_abs_mse": 0.17158792912960052,
    "test_loss": 5.341993118872483,
    "test_abs_mse": 50.101226806640625,
    "tracker": {
      "initial_train_loss": 0.303800304828851,
      "train_threshold": 0.10126676827628367,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.20980016996269812,
      "patience_no_improve_epochs": 79,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_27_232653/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_27_232653/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_27_232653/config.yaml"
}