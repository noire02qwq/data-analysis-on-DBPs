{
  "model_name": "mlp-other-value/trial_5_6b4f9d",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.22271042986903894,
    "mid_layer_count": 12,
    "mid_layer_size": 466
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 199,
    "learning_rate": 0.0006784642555290673,
    "weight_decay": 0.002835583086652015,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149,
      150
    ],
    "train_loss": [
      0.42704823546268317,
      0.26221139033469804,
      0.236225870232924,
      0.22081315154071157,
      0.21257707520195496,
      0.20628597194175038,
      0.20041319560078,
      0.19732882137319074,
      0.1928269727286496,
      0.19106068923733,
      0.18915345374898093,
      0.18595556726343757,
      0.18510912926060044,
      0.17988430806318573,
      0.17922954513223555,
      0.17731795649021756,
      0.17754862189728704,
      0.17524001967370234,
      0.17491085619391877,
      0.1716296401404307,
      0.17054147347846113,
      0.1714219008598681,
      0.17045859191633606,
      0.17001698301840343,
      0.16707781107456884,
      0.1659002083101873,
      0.1646850753160793,
      0.16453208923989715,
      0.16222182307306346,
      0.16028274112921484,
      0.16070104364387924,
      0.16034644964094222,
      0.1610531585492679,
      0.15905582998473564,
      0.15824493859871158,
      0.15967578594771148,
      0.1573072192323642,
      0.15464421833414735,
      0.15664204021771483,
      0.15519388943811208,
      0.152729332630545,
      0.1556303458677279,
      0.15374917905489074,
      0.15285126639653346,
      0.15166217653131472,
      0.15247793210476346,
      0.1524938275247216,
      0.15441753605276484,
      0.15017277643413285,
      0.15060979519909073,
      0.15044688516362867,
      0.149396759651414,
      0.14979563497786738,
      0.15010490736184884,
      0.15098261443746128,
      0.14822725523138977,
      0.14954041551345584,
      0.14765629448329198,
      0.14757592144067194,
      0.147426684238418,
      0.14594944849755595,
      0.14795835559691692,
      0.14595040444642107,
      0.14777054387661295,
      0.14504456887639994,
      0.14510381521094207,
      0.14582624457673332,
      0.14519506085639186,
      0.1467163900975205,
      0.14493676184701915,
      0.1430386985308577,
      0.14448318015755354,
      0.14576967549116077,
      0.1434515646953669,
      0.14316569444264218,
      0.14299588174912303,
      0.14436653306016775,
      0.14416190014895017,
      0.141086744184698,
      0.143024072247921,
      0.14312039528246595,
      0.14451895452168062,
      0.14195400366646593,
      0.14393004885334246,
      0.14319158344696337,
      0.1413022369756079,
      0.143298582549949,
      0.14268653702780246,
      0.14183267917849118,
      0.14158434595142408,
      0.14333101251034047,
      0.1432684598325261,
      0.14176379554183927,
      0.14194182956781431,
      0.14056931858573618,
      0.14340184948451554,
      0.14350443192327125,
      0.1417263910076889,
      0.14071526662807332,
      0.14157196328430038,
      0.1445812466289139,
      0.14086701599771148,
      0.1409386156194711,
      0.13934489250328372,
      0.14129234046860192,
      0.14091302606426734,
      0.13830765909880874,
      0.14034929047178585,
      0.1396373256031766,
      0.14057045833820744,
      0.14009860629314272,
      0.13964893307924853,
      0.1395430500801173,
      0.13945386025399015,
      0.1400357997613558,
      0.13898219793687086,
      0.14070027822742345,
      0.13816078528264902,
      0.13990403295304912,
      0.13980605030549895,
      0.1388281161752097,
      0.14033132067773055,
      0.13856962247784624,
      0.13805168653896155,
      0.1388398004593514,
      0.13835211092364397,
      0.13895599626620161,
      0.1373587404958342,
      0.1404426312585361,
      0.13818588542473384,
      0.13768401330077937,
      0.13781713503864468,
      0.13694999212463158,
      0.13898601078009257,
      0.1371417490592472,
      0.13759939750038153,
      0.1385773612542786,
      0.13788180775546674,
      0.1393246097416603,
      0.1374303435810243,
      0.13818856105762697,
      0.13683875125587722,
      0.13631137651895456,
      0.13622856166800545,
      0.13884886004042174,
      0.13708467353297815,
      0.13745553041877595,
      0.13697259307286108,
      0.13667973574860667,
      0.13694912230948597
    ],
    "val_loss": [
      0.3626942854575411,
      0.3851158837849152,
      0.4360652683202378,
      0.45439702602114507,
      0.5108252942026732,
      0.4685554428282612,
      0.46044776939346405,
      0.46125009379790216,
      0.564557843436738,
      0.535275174980749,
      0.6091930840632873,
      0.5448419408839262,
      0.5125054609811235,
      0.5189326409942019,
      0.5868544640699903,
      0.5402913989019608,
      0.5406898401320694,
      0.592509355980479,
      0.647571266964524,
      0.5011351506465567,
      0.5323489172640675,
      0.5754182953677491,
      0.553447393595637,
      0.5746590520851983,
      0.5846575485062814,
      0.5587471188051615,
      0.6375610023603111,
      0.5874390348256705,
      0.615413881253875,
      0.5216926492438345,
      0.5266907827538287,
      0.6214371698211411,
      0.6214985186468341,
      0.5543561883984569,
      0.5917110863381517,
      0.6032811323771934,
      0.5013758782988894,
      0.5553057897724434,
      0.6801363159796435,
      0.6091024613264435,
      0.6138245023831636,
      0.6322688478864953,
      0.5673714762587033,
      0.6111776892430412,
      0.6273238874525724,
      0.6112612950498473,
      0.5131823340486623,
      0.537545419569144,
      0.5598053260968474,
      0.6109895235317909,
      0.5905359121273734,
      0.5383503497316094,
      0.5794913236743319,
      0.5964123836712922,
      0.614327392615601,
      0.5450818741214489,
      0.6033635994452916,
      0.5934120915160922,
      0.6363474739525846,
      0.5431159710768098,
      0.5238688844629747,
      0.6041311838848148,
      0.47874123801192836,
      0.5673601329683544,
      0.5757434692033037,
      0.5765954646254015,
      0.541476091327603,
      0.5921359816889563,
      0.5660618035557741,
      0.5821183943507557,
      0.6178608191941313,
      0.5621939707525119,
      0.5770168940263416,
      0.5266773492454768,
      0.6281711505781747,
      0.5404466086920507,
      0.5793872838159522,
      0.5796905387482957,
      0.5561989033293582,
      0.5814580316984368,
      0.6401892362508231,
      0.6195399822232253,
      0.5546302972930277,
      0.5518973320097981,
      0.525440849354881,
      0.5430459010609967,
      0.538180098892329,
      0.5227831120708746,
      0.48729697948176703,
      0.526172439258791,
      0.570976259403243,
      0.5021062136677925,
      0.5299211438053739,
      0.5860745966791393,
      0.5221954079043722,
      0.5965848727274441,
      0.5442720523271375,
      0.5287384149735559,
      0.5729103488479546,
      0.4555677693136438,
      0.5926104552151558,
      0.5797852518048116,
      0.5133408750156443,
      0.601327347911582,
      0.5272297316771781,
      0.5581413937409124,
      0.512213566818994,
      0.5737034755507986,
      0.4777392960906386,
      0.620165996574713,
      0.5921793452681539,
      0.6110593459384884,
      0.6189496387576986,
      0.5638614198137186,
      0.544039522731554,
      0.6138648398175924,
      0.5536495378408246,
      0.593421611680599,
      0.649402577032943,
      0.5211597111321495,
      0.6274615290100704,
      0.5706537453401945,
      0.536672255722527,
      0.6313701863818897,
      0.590275624711178,
      0.5964360065490543,
      0.5801027893752395,
      0.5966728565132546,
      0.5995776450651848,
      0.5434136230163945,
      0.5384047841329774,
      0.48030206263957625,
      0.5191787807259731,
      0.6118421946635503,
      0.48688321901028025,
      0.5634821327325112,
      0.6209113732604923,
      0.5565175610477339,
      0.5488720011523741,
      0.5196269619786097,
      0.558716584518998,
      0.614593444082016,
      0.5721705378931082,
      0.5490860702525713,
      0.5506443688032513,
      0.5401055867577385,
      0.5352428128084022,
      0.49785647833507934,
      0.53714109380802,
      0.5446379876243854
    ],
    "best_epoch": 100,
    "best_val_loss": 0.4555677693136438,
    "test_loss": 0.5366856311782126,
    "tracker": {
      "initial_train_loss": 0.42704823546268317,
      "train_threshold": 0.1423494118208944,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4555677693136438,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_5_6b4f9d/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_5_6b4f9d/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_5_6b4f9d/config.yaml"
}