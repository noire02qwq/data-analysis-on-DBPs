{
  "model_name": "mlp-trc-value/trial_59_89f85e",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.22458658088246788,
    "mid_layer_count": 13,
    "mid_layer_size": 346
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 197,
    "learning_rate": 0.0018401129062490037,
    "weight_decay": 0.0025236971495958853,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.2502844992656167,
      0.09238543926478732,
      0.07363558392837957,
      0.07224235989931319,
      0.06715387282697145,
      0.06376501452607825,
      0.06333721568162867,
      0.06084363165814687,
      0.06065947903829578,
      0.058752363687691746,
      0.057815424307584455,
      0.05881363949597478,
      0.05623090247159634,
      0.05660111654842279,
      0.053369901712607304,
      0.052605084864171335,
      0.05308786340119014,
      0.054433280273339206,
      0.05412117937955338,
      0.05312172925695127,
      0.05587596871941257,
      0.053932683356488556,
      0.05438961052484409,
      0.05401834796754793,
      0.05047362454937032,
      0.05220812819888571,
      0.05398190828740765,
      0.05420937159864672,
      0.05244519959336262,
      0.053760573598128546,
      0.05095231275778052,
      0.0517166551630686,
      0.05157727514345365,
      0.0522065394777344,
      0.051105466610123676,
      0.050800673336291416,
      0.05011122646942742,
      0.05217283884739038,
      0.05262391091400367,
      0.0507734712588865,
      0.05161760235133616,
      0.050210659861423194,
      0.05055629884276545,
      0.050903761431597756,
      0.053504099499810776,
      0.04984542168820207,
      0.05192375406976493,
      0.05079771929863494,
      0.05125485854285491,
      0.050468647578734045,
      0.05180687088616816,
      0.05072048948786239,
      0.05208719689150524,
      0.04957113823704823,
      0.050813162431747806,
      0.05170922019419042,
      0.048495652229587745,
      0.051935920649026066,
      0.05100933864297944,
      0.05181430828585082,
      0.05412726629986067,
      0.053053488034569586,
      0.051550230478677704,
      0.049648374343446704,
      0.05044987188674139,
      0.0497523850745585,
      0.05172283748683714,
      0.0514261021678756,
      0.051396037982810214,
      0.04860531645332424,
      0.049657455110791525,
      0.04976501316548908,
      0.04947281746636252,
      0.052365541540797304,
      0.05079492779564267,
      0.0495268128551409,
      0.05142183452672595,
      0.05142035791645636,
      0.04895137278903075,
      0.04921348761813022
    ],
    "val_loss": [
      0.29163920342431454,
      0.20803596863556587,
      0.25262216806166365,
      0.35619339428641306,
      0.30294198784531057,
      0.257138646361669,
      0.2841628154985116,
      0.3310797795608729,
      0.29723264551359024,
      0.38856233781884,
      0.2799071990745421,
      0.4224292645074739,
      0.3222310116826863,
      0.44109291047482435,
      0.3608280631997985,
      0.34199479467564536,
      0.3289286668752571,
      0.3406444764891249,
      0.3009025819811546,
      0.3130646104662272,
      0.34399224039903303,
      0.3236477766799445,
      0.28250909958057063,
      0.28108476758404766,
      0.29366058889932617,
      0.3070027261459363,
      0.28265949593868084,
      0.3237407255382416,
      0.33964581047881864,
      0.3237204660053649,
      0.30122229685215,
      0.28748807816872163,
      0.3029538059997523,
      0.30322494307967895,
      0.354525013174304,
      0.2956935562539154,
      0.3966600168585599,
      0.2911296827629387,
      0.29888353970816395,
      0.3812391872021431,
      0.33241442503619517,
      0.33665010951972474,
      0.2893896351841663,
      0.3112004187259221,
      0.3056353116229533,
      0.3147569928909401,
      0.35875461541317,
      0.2905471019268393,
      0.2773469052450386,
      0.3242753843782458,
      0.4353618381210341,
      0.33857837728152196,
      0.2813374796592279,
      0.29914901606783184,
      0.28131896870958056,
      0.29100056518493833,
      0.2849332899401734,
      0.30676006870734657,
      0.3626349785883805,
      0.4000335262262982,
      0.3011406300511367,
      0.370285305467819,
      0.41199167196800607,
      0.29343303467766074,
      0.3256975818035042,
      0.2756285463833434,
      0.29179712732707314,
      0.3115944422324171,
      0.30892839285204865,
      0.3181199487655641,
      0.3226477638533908,
      0.30007580857010124,
      0.3048529538588074,
      0.270613753595975,
      0.27856487292394844,
      0.29908597361363337,
      0.28038656437869913,
      0.29334655734570975,
      0.31523426672901045,
      0.30755640414102886
    ],
    "best_epoch": 3,
    "best_val_loss": 0.25262216806166365,
    "test_loss": 5.005048215460549,
    "tracker": {
      "initial_train_loss": 0.2502844992656167,
      "train_threshold": 0.08342816642187223,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.25262216806166365,
      "patience_no_improve_epochs": 78,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_59_89f85e/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_59_89f85e/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_59_89f85e/config.yaml"
}