{
  "model_name": "mlp-other-value/trial_1_b1791c",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.4692936590941377,
    "mid_layer_count": 5,
    "mid_layer_size": 503
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 265,
    "learning_rate": 0.0019894272915346248,
    "weight_decay": 0.0005129425502860512,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138
    ],
    "train_loss": [
      0.43988897841043384,
      0.2971724369216724,
      0.2676215925167438,
      0.25112596053674074,
      0.23928949481336015,
      0.2305578415025467,
      0.22257770587995518,
      0.21772392325604065,
      0.2115789500336087,
      0.206934152254161,
      0.19885088073490154,
      0.1959770249614751,
      0.19445153098532394,
      0.19029979374146938,
      0.18821938969902102,
      0.18417814569313629,
      0.18181606911203077,
      0.17832889492165252,
      0.1779856958687917,
      0.17688129149786383,
      0.17446543634503606,
      0.1724207219082371,
      0.17094172688326265,
      0.17039886895488812,
      0.17018621292762293,
      0.1690636936588554,
      0.16564912528847045,
      0.16482550809288893,
      0.16537559005680788,
      0.16176824454407376,
      0.16300194809502855,
      0.16319057352462446,
      0.16065039568838246,
      0.15993758971459318,
      0.15864352824566852,
      0.15734008987701326,
      0.1579548714194101,
      0.15653830871230642,
      0.15824678014598792,
      0.15424639956902364,
      0.1547561954819679,
      0.1556235312203709,
      0.15457437240952035,
      0.15534064630519553,
      0.15187660752274307,
      0.1527656770501001,
      0.148875710647601,
      0.15200336755331265,
      0.1504774574819224,
      0.14885970533444615,
      0.15133030975515596,
      0.14692481936530433,
      0.14808631471796424,
      0.14824865214821006,
      0.14599836250244347,
      0.14672702485136402,
      0.14441767195502478,
      0.1456617089614402,
      0.14656361263950646,
      0.14295717835112864,
      0.1434814330140724,
      0.14605237772566895,
      0.1472703087511064,
      0.14645167539185777,
      0.14660433509323523,
      0.14336675150523495,
      0.14366689690791565,
      0.14370803696305523,
      0.143422490158804,
      0.14362868456396463,
      0.1449218060182892,
      0.1434167682944872,
      0.14408502184340072,
      0.14069456190039037,
      0.14376336366718032,
      0.13938487161537694,
      0.14258988310758305,
      0.1401963598697445,
      0.1406904823844894,
      0.14137211968484845,
      0.13943007038672073,
      0.14003746210286377,
      0.14034060148829036,
      0.14045005873526104,
      0.13817150205213208,
      0.14203730943670573,
      0.14082560931958865,
      0.139884462734907,
      0.14013261454951126,
      0.14018855231688412,
      0.14050246328746221,
      0.13956227002635774,
      0.14077747830802842,
      0.14091295196654216,
      0.13801341660209898,
      0.13836898409564138,
      0.14047464949980554,
      0.1399900642261406,
      0.13633993825659713,
      0.13726119890239466,
      0.14084967950682967,
      0.13867590337773816,
      0.1368529927004616,
      0.1361136258818236,
      0.13628952506511044,
      0.13596620936789625,
      0.13851283639268028,
      0.1397245685790229,
      0.13991905101457885,
      0.1381000291991916,
      0.13911813863191377,
      0.1393308168446302,
      0.13727384906504905,
      0.1364803846071108,
      0.13649827942038084,
      0.1389170822526413,
      0.1350935086676743,
      0.13733056048385267,
      0.1364276979640394,
      0.13721849301828978,
      0.1362041056207766,
      0.1357764773024939,
      0.1351289618024464,
      0.13653744980138563,
      0.1363255489845041,
      0.13499484174507834,
      0.13545476234570078,
      0.13715494668093048,
      0.13878545227946532,
      0.13643697660899945,
      0.13429938261327895,
      0.13705072761644702,
      0.13698713206664576,
      0.1382741919403782,
      0.13575013217183185,
      0.13492999341493694,
      0.13492835715619522,
      0.1365303786413189
    ],
    "val_loss": [
      0.3813411564437929,
      0.4076673133287601,
      0.5117932616281295,
      0.47065432409861846,
      0.42046137145179474,
      0.47582719626719366,
      0.5235318422406733,
      0.5118155999633367,
      0.5447208592723943,
      0.5486469413349014,
      0.5506725081962026,
      0.5075232866638435,
      0.5227857983844009,
      0.5218450331580853,
      0.5396346048769837,
      0.5617451681169922,
      0.5419549791666562,
      0.5554719203246568,
      0.5395653139420612,
      0.47465878613516244,
      0.4994670994535178,
      0.5325708084566865,
      0.5730371739336116,
      0.4820874261552702,
      0.4830378692842529,
      0.47952595254975167,
      0.48217192934658715,
      0.525485669959805,
      0.4643221264203152,
      0.43491105953911824,
      0.4200131475122389,
      0.5020989130981668,
      0.4814806319996268,
      0.4477113500059008,
      0.4304054757792079,
      0.46709531666097526,
      0.4178909574172454,
      0.4364834310051924,
      0.4694808615806574,
      0.4955231664914214,
      0.47179253872283206,
      0.42783674446051706,
      0.4319213236163476,
      0.4487083717556057,
      0.42009903450390534,
      0.4088091440275758,
      0.43732587199011247,
      0.41939565401055856,
      0.43529888099717523,
      0.4285578133906433,
      0.4394894865993968,
      0.4133973857332133,
      0.4243404414660916,
      0.4695365941096209,
      0.44112195355628064,
      0.4196264164711901,
      0.5046710926080178,
      0.42267094030530156,
      0.4501726781938247,
      0.4474069082183752,
      0.4470118871349061,
      0.4654692732199223,
      0.46017202208499,
      0.45992713372507493,
      0.42145110336606373,
      0.42330079811240384,
      0.42686986700146495,
      0.42139268876192815,
      0.4369340838786371,
      0.425648123873565,
      0.43108840420574485,
      0.46073053063389785,
      0.4238549814877396,
      0.41814059094932976,
      0.4950193960420386,
      0.4248845661560932,
      0.4136791258693455,
      0.4322180491453873,
      0.4500519344192779,
      0.42750788654039007,
      0.4541687545572926,
      0.4112383503310695,
      0.487886623886531,
      0.4205599439715197,
      0.444755804886718,
      0.4795285594052897,
      0.4443616094346532,
      0.3945321810102748,
      0.44483258374436885,
      0.4332897146037239,
      0.43765800000129346,
      0.4349966074624461,
      0.4533492838461956,
      0.4328312715013584,
      0.4541226160561967,
      0.43051831415313446,
      0.44691282872132915,
      0.43690794568040414,
      0.4153256205741517,
      0.42325205266654137,
      0.459514212153272,
      0.42457634063359506,
      0.4353667481127613,
      0.45041814888130405,
      0.41210801591594776,
      0.40465966000885306,
      0.397692460544452,
      0.4603288736707436,
      0.45573087549673585,
      0.43387196958065033,
      0.4530050777300389,
      0.4593544383338112,
      0.4393532958751667,
      0.44019278669785594,
      0.40799391015382586,
      0.4461635285598075,
      0.4385962785182599,
      0.4402371230284254,
      0.48773254242218184,
      0.4228256515667824,
      0.42278486744550886,
      0.42921701841011733,
      0.4085699067322794,
      0.4609653313984414,
      0.45286103594535126,
      0.44654272202246204,
      0.4797900057659892,
      0.4751831252507107,
      0.43442907095133904,
      0.4254464525394811,
      0.43515337321037306,
      0.41515153084329504,
      0.4230704894233607,
      0.44680068632978165,
      0.4271318813016315,
      0.49818739689841957,
      0.4380414106710228,
      0.44353276294862437
    ],
    "best_epoch": 88,
    "best_val_loss": 0.3945321810102748,
    "test_loss": 0.5330422763761721,
    "tracker": {
      "initial_train_loss": 0.43988897841043384,
      "train_threshold": 0.1466296594701446,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3945321810102748,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_1_b1791c/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_1_b1791c/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_1_b1791c/config.yaml"
}