epoch,train_loss,val_loss
1,0.557428,0.361112
2,0.206796,0.353208
3,0.168102,0.322110
4,0.150924,0.324885
5,0.130599,0.370816
6,0.108328,0.282956
7,0.091409,0.290791
8,0.080506,0.205484
9,0.067916,0.221723
10,0.061715,0.184194
11,0.056969,0.194568
12,0.053404,0.187804
13,0.052505,0.188627
14,0.051836,0.185283
15,0.050166,0.185588
16,0.048648,0.192000
17,0.047023,0.200835
18,0.046342,0.202202
19,0.048436,0.219086
20,0.045698,0.203634
21,0.044391,0.203246
22,0.042662,0.209549
23,0.043047,0.216119
24,0.042177,0.224784
25,0.043532,0.237609
26,0.043120,0.244232
27,0.042961,0.235031
28,0.039889,0.235521
29,0.040312,0.248719
30,0.038302,0.259798
31,0.037811,0.256188
32,0.038935,0.270243
33,0.037814,0.276528
34,0.038455,0.299061
35,0.038832,0.273696
36,0.037368,0.291633
37,0.038060,0.297048
38,0.036528,0.288734
39,0.036449,0.305833
40,0.036699,0.269553
41,0.037013,0.320278
42,0.035125,0.350436
43,0.035681,0.313998
44,0.034977,0.319015
45,0.034951,0.319462
46,0.034486,0.342956
47,0.034499,0.312595
48,0.036511,0.317185
49,0.034418,0.351387
50,0.035206,0.331538
51,0.034588,0.362832
52,0.035070,0.324342
53,0.034383,0.315210
54,0.034864,0.344051
55,0.033896,0.337469
56,0.032929,0.348786
57,0.033188,0.346738
58,0.034413,0.349171
59,0.033029,0.337637
60,0.033423,0.333315
61,0.035413,0.338057
62,0.035247,0.321170
63,0.032956,0.328884
64,0.034658,0.349624
65,0.035209,0.374768
66,0.034172,0.345141
67,0.032215,0.339516
68,0.033067,0.334403
69,0.033572,0.381261
70,0.033730,0.365808
71,0.032795,0.347005
72,0.031716,0.383957
73,0.032511,0.347714
74,0.031527,0.363523
75,0.033306,0.343667
76,0.031979,0.350092
77,0.031288,0.391089
78,0.031054,0.356405
79,0.031675,0.345600
80,0.030369,0.382571
