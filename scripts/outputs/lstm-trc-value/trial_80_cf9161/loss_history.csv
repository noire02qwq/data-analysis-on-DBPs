epoch,train_loss,val_loss
1,0.999812,0.353637
2,0.999695,0.356868
3,0.999396,0.343614
4,0.999667,0.347841
5,0.999794,0.360138
6,0.999563,0.349759
7,0.999587,0.347126
8,0.999495,0.355285
9,0.999501,0.354704
10,0.999410,0.347239
11,0.999475,0.358620
12,0.999586,0.347642
13,0.999342,0.352626
14,0.999384,0.351850
15,0.999364,0.355379
16,0.999466,0.354158
17,0.999422,0.351747
18,0.999285,0.353060
19,0.999486,0.356481
20,0.999275,0.351199
21,0.999612,0.353967
22,0.999761,0.350857
23,0.999255,0.354911
24,0.999374,0.352646
25,0.999297,0.352791
26,0.999276,0.352440
27,0.999317,0.350256
28,0.999317,0.350532
29,0.999317,0.353310
30,0.999405,0.352896
31,0.999331,0.351823
32,0.999311,0.351294
33,0.999261,0.352449
34,0.999321,0.352065
35,0.999276,0.353343
36,0.999353,0.349211
37,0.999295,0.353000
38,0.999371,0.353007
39,0.999280,0.351373
40,0.999257,0.350145
41,0.999261,0.352361
42,0.999312,0.354150
43,0.999328,0.352493
44,0.999332,0.353274
45,0.999293,0.349629
46,0.999240,0.352659
47,0.999294,0.353371
48,0.999384,0.351805
49,0.999334,0.353015
50,0.999368,0.349535
