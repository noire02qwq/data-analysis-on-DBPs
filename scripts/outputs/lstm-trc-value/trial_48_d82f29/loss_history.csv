epoch,train_loss,val_loss
1,1.000564,0.345716
2,0.999841,0.353731
3,0.999469,0.347943
4,0.999649,0.346418
5,0.999324,0.348980
6,0.999332,0.353086
7,0.999309,0.353331
8,0.999321,0.353026
9,0.999331,0.353642
10,0.999254,0.352783
11,0.999400,0.351909
12,0.999234,0.350273
13,0.999205,0.351225
14,0.999221,0.351831
15,0.999218,0.351823
16,0.999202,0.352437
17,0.999248,0.351588
18,0.999230,0.352082
19,0.999225,0.352210
20,0.999275,0.351762
21,0.999371,0.350903
22,0.999257,0.352121
23,0.999253,0.351567
24,0.999225,0.351201
25,0.999196,0.350957
26,0.999201,0.352956
27,0.999252,0.352344
28,0.999255,0.351440
29,0.999205,0.351563
30,0.999253,0.350682
31,0.999208,0.350590
32,0.999286,0.349555
33,0.999252,0.352324
34,0.999191,0.351580
35,0.999229,0.351836
36,0.999283,0.350584
37,0.999243,0.352005
38,0.999224,0.351551
39,0.999190,0.350422
40,0.999219,0.350598
41,0.999212,0.350787
42,0.999186,0.350084
43,0.999257,0.351525
44,0.999206,0.350680
45,0.999225,0.350637
46,0.999181,0.351114
47,0.999199,0.350520
48,0.999198,0.351853
49,0.999196,0.350673
50,0.999206,0.351558
