{
  "model_name": "mlp_with_history-trc-value/trial_8_e019aa",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 57,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.39206672865753367,
    "mid_layer_count": 7,
    "mid_layer_size": 912
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 158,
    "learning_rate": 0.0008613294527953498,
    "weight_decay": 0.002152155717623562,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7740,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 570,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149,
      150,
      151,
      152,
      153,
      154,
      155
    ],
    "train_loss": [
      0.41547428846205237,
      0.17539207877769333,
      0.15843193579166742,
      0.16913721586074631,
      0.15420996481673047,
      0.15171096763869588,
      0.15577917660969173,
      0.15159518833654795,
      0.14634148176826864,
      0.1374673891841441,
      0.14980466021585834,
      0.14704148132902709,
      0.14294133489176591,
      0.14377976597241038,
      0.1513927737756293,
      0.1562469901849133,
      0.14600295778893377,
      0.1366584225295434,
      0.13353888163347885,
      0.13948640964289968,
      0.1336713104419776,
      0.13439500625473894,
      0.13302850400215588,
      0.12967989205235966,
      0.1405919313681064,
      0.13904137540541261,
      0.12986773137936913,
      0.1285338204248161,
      0.12976146578134184,
      0.13196839420678388,
      0.13423471259631853,
      0.12832884316258036,
      0.12546328234195092,
      0.12457683171104707,
      0.1267821896792382,
      0.1269415825143341,
      0.1235294222157901,
      0.13056545946025108,
      0.12852244138217095,
      0.1209637520483452,
      0.1234848620317087,
      0.12047950956941575,
      0.122313349141477,
      0.12012396635973792,
      0.11715164752508626,
      0.11198732276719053,
      0.16142201799831957,
      0.12557795578156639,
      0.12067333854908167,
      0.1216815803132624,
      0.12241799491204956,
      0.11952464769591965,
      0.11516744839821676,
      0.11393002186557735,
      0.11226285475015024,
      0.1276947964069455,
      0.114428330988693,
      0.11968190417040227,
      0.11631351192060675,
      0.11264366416660082,
      0.11730981433345367,
      0.1154007867479201,
      0.11403376068101681,
      0.1087271340287625,
      0.11158701724899832,
      0.11139905205338192,
      0.12035010642629569,
      0.11450463360132174,
      0.10907210447953036,
      0.10970563264972788,
      0.11191040354489665,
      0.12777722229175173,
      0.11007344989004986,
      0.1077001150341305,
      0.0956130207066234,
      0.09735096575600849,
      0.10434572674353301,
      0.10193557192881902,
      0.10425136196751927,
      0.09338345085427127,
      0.08900816032436774,
      0.09372401903612053,
      0.09350663469743359,
      0.09145928099847733,
      0.09481922161479021,
      0.08918752450428576,
      0.08743634830091813,
      0.09738531527747171,
      0.09337681284516049,
      0.08814008231888446,
      0.08757834372613627,
      0.08152763591044479,
      0.08494194065261565,
      0.08115127917369515,
      0.0808765021684635,
      0.08012575207408085,
      0.08489687502076151,
      0.08816684331042206,
      0.08686476424721476,
      0.08131508410400506,
      0.0833565739929214,
      0.07815887020270337,
      0.0797464384290676,
      0.08520283308602118,
      0.08239886368352929,
      0.07796169901868323,
      0.07761805467307567,
      0.07942617094235672,
      0.0853794301203055,
      0.07962137444151772,
      0.07665310048086699,
      0.0770221821954161,
      0.10287310971327376,
      0.08601305321321007,
      0.07786699372033277,
      0.07721771869221244,
      0.07987367635838283,
      0.07505823566027237,
      0.07905529748927562,
      0.07823963205327668,
      0.07836229208404395,
      0.08204814437343631,
      0.07495028330855437,
      0.07563646592642602,
      0.08109845728144165,
      0.08141825264488234,
      0.07940570213170169,
      0.07866169374907818,
      0.07699609651430017,
      0.07784461599584544,
      0.07642878826120411,
      0.07862579038015324,
      0.07542622173036562,
      0.16878400109515787,
      0.12923760120913347,
      0.09789053743045767,
      0.08674916552442297,
      0.08328489375129842,
      0.08333881968675658,
      0.0751984605146933,
      0.0790552629576635,
      0.08192505935635369,
      0.08664034595015128,
      0.08320185541240281,
      0.07846769239724606,
      0.0729182657894007,
      0.07623043642295116,
      0.08029613791644881,
      0.07847719974623324,
      0.07358270862286559,
      0.07259035701610783,
      0.07815708194977246,
      0.07682890666489915,
      0.07396684297449521,
      0.08190052571973597
    ],
    "val_loss": [
      0.2127377894734908,
      0.20489645998947278,
      0.257949833835135,
      0.30284690574079215,
      0.293324405601817,
      0.2757406999161857,
      0.27634219782215036,
      0.28116662430236794,
      0.2690154678383452,
      0.2925798615072659,
      0.27016577334505715,
      0.29910481470876826,
      0.28528511445010135,
      0.2685223885795135,
      0.2834389116213529,
      0.27008569927629594,
      0.2894770246712926,
      0.26450018014781135,
      0.2628762513332203,
      0.2744413845597984,
      0.29206700000666574,
      0.29523705418059926,
      0.2765966717086866,
      0.2996401280744704,
      0.28131879759941275,
      0.27169346165157365,
      0.2890664683376065,
      0.27293838179129326,
      0.2884772917869205,
      0.29158171073137645,
      0.28852379235054204,
      0.26872471673135273,
      0.28827499563465575,
      0.2763406291581735,
      0.3266304796572752,
      0.2639659066913192,
      0.28581348243587745,
      0.27206649485819356,
      0.28260038259946657,
      0.28275315444358806,
      0.3040407256028074,
      0.26364034181851115,
      0.28272168049198426,
      0.27953248079754633,
      0.2677357374417211,
      0.26939491802703835,
      0.28259931929231047,
      0.2619577034058685,
      0.2985971776824333,
      0.2633231177859142,
      0.2966335632553893,
      0.2710317123592078,
      0.28305178528908126,
      0.2587451112863725,
      0.27710130288304685,
      0.2732604850373582,
      0.2830009552510734,
      0.2530363589502916,
      0.2780099675817761,
      0.28647570122858723,
      0.2646171486819397,
      0.2604959514839742,
      0.36746456979099146,
      0.39015792076236117,
      0.3554981335729896,
      0.261167106766276,
      0.2853490401148618,
      0.25671839354459397,
      0.26497471629457914,
      0.2654321148344678,
      0.3682031645902438,
      0.2619681682995337,
      0.2861645974040388,
      0.27869748477182704,
      0.29913648218585703,
      0.2988980860990322,
      0.25219574174704307,
      0.41348388639841965,
      0.32663874532469733,
      0.25503211396406156,
      0.3765375141745913,
      0.3867467699516676,
      0.39839912483658263,
      0.3760734045866899,
      0.2766722554798255,
      0.3436796985878916,
      0.35403232727043643,
      0.35141396277366643,
      0.3940772122073316,
      0.3205007254564298,
      0.298967268759619,
      0.2582249603942483,
      0.31610133367295035,
      0.3437432140067309,
      0.3812275379673093,
      0.3613945732818928,
      0.3822685641576787,
      0.3330243935507393,
      0.44775244501714934,
      0.3056614286082234,
      0.28681188461978635,
      0.3294840470112548,
      0.4894662378857771,
      0.46858618870645224,
      0.24381084617918836,
      0.49848318924893165,
      0.30380225612107153,
      0.3896471040156073,
      0.5770833541131662,
      0.34044858461279354,
      0.3551321169952611,
      0.2764768511012286,
      0.29100506746260346,
      0.32339230857923357,
      0.26598255932331083,
      0.5887157306030482,
      0.40538134373456775,
      0.2707343080488151,
      0.3174238662609083,
      0.3992414540449481,
      0.4082751154297305,
      0.4478185556605904,
      0.4491698573984786,
      0.33133314364550714,
      0.3817705194460239,
      0.5394693741162202,
      0.41610485782657197,
      0.330191289140525,
      0.8984798705038017,
      0.4058725265931048,
      0.31061765995255847,
      0.6053929768458098,
      0.48722114867926714,
      0.29567501725193984,
      0.2774189539833697,
      0.25736961961238686,
      0.2807338575670819,
      0.27237902229462196,
      0.38160474825494306,
      0.5833814188860312,
      0.2693781504820207,
      0.5463565601047106,
      0.28378794552858716,
      0.27275512756077114,
      0.268687716211209,
      0.5388635689916903,
      0.3243335248132844,
      0.2707475359612953,
      0.31376175444997,
      0.4088314204872725,
      0.24654243582647717,
      0.33337911717638286,
      0.3172659448208566,
      0.2559857348972809,
      0.2552171572842105
    ],
    "best_epoch": 105,
    "best_val_loss": 0.24381084617918836,
    "test_loss": 4.3461697321189074,
    "tracker": {
      "initial_train_loss": 0.41547428846205237,
      "train_threshold": 0.1384914294873508,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.24381084617918836,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_8_e019aa/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_8_e019aa/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_8_e019aa/config.yaml"
}