{
  "model_name": "mlp_with_history-trc-value/trial_35_41e410",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 29,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.2060150789900302,
    "mid_layer_count": 3,
    "mid_layer_size": 727
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 490,
    "learning_rate": 0.0018393467914106158,
    "weight_decay": 0.0010165607437068267,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7768,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 290,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      2.395010556147101,
      0.7323038843292532,
      0.31762277077879647,
      0.20246625983613772,
      0.1571874552157954,
      0.14386999801023798,
      0.14312947227645484,
      0.13292786691157507,
      0.12961643839103432,
      0.14940615050325862,
      0.16539278702021995,
      0.132074922749084,
      0.13018323769783324,
      0.12646958103017875,
      0.12127881232422731,
      0.11499811271368598,
      0.11910809745127766,
      0.11778268520360627,
      0.1204535567885539,
      0.11733552046603572,
      0.11757050552640405,
      0.1170899596959199,
      0.1118457812804395,
      0.11502426504958363,
      0.11186451948104939,
      0.11217227901776161,
      0.1299826805964189,
      0.10960443976817674,
      0.10883129581072426,
      0.10745015584246997,
      0.10988992991464944,
      0.10647893013925619,
      0.10850887585442846,
      0.11320994485142793,
      0.10536915643177121,
      0.11102963955046649,
      0.10638047628158398,
      0.10239244851712463,
      0.1020808708494343,
      0.11651067064171532,
      0.10560766774221073,
      0.11985277050931532,
      0.10430352779414148,
      0.1012956229787623,
      0.10468739725795145,
      0.10466398136262484,
      0.10284789033755891,
      0.09948234253751936,
      0.10179766438840039,
      0.1022265335078803,
      0.11024534255534749,
      0.10247010540267036,
      0.10172790236172605,
      0.10282293750101702,
      0.09544264073613129,
      0.10632413268534334,
      0.10205300054469757,
      0.10856015191065295,
      0.09979473801577189,
      0.09842141084257901,
      0.09806203236179974,
      0.09887841842631233,
      0.09421514587555499,
      0.09668628140578063,
      0.0976296959811271,
      0.09609297513156116,
      0.0978965677578006,
      0.09842342775925057,
      0.09623104622002487,
      0.09978014982500172,
      0.09700150741791749,
      0.09664763334129546,
      0.0958166826712054,
      0.0945737868236679,
      0.09319727609258234,
      0.10275397998550341,
      0.09513678317304497,
      0.09357435643158846,
      0.0953649903957403,
      0.09627428165916066
    ],
    "val_loss": [
      0.3608817930617732,
      0.3063651321533911,
      0.2166812460044187,
      0.19837694345209414,
      0.19321881578175606,
      0.17061706579953967,
      0.19907810893690514,
      0.18754357391756452,
      0.2448358430030817,
      0.23601598841344526,
      0.24543626436930216,
      0.29314559305499416,
      0.19370489149259593,
      0.19022147605072953,
      0.21294480297870622,
      0.21859761837222977,
      0.21580197053130515,
      0.20915631627563588,
      0.2592479502949529,
      0.47914073355272857,
      0.24047627455058568,
      0.25489741852674297,
      0.25197767628033363,
      0.3165501269573223,
      0.2739271587039718,
      0.2776342235884802,
      0.321076855509581,
      0.34492274759683067,
      0.2602030097389828,
      0.31777845802689025,
      0.26289630486088955,
      0.28059929427495617,
      0.2755104190932063,
      0.3177005734718488,
      0.29975072499699223,
      0.2712366518057035,
      0.2665622681379318,
      0.28262480000357426,
      0.2683687046794834,
      0.2866801737645964,
      0.27323107476050623,
      0.2242083663042791,
      0.2805473889464033,
      0.2768313906373021,
      0.3535280808538734,
      0.26866867529328714,
      0.2766005992443262,
      0.2755295959061491,
      0.274194170012624,
      0.2742050405881719,
      0.28009791558463415,
      0.2739965067562943,
      0.28192147795490163,
      0.28077978139999743,
      0.2833670729068582,
      0.2882893158200972,
      0.27514830228320497,
      0.2761242844075143,
      0.2903100142623493,
      0.2875517572047646,
      0.28071732018254475,
      0.2823447043265768,
      0.2776729599489066,
      0.28813316135438616,
      0.28182884430635474,
      0.2834446708822322,
      0.2751324105740129,
      0.30562426788944325,
      0.3113463115014002,
      0.28747751417675776,
      0.2839255741501818,
      0.28312285924832264,
      0.2909039469536193,
      0.27628971123231383,
      0.28123877464074215,
      0.32349292179959976,
      0.301339529432401,
      0.28148290825015054,
      0.29098623426642245,
      0.2751674384414079
    ],
    "best_epoch": 6,
    "best_val_loss": 0.17061706579953967,
    "test_loss": 4.0719526529882515,
    "tracker": {
      "initial_train_loss": 2.395010556147101,
      "train_threshold": 0.7983368520490336,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.17061706579953967,
      "patience_no_improve_epochs": 74,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_35_41e410/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_35_41e410/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_35_41e410/config.yaml"
}