{
  "model_name": "mlp-trc-rate/trial_30_ee46b4",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.27854256142259687,
    "mid_layer_count": 10,
    "mid_layer_size": 408
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 307,
    "learning_rate": 0.00045388925949101685,
    "weight_decay": 0.004613497467915216,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.5304832194858695,
      0.17317135043904805,
      0.12969946927878873,
      0.10812868268203742,
      0.09734821042046907,
      0.09024616226404829,
      0.08564746394569964,
      0.07978417341616015,
      0.076272799009376,
      0.0752664320476701,
      0.07449916794632355,
      0.07084574345059659,
      0.07019129998049196,
      0.06936888436353424,
      0.06672638561911097,
      0.06705180031002302,
      0.06738634872082534,
      0.06573331345105903,
      0.06405821004753437,
      0.06557840944959253,
      0.06268842906866504,
      0.06306852089750531,
      0.0627463858200953,
      0.06077574608057141,
      0.06106161163176571,
      0.06075779288881036,
      0.060494508488670475,
      0.05969199685598717,
      0.05789487500397394,
      0.05938810306534806,
      0.060025538209388045,
      0.05787710084786792,
      0.0593642433393286,
      0.05742191925612381,
      0.05744865732463416,
      0.05704314806754235,
      0.05745313949013304,
      0.05643937319494199,
      0.05630188938583883,
      0.055956142214822154,
      0.057496923073579585,
      0.057545473251975364,
      0.0546649506744695,
      0.05460778411225501,
      0.055040238560366134,
      0.05643217955424946,
      0.0558628898860362,
      0.05511993747883084,
      0.05578814797808706,
      0.05564632552368648,
      0.05364145281910514,
      0.055385496059271115,
      0.05590559091474412,
      0.05486532184355087,
      0.05375105493045911,
      0.05340246144030387,
      0.05368501315177206,
      0.05473967685362753,
      0.053824487590484735,
      0.054599154420892755,
      0.05360688197461381,
      0.052777213767446145,
      0.05372194806185516,
      0.055003624437630114,
      0.053212597639347235,
      0.055323688749638715,
      0.05479120046833101,
      0.054549252323848336,
      0.05412666978464563,
      0.05323810261669925,
      0.05519105468648727,
      0.05338021582389119,
      0.052715145645920225,
      0.05256202125901776,
      0.05443109999128401,
      0.05236114164276298,
      0.053888155101082184,
      0.05234934635729882,
      0.05264176293660917,
      0.05322960985842624
    ],
    "val_loss": [
      0.4341187487863852,
      0.3663631381255067,
      0.2171902810875884,
      0.20511727445942912,
      0.21089851133926898,
      0.20373396672040758,
      0.21468092811009484,
      0.20692116506286187,
      0.21704385760881587,
      0.22774794927413414,
      0.23803365526129744,
      0.24877345137811172,
      0.22568296958541798,
      0.25441361809272073,
      0.29601025683303434,
      0.23744187565509253,
      0.24574994731270625,
      0.25452099171450393,
      0.24789100097949635,
      0.2600664911211697,
      0.25181076102025673,
      0.2822396400501717,
      0.25723544411294297,
      0.2964160264296803,
      0.2662435073818186,
      0.28152543048257245,
      0.2703152497338053,
      0.283444743897922,
      0.341350716478498,
      0.3503623268104153,
      0.32780125708302515,
      0.2946307948985678,
      0.2889277494428847,
      0.31145582095703145,
      0.3332071495571447,
      0.34172201502488225,
      0.2973909256567141,
      0.3309391504744748,
      0.2988880417783728,
      0.3016762277724857,
      0.3511300529102365,
      0.313487674363939,
      0.3452437005357114,
      0.3371670634491358,
      0.36606026442643413,
      0.3259999850508339,
      0.3593937754207207,
      0.28586938321746574,
      0.28756114903413604,
      0.30829606129603826,
      0.36347756316985735,
      0.34629196298091175,
      0.29226539288340747,
      0.32815474381413823,
      0.30573456775463986,
      0.3137053564670468,
      0.3736036879306068,
      0.322365789844872,
      0.3373557821630004,
      0.3444004892589089,
      0.3140187378325862,
      0.3364805827017673,
      0.3368313381972606,
      0.3208348633409171,
      0.332324197743378,
      0.29673611263515887,
      0.28306717949244614,
      0.32283479540558635,
      0.3524055745709174,
      0.35523856067862697,
      0.3329654612004043,
      0.3296313828850042,
      0.32726614341965155,
      0.3301951402073313,
      0.3250220928898829,
      0.33451630750302963,
      0.33228802853849476,
      0.3280657680035976,
      0.3291505490981801,
      0.3279222964392808
    ],
    "best_epoch": 6,
    "best_val_loss": 0.20373396672040758,
    "best_val_abs_mse": 0.20206986367702484,
    "test_loss": 4.8411274878887465,
    "test_abs_mse": 46.77778244018555,
    "tracker": {
      "initial_train_loss": 0.5304832194858695,
      "train_threshold": 0.17682773982862318,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.20373396672040758,
      "patience_no_improve_epochs": 74,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_30_ee46b4/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_30_ee46b4/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_30_ee46b4/config.yaml"
}