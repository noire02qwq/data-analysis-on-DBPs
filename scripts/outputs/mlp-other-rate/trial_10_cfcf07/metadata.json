{
  "model_name": "mlp-other-rate/trial_10_cfcf07",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.48486607941577703,
    "mid_layer_count": 2,
    "mid_layer_size": 173
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 129,
    "learning_rate": 0.0013624229636743875,
    "weight_decay": 0.00022715306686392457,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103
    ],
    "train_loss": [
      0.4092736134029401,
      0.28978438392327405,
      0.26506244990039995,
      0.24985666433898776,
      0.24002262162452725,
      0.23217174921542208,
      0.22845296497113157,
      0.21696651792903934,
      0.21270977373900568,
      0.20770049143129585,
      0.1983176055471826,
      0.19713985420507366,
      0.19197275657197216,
      0.1870264626232828,
      0.1841007719411796,
      0.18232333174633822,
      0.18072425631788097,
      0.17496284606435042,
      0.17280216357948353,
      0.16975514137932984,
      0.17106388091444663,
      0.16615498552204952,
      0.16336923712274856,
      0.1654602189578418,
      0.16245330012512854,
      0.16025165630348712,
      0.1603365222316115,
      0.15796426235826705,
      0.15937770942676183,
      0.15551185656841623,
      0.15812345392134264,
      0.15712568161386964,
      0.15233446581966759,
      0.1524719576355645,
      0.1493090769947875,
      0.14969511269727934,
      0.1500453086461912,
      0.1491834158264196,
      0.1481084942821511,
      0.14470562781888194,
      0.1478002938700447,
      0.14405590171933846,
      0.14442996789685514,
      0.14512775321632027,
      0.14466349225493197,
      0.14173911011688461,
      0.14132617040895204,
      0.14134004255665944,
      0.1428279808692332,
      0.14110547835900883,
      0.14322595416413875,
      0.1400973959455602,
      0.13882234125561044,
      0.13729098600059703,
      0.13941838798433803,
      0.14085387300915936,
      0.13668642567997255,
      0.13812354206752173,
      0.13741475174833317,
      0.1360229474897107,
      0.13762147192116453,
      0.13745312288158854,
      0.13583535483042938,
      0.13603174722939348,
      0.13673834242844135,
      0.13571502928220197,
      0.13519685245331678,
      0.13660433937749109,
      0.13433980473005172,
      0.13483279283369212,
      0.13217719779156337,
      0.13256110222756923,
      0.1324109948536963,
      0.1314524021381947,
      0.13325279108365723,
      0.13209915326849933,
      0.13343730777704665,
      0.132295583027404,
      0.1325313360666834,
      0.13241706951581067,
      0.13211490770179746,
      0.13027555441026079,
      0.1280786103108805,
      0.1303611954147538,
      0.12751648679811445,
      0.13225941726313822,
      0.12792954459526468,
      0.12922416105025422,
      0.12963070499478027,
      0.12713019835216502,
      0.1300493875186816,
      0.1296934873561421,
      0.1311700993736947,
      0.12914673776474286,
      0.12849731011083948,
      0.13134490914275826,
      0.1272322448040275,
      0.12893386183257835,
      0.12704702029592443,
      0.1274007047441004,
      0.12887760675801352,
      0.1301613300933616,
      0.1297141014564383
    ],
    "val_loss": [
      0.38902441366703927,
      0.43017204668885933,
      0.461840632270107,
      0.4698464623914507,
      0.502526264782705,
      0.4744734742505822,
      0.4909088768198818,
      0.4745309797723493,
      0.47842649382031605,
      0.5136371258913935,
      0.5042076756118122,
      0.4528337806329399,
      0.4775638874196364,
      0.4877062693550558,
      0.47081228237219913,
      0.48515971842818634,
      0.46834959317734853,
      0.45178402678338353,
      0.5222758632978637,
      0.45312100440977576,
      0.44999052150520735,
      0.48701441178466387,
      0.46589516436313083,
      0.48181542169280395,
      0.4749468113847835,
      0.4320812166540209,
      0.49001902714817824,
      0.4723055386480814,
      0.45513911195500883,
      0.4747943330890761,
      0.4556293837369202,
      0.4560791867065751,
      0.48614157303097005,
      0.430312150395559,
      0.43941110027229,
      0.4567193100418516,
      0.39765217768217986,
      0.4420016206354795,
      0.38868691983694087,
      0.4328245590591502,
      0.4275959486621404,
      0.42857475216963337,
      0.4094439616906429,
      0.4191112025947628,
      0.41590353672777464,
      0.44126235165683453,
      0.43000507993612463,
      0.433624437518284,
      0.4299409211663429,
      0.4313586972609252,
      0.39308682748389817,
      0.3972683129642538,
      0.388439275212809,
      0.45108897519593466,
      0.4317509969975242,
      0.4596941282894618,
      0.46126798036658834,
      0.44182821061618316,
      0.443758762061239,
      0.46055108905284703,
      0.44132458564496324,
      0.413186861922641,
      0.42002522355157457,
      0.4155990379254618,
      0.43464659358302277,
      0.42306072703467873,
      0.4210684055116719,
      0.48699342356827446,
      0.430229623435054,
      0.41439611149539135,
      0.4144443703090359,
      0.4085114283832961,
      0.41338020143974685,
      0.4161899230035836,
      0.4464920353389786,
      0.4041877706629966,
      0.4148296078968191,
      0.4187126769098693,
      0.40607375518201355,
      0.4265826028219597,
      0.4332926411605524,
      0.4184463210136234,
      0.43501583651422027,
      0.411529907470424,
      0.41956247360317295,
      0.41897461263540975,
      0.4232809304477212,
      0.42198217444924896,
      0.4166886114074798,
      0.3890466407655242,
      0.40075978170522675,
      0.4567806712703077,
      0.40610839845891483,
      0.4114434801755908,
      0.42246459902983585,
      0.41486971474247064,
      0.4423249380094206,
      0.4137901215451563,
      0.45897124750082363,
      0.4186293547515741,
      0.49153713508548136,
      0.4404255570408827,
      0.4135681977573626
    ],
    "best_epoch": 90,
    "best_val_loss": 0.3890466407655242,
    "best_val_abs_mse": 0.49606427550315857,
    "test_loss": 0.5259997666274246,
    "test_abs_mse": 1.1944280862808228,
    "tracker": {
      "initial_train_loss": 0.4092736134029401,
      "train_threshold": 0.13642453780098004,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.388439275212809,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-rate/trial_10_cfcf07/best_model.pt",
    "last": "scripts/outputs/mlp-other-rate/trial_10_cfcf07/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-rate/trial_10_cfcf07/config.yaml"
}