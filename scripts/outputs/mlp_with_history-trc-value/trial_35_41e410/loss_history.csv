epoch,train_loss,val_loss
1,2.395011,0.360882
2,0.732304,0.306365
3,0.317623,0.216681
4,0.202466,0.198377
5,0.157187,0.193219
6,0.143870,0.170617
7,0.143129,0.199078
8,0.132928,0.187544
9,0.129616,0.244836
10,0.149406,0.236016
11,0.165393,0.245436
12,0.132075,0.293146
13,0.130183,0.193705
14,0.126470,0.190221
15,0.121279,0.212945
16,0.114998,0.218598
17,0.119108,0.215802
18,0.117783,0.209156
19,0.120454,0.259248
20,0.117336,0.479141
21,0.117571,0.240476
22,0.117090,0.254897
23,0.111846,0.251978
24,0.115024,0.316550
25,0.111865,0.273927
26,0.112172,0.277634
27,0.129983,0.321077
28,0.109604,0.344923
29,0.108831,0.260203
30,0.107450,0.317778
31,0.109890,0.262896
32,0.106479,0.280599
33,0.108509,0.275510
34,0.113210,0.317701
35,0.105369,0.299751
36,0.111030,0.271237
37,0.106380,0.266562
38,0.102392,0.282625
39,0.102081,0.268369
40,0.116511,0.286680
41,0.105608,0.273231
42,0.119853,0.224208
43,0.104304,0.280547
44,0.101296,0.276831
45,0.104687,0.353528
46,0.104664,0.268669
47,0.102848,0.276601
48,0.099482,0.275530
49,0.101798,0.274194
50,0.102227,0.274205
51,0.110245,0.280098
52,0.102470,0.273997
53,0.101728,0.281921
54,0.102823,0.280780
55,0.095443,0.283367
56,0.106324,0.288289
57,0.102053,0.275148
58,0.108560,0.276124
59,0.099795,0.290310
60,0.098421,0.287552
61,0.098062,0.280717
62,0.098878,0.282345
63,0.094215,0.277673
64,0.096686,0.288133
65,0.097630,0.281829
66,0.096093,0.283445
67,0.097897,0.275132
68,0.098423,0.305624
69,0.096231,0.311346
70,0.099780,0.287478
71,0.097002,0.283926
72,0.096648,0.283123
73,0.095817,0.290904
74,0.094574,0.276290
75,0.093197,0.281239
76,0.102754,0.323493
77,0.095137,0.301340
78,0.093574,0.281483
79,0.095365,0.290986
80,0.096274,0.275167
