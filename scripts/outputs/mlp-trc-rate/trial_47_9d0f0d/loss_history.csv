epoch,train_loss,val_loss
1,0.317451,0.350494
2,0.108122,0.188126
3,0.077052,0.199777
4,0.071063,0.265261
5,0.065191,0.254300
6,0.059267,0.246864
7,0.056459,0.280652
8,0.055813,0.244173
9,0.053429,0.273505
10,0.054187,0.300091
11,0.052507,0.287457
12,0.048665,0.301340
13,0.047742,0.265166
14,0.046438,0.319187
15,0.049170,0.274718
16,0.047111,0.306378
17,0.047584,0.357575
18,0.044669,0.316821
19,0.044361,0.297198
20,0.043629,0.324136
21,0.041697,0.329508
22,0.043608,0.295231
23,0.042725,0.296097
24,0.041659,0.340574
25,0.039672,0.343128
26,0.041790,0.357711
27,0.039881,0.356074
28,0.039483,0.328858
29,0.039529,0.365437
30,0.039849,0.334179
31,0.039625,0.313324
32,0.038934,0.325763
33,0.040943,0.314486
34,0.039064,0.323745
35,0.036624,0.356128
36,0.037513,0.339460
37,0.037038,0.358796
38,0.035906,0.344928
39,0.037891,0.310566
40,0.037857,0.308289
41,0.037036,0.319086
42,0.036804,0.336830
43,0.037473,0.341017
44,0.035985,0.347443
45,0.034834,0.341133
46,0.034596,0.383775
47,0.034904,0.331280
48,0.035278,0.310982
49,0.035392,0.314761
50,0.033891,0.313583
51,0.034143,0.358159
52,0.033940,0.332444
53,0.035321,0.310834
54,0.034435,0.392899
55,0.034513,0.382050
56,0.035666,0.358363
57,0.033752,0.401262
58,0.034228,0.363722
59,0.033333,0.319239
60,0.033010,0.322591
61,0.033351,0.336409
62,0.033926,0.327334
63,0.033805,0.347825
64,0.033898,0.323613
65,0.032733,0.317101
66,0.032383,0.340714
67,0.033288,0.324040
68,0.032973,0.347574
69,0.032199,0.382092
70,0.032283,0.323474
71,0.035599,0.336341
72,0.034558,0.322919
73,0.032868,0.330303
74,0.031559,0.308038
75,0.032949,0.307814
76,0.034478,0.297193
77,0.032136,0.305866
78,0.031558,0.315168
79,0.032947,0.320162
80,0.031954,0.313670
