epoch,train_loss,val_loss
1,0.999372,0.359930
2,0.998913,0.350806
3,0.998759,0.351004
4,0.998845,0.349943
5,0.998708,0.352340
6,0.998782,0.354156
7,0.998736,0.353967
8,0.998790,0.353953
9,0.998710,0.354055
10,0.998677,0.353406
11,0.998674,0.353469
12,0.998715,0.354026
13,0.998666,0.352822
14,0.998657,0.353527
15,0.998680,0.353642
16,0.998675,0.352751
17,0.998637,0.353535
18,0.998675,0.353766
19,0.998637,0.353392
20,0.998654,0.353965
21,0.998672,0.353150
22,0.998645,0.352526
23,0.998652,0.352550
24,0.998656,0.354074
25,0.998647,0.353673
26,0.998642,0.353112
27,0.998642,0.353104
28,0.998640,0.353400
29,0.998643,0.353631
30,0.998667,0.354160
31,0.998644,0.352787
32,0.998648,0.353080
33,0.998646,0.352727
34,0.998625,0.353137
35,0.998645,0.353120
36,0.998649,0.353653
37,0.998646,0.352902
38,0.998633,0.353485
39,0.998640,0.353915
40,0.998642,0.354061
41,0.998642,0.353724
42,0.998671,0.353525
43,0.998648,0.353856
44,0.998648,0.354219
45,0.998638,0.353879
46,0.998643,0.354002
47,0.998637,0.352957
48,0.998652,0.353829
49,0.998662,0.353056
50,0.998632,0.353270
