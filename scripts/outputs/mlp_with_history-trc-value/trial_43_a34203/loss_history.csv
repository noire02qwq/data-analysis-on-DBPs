epoch,train_loss,val_loss
1,1.052317,0.344462
2,0.973331,0.610563
3,0.516969,0.310850
4,0.228332,0.235001
5,0.137883,0.219003
6,0.125523,0.264061
7,0.128772,0.738695
8,0.120074,0.288411
9,0.111804,0.591382
10,0.114616,0.301095
11,0.113791,0.698726
12,0.159551,0.270930
13,0.112640,0.292868
14,0.108962,0.600262
15,0.111296,0.326729
16,0.109010,0.577488
17,0.108251,0.331397
18,0.107521,0.304186
19,0.106621,0.344160
20,0.107427,0.313615
21,0.101382,0.530654
22,0.103567,0.271485
23,0.105079,0.262796
24,0.111301,0.335214
25,0.125037,0.259291
26,0.115201,0.284928
27,0.109146,0.277968
28,0.103243,0.360068
29,0.103272,0.321328
30,0.103951,0.288016
31,0.101738,0.325593
32,0.102040,0.351019
33,0.099822,0.277256
34,0.100787,0.271182
35,0.133736,0.294865
36,0.144119,0.258728
37,0.104486,0.262735
38,0.102098,0.298136
39,0.105824,0.288731
40,0.105280,0.297672
41,0.104737,0.333435
42,0.104361,0.304792
43,0.106147,0.264560
44,0.106045,0.333424
45,0.106292,0.296105
46,0.102356,0.276532
47,0.100932,0.269673
48,0.097531,0.295544
49,0.109654,0.289258
50,0.110405,0.283613
51,0.100731,0.270553
52,0.097903,0.291214
53,0.095796,0.300433
54,0.096095,0.310064
55,0.104591,0.364579
56,0.103996,0.278426
57,0.098677,0.320525
58,0.096785,0.273898
59,0.098140,0.272597
60,0.096489,0.287907
61,0.097249,0.306869
62,0.098917,0.277617
63,0.099024,0.289375
64,0.103883,0.336413
65,0.279436,0.299974
66,0.136464,0.301707
67,0.110311,0.279638
68,0.104135,0.298301
69,0.112402,0.334628
70,0.102224,0.305763
71,0.101481,0.349641
72,0.099318,0.434220
73,0.099231,0.459374
74,0.096835,0.354234
75,0.095013,0.349544
76,0.098536,0.606956
77,0.099288,0.285203
78,0.098064,0.291085
79,0.103752,0.518881
80,0.311799,0.742876
