epoch,train_loss,val_loss
1,0.529307,0.454687
2,0.321688,0.368744
3,0.275372,0.380424
4,0.258287,0.388749
5,0.246316,0.363980
6,0.234139,0.379168
7,0.225777,0.358554
8,0.214585,0.379556
9,0.195582,0.487620
10,0.183602,0.563732
11,0.178986,0.603424
12,0.176388,0.616756
13,0.172373,0.592457
14,0.174275,0.543908
15,0.193460,0.612013
16,0.171511,0.621946
17,0.161920,0.626108
18,0.165581,0.572273
19,0.162878,0.649592
20,0.152872,0.564897
21,0.158211,0.597208
22,0.143686,0.606844
23,0.144304,0.596348
24,0.145091,0.610364
25,0.147046,0.654511
26,0.170918,0.638301
27,0.210408,0.572963
28,0.175598,0.594802
29,0.161214,0.626793
30,0.159047,0.627963
31,0.153846,0.630285
32,0.150915,0.662298
33,0.150486,0.633646
34,0.146562,0.633691
35,0.145487,0.615771
36,0.145296,0.620931
37,0.148835,0.641153
38,0.143687,0.683360
39,0.146428,0.667785
40,0.139518,0.723931
41,0.140684,0.678467
42,0.137339,0.690153
43,0.136623,0.668607
44,0.135716,0.659802
45,0.129410,0.643724
46,0.132643,0.660505
47,0.130112,0.651671
48,0.133427,0.694299
49,0.134291,0.692352
50,0.132327,0.703596
51,0.130299,0.655370
52,0.126691,0.687186
53,0.122772,0.676505
54,0.124958,0.677829
55,0.121426,0.668963
56,0.121703,0.666320
57,0.120900,0.666478
58,0.120981,0.658143
59,0.120944,0.676487
60,0.124706,0.676737
61,0.116277,0.688017
62,0.114988,0.679263
63,0.119224,0.673501
64,0.117376,0.728492
65,0.116390,0.724440
66,0.113950,0.728849
67,0.119323,0.703070
68,0.112295,0.691828
69,0.111428,0.668886
70,0.115675,0.724686
71,0.114107,0.691480
72,0.108021,0.682812
73,0.111749,0.717690
74,0.109325,0.721881
75,0.107853,0.772760
76,0.103435,0.746048
77,0.133666,0.777513
78,0.129357,0.819932
79,0.109363,0.811943
80,0.100096,0.775251
