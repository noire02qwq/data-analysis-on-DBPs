epoch,train_loss,val_loss
1,0.959924,0.279397
2,0.688186,0.322571
3,0.307711,0.170734
4,0.150002,0.215331
5,0.133306,0.200137
6,0.128229,0.474367
7,0.126470,0.219664
8,0.137860,0.227849
9,0.124303,0.229688
10,0.118063,0.239908
11,0.123299,0.271193
12,0.118199,0.242045
13,0.116029,0.295935
14,0.115672,0.343653
15,0.116794,0.401673
16,0.113036,0.693627
17,0.110120,0.278929
18,0.108494,0.515060
19,0.109909,0.295525
20,0.123002,0.262809
21,0.111489,0.282855
22,0.112749,0.267940
23,0.106701,0.299021
24,0.104258,0.496838
25,0.105729,0.279742
26,0.102224,0.292247
27,0.104096,0.283147
28,0.100924,0.362585
29,0.107165,0.270188
30,0.107226,0.272207
31,0.109499,0.290660
32,0.105213,0.275505
33,0.102537,0.305274
34,0.097531,0.274310
35,0.101129,0.371949
36,0.103070,0.277229
37,0.106017,0.257699
38,0.108148,0.399359
39,0.129737,0.331339
40,0.115405,0.279146
41,0.101090,0.309984
42,0.096742,0.324850
43,0.098288,0.283531
44,0.096684,0.280453
45,0.101277,0.264640
46,0.098065,0.348280
47,0.112008,0.474843
48,0.148622,0.262646
49,0.114118,0.242217
50,0.098722,0.274674
51,0.097948,0.345190
52,0.094838,0.297576
53,0.096753,0.312384
54,0.093938,0.361193
55,0.095546,0.255186
56,0.092911,0.294702
57,0.092448,0.295222
58,0.095249,0.271804
59,0.097902,0.362940
60,0.093679,0.284060
61,0.096586,0.270398
62,0.104775,0.264217
63,0.094488,0.299102
64,0.094624,0.374371
65,0.093559,0.285807
66,0.090535,0.311367
67,0.088359,0.372766
68,0.094306,0.319178
69,0.094245,0.265884
70,0.616267,4.567771
71,0.974784,0.387704
72,1.600129,0.386653
73,1.025238,0.384531
74,1.003727,0.377278
75,1.001176,0.372268
76,1.000367,0.368378
77,0.995480,0.366043
78,0.918078,0.632428
79,0.766239,0.244957
80,0.623544,0.329928
