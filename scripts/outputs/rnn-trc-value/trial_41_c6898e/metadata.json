{
  "model_name": "rnn-trc-value/trial_41_c6898e",
  "model_type": "RNN",
  "model_format": "torch",
  "model_params": {
    "history_length": 134,
    "units": 155,
    "num_layers": 5,
    "dropout": 0.20635798160832391
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 161,
    "learning_rate": 0.00036155271302807057,
    "weight_decay": 0.0006449857738307123,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7663,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 134,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122
    ],
    "train_loss": [
      0.304608085347454,
      0.11896441671834451,
      0.07287106088030965,
      0.05924667611243705,
      0.050625923676818556,
      0.045088763502743046,
      0.04059167125393699,
      0.03965644578217418,
      0.035949906151735427,
      0.03660213977655581,
      0.03499272951894417,
      0.03311152317618695,
      0.02974801799704158,
      0.03030713667219735,
      0.030188003477643974,
      0.028040428950597034,
      0.026682955409413168,
      0.028810042142430516,
      0.024562606812116528,
      0.025480379048468983,
      0.024272088293225823,
      0.026054650216489644,
      0.022659039106373142,
      0.02275664322554645,
      0.023644615137060194,
      0.02286957829226157,
      0.02327390634273092,
      0.02531770377686172,
      0.024675858254081025,
      0.02426689934035544,
      0.0248462213377106,
      0.02374139583363213,
      0.0214349673196827,
      0.021890474039038883,
      0.021668228724395094,
      0.023614265046538314,
      0.023534035503632887,
      0.02386389351782305,
      0.024671012809144972,
      0.02292516114732024,
      0.021641638396354253,
      0.021615957803358208,
      0.021232683250091606,
      0.021359195701586398,
      0.020727894921937422,
      0.023826962040595562,
      0.021233485942106327,
      0.021243569040195788,
      0.02235249589492303,
      0.02068795510070039,
      0.020875481140239422,
      0.021557635804034237,
      0.01985306385770862,
      0.023387787233817892,
      0.021459886776513084,
      0.021468735518402848,
      0.021270756428772283,
      0.020504791459716922,
      0.021700728370860446,
      0.02083421401843831,
      0.020793801426603607,
      0.02125442296832423,
      0.02018058681638157,
      0.020765352865862625,
      0.02299170675001427,
      0.020738003856176638,
      0.020884300023900706,
      0.02060194652778905,
      0.02118830062919562,
      0.02181387933207627,
      0.02115453217598122,
      0.02171397975202478,
      0.022059169849136567,
      0.020958333449885708,
      0.019160436476423653,
      0.02067222844983818,
      0.020661558276284197,
      0.16549046737965065,
      0.09629328671221041,
      0.06247761997215729,
      0.05572656639144904,
      0.04978498489804139,
      0.04556841805575334,
      0.037530874127832514,
      0.03466201934058758,
      0.031705580474319026,
      0.030666313181167856,
      0.031225458137291415,
      0.029763295697190502,
      0.02845696782061042,
      0.02840338057240307,
      0.029956000547262517,
      0.027838267873557976,
      0.026871311274502617,
      0.026760815466912984,
      0.026281147961190347,
      0.025343167891259934,
      0.025662062088793024,
      0.02912783589270965,
      0.02675454795596829,
      0.024018874238050124,
      0.025788575360770484,
      0.025730584902317208,
      0.02517881768625694,
      0.023930920171779283,
      0.02413048334327361,
      0.02271549038090221,
      0.023160919303767957,
      0.024046504751682032,
      0.02388919263025161,
      0.022429391860370768,
      0.025761962506949752,
      0.022422969482015588,
      0.02217129077317547,
      0.022136571228749194,
      0.020954303657819563,
      0.021328308371992052,
      0.02352811473175158,
      0.02173643795846065,
      0.02301762130951992,
      0.023458614803458823,
      0.021003809239913195
    ],
    "val_loss": [
      0.525347683576499,
      0.3122447375319675,
      0.27369988470667317,
      0.26936865438801977,
      0.2680286976235534,
      0.2653381974754219,
      0.27061340917169513,
      0.27926723212003707,
      0.27477453066158797,
      0.27695852111980407,
      0.2795866728152433,
      0.29452342316396757,
      0.29738638179744786,
      0.31020345143683836,
      0.28976176879675447,
      0.2938682571890022,
      0.278621049659204,
      0.28899938083382065,
      0.2907661416082682,
      0.28310294702069133,
      0.2837019990940026,
      0.2824177021183029,
      0.28572040857959113,
      0.2718045631367825,
      0.2767273526393368,
      0.2856550180961093,
      0.28523258841010984,
      0.2784787907136861,
      0.2691943231958918,
      0.274573508467146,
      0.27177016755041783,
      0.280292403364476,
      0.2740693662415989,
      0.2748907618481153,
      0.2790744006287998,
      0.2924176858983443,
      0.2733930322994104,
      0.27415565225981664,
      0.2730472674794094,
      0.284011735860816,
      0.28083929956003933,
      0.2743976960917879,
      0.28605374466003236,
      0.2786303923359353,
      0.28847543699276484,
      0.285734727123228,
      0.2794832217512641,
      0.274492480444114,
      0.28542741856978326,
      0.28120612757180086,
      0.27127946185472307,
      0.2705775845728948,
      0.27635040219070134,
      0.2917047694581979,
      0.2762800521657852,
      0.27406802754514586,
      0.28736958022000725,
      0.27449159434254833,
      0.2910428723275751,
      0.2836971143628666,
      0.28252321341058273,
      0.27133954289609086,
      0.27321432440089966,
      0.27542101717860756,
      0.2802729809589818,
      0.2699659136017996,
      0.2868777075258201,
      0.2796324764785474,
      0.2733349273014747,
      0.276002340152592,
      0.2756318757857034,
      0.25538490114477047,
      0.2695839656449988,
      0.2916855547521375,
      0.27919744858350937,
      0.27725051912718907,
      0.2852724720272208,
      0.3242881655603826,
      0.30779905048182266,
      0.30839731272109255,
      0.31234018926670454,
      0.3073003496305493,
      0.325547109600045,
      0.3282492392311642,
      0.322991098578417,
      0.3285670338934678,
      0.32281904626793845,
      0.32220551433365147,
      0.33877087837297043,
      0.31784431455868806,
      0.35526167344257326,
      0.3296365337011343,
      0.3408149968966574,
      0.3244983195221263,
      0.31907734134775434,
      0.3316094701607784,
      0.32790273627165906,
      0.3317202829214895,
      0.3192326926854913,
      0.33617667726012407,
      0.3504919317166159,
      0.34493833560898096,
      0.33756700298096426,
      0.34918635544328097,
      0.34597767124253653,
      0.32985183235458626,
      0.331610714532658,
      0.34042111130509367,
      0.3392498955164038,
      0.35897914614238424,
      0.35457321075599885,
      0.34599610945421777,
      0.3429038684056726,
      0.3490082571762586,
      0.3295766557505477,
      0.3364009310641956,
      0.3393199186392887,
      0.3348670725258971,
      0.318275223625545,
      0.3300015018048311,
      0.3282072256391723,
      0.33094271135343584
    ],
    "best_epoch": 72,
    "best_val_loss": 0.25538490114477047,
    "test_loss": 4.57749547599035,
    "tracker": {
      "initial_train_loss": 0.304608085347454,
      "train_threshold": 0.10153602844915133,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.25538490114477047,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/rnn-trc-value/trial_41_c6898e/best_model.pt",
    "last": "scripts/outputs/rnn-trc-value/trial_41_c6898e/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/rnn-trc-value/trial_41_c6898e/config.yaml"
}