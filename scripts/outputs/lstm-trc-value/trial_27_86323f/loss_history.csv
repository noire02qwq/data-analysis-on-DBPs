epoch,train_loss,val_loss
1,1.002413,0.350786
2,1.002263,0.347231
3,1.001987,0.351411
4,1.001859,0.348805
5,1.001716,0.349538
6,1.001681,0.344010
7,1.001607,0.347142
8,1.001563,0.345223
9,1.001576,0.348163
10,1.001490,0.346059
11,1.001574,0.349357
12,1.001493,0.347324
13,1.001618,0.347774
14,1.001436,0.347566
15,1.001457,0.348994
16,1.001495,0.348693
17,1.001562,0.348363
18,1.001428,0.348722
19,1.001445,0.348490
20,1.001444,0.348047
21,1.001474,0.350772
22,1.001448,0.348815
23,1.001482,0.349108
24,1.001517,0.349807
25,1.001422,0.346284
26,1.001443,0.346318
27,1.001471,0.349000
28,1.001450,0.347038
29,1.001479,0.347748
30,1.001607,0.351018
31,1.001484,0.348178
32,1.001426,0.351120
33,1.001392,0.348176
34,1.001465,0.349437
35,1.001431,0.347783
36,1.001429,0.348222
37,1.001427,0.347783
38,1.001419,0.348820
39,1.001409,0.348509
40,1.001402,0.350547
41,1.001501,0.348058
42,1.001412,0.349858
43,1.001455,0.349857
44,1.001487,0.349456
45,1.001425,0.349497
46,1.001469,0.348397
47,1.001462,0.348070
48,1.001441,0.348271
49,1.001423,0.350057
50,1.001443,0.349974
