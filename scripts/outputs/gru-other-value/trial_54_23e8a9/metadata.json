{
  "model_name": "gru-other-value/trial_54_23e8a9",
  "model_type": "GRU",
  "model_format": "torch",
  "model_params": {
    "history_length": 44,
    "units": 179,
    "num_layers": 2,
    "dropout": 0.4625426231804253
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 177,
    "learning_rate": 0.0006379311085992494,
    "weight_decay": 0.001094026663809239,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7753,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 44,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118
    ],
    "train_loss": [
      0.40379741396017416,
      0.2491195933131976,
      0.22777355953476344,
      0.21586815931367118,
      0.20019400192048187,
      0.1875625112668539,
      0.1672301803898476,
      0.15644985750676985,
      0.13992269893400164,
      0.1314379168818739,
      0.12550899599938642,
      0.12306359841387518,
      0.12025136464848052,
      0.11524029821253555,
      0.118212837052702,
      0.10779472414726567,
      0.10521269088312378,
      0.10014930150958011,
      0.0962837545147607,
      0.09513692267495678,
      0.08916561848003603,
      0.08759067444459678,
      0.08012952128160727,
      0.07703412186095411,
      0.08061936984239171,
      0.07715067144122476,
      0.06998229140576033,
      0.06973237964636615,
      0.07128475975366803,
      0.07126394496200224,
      0.06505593567400475,
      0.06663227525229656,
      0.06782293937668853,
      0.06060785566937473,
      0.06417592351336748,
      0.061459888936561353,
      0.05727524232702164,
      0.06285961159798893,
      0.05824309543705396,
      0.05614357272528932,
      0.057429716033784405,
      0.0555939946996809,
      0.054831938352736136,
      0.05300508790735843,
      0.05989372866620068,
      0.053987961556528456,
      0.055393296172949295,
      0.0525426023274441,
      0.05077943918602122,
      0.054888684501494034,
      0.05096535919928234,
      0.05144472279430097,
      0.05516867791470075,
      0.051304301552836794,
      0.056440754420839095,
      0.051822655686625016,
      0.0481821093037984,
      0.054026224671944824,
      0.04617741004095744,
      0.04803326265499867,
      0.0494088661821753,
      0.04782912027444914,
      0.051344433561299946,
      0.045683301823336464,
      0.04617858974568908,
      0.045752072254431016,
      0.04738650590711819,
      0.05080159724010478,
      0.0461970143746664,
      0.04644541281812286,
      0.045870939087313434,
      0.044247004748982154,
      0.05006846581142087,
      0.04423147917618355,
      0.045021678902104054,
      0.044797587023098266,
      0.04776199858197932,
      0.051326173268413294,
      0.045238693913005945,
      0.043465533528626386,
      0.042910713716374664,
      0.0496327304883717,
      0.04450398963148957,
      0.043801787661192235,
      0.04601436246493532,
      0.04601886277898472,
      0.04255741233491181,
      0.04050464598577545,
      0.04127991326921112,
      0.04133033631308208,
      0.042073456837902465,
      0.041377683488588925,
      0.044090067393338775,
      0.04780334989818607,
      0.04367766351249623,
      0.04350726734128488,
      0.04081290006429999,
      0.04227693116574169,
      0.058668556971641014,
      0.04365545100373067,
      0.041151623579032126,
      0.045717809734656764,
      0.042412544608954134,
      0.04063953684039167,
      0.03977133672721429,
      0.041475958192419976,
      0.041822845032891506,
      0.04433224156189469,
      0.04536277927072928,
      0.041068074929011524,
      0.04049719197779613,
      0.0414623940808226,
      0.03966982086658416,
      0.039225996529961435,
      0.040716722122311026,
      0.04001303245759727,
      0.042227627838521284,
      0.040798625635990064
    ],
    "val_loss": [
      0.355768428747347,
      0.40611043247634065,
      0.5028877545170441,
      0.5349707417591604,
      0.5708176224040771,
      0.6648824325489426,
      0.7421783778794154,
      0.7525129901925603,
      0.8958163200827416,
      0.8565459167796695,
      0.7433287797663026,
      0.8726551912144986,
      0.7633562737685478,
      0.6794105185050807,
      0.6340838916622058,
      0.6783725182096402,
      0.5551895602734503,
      0.5095494318017346,
      0.6804205651233296,
      0.6379866649023073,
      0.6630434380141561,
      0.587934836575728,
      0.5582003762666694,
      0.60629870140267,
      0.5575719759760502,
      0.5991351656214206,
      0.6294988317047051,
      0.6391899940228748,
      0.6335049585132542,
      0.5234272867396563,
      0.6578353093145136,
      0.642188645827913,
      0.6507963610534182,
      0.555845491454273,
      0.4838798833598277,
      0.5260332212744359,
      0.4606103040322572,
      0.511113100815676,
      0.5805989490163898,
      0.5251568538253892,
      0.45038741536126164,
      0.4795380097797174,
      0.5023945420712768,
      0.507831852071121,
      0.43174427315860453,
      0.45664547504243735,
      0.45660892006255194,
      0.48207563418828087,
      0.4804569374435319,
      0.4870988105763932,
      0.4967932296548775,
      0.5241498805805594,
      0.49751177430152893,
      0.4474404369107264,
      0.4432954980986204,
      0.46862370341480847,
      0.4426060013473034,
      0.4594361917522853,
      0.45838290029567874,
      0.4443316545047446,
      0.48992341007301193,
      0.4631683838492382,
      0.42412600046146415,
      0.4761888958915265,
      0.46241036328280755,
      0.424391275095547,
      0.43061488836468337,
      0.39629569839753076,
      0.4369890885661819,
      0.43109390459910124,
      0.4710838889290473,
      0.4386535411466381,
      0.4302530342144167,
      0.4602874568390275,
      0.4511372678026468,
      0.46547801490136964,
      0.46998571915005494,
      0.44913461731222576,
      0.447795999433823,
      0.4520261670033375,
      0.49238646125008245,
      0.41309131949604627,
      0.46553224144938465,
      0.44686950143582804,
      0.48210463787981134,
      0.44792411641446417,
      0.4688329815329192,
      0.45828111875735356,
      0.4726280721361766,
      0.4302735838258338,
      0.4345265878888661,
      0.4556583370634182,
      0.43282888052527774,
      0.44073234285244683,
      0.41520738499964066,
      0.4641659950424811,
      0.42027378777365487,
      0.4591121222623094,
      0.40651272183763765,
      0.4174867035118406,
      0.43811936548013175,
      0.4308039106205552,
      0.4300620948661587,
      0.42092033059386436,
      0.4448513557186384,
      0.4171520353568171,
      0.4400309847411281,
      0.4103337420853312,
      0.43999022866437537,
      0.417030515535149,
      0.4497089574704627,
      0.4523676257468983,
      0.4346289266190843,
      0.4457775866110882,
      0.46300785348800844,
      0.45980062959436885,
      0.4598186782020295,
      0.448274257921887
    ],
    "best_epoch": 68,
    "best_val_loss": 0.39629569839753076,
    "test_loss": 0.34457637026959487,
    "tracker": {
      "initial_train_loss": 0.40379741396017416,
      "train_threshold": 0.1345991379867247,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.39629569839753076,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/gru-other-value/trial_54_23e8a9/best_model.pt",
    "last": "scripts/outputs/gru-other-value/trial_54_23e8a9/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/gru-other-value/trial_54_23e8a9/config.yaml"
}