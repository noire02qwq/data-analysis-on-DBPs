epoch,train_loss,val_loss
1,1.000303,0.348996
2,1.000161,0.350336
3,1.000542,0.352714
4,0.999718,0.346151
5,1.000108,0.350241
6,1.000205,0.355897
7,1.000135,0.351155
8,1.000073,0.344887
9,1.000140,0.348861
10,0.999900,0.347150
11,1.000083,0.346467
12,1.000061,0.349339
13,0.999940,0.351688
14,0.999850,0.352185
15,1.000004,0.350709
16,0.999854,0.352181
17,0.999841,0.353442
18,1.000112,0.352841
19,0.999989,0.353686
20,0.999925,0.351868
21,0.999971,0.348214
22,1.000021,0.347607
23,0.999999,0.350135
24,0.999928,0.349481
25,0.999931,0.349026
26,0.999943,0.351150
27,0.999923,0.349748
28,0.999956,0.348385
29,1.000021,0.351913
30,0.999920,0.350073
31,0.999879,0.350052
32,0.999929,0.349759
33,0.999908,0.350922
34,0.999936,0.349117
35,0.999902,0.348840
36,0.999874,0.350768
37,0.999871,0.350053
38,0.999947,0.351470
39,0.999858,0.351011
40,0.999895,0.350927
41,0.999867,0.348357
42,0.999957,0.346658
43,0.999926,0.347364
44,0.999907,0.347571
45,0.999925,0.346926
46,0.999993,0.345941
47,0.999938,0.346905
48,0.999907,0.348299
49,0.999904,0.348193
50,0.999940,0.349208
