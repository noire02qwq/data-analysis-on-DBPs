{
  "model_name": "gru-other-value/trial_28_ae57f1",
  "model_type": "GRU",
  "model_format": "torch",
  "model_params": {
    "history_length": 110,
    "units": 295,
    "num_layers": 2,
    "dropout": 0.3356941944189782
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 225,
    "learning_rate": 0.001609779271070837,
    "weight_decay": 0.0001534793648006899,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7687,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 110,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144
    ],
    "train_loss": [
      0.3249104383170287,
      0.2197090757440587,
      0.1993639483433389,
      0.17747688583454913,
      0.14670194105463374,
      0.1298262051219312,
      0.12226881280578251,
      0.09692276739184004,
      0.08763800559877279,
      0.0785759573934896,
      0.06460715061085376,
      0.06520185431026197,
      0.05702477278624273,
      0.05754680624656952,
      0.04936742895025107,
      0.041011279059472966,
      0.036509784686783675,
      0.03939726372498157,
      0.03405324783948187,
      0.03352908566943052,
      0.03381701328826692,
      0.029691543276949357,
      0.030877832884020563,
      0.03192550373056845,
      0.03338925538629902,
      0.030162313608233387,
      0.02778490121593025,
      0.0406418741687103,
      0.05417397248090919,
      0.0440177434903446,
      0.03015002540549082,
      0.02631676214159163,
      0.026253955201268258,
      0.02663155107249965,
      0.025713169505048886,
      0.02534837689683475,
      0.02545300194237847,
      0.02575155914399719,
      0.0261527028192124,
      0.029340620646361056,
      0.027336044620353734,
      0.02530765862384535,
      0.024979800565978306,
      0.045810386550621106,
      0.048378490371220335,
      0.0334902056847245,
      0.026379522279290673,
      0.023698580553443795,
      0.02396212042800872,
      0.024073340825245117,
      0.023389912739975705,
      0.0232150088971464,
      0.023510955315782574,
      0.02484193113303563,
      0.02372594626386097,
      0.024043511030113603,
      0.02420273478441808,
      0.023179538039866405,
      0.024166014601823115,
      0.024337079277603993,
      0.02496380174123754,
      0.022427554351958666,
      0.023999745653331846,
      0.02427744725046681,
      0.023559441843293137,
      0.023267575181391626,
      0.024389274008606025,
      0.04448004781543681,
      0.058135894877990944,
      0.037058948619523566,
      0.02492977948128766,
      0.02269439089278088,
      0.023776566725322634,
      0.022521048335980513,
      0.021693218010922968,
      0.021473138529772923,
      0.02152548688138564,
      0.02133730499923648,
      0.02133158325283452,
      0.022934122354904884,
      0.03185933850016491,
      0.05423424000128148,
      0.04943761058104229,
      0.033679445373642904,
      0.02647033351176316,
      0.023232750276219197,
      0.022050179163105733,
      0.022457424080195843,
      0.022594750176616527,
      0.021565917329054607,
      0.021077602871050215,
      0.022577860529899317,
      0.035295673468539956,
      0.03490943616832576,
      0.023816574314015265,
      0.021140496539591935,
      0.020908457255038187,
      0.021199226942767754,
      0.021299992847562038,
      0.021704234260616476,
      0.021231491716935526,
      0.021232460784062275,
      0.021551740933580393,
      0.02239103131849162,
      0.02125412449012912,
      0.022466953345155846,
      0.02497650715032394,
      0.022237261605810184,
      0.022022342585105728,
      0.02170946834461345,
      0.02168051427426753,
      0.021726506857313647,
      0.022818595047153778,
      0.027966491201015572,
      0.07586622787284512,
      0.05810666089378083,
      0.029172638226923217,
      0.023244134357984888,
      0.02187719583294242,
      0.021146353109081483,
      0.020454152835540536,
      0.021135188473180893,
      0.02111052161854871,
      0.020952504246223184,
      0.020255401629978322,
      0.020536841569497213,
      0.02087293255599745,
      0.02135030587758814,
      0.020817427934369494,
      0.020804572146794445,
      0.022055705605093907,
      0.020854943533321034,
      0.02089040819470712,
      0.021552118929874776,
      0.020821121029281502,
      0.022280390440634543,
      0.02188694942367004,
      0.020723910130927743,
      0.02087741073657613,
      0.021223826914457733,
      0.020746338453918746,
      0.020379672453817377,
      0.021411322208933888,
      0.020901099415124046
    ],
    "val_loss": [
      0.38907259434996966,
      0.5645623697849091,
      0.7111797808797774,
      0.6922312886147441,
      0.688399173899325,
      0.5175176953261127,
      0.7425744452563945,
      0.7624591934511404,
      0.6184917039232339,
      0.7279373939165812,
      0.5842500722069226,
      0.7127094406656876,
      0.5122516091667606,
      0.5227868696618937,
      0.569014797087558,
      0.6708185688821141,
      0.7143532723902228,
      0.6972770856659927,
      0.7915024821183638,
      0.747551721392456,
      0.7198094054164287,
      0.7029782138586401,
      0.6108034957802582,
      0.6201377881768935,
      0.6892599219422855,
      0.6087455673221343,
      0.6624633100575316,
      0.6221166247290052,
      0.6079464940030774,
      0.6336590334505379,
      0.5727841295971128,
      0.7037852905735285,
      0.6008663367100818,
      0.6114358278270253,
      0.7238404888682023,
      0.5971866531777168,
      0.6727034959518267,
      0.7185055589426064,
      0.6216085036536176,
      0.6419709678627774,
      0.6522499547300938,
      0.6505289822370707,
      0.6755507820380662,
      0.5171345657931117,
      0.5834787770391938,
      0.5946232222332926,
      0.5832415393548097,
      0.6425557083890824,
      0.5518795056882019,
      0.6902447778753892,
      0.6286734463479704,
      0.6564975906007304,
      0.708995441476742,
      0.584007348039907,
      0.6508956808529928,
      0.5824202087200331,
      0.6878043807106103,
      0.6918646633223502,
      0.6128467017126654,
      0.645249287525337,
      0.6614181890548346,
      0.6606115202257733,
      0.6592018466866659,
      0.7139783108573474,
      0.6883991328988247,
      0.6853204093382744,
      0.6426907657327766,
      0.48177752960584835,
      0.5435627185834382,
      0.5758461612918063,
      0.7017929349652308,
      0.6067032586047035,
      0.6165163629872357,
      0.6690808837999127,
      0.6003936531836401,
      0.6412297631809097,
      0.690685549806692,
      0.6657057941673759,
      0.7050131846241608,
      0.7044223197206052,
      0.6611174630547711,
      0.7572171375333906,
      0.5191541489012941,
      0.5008004134643578,
      0.5679088412466163,
      0.6059172024537703,
      0.5889645852817746,
      0.667348956678085,
      0.6318904221682491,
      0.6252480015872481,
      0.6172233697272347,
      0.6211428021688661,
      0.6730282125537267,
      0.47230671959633597,
      0.5796696370590233,
      0.5815320743950542,
      0.6521273368222271,
      0.623408177120243,
      0.585657713299026,
      0.602986401248121,
      0.6305452781076917,
      0.664211239554211,
      0.6048329624676418,
      0.6674361769667643,
      0.6467249542028605,
      0.6576949540012611,
      0.62647620425699,
      0.646569629272301,
      0.6383124036703282,
      0.6679680868537127,
      0.6400882186379261,
      0.6370598398104399,
      0.6575047077533014,
      0.5754342208097795,
      0.5513013939033011,
      0.5990392060024653,
      0.5831642267322112,
      0.5961940890836145,
      0.5949594233028903,
      0.5833421569250657,
      0.6235925520430068,
      0.6628111868561385,
      0.5434975821948694,
      0.6185392934360547,
      0.629857234879882,
      0.5807420731393876,
      0.5847421359426961,
      0.5640554857735862,
      0.615370962924943,
      0.6313379448866416,
      0.6442978623919858,
      0.6298539672426121,
      0.6295693945474253,
      0.5857241348235193,
      0.6784689443375536,
      0.6343991937126942,
      0.6713977667564404,
      0.6428642669123804,
      0.6222910002587798,
      0.6763825709234454,
      0.6654944882956807,
      0.7016634981253904,
      0.6865336220867619,
      0.7327139031833517
    ],
    "best_epoch": 94,
    "best_val_loss": 0.47230671959633597,
    "test_loss": 0.5026569491270128,
    "tracker": {
      "initial_train_loss": 0.3249104383170287,
      "train_threshold": 0.10830347943900957,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.47230671959633597,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/gru-other-value/trial_28_ae57f1/best_model.pt",
    "last": "scripts/outputs/gru-other-value/trial_28_ae57f1/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/gru-other-value/trial_28_ae57f1/config.yaml"
}