# 中期实验完善

基于1109-1116的所有实验结果与mentor进行了复盘，准备中期汇报前的终版实验。

## 模型配置

### 模型本体选取

- MLP
- MLPHIS(把命名是MLP_WITH_HISTORY MLP_HISTORY全部统一简写为MLPHIS)
- RNN
- LSTM
- GRU(新增)
- TRANSFORMER(新增，采用encoder only)
- XGBOOST
- CATBOOST
- LIGHTGBM

模型本体程序可沿用之前的，只需进行复核完善。

### 模型最终输出目标

以前的实验中，神经网络采用多输出，树模型采用分别输出，多输出时TRC的精度不理想但却是后期最重要的参数，而分别输出时效率又较低难以配置。

本次实验中，把所有模型规范为以下两种输出：

- TRC: 只同时输出TRC-PPL1和TRC-PPL2
- OTHER: 同时输出PPL1和PPL2的toc doc cond ph fdom

### 模型本体回归目标

沿用之前的实验中的两种形式

- 直接回归value，如TRC-PPL1
- 回归对RT的增长率rate，如(TRC-PPL1 - TRC-RT) / TRC-RT，其中原数据没有RT的cond，视作RT的cond等于DT的cond。训练与测试时沿用过去的设置：使用rate的mse作为loss，推理可视化输出的是value值。

## 相关目录与文件命名规范

模型-输出目标-回归目标。例如lstm-trc-rate表示使用lstm模型，输出目标trc，回归形式是回归对rt的增长率。目录结构逻辑沿用之前的实验。针对这次实验的改动，覆盖掉旧的文件编写新的文件。但Archived目录作为备份不要进行操作。

## 调参脚本

由之前的网格爬山换为贝叶斯，使用optuna库，依然用yaml文件来进行调参的设置。基于原来的grid的yaml文件中，如果上下界和间隔全部是整数，采用离散均匀分布间隔1。如果有浮点数，则在该上下界中对数均匀分布。新生成的文件命名举例lstm_bayes.yaml。调参脚本仍然需要产生调参的日志。

## 总结

根据以上要求编写/改动完所有文件后，也请更新每个层级所有相关的README，并告诉我可以配置哪些yaml文件，以及以lstm-trc-rate为例告诉我训练、测试、自动调参脚本分别如何启动。