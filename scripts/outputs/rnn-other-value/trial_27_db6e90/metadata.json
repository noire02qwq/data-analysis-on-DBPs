{
  "model_name": "rnn-other-value/trial_27_db6e90",
  "model_type": "RNN",
  "model_format": "torch",
  "model_params": {
    "history_length": 79,
    "units": 190,
    "num_layers": 5,
    "dropout": 0.2012006441983811
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 321,
    "learning_rate": 0.0014534748436813843,
    "weight_decay": 0.0004572082006426832,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7718,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 79,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122
    ],
    "train_loss": [
      0.3763999785319546,
      0.25720289008400854,
      0.230578718970989,
      0.19267046952585878,
      0.1798845801572937,
      0.1569459784035548,
      0.15714480496226707,
      0.15554586971329729,
      0.16276374037987396,
      0.2034451705158668,
      0.15019585467328614,
      0.13258305142664267,
      0.13189145455044704,
      0.1172195650882349,
      0.11722284305119614,
      0.12990556634532013,
      0.1453686620587356,
      0.12812381172197937,
      0.11253151595573192,
      0.11332002958081552,
      0.11007746051196671,
      0.12098770676676428,
      0.12592988604321076,
      0.11815477862479187,
      0.10845077721183397,
      0.10792596364815206,
      0.10491828627963547,
      0.11398560557457474,
      0.10053754127583191,
      0.09534970672193449,
      0.10558267381504645,
      0.11202847726602541,
      0.0970040505815198,
      0.09956210283173987,
      0.16040270775653098,
      0.21063250689022775,
      0.21353116619537518,
      0.15009063153872065,
      0.13446190057022642,
      0.13041958323867867,
      0.10711866690762521,
      0.10733367100041374,
      0.10478497730110957,
      0.09059615858742906,
      0.13972947777309977,
      0.10579149712897484,
      0.09393717502452574,
      0.11490785583069857,
      0.12805551892312025,
      0.10413889575148222,
      0.08080730877139,
      0.0903994355637442,
      0.09127964095597936,
      0.08847303683216722,
      0.09058486378236921,
      0.08053795812421279,
      0.07722972918482342,
      0.09823658883505981,
      0.0898578275631255,
      0.08635466824806734,
      0.15107255625478436,
      0.1083217282306734,
      0.12374784724932163,
      0.11335640074745551,
      0.09053079735262773,
      0.08658729598262083,
      0.07212441951378187,
      0.08249511167959217,
      0.11212536775929133,
      0.15321939073389107,
      0.26094323587049995,
      0.18368846021667914,
      0.14919037164419882,
      0.1423953376048184,
      0.11962857231957272,
      0.10846488897928336,
      0.12812907896679157,
      0.11733143351417992,
      0.13455046493541734,
      0.10724925344902081,
      0.09849600859003754,
      0.10595623384770195,
      0.0936179962573922,
      0.08216535942168024,
      0.078481090346066,
      0.0954487581171885,
      0.09694600192553393,
      0.10334314374351138,
      0.10148050498394004,
      0.07921019572804215,
      0.07329912555466031,
      0.06656170957105152,
      0.06223276785658598,
      0.06472715270136205,
      0.05958269908927703,
      0.13229796590718404,
      0.10520764602670153,
      0.12495360307899371,
      0.0968140463626394,
      0.0886655463411126,
      0.08584564847784297,
      0.08498294603530376,
      0.08078874221221713,
      0.1460032412972003,
      0.11005903582852966,
      0.08668505327728289,
      0.13322683279727154,
      0.09985174276909702,
      0.08306958653413128,
      0.0718891144331702,
      0.0688145071269047,
      0.10949122133546772,
      0.08049278344112408,
      0.06908308820285909,
      0.07294301037541724,
      0.07260899975110086,
      0.06159808173153987,
      0.06397234312475623,
      0.07702282921443195,
      0.06487770790456722,
      0.06128098012941756,
      0.05565863753707337
    ],
    "val_loss": [
      0.4910539099199329,
      0.4553984747675365,
      0.49837323906357417,
      0.42607407631452926,
      0.5858147621823999,
      0.7658077676094578,
      0.743898448669268,
      0.74342775646441,
      0.4859779862497381,
      0.6072574083051996,
      0.68592247682328,
      0.6823015338557209,
      0.6797937191442815,
      0.6582161425562676,
      0.6477465700603531,
      0.7072757923049842,
      0.5941480204641462,
      0.6360566297512569,
      0.6469707779452473,
      0.7072893219302872,
      0.7114033020452825,
      0.6163518913447144,
      0.6347702152447072,
      0.7764907145125424,
      0.6889405168369859,
      0.6774247082853746,
      0.7891244064994201,
      0.7064310460925816,
      0.7547629083969636,
      0.6822809495924119,
      0.7279767062269642,
      0.6749480165719629,
      0.7876601926045503,
      0.7832273333104784,
      0.6484329484804662,
      0.8759736491356067,
      0.756100059456811,
      0.7695731764246604,
      0.7057603912037647,
      0.773158045452155,
      0.7577405630560692,
      0.6884884205139326,
      0.7088217736182812,
      0.7323873671452086,
      0.6134252017040452,
      0.7487367298610196,
      0.7062646267656795,
      0.6989819471261458,
      0.7751712360514138,
      0.7355986326129851,
      0.7177684706663657,
      0.8265289805695683,
      0.7541869803504673,
      0.7880543711611968,
      0.7474198867237853,
      0.7205157704785199,
      0.7637675994036798,
      0.7639355310846767,
      0.7391348801107107,
      0.8770966789679613,
      0.6265469572144354,
      0.7494923762263295,
      0.648518723213744,
      0.7164478703217949,
      0.7115640619379318,
      0.6474379039943932,
      0.7203991255806592,
      0.7193385958046971,
      0.7381934161850079,
      0.658260795616818,
      0.541525544440318,
      0.401811101189452,
      0.7538600550931014,
      0.6069258422864054,
      0.8075996100367187,
      0.7373690310531034,
      0.7220530491299972,
      0.7891004421486112,
      0.7380258855259347,
      0.8712810157034212,
      0.7771642092637673,
      0.6844546066385186,
      0.8189131615984583,
      0.7441319251265711,
      0.8428417107926871,
      0.6880554934015531,
      0.8021556048469985,
      0.8178198617732454,
      0.6573927066283312,
      0.7396461017295985,
      0.7321640836889158,
      0.773993369936943,
      0.8190710405300478,
      0.7733453777356597,
      0.8615402822187561,
      0.6244932224293669,
      0.8313546739027886,
      0.646816718319576,
      0.7121736920834658,
      0.6328297998109264,
      0.6971919470606093,
      0.8187306804125181,
      0.9149881024694372,
      0.5971076271446523,
      0.6692428226867122,
      0.7648934042159312,
      0.7296292914557243,
      0.6800605173774822,
      0.7508799712547285,
      0.765726164045805,
      0.7057949767230514,
      0.7279825080833036,
      0.8366641629286512,
      0.7877803032671263,
      0.7783507396338764,
      0.8213426111522549,
      0.7951270260987524,
      0.8142745311834855,
      0.8059920126070341,
      0.8268221222042681,
      0.788740601299141,
      0.7848740477360294
    ],
    "best_epoch": 72,
    "best_val_loss": 0.401811101189452,
    "test_loss": 0.5208601663111927,
    "tracker": {
      "initial_train_loss": 0.3763999785319546,
      "train_threshold": 0.12546665951065153,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.401811101189452,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/rnn-other-value/trial_27_db6e90/best_model.pt",
    "last": "scripts/outputs/rnn-other-value/trial_27_db6e90/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/rnn-other-value/trial_27_db6e90/config.yaml"
}