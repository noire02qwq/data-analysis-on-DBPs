epoch,train_loss,val_loss
1,1.006698,0.359657
2,1.006781,0.353604
3,1.006461,0.337849
4,1.006520,0.339511
5,1.006445,0.337501
6,1.006085,0.357641
7,1.006338,0.341720
8,1.006426,0.338756
9,1.006367,0.339074
10,1.006153,0.350202
11,1.006456,0.348477
12,1.006121,0.346152
13,1.006165,0.347024
14,1.006188,0.344878
15,1.006242,0.345976
16,1.006275,0.344165
17,1.006281,0.342777
18,1.006249,0.341148
19,1.006210,0.348220
20,1.006308,0.346513
21,1.006206,0.345196
22,1.006186,0.344992
23,1.006168,0.351436
24,1.006083,0.342769
25,1.006107,0.342896
26,1.006116,0.344227
27,1.006118,0.345451
28,1.006062,0.343844
29,1.006064,0.346564
30,1.006085,0.342677
31,1.006096,0.343155
32,1.006090,0.345436
33,1.006077,0.344237
34,1.006193,0.345749
35,1.006138,0.344175
36,1.006144,0.343347
37,1.006039,0.345193
38,1.006154,0.344248
39,1.006128,0.344398
40,1.006166,0.343807
41,1.006085,0.343372
42,1.006077,0.345090
43,1.006034,0.344113
44,1.006037,0.344580
45,1.006053,0.344040
46,1.006116,0.342489
47,1.006087,0.344170
48,1.006048,0.344160
49,1.006089,0.343951
50,1.006143,0.344841
