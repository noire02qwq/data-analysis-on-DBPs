{
  "model_name": "mlp_with_history-trc-value/trial_17_6303f9",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 16,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.33258360650706514,
    "mid_layer_count": 12,
    "mid_layer_size": 677
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 336,
    "learning_rate": 0.0011400200356436305,
    "weight_decay": 0.0062306142070146986,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7781,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 160,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134
    ],
    "train_loss": [
      0.7403157090040731,
      0.27886136962215047,
      0.19036407286511672,
      0.14297162742284436,
      0.14665227750972892,
      0.14265892048058879,
      0.1311547090095353,
      0.13965971077711076,
      0.1336325486580214,
      0.12706306034189435,
      0.12841448202382597,
      0.12763808364599902,
      0.13184141859559653,
      0.1269297751274533,
      0.1329235286458938,
      0.13744330118928436,
      0.13061630535119603,
      0.12430636577098478,
      0.1320879822104974,
      0.1302701139695968,
      0.1255166744163396,
      0.13269184023149522,
      0.12610325411722387,
      0.12654660379973953,
      0.13240938273359887,
      0.12464682700881123,
      0.13449064117365947,
      0.13288692210591127,
      0.12546527466910645,
      0.12658799749622768,
      0.12443089133465815,
      0.12619099045566598,
      0.3778490783116947,
      0.3318582833763138,
      0.17738216779115895,
      0.18691599532787573,
      0.14599233735513142,
      0.15170678507468185,
      0.1367900893436868,
      0.13111782989378162,
      0.1327857154528872,
      0.12661587150953926,
      0.13222932616575964,
      0.12982828619815348,
      0.13403120625641088,
      0.13319291940822867,
      0.12504232150778152,
      0.1298025350976061,
      0.12900816142566712,
      0.16281192685871101,
      0.13210781070750502,
      0.12718095792135012,
      0.12610175139898508,
      0.12672125051450858,
      0.12455217182433263,
      0.12084763084799569,
      0.1335547869205628,
      0.1417572634234065,
      0.132616188412092,
      0.12951276210816443,
      0.122270604341077,
      0.1291471069881901,
      0.12807581090744044,
      0.12270529995639011,
      0.12480071449000951,
      0.12219223567382671,
      0.13027127979538952,
      0.11611801994297317,
      0.12779571308626672,
      0.12735881714626443,
      0.1236846600100829,
      0.12556191909636466,
      0.12683498896653633,
      0.12246269638396493,
      0.12386686499559117,
      0.14630448845209276,
      0.13081837263278584,
      0.12718166940248407,
      0.12374555465188741,
      0.12363098192155215,
      0.1243363275890362,
      0.34367994251142137,
      0.6984214637437619,
      0.36379658139819826,
      0.23867126446145004,
      0.1824124019639441,
      0.15446814199697234,
      0.14603959342428657,
      0.13718075550735465,
      0.14611754619095477,
      0.13693405338117173,
      0.13512350512169854,
      0.13846564742566198,
      0.12134549134614274,
      0.12781917528151057,
      0.12218024814064529,
      0.12281131296354093,
      0.12463782441032345,
      0.12006556214074092,
      0.1155454295545782,
      0.11654199795794355,
      0.11655300051498621,
      0.11553559724714038,
      0.1144557852197959,
      0.13331854617843866,
      0.10628639992056951,
      0.11359705751750543,
      0.10712578583328235,
      0.10693036756529598,
      0.10827362670385658,
      0.1002103880367615,
      0.10389101534292855,
      0.09963220644197891,
      0.10053220745561485,
      0.09715712631197641,
      0.10558863627356775,
      0.10563391183553601,
      0.09673074034423636,
      0.09347514640417799,
      0.1003443811262593,
      0.09883400071936575,
      0.09512054571653758,
      0.09354387250627287,
      0.09007817871419527,
      0.09559117270713294,
      0.09681633918090952,
      0.09052958175905748,
      0.16899149123492607,
      0.12494617729877357,
      0.10019310357453906,
      0.09717862361647325,
      0.09053456806754287,
      0.09028856885925753,
      0.09280432165415914
    ],
    "val_loss": [
      0.40914751376934394,
      0.6891689245572347,
      0.27344176198194126,
      0.2682207801920211,
      0.3200323106642969,
      0.2679343782499165,
      0.4054904243189418,
      0.2618042092301888,
      0.27287750253063475,
      0.27585867798613933,
      0.2953813965627533,
      0.27889104960207456,
      0.26278087676999096,
      0.3230173892960577,
      0.26489220559597015,
      0.27130052313476266,
      0.26213314724182657,
      0.294099596196306,
      0.26509854873854244,
      0.28028422087252497,
      0.2651896853825289,
      0.28949920950892444,
      0.26833892098800866,
      0.3482153717807667,
      0.2642821876410239,
      0.2750692754091617,
      0.29550792392856345,
      0.28606920117389656,
      0.28733030559417017,
      0.26463135214979777,
      0.32380973586065326,
      0.5952976336736165,
      0.558166632609453,
      0.3764071073360786,
      0.4587452146464479,
      0.26851851121037307,
      0.2779776276585585,
      0.28720266051635057,
      0.27380211736984594,
      0.2713456580381907,
      0.2833825677097914,
      0.3002729692501936,
      0.2907411927769998,
      0.29276242127675495,
      0.27175947054774463,
      0.2840980762671568,
      0.27622836355320707,
      0.3102013649697789,
      0.5236356331202798,
      0.26008186970285313,
      0.2865042366488965,
      0.26947311662628265,
      0.269297982100955,
      0.2936666096577387,
      0.27496845290332494,
      0.2672207332478312,
      0.28086247545873333,
      0.26682807210676684,
      0.29573494226275804,
      0.28173996813283,
      0.26612265618618375,
      0.27369723123704603,
      0.29534722413131576,
      0.2771206527056094,
      0.26263889574005217,
      0.2677288286521763,
      0.28085271332435263,
      0.28113216706021815,
      0.2937940679267495,
      0.30645458716118407,
      0.29040108731763803,
      0.30097768626170246,
      0.26629547853312807,
      0.2729436169841332,
      0.29721631050823694,
      0.28850969665064785,
      0.26222857422457485,
      0.26860657643058344,
      0.2709728382840128,
      0.26993142555573746,
      0.2797728772113423,
      0.4155044625619215,
      0.32220297230931816,
      0.2077990164299925,
      0.31717263310255406,
      0.25092301714919996,
      0.3078790165171652,
      0.29288524799718113,
      0.32794091003740616,
      0.3137701938252249,
      0.31457906650925826,
      0.3212090992463563,
      0.30128002848453866,
      0.3185493038799948,
      0.308657272293896,
      0.3096663336553973,
      0.312610009294784,
      0.3152542468316541,
      0.31736437664060535,
      0.3283913403214095,
      0.3160964695993298,
      0.31536624749263603,
      0.31413207860763914,
      0.5854695753779954,
      0.296077272706403,
      0.3115822230270523,
      0.3304640258500676,
      0.32250164522382313,
      0.3827648981424149,
      0.30673282665763785,
      0.32778186587516417,
      0.3518348994904649,
      0.3730069102641351,
      0.3483404207550837,
      0.3405160532026234,
      0.3475574344218134,
      0.3363610301724451,
      0.37789098475864547,
      0.35482857628853737,
      0.350604292125759,
      0.33953331633956135,
      0.3920133931194237,
      0.34848686065859424,
      0.37404742460407897,
      0.3481216300390438,
      0.3649459527102773,
      0.35895030209404266,
      0.33812654833950684,
      0.3489746420683261,
      0.3561337269351868,
      0.38111322996859065,
      0.3676375727810546,
      0.3813315292318424,
      0.3505996172656556
    ],
    "best_epoch": 84,
    "best_val_loss": 0.2077990164299925,
    "test_loss": 4.785496914786015,
    "tracker": {
      "initial_train_loss": 0.7403157090040731,
      "train_threshold": 0.24677190300135768,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.2077990164299925,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_17_6303f9/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_17_6303f9/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_17_6303f9/config.yaml"
}