{
  "model_name": "mlp-other-value/trial_19_a2b8df",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.33998221163226977,
    "mid_layer_count": 4,
    "mid_layer_size": 484
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 192,
    "learning_rate": 0.0012528315155226847,
    "weight_decay": 0.008090407520658103,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84
    ],
    "train_loss": [
      0.406932824999935,
      0.27543267494534884,
      0.2547149744674204,
      0.24603444720121945,
      0.24175176909790705,
      0.23895266197962048,
      0.23499540221605503,
      0.23391372902751764,
      0.231544701425524,
      0.23081520241061623,
      0.22885415802832565,
      0.2307039063181126,
      0.2299495092289701,
      0.22977362494397738,
      0.2287397371187401,
      0.23053432346583025,
      0.22728769632563828,
      0.22689276939021924,
      0.22821352887361585,
      0.22587095787428538,
      0.22758534562899677,
      0.2273208364163869,
      0.22731042856311356,
      0.2292893052621032,
      0.22708404279782748,
      0.2261908761411523,
      0.22454806901571872,
      0.22877777771897168,
      0.22866887525450333,
      0.2264777106037502,
      0.2271666580542593,
      0.2288804659863629,
      0.22926567809865558,
      0.22764102610763737,
      0.2261862460544869,
      0.2277814011854536,
      0.22700241406096014,
      0.2277678424285093,
      0.22635496656609658,
      0.2260804144907389,
      0.22866822578100868,
      0.22923273654733944,
      0.22643910070117648,
      0.22553683032954028,
      0.22602756147876404,
      0.22609434302431794,
      0.2259711305519567,
      0.22669162770581283,
      0.226516886605184,
      0.2249426700446225,
      0.22745779641412234,
      0.2258127135931375,
      0.22671635171399476,
      0.2280175215758196,
      0.226348605903373,
      0.22598974535928867,
      0.2276464456882521,
      0.225714699068456,
      0.2254470541285759,
      0.22591427627620236,
      0.22753196406541817,
      0.22863426210483934,
      0.2283566289831272,
      0.2263356116014973,
      0.2258182344389549,
      0.22742409989612417,
      0.22615445982100965,
      0.22801066724810007,
      0.22735999475661886,
      0.22574065839742746,
      0.2261890956932242,
      0.22588199036068768,
      0.22930600129836276,
      0.22896990092856387,
      0.2264843701001251,
      0.22548956070391565,
      0.22810798556208917,
      0.22931047374924493,
      0.22718547672232095,
      0.2280045322435461,
      0.22650100311418261,
      0.22590276709026164,
      0.227271343069605,
      0.22821882217281472
    ],
    "val_loss": [
      0.3661558582397278,
      0.4351093010988064,
      0.42215211762639576,
      0.3588717647655281,
      0.4097586460456163,
      0.4508655298255875,
      0.3954071150568431,
      0.40976280923375114,
      0.397234936674198,
      0.41507831676277573,
      0.5274146856662042,
      0.4686431692032043,
      0.4194545862917415,
      0.4472199624170086,
      0.46722839592459675,
      0.40314989946559515,
      0.41348043573116827,
      0.4384549273702199,
      0.5371072934773153,
      0.48740200096975544,
      0.4730793548915201,
      0.43925541917720956,
      0.4578186768971517,
      0.44031104955844536,
      0.45653064336605415,
      0.4984585687785805,
      0.49062802049214255,
      0.45487613735084764,
      0.4516636941247358,
      0.4358422023807457,
      0.4324447327745175,
      0.43075036802691613,
      0.48538841901425117,
      0.4158470387944204,
      0.47363158485846607,
      0.49279751977520786,
      0.4571660280227661,
      0.5057575574178181,
      0.5070964509141659,
      0.507775106258735,
      0.45344981747473073,
      0.47329204996188956,
      0.4672189295648815,
      0.4613613962413308,
      0.47295904559289625,
      0.45460434373981223,
      0.471342305223385,
      0.4681237828945685,
      0.48884924728713347,
      0.5268700482602605,
      0.49267361235475826,
      0.4596223138763519,
      0.4459797632194565,
      0.482870767787545,
      0.604421175882488,
      0.44208484909491624,
      0.4807983863853409,
      0.5978410446715212,
      0.46575542381423674,
      0.43406989874240165,
      0.5350056848126257,
      0.49303840705734525,
      0.4426462664575634,
      0.4627603795000179,
      0.43727613394845743,
      0.5150990354800653,
      0.5102559472272497,
      0.49815148136572923,
      0.4783719709533417,
      0.49259972686539155,
      0.5293927185549707,
      0.47941428872639547,
      0.5641584387796368,
      0.44062356292130705,
      0.5185929065692925,
      0.5115044266877774,
      0.647896509113426,
      0.5090180889575068,
      0.4898598135588412,
      0.5209645770980926,
      0.5124898990471206,
      0.4688681905141134,
      0.4619349641000439,
      0.5100873611644356
    ],
    "best_epoch": 84,
    "best_val_loss": 0.5100873611644356,
    "test_loss": 0.46619762373312806,
    "tracker": {
      "initial_train_loss": 0.406932824999935,
      "train_threshold": 0.13564427499997833,
      "best_tracking": false,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4158470387944204,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_19_a2b8df/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_19_a2b8df/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_19_a2b8df/config.yaml"
}