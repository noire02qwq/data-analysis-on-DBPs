epoch,train_loss,val_loss
1,0.477936,0.467661
2,0.139952,0.301385
3,0.101885,0.261624
4,0.080024,0.226179
5,0.064431,0.313063
6,0.057143,0.220907
7,0.056264,0.309771
8,0.052445,0.242572
9,0.047536,0.291659
10,0.048433,0.274605
11,0.047985,0.266152
12,0.045968,0.310790
13,0.046399,0.241674
14,0.040146,0.265905
15,0.040729,0.257297
16,0.039594,0.305664
17,0.041467,0.285572
18,0.044131,0.275028
19,0.040248,0.283427
20,0.042703,0.277158
21,0.036377,0.281269
22,0.035552,0.301122
23,0.039442,0.291260
24,0.043137,0.285776
25,0.035296,0.308854
26,0.037435,0.300085
27,0.033497,0.304546
28,0.034415,0.304730
29,0.033593,0.317363
30,0.034027,0.318779
31,0.034080,0.313233
32,0.032870,0.355187
33,0.033927,0.339092
34,0.031371,0.324925
35,0.032179,0.330207
36,0.032197,0.344802
37,0.034788,0.315068
38,0.031784,0.366168
39,0.034989,0.339832
40,0.032917,0.371316
41,0.032404,0.347514
42,0.030273,0.354186
43,0.030420,0.377628
44,0.034098,0.320045
45,0.032821,0.368979
46,0.029198,0.358947
47,0.034397,0.368176
48,0.031315,0.324319
49,0.029645,0.387699
50,0.033509,0.319479
51,0.031642,0.355995
52,0.031977,0.372376
53,0.031451,0.375823
54,0.030285,0.322697
55,0.032253,0.336187
56,0.032412,0.353228
57,0.028933,0.434894
58,0.031852,0.386989
59,0.030223,0.360238
60,0.028690,0.374881
61,0.034849,0.398472
62,0.032480,0.330963
63,0.030000,0.343968
64,0.028627,0.382830
65,0.028612,0.364741
66,0.028953,0.342236
67,0.029607,0.533663
68,0.032592,0.377693
69,0.032850,0.346686
70,0.030465,0.347563
71,0.033036,0.401999
72,0.033284,0.335154
73,0.030483,0.322868
74,0.031540,0.362721
75,0.029748,0.461235
76,0.031729,0.319844
77,0.032007,0.343661
78,0.036049,0.326632
79,0.030901,0.334958
80,0.028588,0.369292
