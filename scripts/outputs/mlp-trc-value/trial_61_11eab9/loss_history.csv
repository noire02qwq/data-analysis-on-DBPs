epoch,train_loss,val_loss
1,0.382230,0.291614
2,0.122486,0.194219
3,0.092068,0.201784
4,0.077130,0.261412
5,0.073338,0.220953
6,0.068283,0.230954
7,0.066943,0.232944
8,0.065821,0.236317
9,0.063138,0.265821
10,0.060885,0.266566
11,0.060431,0.246840
12,0.060766,0.244037
13,0.058070,0.242420
14,0.055600,0.280498
15,0.054549,0.263762
16,0.056107,0.255327
17,0.053840,0.273082
18,0.051462,0.301275
19,0.050235,0.275367
20,0.052684,0.284628
21,0.050182,0.280451
22,0.050317,0.288771
23,0.049173,0.284345
24,0.048215,0.284711
25,0.049609,0.288098
26,0.048243,0.284520
27,0.048793,0.310095
28,0.046885,0.313632
29,0.046948,0.319169
30,0.046785,0.296730
31,0.047538,0.288981
32,0.045806,0.289117
33,0.045379,0.320219
34,0.046132,0.346661
35,0.046145,0.347942
36,0.044661,0.319398
37,0.045072,0.318408
38,0.045558,0.308402
39,0.045193,0.321003
40,0.043692,0.321542
41,0.044766,0.305316
42,0.045637,0.300947
43,0.045074,0.329175
44,0.042029,0.337140
45,0.044464,0.333202
46,0.042580,0.304411
47,0.042642,0.331316
48,0.042921,0.295346
49,0.042903,0.338493
50,0.043134,0.314317
51,0.041470,0.342066
52,0.041456,0.309354
53,0.042105,0.310884
54,0.041667,0.318582
55,0.040972,0.327566
56,0.041700,0.335603
57,0.042571,0.317164
58,0.042109,0.352823
59,0.042526,0.304309
60,0.042376,0.330549
61,0.042429,0.330299
62,0.042698,0.379622
63,0.041476,0.351097
64,0.043009,0.328630
65,0.040059,0.327749
66,0.041379,0.306747
67,0.041034,0.332355
68,0.042252,0.319022
69,0.040605,0.317561
70,0.041634,0.292309
71,0.040801,0.335951
72,0.040689,0.302588
73,0.041624,0.305408
74,0.040815,0.327385
75,0.041610,0.318247
76,0.040899,0.308520
77,0.040840,0.300575
78,0.039906,0.349534
79,0.040170,0.311528
80,0.039192,0.304390
