epoch,train_loss,val_loss
1,1.002280,0.345410
2,1.001862,0.351672
3,1.001698,0.350847
4,1.001594,0.347174
5,1.002049,0.343049
6,1.001754,0.344787
7,1.001845,0.344565
8,1.001617,0.348831
9,1.001490,0.349368
10,1.001548,0.348349
11,1.001623,0.347204
12,1.001619,0.345023
13,1.001565,0.347140
14,1.001457,0.346965
15,1.001545,0.348436
16,1.001434,0.344076
17,1.001453,0.347590
18,1.001465,0.346935
19,1.001551,0.347637
20,1.001562,0.350305
21,1.001588,0.350679
22,1.001434,0.349010
23,1.001419,0.347530
24,1.001418,0.348874
25,1.001454,0.350192
26,1.001470,0.348972
27,1.001431,0.348937
28,1.001514,0.349048
29,1.001475,0.348653
30,1.001472,0.349520
31,1.001473,0.348219
32,1.001474,0.347922
33,1.001459,0.347722
34,1.001449,0.349541
35,1.001428,0.347764
36,1.001421,0.349517
37,1.001476,0.348893
38,1.001481,0.348117
39,1.001405,0.349134
40,1.001473,0.349869
41,1.001434,0.346459
42,1.001454,0.348058
43,1.001413,0.348170
44,1.001406,0.348197
45,1.001423,0.348841
46,1.001492,0.349411
47,1.001448,0.349805
48,1.001414,0.348558
49,1.001446,0.347882
50,1.001422,0.347870
