{
  "model_name": "mlp_with_history-other-rate/trial_15_61f894",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 108,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.2823682470002875,
    "mid_layer_count": 5,
    "mid_layer_size": 930
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 447,
    "learning_rate": 0.0016166944175864885,
    "weight_decay": 0.0013361377739551416,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7689,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 1080,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      1.2372308792753512,
      0.6469537085311002,
      0.4259446761452775,
      0.390299652430214,
      0.3811329719823085,
      0.3660582618070588,
      0.3884463388730063,
      0.34881818907315776,
      0.3465775499528058,
      0.319957939375205,
      0.310594022436808,
      0.2890882592763093,
      0.2822346389119252,
      0.27103920883840293,
      0.26820311192139673,
      0.2696412021510079,
      0.26540559525607016,
      0.26573431426154137,
      0.25408075358013693,
      0.2464030202110438,
      0.2568201996063377,
      0.2471020547465984,
      0.24513793587568353,
      0.24573953391586575,
      0.2413831498013127,
      0.24082996759315137,
      0.2344620061011413,
      0.2476674390057777,
      0.24042667155497435,
      0.24519980103184458,
      0.23253823361543766,
      0.2305433632943298,
      0.2302619882314595,
      0.2275760446471997,
      0.2271252300501614,
      0.22705237286610852,
      0.2243683594386186,
      0.22754104797071747,
      0.22474951297916848,
      0.22428356084886863,
      0.21940581688902316,
      0.22080291329163199,
      0.21971292224564778,
      0.2211107516946897,
      0.21904388799176194,
      0.21743119001923433,
      0.21742413372347888,
      0.21733595875618378,
      0.22384414812851547,
      0.2095092528100317,
      0.22308401868671726,
      0.22584078955408468,
      0.20811048517504382,
      0.2120085812049874,
      0.2059777508745238,
      0.20128445641816803,
      0.20435321482186944,
      0.1979513912637207,
      0.19434899788232135,
      0.19492655850647483,
      0.18982989245962456,
      0.21693955756610508,
      0.20540644859272292,
      0.1930180387923925,
      0.2014725039270861,
      0.19331331219679668,
      0.18825191942523617,
      0.18769772954276423,
      0.19089969785079516,
      0.19617217114624733,
      0.1830625783592474,
      0.20358840747940973,
      0.18297206193871485,
      0.17813735013704862,
      0.1800352731197084,
      0.18092263978042966,
      0.17838777077300355,
      0.17370489082715962,
      0.1717574412044584,
      0.17711947048449952
    ],
    "val_loss": [
      1.301964499796936,
      0.4500338299278014,
      0.4942132797069892,
      0.4950751494237049,
      0.4987092544397194,
      0.5026961527809412,
      0.5642819392556202,
      0.7487980212726278,
      0.5757908425823657,
      0.5157241289397914,
      0.4540224966174828,
      0.433118941808889,
      0.3864150836885332,
      0.5112843323476657,
      0.44918599151922556,
      0.39124779287212624,
      0.4787135632184451,
      0.461670465383701,
      0.466503911251258,
      0.4766890228106947,
      0.4373237712832982,
      0.47030870018604987,
      0.46221638801925913,
      0.5048902268850518,
      0.5155180004096317,
      0.44820388468082795,
      0.5583454075464589,
      0.5125361822411686,
      0.44259383960398374,
      0.4841413028850527,
      0.5516775097987966,
      0.5171681040418362,
      0.5705276460570846,
      0.44570061620659457,
      0.509413895617702,
      0.4781387407042666,
      0.4765923001898263,
      0.4692477856389063,
      0.5255124791296656,
      0.563774418322269,
      0.554727843653656,
      0.46967477578959776,
      0.553808281026379,
      0.479459279445474,
      0.5408510049035449,
      0.42382181939964525,
      0.45954381243554415,
      0.6362827815070837,
      0.41774231366768566,
      0.43777951747179034,
      0.47248415860408793,
      0.49376579971905954,
      0.49982942308851347,
      0.4578154008902475,
      0.5528094251221882,
      0.5927923641697376,
      0.5795420973422285,
      0.5373879065592132,
      0.44984872725730884,
      0.587321167015387,
      0.45981326982111276,
      0.46508631320770627,
      0.4734764354046947,
      0.4453255018698955,
      0.4207375557658201,
      0.4783133938283977,
      0.5944800508504142,
      0.5186443859499371,
      0.6243330872076714,
      0.4550766402643598,
      0.5435712368010047,
      0.4851637440438042,
      0.44875871694373515,
      0.49049741396468555,
      0.6842908668839289,
      0.5360724303715243,
      0.5401988264240191,
      0.46795826651557476,
      0.47102416640448713,
      0.6149051173272247
    ],
    "best_epoch": 13,
    "best_val_loss": 0.3864150836885332,
    "best_val_abs_mse": 0.4755525588989258,
    "test_loss": 0.5487123438152686,
    "test_abs_mse": 1.3756190538406372,
    "tracker": {
      "initial_train_loss": 1.2372308792753512,
      "train_threshold": 0.41241029309178373,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3864150836885332,
      "patience_no_improve_epochs": 67,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-rate/trial_15_61f894/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-rate/trial_15_61f894/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-rate/trial_15_61f894/config.yaml"
}