epoch,train_loss,val_loss
1,0.997468,0.359145
2,0.942494,0.339536
3,0.464962,0.853339
4,0.291114,0.186710
5,0.177320,0.258690
6,0.143435,1.571767
7,0.143020,0.305359
8,0.135953,0.266236
9,0.158124,0.217974
10,0.137756,0.615706
11,0.139792,0.607051
12,0.129302,0.274479
13,0.141626,0.267141
14,0.198520,0.273572
15,0.141763,0.261698
16,0.124983,0.279815
17,0.127685,0.282836
18,0.135565,0.329952
19,0.123293,0.280420
20,0.124565,0.268894
21,0.134124,0.398560
22,0.127936,0.289854
23,0.127610,0.287248
24,0.224015,0.284321
25,0.139458,0.255997
26,0.128126,0.376291
27,0.126315,0.287734
28,0.124970,0.261423
29,0.122199,0.356567
30,0.146993,0.265708
31,0.159018,0.247018
32,0.124567,0.346183
33,0.129120,0.421864
34,0.131168,0.270410
35,0.126668,0.289386
36,0.123289,0.282725
37,0.120908,0.266861
38,0.120373,0.292746
39,0.338332,0.298704
40,0.223328,0.347613
41,0.151649,0.318906
42,0.142615,0.315905
43,0.182541,0.349143
44,0.131326,0.351760
45,0.126453,0.435547
46,0.150709,0.617133
47,0.757047,0.557170
48,0.358914,0.304543
49,0.180702,0.931998
50,0.166357,1.306082
51,0.162205,0.390609
52,0.146341,0.273443
53,0.152058,0.336234
54,0.137728,0.304111
55,0.185894,0.261155
56,0.159622,0.286974
57,0.136777,0.279240
58,0.134075,0.723258
59,0.136409,0.292274
60,0.132143,0.286954
61,0.148564,0.302953
62,0.135497,0.332227
63,0.127153,0.355580
64,0.125298,0.404960
65,0.129583,0.371138
66,0.177213,0.330490
67,0.389300,0.329494
68,0.157028,0.287279
69,0.134447,0.438274
70,0.130181,0.448680
71,0.153852,0.302588
72,0.206326,0.268663
73,0.141646,0.363348
74,0.133108,0.410004
75,0.132197,0.262530
76,0.128523,0.365069
77,0.123373,0.281614
78,0.128261,0.266498
79,0.126739,0.288218
80,0.129729,0.298176
