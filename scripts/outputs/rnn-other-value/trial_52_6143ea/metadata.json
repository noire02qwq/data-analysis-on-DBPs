{
  "model_name": "rnn-other-value/trial_52_6143ea",
  "model_type": "RNN",
  "model_format": "torch",
  "model_params": {
    "history_length": 32,
    "units": 337,
    "num_layers": 2,
    "dropout": 0.4760937614367015
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 336,
    "learning_rate": 0.0013269058633238388,
    "weight_decay": 0.0005672417033053871,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7765,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 32,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119
    ],
    "train_loss": [
      0.35681085368547605,
      0.2598577089046403,
      0.23857947606389476,
      0.21756211362457706,
      0.1948918978936121,
      0.23415029174999044,
      0.17706038693574191,
      0.17291692442573123,
      0.14803282486686228,
      0.14323110119112828,
      0.1417860825024953,
      0.1379109830585358,
      0.12781988642941886,
      0.13196002222304948,
      0.11881334256220079,
      0.12804061165373323,
      0.12037770428622221,
      0.13795333452287675,
      0.110365783884229,
      0.10824750434158698,
      0.13853531954983933,
      0.132280405427054,
      0.11684099749949235,
      0.10655386010178887,
      0.10873103900947498,
      0.10217952265116913,
      0.09832286635235057,
      0.08795292141912679,
      0.08107320048677791,
      0.09851681931665154,
      0.0949948820869,
      0.08442914355054489,
      0.08618592169886624,
      0.07633410911270672,
      0.06733469068668231,
      0.06811792256223027,
      0.07890766734222558,
      0.084986836615295,
      0.08516094799358002,
      0.08232603968677027,
      0.08276685480812788,
      0.11826129099072293,
      0.08709165786572295,
      0.07698857668554561,
      0.08040344122718092,
      0.07617757241292608,
      0.07263635241133277,
      0.06594205264287538,
      0.12031498245381572,
      0.10309183224411987,
      0.09941724727154545,
      0.08864374951209396,
      0.09769664466553785,
      0.07543341413917498,
      0.06291043194009655,
      0.16768482125964537,
      0.19569694914130034,
      0.13204333265213067,
      0.11367229915248603,
      0.11473623647738947,
      0.09742874886075374,
      0.1018271160553673,
      0.08409309541783791,
      0.10173498478460834,
      0.0851269312082992,
      0.18200737294061523,
      0.12295524976519101,
      0.11739881402703155,
      0.16149763799220304,
      0.49753201241963,
      0.35850822339883864,
      0.2962651901604357,
      0.260297242054537,
      0.2378925983416827,
      0.2169212024287109,
      0.21545873730703086,
      0.2360311209061648,
      0.22040381706958423,
      0.19950201892403732,
      0.1853644487248339,
      0.17618260588748794,
      0.16791538585790572,
      0.16554698081493993,
      0.16412578544460107,
      0.1615489463440004,
      0.148883317541439,
      0.13696808584144787,
      0.13758937945902464,
      0.16425854106795304,
      0.2158174860308574,
      0.1664505103798505,
      0.15418525737520195,
      0.1389351680807659,
      0.1303199588897454,
      0.12477911915594121,
      0.1147863596178836,
      0.12284283395820637,
      0.11122368163089175,
      0.10346448195226256,
      0.11702161864818332,
      0.1104024370130768,
      0.10289272924085163,
      0.15306836367804852,
      0.11640136336904146,
      0.14719964170256356,
      0.24486090937354682,
      0.18639788475830327,
      0.1883472105839601,
      0.16059771247510363,
      0.16160555311502062,
      0.15944129159603285,
      0.13115902421594203,
      0.1282798955345338,
      0.12296984614822377,
      0.11470268341087174,
      0.11668984001767459,
      0.12097256405366595,
      0.12094674828220627,
      0.1056878024946085
    ],
    "val_loss": [
      0.40368683709355885,
      0.4793437219665436,
      0.4837477523409678,
      0.5504128665981178,
      0.7453629830640233,
      0.3286931992290977,
      0.7686467125030335,
      0.5850470595730993,
      0.38873675740407615,
      0.4145408721741088,
      0.3711069148457693,
      0.5067664763170802,
      0.4135185710684268,
      0.4312008393738798,
      0.4423379386256555,
      0.4224921828258537,
      0.41397499374286856,
      0.4033907857483732,
      0.4357810142511379,
      0.42224045941929617,
      0.47121863943374087,
      0.47321710179665843,
      0.510780931661229,
      0.44568890640121733,
      0.4378150989195544,
      0.45099059457550505,
      0.45360064110356174,
      0.41136912742774645,
      0.39005371653391213,
      0.44489829012019905,
      0.4472035792059527,
      0.42541542859848386,
      0.38588652817788954,
      0.4380170101891021,
      0.4426936795611581,
      0.44935595175463283,
      0.38369903892814045,
      0.4924535567888957,
      0.567378126718327,
      0.41147162121926956,
      0.3603543337947594,
      0.36975645333706975,
      0.3968145516818155,
      0.4421604661170594,
      0.460697029236548,
      0.42251807565460664,
      0.3984086671275293,
      0.42696177416932796,
      0.43784994886306944,
      0.4359548569439414,
      0.429327941654685,
      0.3893847267784758,
      0.3696492978912628,
      0.39054610432978876,
      0.4169670018607271,
      0.5632203764544276,
      0.4789004937617365,
      0.4814958041299603,
      0.43881669794014116,
      0.5179500487036334,
      0.4506952589143536,
      0.39954290996768516,
      0.4106689301793447,
      0.38186433286723975,
      0.43447073205502446,
      0.43129561033077585,
      0.4015425855528095,
      0.435756549935141,
      0.3585146015275738,
      0.559625113938383,
      0.5387849288072415,
      0.4161724319714986,
      0.4156301182187246,
      0.4111894936618691,
      0.40425549517134707,
      0.4272437024259282,
      0.4135619889476342,
      0.4826016641662506,
      0.4219321106008427,
      0.4484345528180014,
      0.5049114911856052,
      0.5056917921511713,
      0.5518207138883854,
      0.5462064330449361,
      0.5717475421414404,
      0.5918734457678424,
      0.6328865315385921,
      0.6347105023389805,
      0.5422495915504273,
      0.5439521077864184,
      0.6908820633402841,
      0.6822240162752345,
      0.7095208247978531,
      0.7823409261817704,
      0.6784723100548019,
      0.7565161076848378,
      0.719487344647596,
      0.6993942089423448,
      0.7525510566677162,
      0.776476768819158,
      0.773124150458924,
      0.8162086917968567,
      0.7126308007154636,
      0.6815477202038565,
      0.4551086383665393,
      0.402733600674989,
      0.408669110757862,
      0.38356156834585226,
      0.4296761085173327,
      0.4164823801931507,
      0.4009103388129594,
      0.4061709154865699,
      0.6090295935819249,
      0.5049740444400354,
      0.5277606928419925,
      0.5290613479956895,
      0.723757947776132,
      0.6276483572171834,
      0.800187478022661
    ],
    "best_epoch": 69,
    "best_val_loss": 0.3585146015275738,
    "test_loss": 0.36402369287025416,
    "tracker": {
      "initial_train_loss": 0.35681085368547605,
      "train_threshold": 0.11893695122849202,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3585146015275738,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/rnn-other-value/trial_52_6143ea/best_model.pt",
    "last": "scripts/outputs/rnn-other-value/trial_52_6143ea/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/rnn-other-value/trial_52_6143ea/config.yaml"
}