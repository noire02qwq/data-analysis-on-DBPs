{
  "model_name": "lstm_regressor",
  "model_type": "LSTM",
  "model_params": {
    "history_length": 72,
    "hidden_size": 192,
    "num_layers": 2,
    "dropout": 0.3,
    "fc_dim": 96
  },
  "input_dim": 24,
  "output_dim": 6,
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "non_target_columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "DO-PPL1",
    "DO-PPL2",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2"
  ],
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "split_boundaries": {
    "train_end": 8250,
    "val_end": 10018,
    "test_end": 11787
  },
  "dataset_sizes": {
    "train": 8179,
    "val": 1768,
    "test": 1769
  },
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100
    ],
    "train_loss": [
      0.29364176106738615,
      0.06016743733503333,
      0.028061477613168163,
      0.02481200297202891,
      0.023278385923424082,
      0.02236486986044465,
      0.021625094104119613,
      0.021297561883132053,
      0.020562207981714528,
      0.020020579338950056,
      0.019796686818150718,
      0.019570218091041508,
      0.019137393143918466,
      0.018894619145467632,
      0.01844796924659968,
      0.018482141509408006,
      0.01840308433377425,
      0.018007895385117517,
      0.01769287948456672,
      0.017704650292840064,
      0.01752337814698244,
      0.01734784867526602,
      0.017263150887468402,
      0.017259207587297,
      0.017039509304186646,
      0.016779521343789367,
      0.01670257099608634,
      0.016660837051557152,
      0.016643789227469355,
      0.016299857795675745,
      0.016215403780281027,
      0.016264314785452136,
      0.016086733980401065,
      0.016002342288921743,
      0.015808439900207482,
      0.015761826441182944,
      0.015856621987131145,
      0.016043767760717163,
      0.015801912258232385,
      0.015760896973168882,
      0.015524027016806835,
      0.015430040217650003,
      0.01546071470148159,
      0.015426573149658587,
      0.015365419583696872,
      0.015176137246356382,
      0.01528285559267261,
      0.015242347189513682,
      0.01515695880911766,
      0.015285900213814537,
      0.015296567848692613,
      0.014995351543066802,
      0.014886917398819161,
      0.015339878943764372,
      0.014985956619527254,
      0.01479140294881781,
      0.014737861843235169,
      0.014679791736468328,
      0.01474736875185233,
      0.014745025607223345,
      0.01453174089336307,
      0.014698075512835173,
      0.014420529319170868,
      0.014534828376750526,
      0.01464059044539688,
      0.014482423006579133,
      0.014425700983602605,
      0.014525328273882105,
      0.01446961544521052,
      0.014308619398912018,
      0.014255912170230409,
      0.014336703333109598,
      0.014304561371391139,
      0.014441534463142667,
      0.014254632933257277,
      0.014227057590002113,
      0.01409898056766069,
      0.014271239673226674,
      0.014220988183442983,
      0.014056080795604992,
      0.01403439419121115,
      0.014011088346506568,
      0.014027356114664364,
      0.013839809180967586,
      0.013881889081829144,
      0.013969939444152616,
      0.013896898744664954,
      0.013846206248648258,
      0.013666094095972352,
      0.013830478607502365,
      0.01363151669201648,
      0.013583431100086342,
      0.013494139394311476,
      0.013676799211146881,
      0.013448558051923892,
      0.013571055101346657,
      0.013423870868529059,
      0.013472177289009115,
      0.013557571865848697,
      0.01341084691101822
    ],
    "val_loss": [
      0.2887484598483435,
      0.1735138065135317,
      0.1316590448040768,
      0.11443178524258989,
      0.10034175641935875,
      0.0864963888852305,
      0.08052473282652203,
      0.08050072186403145,
      0.08244873596802017,
      0.07247001532785494,
      0.07315326674221867,
      0.06818303499556234,
      0.07559225671161893,
      0.06955170880885146,
      0.07355254241244286,
      0.06402092369703147,
      0.060297592125866745,
      0.06610120286768918,
      0.062191047752065354,
      0.06894421921326564,
      0.0677937481602932,
      0.06777294101488536,
      0.059681453518738034,
      0.06205944507909576,
      0.06160344979072588,
      0.0672399080042386,
      0.06310166681514066,
      0.06624895266817706,
      0.05968574505316186,
      0.06484472320090591,
      0.07189143310844628,
      0.05769526331403137,
      0.06126129809278169,
      0.06109027126256157,
      0.06116345801234785,
      0.06157719455153694,
      0.06046812748747174,
      0.05650337195504305,
      0.06432377226751854,
      0.06057382634592272,
      0.05858879566732036,
      0.06009082078124603,
      0.060408676574133104,
      0.0543312617826246,
      0.0613148806456527,
      0.05945312187952154,
      0.05409018513304076,
      0.06421334663936995,
      0.057630363632650936,
      0.057969286093884465,
      0.05541161451134746,
      0.04902594108387356,
      0.05652472572359025,
      0.06270652564402619,
      0.06151226317990419,
      0.057740003140263965,
      0.05882809934842641,
      0.06145577962042519,
      0.05416956220277294,
      0.06270133869140936,
      0.059924830476083366,
      0.06443703201561492,
      0.05941358303052807,
      0.05741392258065858,
      0.05613177057305073,
      0.05505277250147513,
      0.055359950702114885,
      0.05899226780121143,
      0.057493492084390974,
      0.057499601021071906,
      0.05521079803484058,
      0.053572015322711136,
      0.05877801688278422,
      0.06373059446185962,
      0.05607549259565535,
      0.053583527582263514,
      0.055456578259554384,
      0.06245905309241282,
      0.059851709803844466,
      0.06874158533450166,
      0.05741692189447481,
      0.0596675396774689,
      0.058553335758355946,
      0.06511325722905845,
      0.05817647022089807,
      0.06121774934805357,
      0.058651101467835955,
      0.05486350961670077,
      0.05666102017212777,
      0.06347236354156857,
      0.057958733239864335,
      0.06163142776597139,
      0.05505821432463184,
      0.055659756940953875,
      0.05985703167602487,
      0.05704490341482119,
      0.05889741442591896,
      0.06242115863038404,
      0.0657235129116887,
      0.05966705124302687
    ],
    "best_epoch": 52,
    "best_val_loss": 0.04902594108387356,
    "test_loss": 0.13318940695562625,
    "threshold": 0.057749691969668705
  },
  "config_path": "models/configs/lstm_config.yaml"
}