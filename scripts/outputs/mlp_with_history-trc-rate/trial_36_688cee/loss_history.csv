epoch,train_loss,val_loss
1,0.693811,0.288061
2,0.245255,0.208586
3,0.176100,0.338729
4,0.165882,0.266368
5,0.146876,0.257165
6,0.138769,0.260746
7,0.140583,0.303964
8,0.143883,0.276573
9,0.137725,0.263601
10,0.135247,0.261599
11,0.129022,0.287797
12,0.133066,0.269391
13,0.132201,0.265452
14,0.131603,0.292397
15,0.132646,0.293986
16,0.128174,0.285118
17,0.133907,0.282344
18,0.134838,0.270400
19,0.127560,0.272735
20,0.122709,0.288579
21,0.126876,0.264361
22,0.122136,0.268807
23,0.125281,0.268396
24,0.130182,0.308901
25,0.122799,0.271371
26,0.124476,0.270837
27,0.132471,0.293225
28,0.122576,0.274099
29,0.123903,0.282344
30,0.122350,0.275594
31,0.124605,0.275351
32,0.120882,0.294035
33,0.124236,0.283319
34,0.122569,0.380010
35,0.133695,0.274552
36,0.130531,0.282990
37,0.127007,0.293760
38,0.120221,0.278091
39,0.119820,0.278324
40,0.123834,0.320109
41,0.125875,0.279719
42,0.125791,0.282153
43,0.125123,0.277717
44,0.120994,0.281014
45,0.124347,0.328462
46,0.123483,0.301531
47,0.119654,0.280940
48,0.123231,0.275027
49,0.120641,0.282986
50,0.126207,0.302918
51,0.126867,0.296457
52,0.123745,0.290764
53,0.123136,0.325020
54,0.120414,0.277457
55,0.123445,0.286245
56,0.120089,0.284010
57,0.121240,0.283085
58,0.117056,0.292152
59,0.137479,0.281510
60,0.133403,0.299451
61,0.125550,0.298681
62,0.123567,0.301186
63,0.122671,0.288221
64,0.123538,0.280185
65,0.119103,0.282627
66,0.121476,0.284732
67,0.121247,0.293187
68,0.126262,0.320509
69,0.123159,0.297664
70,0.126639,0.290998
71,0.122082,0.285140
72,0.119444,0.292995
73,0.120571,0.280511
74,0.130185,0.341354
75,0.123232,0.299871
76,0.122989,0.281500
77,0.115582,0.292151
78,0.120103,0.289593
79,0.117489,0.305589
80,0.125259,0.295225
