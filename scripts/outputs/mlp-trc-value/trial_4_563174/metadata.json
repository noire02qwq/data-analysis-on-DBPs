{
  "model_name": "mlp-trc-value/trial_4_563174",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.2005729420712155,
    "mid_layer_count": 2,
    "mid_layer_size": 488
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 142,
    "learning_rate": 0.0019547878738797827,
    "weight_decay": 0.0006729911454272546,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.19065365925041328,
      0.07223746768189829,
      0.06646936358057302,
      0.06040739592331045,
      0.06215798254557271,
      0.05956149476653432,
      0.05189054917779227,
      0.0510628057625613,
      0.049730698676018176,
      0.049040411441768975,
      0.04669603679889193,
      0.04992404438864885,
      0.04934756786755074,
      0.047876106179474624,
      0.046587742074727705,
      0.04388599615045209,
      0.04365444910249507,
      0.0449788328699802,
      0.042821571877414505,
      0.04326325355517201,
      0.04258705976454034,
      0.044394100594285085,
      0.044080206931302525,
      0.043514532014620556,
      0.042875230464302555,
      0.043557550621459336,
      0.04303729526312489,
      0.04275578182437225,
      0.04234740957942695,
      0.040971567607716516,
      0.04185138569916362,
      0.044018228975563796,
      0.04298267141366812,
      0.04234994003781452,
      0.04655084302844819,
      0.04123320072992543,
      0.04367319312808665,
      0.042146329728818634,
      0.043731302590615445,
      0.03947853186134805,
      0.04106722613524219,
      0.03978742062500757,
      0.03936771530057832,
      0.04079839001754237,
      0.04033197665070038,
      0.040281993521424274,
      0.03902477296398978,
      0.03921564835519852,
      0.04036316137164525,
      0.039381377501704715,
      0.04283053625763044,
      0.04034822769013887,
      0.0402874298820921,
      0.03919504788308082,
      0.04059259609685778,
      0.040202793911799,
      0.03964832174534856,
      0.03914713731447494,
      0.03839820679066929,
      0.0388188494542368,
      0.038433780453586926,
      0.039196223131413944,
      0.03878900293058206,
      0.03894889472686079,
      0.045227117553590324,
      0.03757384817152757,
      0.04347940801278238,
      0.039453097660211094,
      0.037420273091875324,
      0.038247653305637584,
      0.0385428750576913,
      0.038127192943569574,
      0.03919129413894242,
      0.03918414432440754,
      0.04240147747040147,
      0.040800865169991096,
      0.04012153844462336,
      0.03733016632921638,
      0.03910040261444677,
      0.03840994702823166
    ],
    "val_loss": [
      0.1996989424870221,
      0.22222282660087783,
      0.25424694892710553,
      0.3216399876099682,
      0.24586251007314927,
      0.32732387998191537,
      0.2532665523828682,
      0.26157458089515123,
      0.29445841002339374,
      0.32781307053735514,
      0.3000853313300424,
      0.2952300688842992,
      0.2723082989833491,
      0.3334106558543479,
      0.29385629367685606,
      0.29516814518608375,
      0.28566095818971804,
      0.395386487856775,
      0.2748906108500536,
      0.2891757263595651,
      0.3049936766150647,
      0.27938833622384573,
      0.2839318734376195,
      0.30011515785343273,
      0.28722430649854824,
      0.3078293039167891,
      0.2863782032833485,
      0.29142435486177487,
      0.3021392537336685,
      0.30715374760552794,
      0.29400155868626643,
      0.29633680539886037,
      0.29607937254547,
      0.29924946110360995,
      0.3103564190695029,
      0.30538010371703944,
      0.3070218959388262,
      0.3110194807281037,
      0.29567957905729014,
      0.3013952816987109,
      0.3089582598294148,
      0.31055084694243834,
      0.29670425216014873,
      0.31094633577068054,
      0.30664839443198577,
      0.2990351541380504,
      0.30652403851558346,
      0.30116702386228267,
      0.3097232849521194,
      0.3088435914099752,
      0.30060259290039537,
      0.3074395434228246,
      0.3053618392678435,
      0.3055884173619533,
      0.3071106717726606,
      0.30498512475834993,
      0.30779992976186876,
      0.3036997089441308,
      0.3027605801486148,
      0.30823940906651365,
      0.30382585174175436,
      0.3000519579934503,
      0.3038783108759783,
      0.3016628945882092,
      0.33226150090466,
      0.3105932880862209,
      0.31121029119916305,
      0.2960269865362409,
      0.3080836695222976,
      0.3049889501898053,
      0.303999003660893,
      0.29985890156494643,
      0.3091858496298333,
      0.3113643329055188,
      0.303446587842114,
      0.30070446219049884,
      0.30236583125894656,
      0.3080079821813963,
      0.30272770190533405,
      0.2995994403824478
    ],
    "best_epoch": 5,
    "best_val_loss": 0.24586251007314927,
    "test_loss": 4.541553764252001,
    "tracker": {
      "initial_train_loss": 0.19065365925041328,
      "train_threshold": 0.06355121975013776,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.24586251007314927,
      "patience_no_improve_epochs": 75,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_4_563174/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_4_563174/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_4_563174/config.yaml"
}