{
  "model_name": "mlp-trc-value/trial_47_56f5af",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.21689295116345628,
    "mid_layer_count": 13,
    "mid_layer_size": 264
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 251,
    "learning_rate": 0.0005128042603053256,
    "weight_decay": 0.005929748668428392,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.4396633066565731,
      0.1439132681159468,
      0.10475127334458482,
      0.09202566548891408,
      0.08394484720615744,
      0.07771366335147693,
      0.07223000736661511,
      0.0720799652192495,
      0.07667030305771291,
      0.06896388429857833,
      0.06646032585380642,
      0.06408993574408857,
      0.06750163548182087,
      0.06359625440339375,
      0.06372002173710199,
      0.06975301516062177,
      0.06212099744298478,
      0.06107641911261231,
      0.059639056968675205,
      0.05935983813911095,
      0.060124775098532576,
      0.057865257282717956,
      0.05940915037447318,
      0.05766292682788184,
      0.06192236103302871,
      0.05543540903448814,
      0.055898310828298374,
      0.05629996721250024,
      0.055076460822319574,
      0.058413995132653024,
      0.05807551540665638,
      0.054031808298652666,
      0.05609293640464575,
      0.05634930851191221,
      0.055361210238599454,
      0.05575968498405186,
      0.05437374787989061,
      0.05444626466802614,
      0.05368915624130974,
      0.054213095298194625,
      0.05676196780956024,
      0.05790736935765178,
      0.05604504057521114,
      0.05377080502000954,
      0.053719513844593544,
      0.05354143229918626,
      0.054266258818085465,
      0.05363497668289493,
      0.05434149841640838,
      0.05563397244481,
      0.05398906070238248,
      0.0530968200054121,
      0.052623353613250955,
      0.054062464012606226,
      0.05301852125374398,
      0.05428668951616647,
      0.054270914101112094,
      0.05412363426032557,
      0.05577655845183617,
      0.052255141760976176,
      0.05428204272160275,
      0.0521148358112829,
      0.05353360446795951,
      0.05435973035268153,
      0.054102798156906634,
      0.05460772460939151,
      0.05282937085256936,
      0.055831304972579446,
      0.05280863249644813,
      0.05163359620645184,
      0.053168220007328605,
      0.051797669888376086,
      0.052710234533504166,
      0.05226697182314343,
      0.052195386835667816,
      0.05141025995037658,
      0.05192308939311017,
      0.05203863711986574,
      0.052891609793182,
      0.053230681469527315
    ],
    "val_loss": [
      0.37973409685010684,
      0.24259777409052422,
      0.2646985227052502,
      0.2804657138058704,
      0.2765283282980055,
      0.25237120455632844,
      0.22927390222443256,
      0.306390499766403,
      0.22866413533062993,
      0.26372898544803886,
      0.32702595616863694,
      0.22101740241162257,
      0.22899418723529685,
      0.3556409125076886,
      0.4740831706026,
      0.2593193033944347,
      0.3230894975475744,
      0.28684326393117093,
      0.29552928889226054,
      0.3098606750447147,
      0.3108270964468132,
      0.29001118330519177,
      0.2963039507252906,
      0.26633737682738523,
      0.2806024873640366,
      0.3116307793285497,
      0.2952125122971431,
      0.35317109894386667,
      0.3328045241869317,
      0.3726308379255369,
      0.3287642426532275,
      0.28507783140340254,
      0.3818799009055881,
      0.3519265492128844,
      0.342640053388289,
      0.41179134718583016,
      0.33369237869576424,
      0.33431627557997756,
      0.32826769884653434,
      0.30290196857744167,
      0.32174573461162653,
      0.3336909489594623,
      0.3050564412551815,
      0.32162242103479577,
      0.3408175287634402,
      0.39259737578895454,
      0.34212494121228687,
      0.2962314863304446,
      0.2978811349998602,
      0.33266571756050795,
      0.370718682972257,
      0.4188520031172537,
      0.3137375969618202,
      0.36432252149962024,
      0.3413375696379268,
      0.3345847156924937,
      0.32507854734218405,
      0.44676526264471567,
      0.3153544155468127,
      0.33806128362472543,
      0.32443121313758777,
      0.33629148206534143,
      0.33752793242630663,
      0.33428950373997945,
      0.3693484733483481,
      0.331669222409586,
      0.41117058775560583,
      0.29917652258192173,
      0.35541425293456474,
      0.3367901582404703,
      0.34811707775549083,
      0.34218678901607763,
      0.3662203947383308,
      0.3302921194159342,
      0.34080106534376114,
      0.325305511871587,
      0.2998176481764384,
      0.3798349213200861,
      0.29881272388811775,
      0.2953593162072454
    ],
    "best_epoch": 12,
    "best_val_loss": 0.22101740241162257,
    "test_loss": 4.668071260934241,
    "tracker": {
      "initial_train_loss": 0.4396633066565731,
      "train_threshold": 0.14655443555219103,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.22101740241162257,
      "patience_no_improve_epochs": 68,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_47_56f5af/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_47_56f5af/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_47_56f5af/config.yaml"
}