epoch,train_loss,val_loss
1,0.995046,0.352213
2,0.891742,0.331424
3,0.608052,0.298870
4,0.565220,0.222366
5,0.278994,0.200432
6,0.142857,0.548920
7,0.132124,0.998446
8,0.135045,0.523918
9,0.117937,0.569601
10,0.109715,0.392372
11,0.116887,0.213222
12,0.111394,0.572109
13,0.109143,0.492580
14,0.119648,0.885436
15,0.122311,0.366215
16,0.110488,0.830737
17,0.117696,0.244765
18,0.108879,0.320029
19,0.107569,0.397130
20,0.108826,0.449043
21,0.109744,0.233283
22,0.116262,0.290873
23,0.115052,0.273554
24,0.159004,0.253559
25,0.162528,0.202567
26,0.111664,0.374315
27,0.118004,0.225086
28,0.116344,0.226624
29,0.104429,0.234949
30,0.116412,0.257872
31,0.106105,0.277572
32,0.104964,0.445982
33,0.103840,0.293584
34,0.104385,0.391618
35,0.104351,0.291079
36,0.105828,0.268163
37,0.121386,0.242374
38,1.501002,0.294667
39,1.004769,0.378289
40,0.954356,0.378213
41,0.723693,1.105248
42,0.420278,0.306043
43,0.234494,0.539676
44,0.202058,0.438948
45,0.161249,0.294763
46,0.153190,0.380566
47,0.153859,0.522703
48,0.141685,0.742801
49,0.134913,0.272894
50,0.148423,0.318571
51,0.139915,0.802894
52,0.167021,0.267351
53,0.131926,0.347491
54,0.122909,0.508834
55,0.126767,0.422285
56,0.130411,0.297631
57,0.124054,0.536157
58,0.122523,0.667664
59,0.131139,0.266938
60,0.126335,0.599508
61,0.123499,0.281390
62,0.136210,0.735225
63,0.137708,0.309651
64,0.144923,0.289195
65,0.130420,0.401435
66,0.123627,0.568330
67,0.120164,0.363997
68,0.122870,0.315281
69,0.119700,0.342551
70,0.121900,0.284629
71,0.172846,0.309891
72,0.164515,0.507158
73,0.136112,0.281998
74,0.119896,0.307751
75,0.122863,0.342100
76,0.113340,0.577982
77,0.118458,0.275687
78,0.124100,0.275926
79,0.118237,0.301850
80,0.147478,0.305362
