{
  "model_name": "mlp-trc-rate/trial_15_8ca2d8",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.16492563004255498,
    "mid_layer_count": 4,
    "mid_layer_size": 263
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 177,
    "learning_rate": 0.0008042055353266259,
    "weight_decay": 0.0005500537017284042,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.2854521931175347,
      0.09671239659004774,
      0.06931675729050797,
      0.06333320033762808,
      0.057315624220580584,
      0.0590608397712802,
      0.053244357364297126,
      0.052529315569802636,
      0.05186467774483777,
      0.05054762534961571,
      0.048080011959039076,
      0.04753376725533563,
      0.04892255780141344,
      0.04769131841244087,
      0.050273289308601796,
      0.05510647402476116,
      0.04534860986694426,
      0.04733441799344842,
      0.04234607426976243,
      0.04072697186224228,
      0.04114231511949537,
      0.04091010398144001,
      0.04363341844201531,
      0.04076081579775689,
      0.04365464302927653,
      0.039934491741783026,
      0.03777285076423585,
      0.04059990965500818,
      0.0387308753942311,
      0.04056788869598749,
      0.0381176165121585,
      0.039349958381824396,
      0.03788559397433112,
      0.03856808971231369,
      0.037070815182893534,
      0.03940250177587215,
      0.0370360537995515,
      0.036637325799823754,
      0.03626182863561426,
      0.03600980909044289,
      0.03867516308672164,
      0.03584985587895949,
      0.03502630125736008,
      0.03629313709750474,
      0.035884675256842954,
      0.03533360734127993,
      0.03578708655706938,
      0.03644155216077892,
      0.03531425901755056,
      0.040268781566739145,
      0.03413314577990072,
      0.035423990941127186,
      0.03402183054558829,
      0.03449789691418256,
      0.03421077136740685,
      0.03374638984848546,
      0.03495809371144023,
      0.036208486037301126,
      0.033568090607501516,
      0.03361778314836541,
      0.03407066471118761,
      0.03361035292712984,
      0.03443431081594359,
      0.035485541415742464,
      0.03466280428630578,
      0.033280441988108554,
      0.0323215746134424,
      0.034246330882727015,
      0.03291094668134053,
      0.03322306365489562,
      0.031820003693974,
      0.032787655987439934,
      0.03398829734042715,
      0.03461515508891261,
      0.03430576603324475,
      0.03148741616373867,
      0.03294330986294076,
      0.032010959463481675,
      0.03600409110193798,
      0.03157028991188099
    ],
    "val_loss": [
      0.4797390039943292,
      0.2129146568265236,
      0.22529841905604758,
      0.305927886876339,
      0.3011377770788298,
      0.3499213653566416,
      0.27288952619283496,
      0.3369882848782989,
      0.3478038773821767,
      0.45520521028156946,
      0.3418665437908944,
      0.29161282326289995,
      0.32397840235627695,
      0.33322151706492653,
      0.5751680991372573,
      0.376268302074851,
      0.35460172878455615,
      0.45669727623016537,
      0.4090741686567575,
      0.44160474676215006,
      0.41288246810770857,
      0.3750445240193945,
      0.36208013921842247,
      0.35855399804290183,
      0.3817725126737517,
      0.3885837431071315,
      0.42904952847159017,
      0.4844507521787982,
      0.39953341736921116,
      0.4441288251519025,
      0.43372144755756786,
      0.34666987154632806,
      0.4290111613309312,
      0.5149563835978419,
      0.3935581824636299,
      0.4661430156906832,
      0.4247269289199999,
      0.38039429073673703,
      0.45647193409480197,
      0.473513854375321,
      0.47070053033865317,
      0.4095525887443455,
      0.40315659201876847,
      0.44068846370757164,
      0.4253727370426951,
      0.34561856266356517,
      0.3948005664469061,
      0.3797752534647188,
      0.3475272576307911,
      0.37010726632472285,
      0.4611441358589305,
      0.3933060698133118,
      0.36640783533186255,
      0.4132281114810152,
      0.3792040156367832,
      0.4147928944426382,
      0.3832191840383018,
      0.4386650731062104,
      0.3960821889073192,
      0.40029639222597824,
      0.44116304244310733,
      0.4238457535544109,
      0.39383318295512726,
      0.3620392200631831,
      0.3533674082980898,
      0.38012508926745836,
      0.40631470174534234,
      0.3548327152500163,
      0.395963644626701,
      0.3187388275376337,
      0.47241109446650315,
      0.3757331998494571,
      0.3374979966225292,
      0.37660243913843605,
      0.3179731240094511,
      0.40651253888126976,
      0.3022403162586207,
      0.42260967917561887,
      0.33290776204719336,
      0.35429477217735467
    ],
    "best_epoch": 3,
    "best_val_loss": 0.22529841905604758,
    "best_val_abs_mse": 0.1735156774520874,
    "test_loss": 5.256502781615874,
    "test_abs_mse": 49.634124755859375,
    "tracker": {
      "initial_train_loss": 0.2854521931175347,
      "train_threshold": 0.09515073103917825,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.22529841905604758,
      "patience_no_improve_epochs": 78,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_15_8ca2d8/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_15_8ca2d8/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_15_8ca2d8/config.yaml"
}