{
  "model_name": "mlp-trc-rate/trial_34_a98f85",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.23277249540157638,
    "mid_layer_count": 6,
    "mid_layer_size": 440
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 371,
    "learning_rate": 0.0004478155042903518,
    "weight_decay": 0.0001598850087366592,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.5709971811100573,
      0.19579472974145362,
      0.13767727885706843,
      0.11131289783385456,
      0.09608594999778126,
      0.08641934384228236,
      0.07972235625046853,
      0.07586563848199876,
      0.07575730705015427,
      0.0716472574165153,
      0.0679660260903359,
      0.06576592782526643,
      0.06729261391724972,
      0.06688770770323221,
      0.06479129698481115,
      0.07234660469916859,
      0.0636032760958486,
      0.06435754718741601,
      0.0621586776906677,
      0.05892208391124848,
      0.059396112773504366,
      0.05753571558848841,
      0.060365988995751824,
      0.056712682930424835,
      0.0568489554338635,
      0.055102158094488235,
      0.053321642218670855,
      0.05483835465917455,
      0.05367947838103362,
      0.061010858914664366,
      0.05732627655534774,
      0.05228863640226282,
      0.051517827735937605,
      0.053362740922419154,
      0.05622200928141041,
      0.05920955732038551,
      0.05300034996501532,
      0.051379503477259655,
      0.05190872749540211,
      0.04981463215289482,
      0.05274998692278605,
      0.050892592052245306,
      0.05039867650232005,
      0.04937413886185638,
      0.047960695054663056,
      0.050141692253545485,
      0.04822884757299188,
      0.046991034142344255,
      0.04955300812123524,
      0.049783533900400856,
      0.045603821214418444,
      0.046892413542175396,
      0.04530630410247969,
      0.044420723528579724,
      0.04562829391483223,
      0.04585947382577784,
      0.05175235796970181,
      0.046609644827052085,
      0.04434198238363651,
      0.044889158330353146,
      0.04532652738345944,
      0.04281728460394676,
      0.04385569665758747,
      0.043089422689518556,
      0.04390811176541495,
      0.042333845269430015,
      0.0424883617503925,
      0.04297871830246735,
      0.04379638449875222,
      0.044822059621916883,
      0.0438490401850244,
      0.04496579175015072,
      0.04428042556501336,
      0.04250661295916543,
      0.04302421193608126,
      0.04201234999677121,
      0.04190717946323234,
      0.0412161343354921,
      0.049719330285359964,
      0.043825319178761764
    ],
    "val_loss": [
      0.5457969391328132,
      0.2872799669464905,
      0.20360915419495035,
      0.25319059912762243,
      0.19801066054956998,
      0.20091646035051275,
      0.1979384169484416,
      0.18816778905979709,
      0.19879348648343972,
      0.21087124549231664,
      0.21567773446552232,
      0.20675681890016365,
      0.25062189742833557,
      0.2257751920589519,
      0.2806082741307195,
      0.24464246302530795,
      0.25195330210074696,
      0.23379128471150726,
      0.2606493265273239,
      0.23679845862670573,
      0.24256934595299873,
      0.24767525548862662,
      0.25766223906065355,
      0.23940924238413572,
      0.2891840633082979,
      0.26269728549181703,
      0.25273511053291625,
      0.24720498262207485,
      0.24360268703232446,
      0.263800406441494,
      0.2636894154881021,
      0.25992247701628124,
      0.26512265737631363,
      0.24511841762654796,
      0.2534794310052059,
      0.26974716336427335,
      0.2622901799235337,
      0.26668820515788066,
      0.2691784102413915,
      0.27650235127769185,
      0.265087705389959,
      0.2765047157450975,
      0.2732160447198831,
      0.28193395782016706,
      0.277942958107207,
      0.28013018170695103,
      0.29593262159583456,
      0.26674392298867783,
      0.2789431315975007,
      0.29769356154953824,
      0.2876022223929713,
      0.2865180395019358,
      0.2772642394427411,
      0.2863416013056914,
      0.27836989390100547,
      0.2777262273395133,
      0.27968628119208855,
      0.2855594048086933,
      0.29062026401613644,
      0.28514653888202,
      0.2899457507872742,
      0.32313799950333233,
      0.31738662250273064,
      0.3126625990829693,
      0.3111059969770694,
      0.3135106036472999,
      0.2968591265447304,
      0.2972083750342627,
      0.3251448447397815,
      0.3318602453069594,
      0.31314085877673353,
      0.31797182068206414,
      0.3115016224230835,
      0.29618955958456156,
      0.3045851757114162,
      0.31552175128285936,
      0.32027466524793896,
      0.3342742152679377,
      0.26594233674493556,
      0.27467433179053896
    ],
    "best_epoch": 8,
    "best_val_loss": 0.18816778905979709,
    "best_val_abs_mse": 0.21010787785053253,
    "test_loss": 4.824901228458687,
    "test_abs_mse": 47.17564392089844,
    "tracker": {
      "initial_train_loss": 0.5709971811100573,
      "train_threshold": 0.19033239370335242,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.18816778905979709,
      "patience_no_improve_epochs": 72,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_34_a98f85/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_34_a98f85/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_34_a98f85/config.yaml"
}