{
  "model_name": "mlp_with_history-other-rate/trial_24_4866b3",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 126,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.34813584752200055,
    "mid_layer_count": 7,
    "mid_layer_size": 882
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 509,
    "learning_rate": 0.0018317977842029457,
    "weight_decay": 0.0009141622210569982,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7671,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 1260,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      14.271827607822456,
      0.8005089701550707,
      0.5236872891266456,
      0.45519878653018575,
      0.44231559313457836,
      0.429131998506554,
      0.4140519139400254,
      0.41540997493936843,
      0.4107928209627425,
      0.4182454037854358,
      0.39369343456039685,
      0.38784785107362846,
      0.3719142023913476,
      0.43002911471291794,
      0.3565402231919161,
      0.35692854309358646,
      0.34887914606465337,
      0.33374550779318657,
      0.37344811185601945,
      0.33512447096660913,
      0.3411848446821206,
      0.3312910201768337,
      0.318446319508997,
      0.3399347846223018,
      0.31674550724470885,
      0.31832953099476563,
      0.3100303193026642,
      0.3132419697488711,
      0.29992492426064904,
      0.2970767436609043,
      0.3243370149355018,
      0.2998510409622953,
      0.29896632998136663,
      0.2888395451587177,
      0.2935330021561645,
      0.2857804211919365,
      0.2884663131849005,
      0.2900240310143498,
      0.2751088567926029,
      0.27354205257266956,
      0.27646032521209074,
      0.27475109878597725,
      0.26599624357693136,
      0.2591437454380434,
      0.2592876395996135,
      0.2548940517498794,
      0.25777629657894113,
      0.2601139777981152,
      0.25759527836834617,
      0.2480975213448362,
      0.2493790491896772,
      0.24617211006289433,
      0.24963197173855944,
      0.24093869070142115,
      0.25093736774124825,
      0.23627118965417337,
      0.23642957693648423,
      0.23507519706203736,
      0.23169448191821848,
      0.2281328860018123,
      0.22481699787316306,
      0.23115241879155624,
      0.23028922841300586,
      0.2319059362410411,
      0.23766448233082837,
      0.22745155657212654,
      0.22551186598391565,
      0.22881338632980144,
      0.21815873346246684,
      0.22756800045596934,
      0.21730504989655103,
      0.2165901829356119,
      0.21733054957711825,
      0.22398894177143927,
      0.21129211411414284,
      0.20791948285901302,
      0.2040827845698804,
      0.22015461606729794,
      0.2117579772169036,
      0.20607728977205544
    ],
    "val_loss": [
      0.7123645735714964,
      0.4808649864650058,
      0.5985724795899705,
      0.49247209027320327,
      0.4713580351925182,
      0.4705473736731592,
      0.4806843118307119,
      0.6053335829230839,
      0.6869523622675571,
      0.5209222565243344,
      0.6611550184959423,
      0.5557573220062398,
      0.7152332446710792,
      0.6789394632874135,
      0.6188729704318646,
      0.5596578681094204,
      0.6450454088206776,
      0.5622501500173958,
      0.5453238407562593,
      0.6020944231195364,
      0.568667739540517,
      0.5762802123220381,
      0.714449139635363,
      0.5837847817176116,
      0.5620036528674428,
      0.5678936892551576,
      0.5920172900496843,
      0.5610722778889233,
      0.5504698097348927,
      0.6004523859275672,
      0.5763705670833588,
      0.5587352673896773,
      0.5693366042421963,
      0.5756811316677196,
      0.5666231881447895,
      0.5675020748269772,
      0.5610758776614766,
      0.547191779172706,
      0.5554425231353965,
      0.5510027054362668,
      0.5632234247947882,
      0.561349438407464,
      0.5528416898079261,
      0.5402205177588377,
      0.5372533717287514,
      0.5835309713008161,
      0.5901690244139312,
      0.5216539989866896,
      0.5329585473159116,
      0.5138630390078008,
      0.5619071928594641,
      0.5624851648679037,
      0.5465339126701126,
      0.5350226936404576,
      0.5215126303677073,
      0.49746733496110596,
      0.5564340316517624,
      0.5384547123830475,
      0.530935032576501,
      0.5521528199315071,
      0.5375525917924807,
      0.5763075776888938,
      0.5586730151387032,
      0.535429221320295,
      0.5477332105447432,
      0.5830032374062938,
      0.48802406414004856,
      0.5791994507173578,
      0.5290814428540047,
      0.524054046055514,
      0.514156697208653,
      0.6147986490301743,
      0.5987605098924951,
      0.5155981191082629,
      0.5216946290460175,
      0.4971811194708961,
      0.6382383945637834,
      0.5019818372087564,
      0.4744722966394739,
      0.5448203702708204
    ],
    "best_epoch": 6,
    "best_val_loss": 0.4705473736731592,
    "best_val_abs_mse": 0.5485633015632629,
    "test_loss": 0.5645028358797708,
    "test_abs_mse": 1.184340238571167,
    "tracker": {
      "initial_train_loss": 14.271827607822456,
      "train_threshold": 4.757275869274152,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4705473736731592,
      "patience_no_improve_epochs": 74,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-rate/trial_24_4866b3/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-rate/trial_24_4866b3/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-rate/trial_24_4866b3/config.yaml"
}