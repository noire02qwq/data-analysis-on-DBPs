{
  "model_name": "mlp-trc-value/trial_12_d37e35",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.3251661626209841,
    "mid_layer_count": 8,
    "mid_layer_size": 147
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 322,
    "learning_rate": 0.0006493404519688691,
    "weight_decay": 0.0002453212816105531,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.4737405003936796,
      0.17007083388254726,
      0.12410790155359328,
      0.1031615288250565,
      0.09398163622651362,
      0.08990867432873943,
      0.08267771021647903,
      0.07613486427337833,
      0.07677196682631021,
      0.0738982476538698,
      0.07191509750216298,
      0.07144406502860946,
      0.06651463359785484,
      0.06746011879534033,
      0.06711752456983217,
      0.0655840394235746,
      0.06539048317087773,
      0.060155300637578096,
      0.06366533998317783,
      0.06205972743575667,
      0.060745872369847465,
      0.0579415451937865,
      0.05796932415026558,
      0.05567515271024376,
      0.057106700909824296,
      0.05663379778623917,
      0.054663776077440974,
      0.05533994178074088,
      0.05367293644824537,
      0.05649228511008316,
      0.05396120995569835,
      0.05396444298969195,
      0.05278561550410911,
      0.05244164979835545,
      0.05108681666818168,
      0.04969678041245645,
      0.0498928860491242,
      0.0476920897252915,
      0.05050209947618507,
      0.04926835030810444,
      0.050936959634199086,
      0.04910841064404346,
      0.04747979339496976,
      0.04796900263695517,
      0.0482206182069828,
      0.047321488525529226,
      0.046353897129521426,
      0.04766898966461741,
      0.045456640366914026,
      0.04667805112313466,
      0.04677429628783523,
      0.04619478333976527,
      0.04538101863102646,
      0.0458550017915777,
      0.04497690611696201,
      0.043579563473649,
      0.04372028547270809,
      0.04493760014227135,
      0.04410476192809056,
      0.04520354536445616,
      0.04415106958111872,
      0.04390379408228208,
      0.04258374774923167,
      0.0436367475608791,
      0.04222666249902448,
      0.04358102865956758,
      0.04292522894726037,
      0.043561419002853215,
      0.04202190232393893,
      0.04226025125310934,
      0.042369390298359635,
      0.04147011423822762,
      0.04374867075219896,
      0.042115043523817446,
      0.04219741052376912,
      0.04217121084476355,
      0.042386185484873815,
      0.04161134406851615,
      0.04182363980917548,
      0.04315578693159884
    ],
    "val_loss": [
      0.26756379647169287,
      0.2508259646996053,
      0.22790740688225467,
      0.20356225790734778,
      0.20254135671222281,
      0.200555000161964,
      0.2111462158223469,
      0.20666638199173049,
      0.21251047945352727,
      0.21218320240829877,
      0.22106706057703066,
      0.2199904081640308,
      0.22475418150424958,
      0.22377122471521715,
      0.23649268716261415,
      0.22731410834023696,
      0.2292659880136123,
      0.2374182114121086,
      0.24358985079173556,
      0.23824411018745986,
      0.24307764997694664,
      0.25118623735037393,
      0.24673948774259247,
      0.244057096143861,
      0.2595217390376294,
      0.26372394806030625,
      0.2514666218020602,
      0.25397300807658785,
      0.26195156375715833,
      0.2809208134735773,
      0.27517492385235376,
      0.27819790362107183,
      0.2855224592399276,
      0.2913120116101589,
      0.27386886977373126,
      0.28333929173514516,
      0.2801562554710461,
      0.28519122672607444,
      0.28062405521328937,
      0.28443407431289464,
      0.2851114206417592,
      0.29149033376378214,
      0.2966731854853873,
      0.2974204852530164,
      0.30775910359835196,
      0.3094644759720314,
      0.3236513063177734,
      0.29436774490077694,
      0.3120137572087749,
      0.2901239684621196,
      0.3007749524435954,
      0.3070160203685839,
      0.30257704269564795,
      0.31082113823089413,
      0.3022172904143969,
      0.3173875896137453,
      0.3038184089351914,
      0.30040124739760055,
      0.30586538271320435,
      0.3121748238132742,
      0.3027798217325332,
      0.3040100867631371,
      0.3064669179613005,
      0.29839994099861133,
      0.3227855887397856,
      0.31192152700916737,
      0.3156330878394628,
      0.30593274764181255,
      0.31666560882624395,
      0.3246477817570021,
      0.3054100705031863,
      0.3205620815319394,
      0.3127570207916691,
      0.3035341816859509,
      0.3200973683064748,
      0.3198191154725894,
      0.30336950173501126,
      0.30869594808600975,
      0.315980318641502,
      0.30469052026684057
    ],
    "best_epoch": 6,
    "best_val_loss": 0.200555000161964,
    "test_loss": 4.67776128778047,
    "tracker": {
      "initial_train_loss": 0.4737405003936796,
      "train_threshold": 0.15791350013122654,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.200555000161964,
      "patience_no_improve_epochs": 74,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_12_d37e35/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_12_d37e35/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_12_d37e35/config.yaml"
}