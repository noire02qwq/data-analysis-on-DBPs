epoch,train_loss,val_loss
1,1.160439,2.505341
2,0.705842,0.542027
3,0.478107,0.535107
4,0.438548,0.737917
5,0.429872,0.513377
6,0.398640,0.563687
7,0.390642,0.543561
8,0.360454,0.564010
9,0.336262,0.594111
10,0.328443,0.518365
11,0.317413,0.492343
12,0.306289,0.531995
13,0.302906,0.488713
14,0.295719,0.494185
15,0.298410,0.492127
16,0.295784,0.577475
17,0.308562,0.555493
18,0.287279,0.501862
19,0.289512,0.502868
20,0.280563,0.547159
21,0.279920,0.560322
22,0.282163,0.556696
23,0.277182,0.497627
24,0.277377,0.517616
25,0.276643,0.621606
26,0.277804,0.479753
27,0.273607,0.479935
28,0.271111,0.496310
29,0.276407,0.477775
30,0.274868,0.398511
31,0.268726,0.445136
32,0.267056,0.465634
33,0.265666,0.463890
34,0.270983,0.532815
35,0.269010,0.483661
36,0.266326,0.463588
37,0.265728,0.483117
38,0.264471,0.551656
39,0.262799,0.555788
40,0.262180,0.503534
41,0.351474,0.585766
42,0.296905,0.466591
43,0.279002,0.577481
44,0.265054,0.497421
45,0.269996,0.475149
46,0.262852,0.605849
47,0.265914,0.509586
48,0.258973,0.502637
49,0.263627,0.477999
50,0.260386,0.494115
51,0.268742,0.498611
52,0.264352,0.574271
53,0.266787,0.567562
54,0.258250,0.478716
55,0.256534,0.530420
56,0.274392,0.513300
57,0.260950,0.450780
58,0.272382,0.459722
59,0.257572,0.486283
60,0.268363,0.506335
61,0.262291,0.497214
62,0.254155,0.490161
63,0.254866,0.531270
64,0.266080,0.510133
65,0.297940,0.508466
66,0.285594,0.568039
67,0.261082,0.430622
68,0.257206,0.554745
69,0.263802,0.470384
70,0.258252,0.467493
71,0.256300,0.558414
72,0.260256,0.507053
73,0.276539,0.479046
74,0.270187,0.459102
75,0.255081,0.510721
76,0.272181,0.623738
77,0.258083,0.463081
78,0.312781,0.643010
79,0.307123,0.456780
80,0.273413,0.493732
