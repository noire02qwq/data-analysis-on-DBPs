epoch,train_loss,val_loss
1,1.041769,0.390827
2,0.481303,0.322941
3,0.220191,0.236235
4,0.170535,0.201399
5,0.162649,0.206017
6,0.154592,0.199056
7,0.149177,0.303602
8,0.157153,0.230894
9,0.149799,0.269824
10,0.162679,0.329917
11,0.146781,0.266696
12,0.138893,0.256831
13,0.135629,0.267006
14,0.134349,0.501937
15,0.142468,0.244099
16,0.130506,0.282777
17,0.132168,0.298565
18,0.132458,0.270256
19,0.135148,0.255662
20,0.133793,0.278508
21,0.128164,0.273404
22,0.123657,0.289962
23,0.123665,0.271635
24,0.120728,0.265490
25,0.130902,0.264480
26,0.133140,0.269698
27,0.118779,0.297393
28,0.119445,0.265313
29,0.119166,0.309321
30,0.129656,0.278396
31,0.119650,0.273914
32,0.114567,0.278273
33,0.116864,0.279874
34,0.144611,0.272880
35,0.122188,0.274734
36,0.112845,0.273386
37,0.111537,0.259936
38,0.114669,0.265006
39,0.119694,0.337313
40,0.118985,0.268221
41,0.113786,0.290110
42,0.110712,0.267121
43,0.117279,0.270248
44,0.116990,0.280793
45,0.216088,0.228548
46,0.158718,0.248130
47,0.135880,0.294133
48,0.121966,0.255098
49,0.126185,0.278551
50,0.116647,0.284932
51,0.119828,0.277531
52,0.114275,0.266078
53,0.114808,0.272254
54,0.112721,0.273897
55,0.109078,0.265525
56,0.107122,0.276332
57,0.116912,0.367243
58,0.114038,0.267541
59,0.110144,0.276853
60,0.111663,0.266224
61,0.104666,0.260526
62,0.110417,0.272108
63,0.113346,0.281158
64,0.105478,0.266609
65,0.107750,0.268481
66,0.107033,0.315779
67,0.105135,0.269968
68,0.102140,0.275347
69,0.111312,0.274775
70,0.116684,0.276029
71,0.113770,0.273324
72,0.113404,0.297256
73,0.104152,0.280847
74,0.112380,0.276898
75,0.103849,0.275779
76,0.102835,0.267929
77,0.102208,0.279422
78,0.105063,0.277670
79,0.102240,0.275519
80,0.100273,0.302937
