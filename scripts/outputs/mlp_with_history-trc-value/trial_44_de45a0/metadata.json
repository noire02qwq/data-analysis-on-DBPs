{
  "model_name": "mlp_with_history-trc-value/trial_44_de45a0",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 48,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.2714480614256701,
    "mid_layer_count": 2,
    "mid_layer_size": 823
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 511,
    "learning_rate": 0.0010664297922936081,
    "weight_decay": 0.00153739929821782,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7749,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 480,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117
    ],
    "train_loss": [
      0.7782324474463079,
      0.29507790476272205,
      0.15729232124358336,
      0.13373638104644034,
      0.1317780369450191,
      0.12182625369004764,
      0.1274035687624816,
      0.12068805341501977,
      0.12339676215288978,
      0.11579306046087244,
      0.11171279315245292,
      0.12121958467291623,
      0.1148536371735161,
      0.11064721078569004,
      0.1250873141414751,
      0.12046983383104623,
      0.11980504020981242,
      0.1166234064137171,
      0.10560130698113368,
      0.10764642147298535,
      0.10208189243815886,
      0.10504898033167935,
      0.10761596286684517,
      0.10716374657287615,
      0.10835620738034218,
      0.10404014032815315,
      0.10786960112450891,
      0.11420129603675172,
      0.10398087068355719,
      0.10720141168074664,
      0.09941957774551041,
      0.10767029001703107,
      0.09948336098144586,
      0.11972534007711677,
      0.10768433719496524,
      0.10061204926781322,
      0.10289964397532937,
      0.13557556422314562,
      0.11095433785178797,
      0.1015283588686825,
      0.10538570056547425,
      0.09849441289740203,
      0.09522057511753722,
      0.09991457772987214,
      0.09835608504113574,
      0.09695020978959057,
      0.10218055100056538,
      0.09727070408569549,
      0.09314235032627792,
      0.0965585306004134,
      0.09347954426085292,
      0.09766509177292804,
      0.09450146679067353,
      0.09308795429019101,
      0.09698563842430993,
      0.0910590888348483,
      0.08907978460798419,
      0.0897974910613321,
      0.094319780162841,
      0.3198446581424521,
      0.9122445293935226,
      1.020056939060449,
      0.9432359385188894,
      0.7098658502155741,
      0.41020619628282956,
      0.22714034490145965,
      0.20663569299563053,
      0.19384949201383134,
      0.1689419129757377,
      0.17020943429734972,
      0.16510780388531432,
      0.15855125406489462,
      0.16292625781427986,
      0.16947318445268578,
      0.17256537851117815,
      0.1529446960626256,
      0.15504174786531505,
      0.16542881032638757,
      0.1543437670966797,
      0.14815435022142628,
      0.16448681628585615,
      0.15516325126064717,
      0.15004576143641243,
      0.15050367642843518,
      0.14726576612893805,
      0.14577250266758945,
      0.15298266801730728,
      0.1592830197840202,
      0.1495340404444809,
      0.15370960183636823,
      0.14877050106145287,
      0.13622399745298702,
      0.13956827362755342,
      0.1353639346070406,
      0.13522150452974796,
      0.1250292766761866,
      0.1264474805791096,
      0.12554619269480874,
      0.1224648489902013,
      0.11178134332638984,
      0.10953083083154709,
      0.1108458302275706,
      0.10578059537004757,
      0.11106844418686365,
      0.10559364922459102,
      0.10335232114188823,
      0.10132116700548682,
      0.10524927857041683,
      0.10607191630199134,
      0.10179851198772535,
      0.10489807044372111,
      0.10341174632660849,
      0.10014595349118208,
      0.09963939093261984,
      0.10391549830002729,
      0.09865194449391361,
      0.09529632731747174
    ],
    "val_loss": [
      0.33709027654307333,
      0.22025881363023184,
      0.253733955169777,
      0.34522367555670397,
      0.2125281949466217,
      0.28495071749398093,
      0.2337529566674354,
      0.22472381872085934,
      0.24264856695481937,
      0.2743045968745283,
      0.2622297987431109,
      0.2503308759277274,
      0.26093561090082823,
      0.4269159349473472,
      0.3334740937559191,
      0.43071187795613874,
      0.22778650109550197,
      0.23703781649760322,
      0.26070672985456306,
      0.32578045707084463,
      0.3559280024919503,
      0.2727939314292577,
      0.2838879766176918,
      0.32379622221617643,
      0.26319502517580984,
      0.24910859565981133,
      0.280230598919049,
      0.2717277619786962,
      0.3131745636162019,
      0.3140822428808419,
      0.28341624175092417,
      0.32504434723206266,
      0.40403801432760533,
      0.27323222832787714,
      0.2864579408647058,
      0.2971052653864472,
      0.2740886613146631,
      0.2820267268930545,
      0.2808814579431347,
      0.28824721170801243,
      0.30981840439542324,
      0.27561916057578106,
      0.321341432819511,
      0.32315510849128226,
      0.33942657602047493,
      0.3022517479220015,
      0.2545059258932482,
      0.2893450951661,
      0.28120363730223413,
      0.2845407614450969,
      0.2968799020983502,
      0.2755681374740458,
      0.35923085704468144,
      0.299201928453888,
      0.27795392249649514,
      0.3489242918544008,
      0.36627729484131055,
      0.36834930494249224,
      0.2949099159771632,
      0.3135671136131187,
      0.3945076358889391,
      0.3784612271421684,
      0.3071671725568657,
      0.24901676457263752,
      0.20479109149961594,
      0.19494157618658986,
      0.17805034269071268,
      0.1966822431606804,
      0.20634822791698806,
      0.21551103494102192,
      0.2141210785637537,
      0.22447156233121893,
      0.2230810506258182,
      0.2507645238146275,
      0.2934093349284219,
      0.23119860529498068,
      0.2476026914322269,
      0.267532378488672,
      0.2427186172410935,
      0.24903314494399612,
      0.2609529134666848,
      0.2358076821321142,
      0.2886563757322952,
      0.2430413571994997,
      0.2642249916998034,
      0.25761633134575307,
      0.24286918833762586,
      0.3224516725446471,
      0.26111275436367815,
      0.25248932808994534,
      0.24748273383781402,
      0.2832211325748149,
      0.2620800329472669,
      0.2578416988298208,
      0.2660746425434858,
      0.2732129003161085,
      0.2971828023451353,
      0.2893935642935737,
      0.2626355234823541,
      0.3345761433968733,
      0.24083730432980074,
      0.2596446797675537,
      0.2887774753133337,
      0.2661533887871725,
      0.26652541540250807,
      0.258895951701317,
      0.32235603612139374,
      0.27784289807348905,
      0.25894731727099707,
      0.2736091574230148,
      0.26321425923999553,
      0.28200946905521934,
      0.25752765951667006,
      0.3080833006873281,
      0.30395891478028664,
      0.2740389138594002,
      0.2798826431643642
    ],
    "best_epoch": 67,
    "best_val_loss": 0.17805034269071268,
    "test_loss": 4.414941782942799,
    "tracker": {
      "initial_train_loss": 0.7782324474463079,
      "train_threshold": 0.25941081581543596,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.17805034269071268,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_44_de45a0/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_44_de45a0/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_44_de45a0/config.yaml"
}