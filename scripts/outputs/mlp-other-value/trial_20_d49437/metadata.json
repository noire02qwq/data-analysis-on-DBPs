{
  "model_name": "mlp-other-value/trial_20_d49437",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.15660531346541018,
    "mid_layer_count": 15,
    "mid_layer_size": 429
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 146,
    "learning_rate": 0.0017441832890297997,
    "weight_decay": 0.0007273978540167325,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113
    ],
    "train_loss": [
      0.3129368662153714,
      0.20610537051221786,
      0.18731630347734113,
      0.1725260822657685,
      0.16249409084590108,
      0.15522437039791406,
      0.14999632888486472,
      0.14316389125400533,
      0.14015763754903382,
      0.1358660870925043,
      0.13575504365649022,
      0.13222697954061033,
      0.1301205155423906,
      0.12663924151992356,
      0.12665302523929317,
      0.1282965145764319,
      0.12030192579846617,
      0.11929575604252353,
      0.1187084307134335,
      0.11813828146124326,
      0.11673298500107458,
      0.11524815246531632,
      0.11446344568989043,
      0.11320960199056129,
      0.11383511087622564,
      0.10922318861354859,
      0.10832861058410159,
      0.10929902275788166,
      0.10872883705939312,
      0.10717866694188656,
      0.104191408507438,
      0.10570430815059323,
      0.10871920413722315,
      0.1046250783893284,
      0.10555532633906575,
      0.10686438862500036,
      0.10605135051033752,
      0.10489226400607546,
      0.10698836414920421,
      0.10207642357760115,
      0.10238366653562632,
      0.1033493992191605,
      0.10008116816292364,
      0.09954107926824939,
      0.10004716902099677,
      0.10160579141124265,
      0.099099204265319,
      0.09979517132105002,
      0.09970122542119503,
      0.10031053926575911,
      0.10077077097590609,
      0.09883728553815767,
      0.09746009177538356,
      0.10019846876778317,
      0.09666922563479581,
      0.09706351463766573,
      0.09796488833823468,
      0.09566252763115975,
      0.09640376168896199,
      0.09639799462420137,
      0.0968155226435583,
      0.09583860372941944,
      0.09606318542969845,
      0.09618189947353747,
      0.09427052951122077,
      0.09594574393661527,
      0.09740715458216943,
      0.09600023492375602,
      0.09626272306603123,
      0.09495946419940905,
      0.0935526263253575,
      0.09390549442939664,
      0.09345049253560263,
      0.09437080965080648,
      0.0936665962301596,
      0.0941275821042067,
      0.0929559900508042,
      0.09549929485061402,
      0.09354371469316879,
      0.0959122227366274,
      0.09410475928999633,
      0.09493707180627191,
      0.09203443801046764,
      0.09370592389238559,
      0.09481944933174329,
      0.09013578206254862,
      0.09245071007371744,
      0.09431849463076822,
      0.09246232934781623,
      0.09242107750147413,
      0.0925847238007113,
      0.0923258481100928,
      0.09262621791325146,
      0.09277397038662599,
      0.09336121006462132,
      0.09279491306077584,
      0.0908930198566127,
      0.09359362578280404,
      0.09206183799272503,
      0.09240986281033967,
      0.0907562320383926,
      0.09265316363372456,
      0.09080019785715349,
      0.09054460491948767,
      0.09178767946016916,
      0.09364566497271522,
      0.09099173992910466,
      0.09206631414213812,
      0.09068437003788121,
      0.09063220109930095,
      0.0902779096992674,
      0.09197219069177459,
      0.09138628664599008
    ],
    "val_loss": [
      0.38835088946148305,
      0.5152758112656856,
      0.5078606781488407,
      0.5201049924610618,
      0.6109160449065848,
      0.6273545638619069,
      0.5393162963633051,
      0.7236572988286704,
      0.6277113146856873,
      0.5835730441405388,
      0.6378346734507355,
      0.5690558018530915,
      0.530939978825118,
      0.49631442312530416,
      0.47128803309744705,
      0.4721490639234017,
      0.5411182116159422,
      0.5816216993474674,
      0.5135699786558122,
      0.5010819922842665,
      0.47180613483675937,
      0.4944298077218547,
      0.48761909651363683,
      0.47506492609035467,
      0.4959304469877374,
      0.5594160293747565,
      0.522621775030376,
      0.47780734686972853,
      0.5400549683028353,
      0.48446922857247426,
      0.44390609059148206,
      0.47692719267870853,
      0.5261317797228248,
      0.44079077771145425,
      0.44180423660192664,
      0.5195808587986195,
      0.41256422907292484,
      0.45474296748459697,
      0.46332014290515533,
      0.5221537227937562,
      0.4273589271628214,
      0.5371247000679998,
      0.449911357292872,
      0.43854927218959716,
      0.5342674592788705,
      0.4763794206305892,
      0.4605268285481516,
      0.41407945685222475,
      0.48943293221339496,
      0.49083119604045045,
      0.4166130165496986,
      0.43498711551199415,
      0.42431099342550344,
      0.46664021718287896,
      0.5012744388626721,
      0.4414739562455052,
      0.46948934300930917,
      0.5126372039496542,
      0.5077665258756655,
      0.45204256580261415,
      0.4505380625585596,
      0.45563230523449216,
      0.3964864733154902,
      0.45176007463903484,
      0.4586613530527332,
      0.40596269500291277,
      0.4622590484197982,
      0.4359181810549633,
      0.4534018767094184,
      0.4524945758416981,
      0.447727479442151,
      0.4726595437366092,
      0.4293478726091499,
      0.431123231324607,
      0.4596639343542967,
      0.41834899816149007,
      0.49391449288336814,
      0.473337660319434,
      0.4394269626833008,
      0.4469883158267615,
      0.45524971306680917,
      0.4748824392964026,
      0.49443003637883476,
      0.4375848474795233,
      0.4534584504580069,
      0.40362708217012666,
      0.45468618311211023,
      0.42023971940942867,
      0.461275456506692,
      0.4168679713578281,
      0.43342438663194277,
      0.4793866086238159,
      0.47099130123764454,
      0.47022747934578424,
      0.43223240186354356,
      0.4345382878166473,
      0.46285316641637664,
      0.43843224071813913,
      0.44201222088879455,
      0.42283833869203125,
      0.4252639316870067,
      0.4096372803706609,
      0.47554619361362055,
      0.39945392087548076,
      0.4278004399049068,
      0.5082382749743805,
      0.4422807638516683,
      0.4419140473186613,
      0.44413445520543765,
      0.46277971082997177,
      0.48122727797773784,
      0.47178986742646395,
      0.4106299755191375
    ],
    "best_epoch": 63,
    "best_val_loss": 0.3964864733154902,
    "test_loss": 0.5021445436857677,
    "tracker": {
      "initial_train_loss": 0.3129368662153714,
      "train_threshold": 0.10431228873845715,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3964864733154902,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_20_d49437/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_20_d49437/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_20_d49437/config.yaml"
}