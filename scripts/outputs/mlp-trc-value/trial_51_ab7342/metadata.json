{
  "model_name": "mlp-trc-value/trial_51_ab7342",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.23949381734257807,
    "mid_layer_count": 13,
    "mid_layer_size": 153
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 170,
    "learning_rate": 0.0006161194373907052,
    "weight_decay": 0.0004521854658089349,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.3268754858353494,
      0.10492445819037825,
      0.08095663248070574,
      0.07095843194202621,
      0.06916840653532037,
      0.06249154611213994,
      0.061558220360624964,
      0.06108415933022932,
      0.05968818851312256,
      0.05450864582049687,
      0.05462591116411708,
      0.05251756287048479,
      0.05271989580868849,
      0.0507951761940432,
      0.04954123542022405,
      0.049083595548786524,
      0.051521995239124166,
      0.0463321786335626,
      0.04686565346262772,
      0.047620212348639626,
      0.04626385271912388,
      0.045731874994203454,
      0.045987108584709384,
      0.04421662311597688,
      0.043894809263143375,
      0.04292204291519139,
      0.04264005222689913,
      0.04278268415209435,
      0.04208615831333117,
      0.041160046148294056,
      0.041266165124209435,
      0.041026209273197334,
      0.0403541813696758,
      0.04098945076631362,
      0.041057841536928714,
      0.0395389992051809,
      0.03991010470154302,
      0.040445152306503945,
      0.040290199510711104,
      0.03849326325136081,
      0.041192571304761456,
      0.039212860893830845,
      0.03942688701893196,
      0.03886836126309104,
      0.039934181173897326,
      0.03834942912156304,
      0.038591722362871166,
      0.03811316289248498,
      0.03998122253613389,
      0.0359846703433888,
      0.036675216750040644,
      0.03689922113162683,
      0.037358308695983035,
      0.03704076507231512,
      0.03787489254180516,
      0.037226018568490366,
      0.036677683266371934,
      0.03801371784486056,
      0.03609505145231873,
      0.03528898740985291,
      0.036147860174624964,
      0.0350487725670641,
      0.037330475200030695,
      0.037716952359935545,
      0.03503159403976812,
      0.03579261163015467,
      0.036678731500272906,
      0.03478831076003485,
      0.03604038311202001,
      0.03577381736809639,
      0.034364528882829974,
      0.034570457663228416,
      0.034718818275908774,
      0.03612175287765806,
      0.03655305477943923,
      0.035928855042784195,
      0.034942250489030297,
      0.03582820578551387,
      0.03489436599267804,
      0.03439316563231783
    ],
    "val_loss": [
      0.2739996925710204,
      0.18583841886215224,
      0.21353627683338292,
      0.28188049402868676,
      0.22181405176124172,
      0.24388245351523338,
      0.23486582519943844,
      0.2440137139404427,
      0.26094145093581633,
      0.26573289859437654,
      0.29658015442644053,
      0.2717348664976701,
      0.26569638656686523,
      0.2930436971636411,
      0.3210202914935921,
      0.29577421628964873,
      0.33793783371900016,
      0.30224358120899714,
      0.2986457944139392,
      0.33507890713785937,
      0.3069426967332998,
      0.29738270515899456,
      0.2972208611600235,
      0.3146657167102941,
      0.29730555870218905,
      0.29375912643924446,
      0.3122697083870629,
      0.3315288011029273,
      0.3265489317744435,
      0.31108008965314504,
      0.314969742191052,
      0.3165890227914035,
      0.3282284067084868,
      0.3234009402664657,
      0.3351315603017093,
      0.32544210718241995,
      0.33455933506661906,
      0.3409730512537285,
      0.32299705322631106,
      0.3353919818395091,
      0.3344669133469373,
      0.31820111880134677,
      0.3200885130393648,
      0.3631278971310504,
      0.35111653481325705,
      0.35483586740217166,
      0.3590811658539101,
      0.3286898241317022,
      0.3389439961488197,
      0.32448114550666896,
      0.34628759276590304,
      0.32442094043209524,
      0.3221838867436804,
      0.33922838879202655,
      0.32848875974109787,
      0.3325795614143867,
      0.33192006303387844,
      0.3289843303246234,
      0.34543389263758045,
      0.3458756196262415,
      0.3393623259275438,
      0.35148932227117574,
      0.34293044593832095,
      0.33905633691765236,
      0.3299203719943762,
      0.33692540584165537,
      0.3389682997196556,
      0.328307216061268,
      0.3201804875457537,
      0.31396185117076614,
      0.35768869837110273,
      0.3367002538243632,
      0.3328243697920959,
      0.3293419627327762,
      0.34541548204100775,
      0.3243634658726211,
      0.32544640817506587,
      0.335276726666771,
      0.3361547634250925,
      0.3185547873556257
    ],
    "best_epoch": 2,
    "best_val_loss": 0.18583841886215224,
    "test_loss": 4.8534462660123285,
    "tracker": {
      "initial_train_loss": 0.3268754858353494,
      "train_threshold": 0.10895849527844981,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.18583841886215224,
      "patience_no_improve_epochs": 79,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_51_ab7342/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_51_ab7342/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_51_ab7342/config.yaml"
}