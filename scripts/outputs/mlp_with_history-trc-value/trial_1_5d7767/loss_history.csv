epoch,train_loss,val_loss
1,0.999812,0.353255
2,0.999211,0.351596
3,0.999467,0.353050
4,0.999238,0.351676
5,0.999240,0.350989
6,0.999230,0.351615
7,0.999158,0.351733
8,0.999241,0.352262
9,0.999188,0.350368
10,0.999293,0.349538
11,0.999224,0.350903
12,0.999093,0.351102
13,0.999204,0.351145
14,0.999235,0.353218
15,0.999211,0.352560
16,0.999233,0.351465
17,0.999211,0.350780
18,0.999195,0.352386
19,0.999154,0.351492
20,0.999135,0.351093
21,0.999235,0.352089
22,0.999172,0.351386
23,0.999206,0.351868
24,0.999166,0.350944
25,0.999176,0.350650
26,0.999176,0.351088
27,0.999177,0.350102
28,0.999194,0.351140
29,0.999170,0.350807
30,0.999157,0.351555
31,0.999158,0.351103
32,0.999182,0.349671
33,0.999219,0.351055
34,0.999174,0.350073
35,0.999163,0.349905
36,0.999180,0.350994
37,0.999172,0.350433
38,0.999158,0.350373
39,0.999189,0.350375
40,0.999169,0.350509
41,0.999161,0.350570
42,0.999176,0.349915
43,0.999191,0.350518
44,0.999166,0.350939
45,0.999180,0.350955
46,0.999171,0.351170
47,0.999176,0.350624
48,0.999199,0.351365
49,0.999151,0.350827
50,0.999159,0.350623
51,0.999176,0.350661
52,0.999170,0.351159
53,0.999151,0.350656
54,0.999171,0.350256
55,0.999144,0.351090
56,0.999175,0.352247
57,0.999159,0.350993
58,0.999155,0.351198
59,0.999196,0.350803
60,0.999163,0.352159
61,0.999176,0.351199
62,0.999166,0.351584
63,0.999163,0.351814
64,0.999155,0.352029
65,0.999180,0.351294
66,0.999165,0.351952
67,0.999182,0.351411
68,0.999177,0.351853
69,0.999171,0.352570
70,0.999181,0.352226
71,0.999157,0.352230
72,0.999162,0.352788
73,0.999180,0.353005
74,0.999228,0.350995
75,0.999155,0.352056
76,0.999154,0.351448
77,0.999157,0.350834
78,0.999160,0.350786
79,0.999170,0.352307
80,0.999161,0.351439
81,0.999152,0.350997
82,0.999159,0.351206
