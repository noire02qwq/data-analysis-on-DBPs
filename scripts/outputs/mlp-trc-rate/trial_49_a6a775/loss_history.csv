epoch,train_loss,val_loss
1,0.528146,0.359850
2,0.175658,0.321776
3,0.127682,0.212458
4,0.105266,0.205897
5,0.091703,0.196914
6,0.085813,0.204963
7,0.081693,0.229699
8,0.075937,0.214423
9,0.074577,0.221705
10,0.070898,0.222032
11,0.070653,0.221198
12,0.070008,0.219855
13,0.067349,0.228883
14,0.066042,0.232120
15,0.065079,0.256570
16,0.062714,0.247322
17,0.060477,0.241976
18,0.062186,0.244041
19,0.060646,0.262722
20,0.058623,0.260116
21,0.057561,0.244142
22,0.057523,0.263761
23,0.059016,0.249838
24,0.056676,0.253465
25,0.056358,0.262208
26,0.053376,0.261930
27,0.054656,0.257467
28,0.053158,0.258922
29,0.053562,0.271036
30,0.052923,0.282977
31,0.051335,0.269465
32,0.051924,0.280399
33,0.050937,0.293808
34,0.050885,0.269338
35,0.050060,0.273043
36,0.050754,0.283732
37,0.048980,0.278181
38,0.049955,0.276784
39,0.050398,0.291626
40,0.047561,0.285982
41,0.048824,0.287630
42,0.048261,0.278688
43,0.046585,0.283986
44,0.049091,0.283589
45,0.047406,0.301163
46,0.050262,0.321254
47,0.046712,0.326721
48,0.046733,0.293876
49,0.046991,0.307579
50,0.046199,0.296555
51,0.046356,0.303856
52,0.045612,0.293625
53,0.046359,0.298215
54,0.045863,0.294296
55,0.044865,0.295902
56,0.043653,0.310009
57,0.044097,0.325228
58,0.044480,0.296729
59,0.044830,0.292345
60,0.043392,0.300673
61,0.043831,0.314185
62,0.044954,0.315867
63,0.042873,0.303441
64,0.043289,0.308780
65,0.042668,0.315955
66,0.042751,0.326759
67,0.042564,0.312291
68,0.042254,0.312897
69,0.044150,0.308689
70,0.042387,0.312032
71,0.041794,0.307988
72,0.042509,0.310317
73,0.041813,0.325544
74,0.041074,0.309299
75,0.041624,0.332905
76,0.040617,0.326696
77,0.042015,0.337863
78,0.040876,0.328259
79,0.041580,0.313237
80,0.041178,0.308744
