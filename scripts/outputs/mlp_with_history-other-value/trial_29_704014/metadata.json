{
  "model_name": "mlp_with_history-other-value/trial_29_704014",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 58,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.4453960097673959,
    "mid_layer_count": 15,
    "mid_layer_size": 564
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 243,
    "learning_rate": 0.0008597969250838876,
    "weight_decay": 0.00020303832147163252,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7739,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 580,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104
    ],
    "train_loss": [
      0.6608471845429849,
      0.41494462350755257,
      0.38910289713156165,
      0.3787080337101983,
      0.3540571561570099,
      0.3186682353980598,
      0.2940991771538477,
      0.2854238298531111,
      0.27256610540167464,
      0.266155745746985,
      0.26062815986541926,
      0.24962378974215962,
      0.23309018820936264,
      0.23023628586252648,
      0.21721106311319596,
      0.210153080724225,
      0.2067317925735351,
      0.20122083638401084,
      0.18990962908763667,
      0.18798084174851942,
      0.18110097289886382,
      0.17795408897305015,
      0.17491739872029038,
      0.16756289636292404,
      0.16294631808861418,
      0.16583095292417188,
      0.15888258160154153,
      0.15656790068937004,
      0.15378918793831767,
      0.15196533409688712,
      0.15022670823730752,
      0.14983696017536116,
      0.15319423166098006,
      0.14531940559705325,
      0.14418862591203846,
      0.14758048030099044,
      0.1430591782433439,
      0.1458152489851482,
      0.13607495363321795,
      0.13593225975163856,
      0.13383835430796995,
      0.14078411090715184,
      0.13652035628741124,
      0.13664929767860462,
      0.13810120599513093,
      0.1333111311596776,
      0.13001708743249218,
      0.13299266770068088,
      0.13493240009865753,
      0.13725142060674458,
      0.13218362066793202,
      0.13209471109609977,
      0.13600310386440245,
      0.1340572370709891,
      0.13327240979529764,
      0.1276405739199285,
      0.12681821415241504,
      0.12031980979013603,
      0.125555829737696,
      0.1219526715417798,
      0.12046585458839013,
      0.1206097170587334,
      0.11938791258118846,
      0.12589298251456477,
      0.12868268537454355,
      0.1256266244421065,
      0.11976780284050284,
      0.12418031391554954,
      0.12550609759068918,
      0.12699215571703043,
      0.12901646262250185,
      0.12216593213461216,
      0.11866369045089575,
      0.1215631037407535,
      0.14022350679620443,
      0.1264904653974814,
      0.11840315483821456,
      0.1213443162130792,
      0.12668581885728653,
      0.12349331607200453,
      0.12086841481756927,
      0.11739825169188922,
      0.12106108302997826,
      0.12470576432050391,
      0.11654303201907118,
      0.11363848029126923,
      0.11370757671289934,
      0.11457188510435745,
      0.12753124632127125,
      0.1278842916063043,
      0.12019613891982465,
      0.11393129263067911,
      0.11356434551631932,
      0.11726016089722605,
      0.12414918149364042,
      0.12012048958018393,
      0.12044016961434319,
      0.11669038736184048,
      0.11434631415182252,
      0.11409267934506401,
      0.11634172536918923,
      0.11044242178932427,
      0.11427023147701801,
      0.11734211912838614
    ],
    "val_loss": [
      0.46426167526466405,
      0.4559268500901268,
      0.464282830349521,
      0.5110819076528093,
      0.5472474758808841,
      0.5238180201656805,
      0.3596561355549775,
      0.3687062240824728,
      0.45693019958670267,
      0.46240984079188213,
      0.4654377207427682,
      0.5059002802935902,
      0.49064841313276464,
      0.47640770574708186,
      0.43601615622550427,
      0.5455696975176563,
      0.47669660378537493,
      0.512798099616866,
      0.4824250954844638,
      0.46351375035986214,
      0.5578625068068505,
      0.477928285220426,
      0.4912915016898138,
      0.507990219618032,
      0.5388689247077096,
      0.4651520966992764,
      0.5370725095004378,
      0.46164504459161243,
      0.5343095398323978,
      0.48491338280860535,
      0.4628993280811938,
      0.5572128237899906,
      0.4833694840441207,
      0.44696645314643485,
      0.4793221408824721,
      0.4639625811960526,
      0.4222935205180488,
      0.44216120540203446,
      0.4378638159149064,
      0.42355995295112003,
      0.42892649998208005,
      0.4742264445224208,
      0.43366494836832237,
      0.4790317101571374,
      0.44084497420730706,
      0.4814866183671409,
      0.4281379840420392,
      0.4462749068608541,
      0.4721853881806671,
      0.47988911900602416,
      0.43378620484096564,
      0.4153405764413451,
      0.4496196375992484,
      0.4123789578185467,
      0.4314338054664121,
      0.46301403911170846,
      0.51505739065166,
      0.4561510857306198,
      0.4641337011567133,
      0.5049480832622437,
      0.4990364609141193,
      0.453592071485912,
      0.470199112335365,
      0.4398596481068762,
      0.47308378570272536,
      0.4976637955375774,
      0.47936363458454967,
      0.4633504086759633,
      0.5044277402633679,
      0.46315739468007744,
      0.4563835191690993,
      0.474302799633877,
      0.4585991720150331,
      0.434660128526345,
      0.49511706706827985,
      0.4386570282057374,
      0.445139528926975,
      0.46933391385092704,
      0.4481862320692953,
      0.42483197244966103,
      0.440898059362066,
      0.47137655576992177,
      0.44783327186892846,
      0.4643526637357866,
      0.47392631922653333,
      0.5040034399953431,
      0.490292657403175,
      0.5828182489839856,
      0.47869168161275144,
      0.4763909215520242,
      0.418044325049052,
      0.4438313247111743,
      0.4947135718996653,
      0.49176435287662607,
      0.5329808629826157,
      0.48388027253889754,
      0.5003678233234469,
      0.4768040739044458,
      0.4674740111845696,
      0.43676080660905664,
      0.44599329773002044,
      0.43770777292683455,
      0.42367804777657914,
      0.5047994057396928
    ],
    "best_epoch": 54,
    "best_val_loss": 0.4123789578185467,
    "test_loss": 0.5623398178733849,
    "tracker": {
      "initial_train_loss": 0.6608471845429849,
      "train_threshold": 0.22028239484766163,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4123789578185467,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-value/trial_29_704014/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-value/trial_29_704014/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-value/trial_29_704014/config.yaml"
}