epoch,train_loss,val_loss
1,1.001973,0.345991
2,1.001821,0.352575
3,1.001946,0.347486
4,1.001870,0.345209
5,1.002083,0.344977
6,1.001894,0.345815
7,1.001859,0.346639
8,1.001875,0.345672
9,1.001871,0.349085
10,1.001782,0.346667
11,1.001942,0.347755
12,1.001800,0.346382
13,1.001828,0.346117
14,1.001783,0.347860
15,1.001827,0.348279
16,1.001800,0.348007
17,1.001807,0.346965
18,1.001836,0.348462
19,1.001781,0.346631
20,1.001793,0.347667
21,1.001795,0.347372
22,1.001803,0.347907
23,1.001779,0.347230
24,1.001810,0.348266
25,1.001781,0.347945
26,1.001764,0.347475
27,1.001773,0.348217
28,1.001776,0.347937
29,1.001759,0.347643
30,1.001785,0.347512
31,1.001764,0.347848
32,1.001767,0.348169
33,1.001768,0.347785
34,1.001760,0.347325
35,1.001789,0.348192
36,1.001778,0.347583
37,1.001768,0.347738
38,1.001757,0.348061
39,1.001757,0.347989
40,1.001761,0.347713
41,1.001776,0.347826
42,1.001775,0.347595
43,1.001761,0.347726
44,1.001768,0.347728
45,1.001759,0.347736
46,1.001757,0.347609
47,1.001790,0.348345
48,1.001752,0.347751
49,1.001757,0.347656
50,1.001758,0.347639
