epoch,train_loss,val_loss
1,1.001621,0.356541
2,1.001268,0.351681
3,0.999611,0.349693
4,0.999659,0.343416
5,0.999686,0.346509
6,0.999782,0.351305
7,0.999529,0.349637
8,0.999379,0.348061
9,0.999516,0.348673
10,0.999371,0.349037
11,0.999758,0.346619
12,0.999348,0.352816
13,0.999275,0.346152
14,0.999624,0.346644
15,0.999369,0.353382
16,0.999247,0.350853
17,0.999363,0.350233
18,0.999288,0.353618
19,0.999443,0.352926
20,0.999302,0.347888
21,0.999382,0.349850
22,0.999555,0.354048
23,0.999495,0.360212
24,0.999722,0.356418
25,0.999496,0.351175
26,0.999344,0.351871
27,0.999300,0.354088
28,0.999276,0.350906
29,0.999275,0.350612
30,0.999260,0.353238
31,0.999353,0.358714
32,0.999538,0.354271
33,0.999429,0.353770
34,0.999386,0.350026
35,0.999318,0.352494
36,0.999285,0.353814
37,0.999274,0.352468
38,0.999311,0.355763
39,0.999384,0.355357
40,0.999270,0.351289
41,0.999290,0.351435
42,0.999290,0.352125
43,0.999324,0.348004
44,0.999313,0.351184
45,0.999248,0.351835
46,0.999254,0.354439
47,0.999350,0.349777
48,0.999485,0.346150
49,0.999415,0.352141
50,0.999284,0.351575
