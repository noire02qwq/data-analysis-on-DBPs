epoch,train_loss,val_loss
1,0.408817,0.390161
2,0.262181,0.452936
3,0.246883,0.406321
4,0.233152,0.392672
5,0.226332,0.394286
6,0.225544,0.408725
7,0.220506,0.430948
8,0.217598,0.444522
9,0.214680,0.442631
10,0.211729,0.462667
11,0.204145,0.393985
12,0.195724,0.572265
13,0.184964,0.577249
14,0.183335,0.560058
15,0.181559,0.513607
16,0.180109,0.550430
17,0.176276,0.612183
18,0.177301,0.565361
19,0.177086,0.584777
20,0.175893,0.681134
21,0.176519,0.741118
22,0.175806,0.694899
23,0.175078,0.801467
24,0.175277,0.704047
25,0.175582,0.642867
26,0.174853,0.631820
27,0.175711,0.526773
28,0.174923,0.667671
29,0.174050,0.467643
30,0.172356,0.513219
31,0.170950,0.470230
32,0.172252,0.723372
33,0.172996,0.678661
34,0.175823,0.801366
35,0.173288,0.676598
36,0.172301,0.639094
37,0.172266,0.556593
38,0.171135,0.499402
39,0.171486,0.639980
40,0.173043,0.723832
41,0.172457,0.522669
42,0.169803,0.545714
43,0.171872,0.619095
44,0.168828,0.559285
45,0.169921,0.540161
46,0.168838,0.507214
47,0.169266,0.632649
48,0.171106,0.552752
49,0.168946,0.519248
50,0.167839,0.543393
51,0.168448,0.503443
52,0.167952,0.607830
53,0.169289,0.742843
54,0.167516,0.531358
55,0.169445,0.596321
56,0.167560,0.572835
57,0.166054,0.617160
58,0.166417,0.628061
59,0.167440,0.591501
60,0.168326,0.582422
61,0.165911,0.597820
62,0.163726,0.704170
63,0.167813,0.542727
64,0.164738,0.573038
65,0.168547,0.543626
66,0.165272,0.494532
67,0.166512,0.522431
68,0.164578,0.616382
69,0.164473,0.537942
70,0.167435,0.651486
71,0.165230,0.591337
72,0.163229,0.614365
73,0.164983,0.530461
74,0.161948,0.525119
75,0.163157,0.562089
76,0.163336,0.611521
77,0.165404,0.549728
78,0.162827,0.573654
79,0.161507,0.567505
80,0.161528,0.623306
