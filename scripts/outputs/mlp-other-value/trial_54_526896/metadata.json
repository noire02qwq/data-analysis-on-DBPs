{
  "model_name": "mlp-other-value/trial_54_526896",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.11531734771681554,
    "mid_layer_count": 8,
    "mid_layer_size": 457
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 168,
    "learning_rate": 0.001207270609200485,
    "weight_decay": 0.0005723033842716601,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149,
      150
    ],
    "train_loss": [
      0.3403599045257069,
      0.21325600489767593,
      0.1894818184053427,
      0.17353560120677752,
      0.16187642280752076,
      0.15631995579870986,
      0.1469892567552133,
      0.14058203353002294,
      0.1364835645523727,
      0.1324228203911363,
      0.13060344061052084,
      0.12879090104395455,
      0.12454014206128343,
      0.12325188796632776,
      0.11994346305001632,
      0.11902714515723223,
      0.1181094632424288,
      0.11437256407545064,
      0.1136710608828184,
      0.11241493920000961,
      0.11010727055443441,
      0.11060135596345301,
      0.10737413325451654,
      0.10604854780184789,
      0.10528850590589414,
      0.10384910889333061,
      0.10266181111351046,
      0.10303107986638581,
      0.10110716570289151,
      0.09992929183332781,
      0.09915308556063106,
      0.10046782268888832,
      0.09846285700400466,
      0.09675060396487435,
      0.09548509842298042,
      0.09681696495974963,
      0.09344795009856227,
      0.09567495397630871,
      0.09550201809516376,
      0.09298927580441739,
      0.0940719530896201,
      0.09203464157110976,
      0.09128326776242977,
      0.09119973725435243,
      0.09241267121284664,
      0.09025304863901246,
      0.08848745243603783,
      0.08887893179017743,
      0.08931449271275974,
      0.08879563240683219,
      0.08874931827516297,
      0.0886760820955298,
      0.08738495930914636,
      0.08743193129382419,
      0.0879116445519852,
      0.08649996339724332,
      0.08640586898655937,
      0.08618189730877873,
      0.08601078449945807,
      0.08619643571194531,
      0.08441060302485681,
      0.0852498893648493,
      0.08731646166054514,
      0.0834960958945745,
      0.08294409758130852,
      0.08421761937068632,
      0.08353414245832878,
      0.08489645472042007,
      0.08293383131582593,
      0.08348688365114598,
      0.08277336290519992,
      0.0820542906165857,
      0.08267920591957817,
      0.08322455117401556,
      0.08342190984045927,
      0.08194395768269323,
      0.08027618423127222,
      0.08304341674126253,
      0.08011355397485966,
      0.081669603229303,
      0.07981226693030319,
      0.08296068420604047,
      0.07942945183684362,
      0.08114984263787825,
      0.08017218883233905,
      0.07976355453740028,
      0.07983042768036909,
      0.07987171930646578,
      0.07902094833036763,
      0.07935146576872601,
      0.08010785278982233,
      0.07816298199333002,
      0.07869749515101872,
      0.07884457848465339,
      0.07995101510178682,
      0.07840983725591096,
      0.08038698590569401,
      0.07952951116935604,
      0.07845670899224318,
      0.07902001209170957,
      0.07791541691099209,
      0.07864787845488631,
      0.07837465223117998,
      0.07677512581131897,
      0.07849175562884271,
      0.07974381478796744,
      0.07620896000306138,
      0.07623485141286121,
      0.0767882511883653,
      0.07722669741231518,
      0.07620023410019965,
      0.07677544409140616,
      0.07762926946149966,
      0.07575150441212064,
      0.07608199066813631,
      0.0767188157605293,
      0.07564488510525245,
      0.07570585285840492,
      0.07584714249212232,
      0.07648245208519676,
      0.07686942558125877,
      0.07711761994903793,
      0.0762595243029499,
      0.07489098676539128,
      0.07449896438090296,
      0.07506724897143228,
      0.07628763837499947,
      0.07426111653194849,
      0.0761994311080461,
      0.0777343208550367,
      0.07402805519553561,
      0.0740438502543764,
      0.07634009908657309,
      0.07540298812569197,
      0.07469290798446837,
      0.07440454017403433,
      0.0750037666282145,
      0.07542309441769533,
      0.07610700631169187,
      0.07338664796167059,
      0.0751927733849476,
      0.07331634612191085,
      0.07439639134520809,
      0.07355324707432183,
      0.07487344452819805,
      0.0760241703055283,
      0.07331768982207977,
      0.07412282598437622,
      0.07420952274072715,
      0.07442950814763603
    ],
    "val_loss": [
      0.39256106226030224,
      0.5168825400089789,
      0.5759738359265698,
      0.5466836998562613,
      0.6542074784904183,
      0.7353884176579778,
      0.5665137567919886,
      0.7433987870901645,
      0.6827001656243901,
      0.6979295988996586,
      0.742616992653487,
      0.5648225438808967,
      0.4908910361592641,
      0.5422547697307107,
      0.4914803222267928,
      0.5577162509906791,
      0.5042504698930387,
      0.5728307476300679,
      0.5991468947090789,
      0.5333023304710846,
      0.5420210496037307,
      0.5829261411449866,
      0.58326126072935,
      0.47607891680951603,
      0.6019052439820981,
      0.5530785490652759,
      0.5334492422863395,
      0.5299909924318691,
      0.5583668482160854,
      0.48081864511181494,
      0.49684961170493486,
      0.49305254131734016,
      0.5237763784245817,
      0.47911041039906577,
      0.45738787679615134,
      0.5161219648972243,
      0.4922044487770446,
      0.45635167081912836,
      0.47413368760468716,
      0.5980344453614629,
      0.4990416995422569,
      0.5346258775202813,
      0.501499448564952,
      0.46194434383672156,
      0.5095780694556094,
      0.5110231225362081,
      0.4881306072552047,
      0.42679836136138366,
      0.5307468600258856,
      0.4923842148509568,
      0.42671370656190516,
      0.47121584301223296,
      0.4373342693208934,
      0.5144103343615275,
      0.4869209568300647,
      0.457759077606087,
      0.45963674683770733,
      0.5333077959314791,
      0.5450052636469196,
      0.4775331335153408,
      0.45261538788943945,
      0.4848984420656444,
      0.475348839716997,
      0.5206750391486162,
      0.4599009887187067,
      0.4441049833140687,
      0.46306856699332505,
      0.46876644920446203,
      0.4590746955243413,
      0.4751407243177562,
      0.5057098914049343,
      0.46157510855240735,
      0.5111641420218759,
      0.44504814197917186,
      0.4702695660248488,
      0.4621445066200759,
      0.5009043044672755,
      0.4557661182866125,
      0.4456365325850641,
      0.45851967698799634,
      0.4865803036861077,
      0.47123465944906906,
      0.4583794378948783,
      0.45713783677466613,
      0.4470722096408912,
      0.45276067499629036,
      0.4296063327503775,
      0.4353864655523243,
      0.47257747992783966,
      0.4473256862449075,
      0.46742701209233906,
      0.4461294618195402,
      0.47126094959453196,
      0.4319670143955482,
      0.4399985803101591,
      0.4739569525518817,
      0.4617384171771432,
      0.42267130798922325,
      0.46702715904412867,
      0.4075196351833686,
      0.4473609224051059,
      0.4440775745643113,
      0.4369767364984501,
      0.44982010483027934,
      0.4201547589487658,
      0.45124628965012326,
      0.461158901702858,
      0.4563986489872733,
      0.4424253181426111,
      0.481314026274367,
      0.45268308431088566,
      0.500546613603295,
      0.43341561620106955,
      0.4815615327058438,
      0.44538263175301923,
      0.46989937556717926,
      0.4336931559497011,
      0.4781057021218146,
      0.4482277722772724,
      0.4116992649917831,
      0.4723809750137215,
      0.4430647490981096,
      0.4473775250112225,
      0.4889894550431988,
      0.47669074628167524,
      0.4430376809157297,
      0.486167382158919,
      0.4717047340498713,
      0.48327930666015534,
      0.45755244850398535,
      0.4151705451711209,
      0.4785022814116792,
      0.48758212149500135,
      0.47529141528163843,
      0.44481996911728455,
      0.43995573542075245,
      0.43299603183826285,
      0.45816173996040205,
      0.4826184798143581,
      0.4870743856458607,
      0.48276067454657867,
      0.5028076119051722,
      0.46084738073948617,
      0.4470799420051232,
      0.4965799036140213,
      0.4584905384543413,
      0.45866761228995406,
      0.42854625757582887,
      0.4676290010620734,
      0.46129522987468513
    ],
    "best_epoch": 100,
    "best_val_loss": 0.4075196351833686,
    "test_loss": 0.5033574783773513,
    "tracker": {
      "initial_train_loss": 0.3403599045257069,
      "train_threshold": 0.11345330150856897,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4075196351833686,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_54_526896/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_54_526896/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_54_526896/config.yaml"
}