epoch,train_loss,val_loss
1,1.003300,0.341224
2,1.002765,0.353991
3,1.002713,0.347367
4,1.002702,0.345638
5,1.002647,0.348058
6,1.002732,0.347045
7,1.002737,0.349167
8,1.002772,0.348193
9,1.002628,0.345073
10,1.002602,0.347037
11,1.002612,0.348797
12,1.002613,0.347398
13,1.002606,0.347853
14,1.002597,0.348131
15,1.002559,0.346994
16,1.002595,0.346633
17,1.002617,0.346848
18,1.002606,0.346683
19,1.002531,0.348661
20,1.002556,0.348223
21,1.002551,0.347724
22,1.002558,0.347652
23,1.002752,0.348470
24,1.002551,0.346230
25,1.002571,0.346957
26,1.002626,0.347041
27,1.002618,0.346147
28,1.002572,0.346296
29,1.002572,0.346126
30,1.002563,0.347463
31,1.002588,0.347723
32,1.002568,0.348052
33,1.002586,0.348923
34,1.002539,0.346809
35,1.002551,0.346953
36,1.002562,0.345874
37,1.002591,0.347399
38,1.002565,0.348014
39,1.002559,0.347134
40,1.002552,0.346990
41,1.002588,0.346942
42,1.002546,0.347765
43,1.002606,0.346540
44,1.002539,0.347876
45,1.002547,0.347902
46,1.002556,0.347346
47,1.002601,0.346321
48,1.002646,0.346503
49,1.002598,0.345420
50,1.002556,0.346484
