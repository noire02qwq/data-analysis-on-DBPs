{
  "model_name": "mlp-other-rate/trial_6_d4767e",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.3213036490238876,
    "mid_layer_count": 4,
    "mid_layer_size": 474
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 353,
    "learning_rate": 0.000851350737350595,
    "weight_decay": 0.004604068707448435,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84
    ],
    "train_loss": [
      0.5071952106930954,
      0.30932046008559605,
      0.27451657860890116,
      0.2571106660096171,
      0.24624204784517045,
      0.23927819829007918,
      0.235115813300694,
      0.22854992439573762,
      0.22626816487659424,
      0.2229600235563691,
      0.22166033250290715,
      0.2178819254059832,
      0.21779642719918793,
      0.2159496488411834,
      0.21613928459473852,
      0.21379433233212544,
      0.21276369615586493,
      0.21152352993345494,
      0.2121555106499337,
      0.21125007627590184,
      0.20996000750774968,
      0.2091460618863753,
      0.20892723929375914,
      0.20887018789682038,
      0.20674434037025677,
      0.2049980021539164,
      0.2058974694825705,
      0.20777788997201077,
      0.20711676350743602,
      0.20447595985754446,
      0.20442716777324677,
      0.20377278023458187,
      0.20403866595629241,
      0.20419412644903986,
      0.2029649187710849,
      0.20450164149087657,
      0.20256766601211906,
      0.2009070392462949,
      0.2057073010908695,
      0.20094130778653674,
      0.20209842671632094,
      0.2004072516334705,
      0.20221949284614324,
      0.2016096893390244,
      0.19962815837547557,
      0.19910479487211905,
      0.2000053985691364,
      0.19888485586982682,
      0.20028200723601647,
      0.1995614592373952,
      0.19908405704497373,
      0.19852417774724007,
      0.19556474056058568,
      0.19656341599005195,
      0.19703610673003957,
      0.196422479113993,
      0.19580153324065483,
      0.1979464018624706,
      0.19610395535765518,
      0.19638136335256284,
      0.1957992612455459,
      0.19567080934638548,
      0.19774583773759158,
      0.19807934464782614,
      0.19611817876258344,
      0.19478561366220631,
      0.1955155421902792,
      0.19601167430513453,
      0.1936217852991902,
      0.19473499275472544,
      0.19352976892577373,
      0.19446907561939455,
      0.19368670888631206,
      0.19411585222128847,
      0.19630575672808886,
      0.1931343608334653,
      0.1925288354294645,
      0.19237089545115743,
      0.19294721739660048,
      0.19387589759547444,
      0.19125375502946868,
      0.19330084368800615,
      0.1931904544542544,
      0.1914195352185684
    ],
    "val_loss": [
      0.5003324131230394,
      0.37242319113658573,
      0.3740561545564386,
      0.4049247640157174,
      0.3961758913929591,
      0.43425297557772274,
      0.4841453444725739,
      0.46915477326887095,
      0.4394377247302118,
      0.4427875520226484,
      0.4548749048463599,
      0.46183820071513065,
      0.4669322719206353,
      0.45869181023207967,
      0.4402749861696523,
      0.47197135387958883,
      0.4801473085484105,
      0.4556449168456529,
      0.4760546671862374,
      0.47904054512699207,
      0.4903157539442628,
      0.45069329062264835,
      0.5032909972492806,
      0.5118503492035552,
      0.47512222018070566,
      0.5120074130193202,
      0.5221556080672556,
      0.49635885384625306,
      0.5347077165445882,
      0.5086850164447002,
      0.5066494051121666,
      0.5261264318388379,
      0.5756096589529586,
      0.4748290424753806,
      0.4997454407686245,
      0.5759606033474386,
      0.5033602691071476,
      0.5375719523893859,
      0.5385521338014545,
      0.5511094456839705,
      0.5127557307035623,
      0.5334531512535261,
      0.5806647171651175,
      0.5416587534868075,
      0.5781700238228558,
      0.5927025557858144,
      0.5520190378506027,
      0.5731129142070959,
      0.5281792811826318,
      0.5972977951882842,
      0.551967838451177,
      0.5452693844269849,
      0.5544056203194008,
      0.5735121833528587,
      0.5516825092766813,
      0.5747748362982344,
      0.5649360731333316,
      0.5243048927384222,
      0.5698049563847616,
      0.5373659267396984,
      0.5523974333873052,
      0.5251090072318465,
      0.5396018922061263,
      0.5810839886526148,
      0.5625850703901873,
      0.5969648884174352,
      0.5683741679627025,
      0.5810046466970872,
      0.5675801796292117,
      0.5508730064162951,
      0.5752558486101156,
      0.5482916888005719,
      0.5752714916974485,
      0.4977672157441071,
      0.5795060733388998,
      0.5576602617066777,
      0.6153496100517091,
      0.5612120789146708,
      0.5552458003341795,
      0.599810404245725,
      0.5665198663394608,
      0.6086805343271016,
      0.6186215150677515,
      0.5746411638970147
    ],
    "best_epoch": 84,
    "best_val_loss": 0.5746411638970147,
    "best_val_abs_mse": 0.6413055658340454,
    "test_loss": 0.5771525681607033,
    "test_abs_mse": 1.2289550304412842,
    "tracker": {
      "initial_train_loss": 0.5071952106930954,
      "train_threshold": 0.1690650702310318,
      "best_tracking": false,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4748290424753806,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-rate/trial_6_d4767e/best_model.pt",
    "last": "scripts/outputs/mlp-other-rate/trial_6_d4767e/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-rate/trial_6_d4767e/config.yaml"
}