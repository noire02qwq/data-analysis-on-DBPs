epoch,train_loss,val_loss
1,0.966425,0.324647
2,1.000309,0.344040
3,0.999230,0.350351
4,0.998743,0.351888
5,0.998956,0.351312
6,0.998931,0.351800
7,0.998707,0.352209
8,0.998634,0.352336
9,0.998824,0.351771
10,0.998640,0.353446
11,0.998791,0.352228
12,0.998485,0.353323
13,0.998696,0.352457
14,0.998643,0.354688
15,0.998684,0.352879
16,0.998679,0.352690
17,0.998806,0.353749
18,0.998736,0.352240
19,0.998711,0.353344
20,0.998779,0.352045
21,0.998662,0.352337
22,0.998767,0.352186
23,0.998668,0.354266
24,0.998801,0.352660
25,0.998722,0.354784
26,0.998531,0.353378
27,0.998778,0.353229
28,0.998587,0.354192
29,0.998702,0.353145
30,0.998700,0.353806
31,0.998649,0.353604
32,0.998654,0.354513
33,0.998798,0.353640
34,0.998633,0.352905
35,0.998638,0.353289
36,0.998718,0.353487
37,0.998727,0.354455
38,0.998643,0.352807
39,0.998587,0.354882
40,0.998742,0.354298
41,0.998688,0.353395
42,0.998679,0.352208
43,0.998802,0.354003
44,0.998634,0.352492
45,0.998677,0.354728
46,0.998675,0.353501
47,0.998588,0.353680
48,0.998761,0.353559
49,0.998569,0.353468
50,0.998630,0.353235
