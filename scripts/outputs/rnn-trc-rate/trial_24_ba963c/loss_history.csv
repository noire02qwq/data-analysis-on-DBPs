epoch,train_loss,val_loss
1,0.460264,0.305540
2,0.222800,0.263995
3,0.188374,0.426541
4,0.159420,0.449234
5,0.132509,0.159313
6,0.144101,0.212355
7,0.122079,0.200831
8,0.123272,0.199667
9,0.119827,0.210195
10,0.121694,0.223867
11,0.119111,0.228208
12,0.115537,0.223764
13,0.109544,0.225150
14,0.124940,0.261974
15,0.112387,0.228827
16,0.112988,0.224628
17,0.112576,0.234097
18,0.116569,0.228396
19,0.106413,0.235338
20,0.109988,0.224272
21,0.104336,0.218612
22,0.109728,0.263118
23,0.109173,0.220575
24,0.106335,0.221007
25,0.107780,0.223986
26,0.107941,0.224746
27,0.102803,0.268729
28,0.116848,0.292649
29,0.109513,0.220160
30,0.102286,0.225362
31,0.101417,0.234410
32,0.100578,0.376345
33,0.107241,0.265935
34,0.102647,0.240363
35,0.112194,0.267700
36,0.097507,0.262160
37,0.103741,0.227794
38,0.099825,0.267134
39,0.099756,0.238960
40,0.098237,0.224699
41,0.095596,0.234236
42,0.102456,0.237949
43,0.109819,0.257329
44,0.102268,0.254424
45,0.098959,0.262911
46,0.096228,0.243278
47,0.101369,0.235564
48,0.097138,0.244753
49,0.100837,0.274725
50,0.093371,0.240879
51,0.100634,0.274798
52,0.099466,0.266016
53,0.096873,0.257343
54,0.097532,0.294560
55,0.102775,0.248687
56,0.096228,0.244280
57,0.092655,0.244986
58,0.095069,0.288554
59,0.097868,0.249798
60,0.104972,0.260108
61,0.096552,0.245050
62,0.102305,0.257213
63,0.095178,0.248764
64,0.096920,0.248528
65,0.096334,0.302785
66,0.093998,0.239754
67,0.096318,0.243156
68,0.097377,0.245503
69,0.103659,0.252790
70,0.092563,0.243965
71,0.143213,0.271242
72,0.114810,0.281663
73,0.095404,0.250300
74,0.097322,0.247872
75,0.090923,0.257304
76,0.092831,0.281305
77,0.094429,0.258055
78,0.091984,0.256611
79,0.099620,0.318215
80,0.098367,0.313977
