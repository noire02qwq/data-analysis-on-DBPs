{
  "model_name": "mlp_with_history-other-rate/trial_57_a06f3a",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 61,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.18641572436645754,
    "mid_layer_count": 14,
    "mid_layer_size": 599
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 267,
    "learning_rate": 0.0011216075491480779,
    "weight_decay": 0.0015896221438231996,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7736,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 610,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.8826561535842478,
      0.39208996695039683,
      0.3571648654694579,
      0.3506323676074796,
      0.33852416709173305,
      0.3109713498283382,
      0.27538508989279004,
      0.2648172701006869,
      0.25187016308746824,
      0.2506830561463071,
      0.24938005506375951,
      0.2379067464121988,
      0.2366222415077033,
      0.22889003150873927,
      0.22403316342511678,
      0.21822592555213,
      0.21562518020504326,
      0.21672943925760463,
      0.20943466403676658,
      0.20115206317808537,
      0.20524212688346313,
      0.20226331012402474,
      0.20096274702631575,
      0.19258075846780973,
      0.19447396538049877,
      0.1956671621215134,
      0.18790283338036753,
      0.5414382145983757,
      0.7800125893679252,
      0.5619481473991642,
      0.3543720839134848,
      0.3319972393631689,
      0.3159825685660373,
      0.29741129319201826,
      0.27860430784854795,
      0.4378021894853019,
      0.36041036839168344,
      0.2991669077345294,
      0.2743680054050289,
      0.26105311878541754,
      0.256910508375272,
      0.25779452314937434,
      0.25362446372548453,
      0.2478726522394118,
      0.2481191821912575,
      0.24529303110280723,
      0.24380933133367114,
      0.2422745787300701,
      0.23987833391432,
      0.23893286484258006,
      0.24152330566686891,
      0.23933145857484472,
      0.2534843053140956,
      0.2530724905438975,
      0.23522057934956012,
      0.23590507622973872,
      0.23408743179949326,
      0.23262047124092372,
      0.23207136927578972,
      0.23288039524289236,
      0.3412840948252329,
      0.3547200297873232,
      0.2950257209226905,
      0.26217555380286695,
      0.250932751389099,
      0.2444024303352081,
      0.24037726558051473,
      0.23966959563797607,
      0.23628298669375455,
      0.23467211528549273,
      0.23409020933857133,
      0.23647249710766335,
      0.23447252782263947,
      0.2338895488187532,
      0.23391222754818886,
      0.23285679768428066,
      0.23014826636141186,
      0.23172302781618678,
      0.2322434964007096,
      0.23210189947251697
    ],
    "val_loss": [
      0.6103276023250854,
      0.4952503263771891,
      0.4923714305290919,
      0.5324190370069293,
      0.4807594384440405,
      0.5640357736341968,
      0.6041232050669765,
      0.5742619234733952,
      0.4844653316600594,
      0.47435440023145276,
      0.44951680058133814,
      0.5408841304882558,
      0.4869060230558504,
      0.5029052457855847,
      0.48161819197995936,
      0.49281304565643125,
      0.5327385343834312,
      0.5268021973485718,
      0.5555841964786637,
      0.5645383801378175,
      0.4918697294360863,
      0.494385877733459,
      0.5190357626555209,
      0.4989402268014982,
      0.5324142193009039,
      0.5058258892533308,
      0.5140723685929162,
      0.5377850863747968,
      0.4761802540746278,
      0.48841089567916834,
      0.5092451703941037,
      0.541954037520343,
      0.5427137292163101,
      0.5508251201428339,
      0.5682692022916086,
      0.5256998341419026,
      0.5584743595141136,
      0.5830077447175622,
      0.5549925444234988,
      0.5365428871737269,
      0.5598232118758613,
      0.5103915971151726,
      0.5457098438220467,
      0.5744953409060389,
      0.5828777137139957,
      0.551124985533917,
      0.5501224687356435,
      0.5708090167158021,
      0.5773354058003354,
      0.6209237886626207,
      0.5951183499244159,
      0.6083154968025085,
      0.6175706437471027,
      0.5178912362117254,
      0.5971601467378839,
      0.565737335477582,
      0.5886397576706852,
      0.6458929394935062,
      0.5616069380082414,
      0.5256178088932337,
      1.0565461977691708,
      0.5491355735830918,
      0.5585435255425062,
      0.5476941379690599,
      0.5866968852763405,
      0.5969075029169371,
      0.6025075099068488,
      0.5153948031410486,
      0.5694601184638317,
      0.5493043803570871,
      0.5359374705233617,
      0.5396328002883646,
      0.5575171261445848,
      0.5309778483194149,
      0.5692348369492028,
      0.551838974230839,
      0.5143309518204121,
      0.5626869052068559,
      0.5372677527412683,
      0.5332536965251683
    ],
    "best_epoch": 11,
    "best_val_loss": 0.44951680058133814,
    "best_val_abs_mse": 0.5167108774185181,
    "test_loss": 0.6024944731814154,
    "test_abs_mse": 1.3904075622558594,
    "tracker": {
      "initial_train_loss": 0.8826561535842478,
      "train_threshold": 0.2942187178614159,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.44951680058133814,
      "patience_no_improve_epochs": 69,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-rate/trial_57_a06f3a/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-rate/trial_57_a06f3a/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-rate/trial_57_a06f3a/config.yaml"
}