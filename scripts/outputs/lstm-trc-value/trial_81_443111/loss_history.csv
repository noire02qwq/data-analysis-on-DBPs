epoch,train_loss,val_loss
1,1.000892,0.367512
2,1.001063,0.339028
3,1.000916,0.362441
4,1.000825,0.347256
5,1.001309,0.354565
6,1.000790,0.351827
7,1.000843,0.354223
8,1.000787,0.350674
9,1.000778,0.354106
10,1.000996,0.351545
11,1.000735,0.349293
12,1.000615,0.345260
13,1.000752,0.350402
14,1.000875,0.356204
15,1.000845,0.355388
16,1.000786,0.350990
17,1.000603,0.349687
18,1.000860,0.352617
19,1.000702,0.353531
20,1.000919,0.347520
21,1.000668,0.352006
22,1.000662,0.348216
23,1.000667,0.348115
24,1.000620,0.350085
25,1.000655,0.347900
26,1.000675,0.349231
27,1.000833,0.347524
28,1.000773,0.353735
29,1.000632,0.349965
30,1.000756,0.350761
31,1.000685,0.347089
32,1.000553,0.350790
33,1.000661,0.352432
34,1.000599,0.348755
35,1.000622,0.350558
36,1.000697,0.349637
37,1.000694,0.350736
38,1.000705,0.349655
39,1.000584,0.351206
40,1.000597,0.349162
41,1.000630,0.350083
42,1.000630,0.350415
43,1.000608,0.351001
44,1.000633,0.347021
45,1.000635,0.351463
46,1.000624,0.349279
47,1.000632,0.347431
48,1.000729,0.351134
49,1.000787,0.350382
50,1.000663,0.349937
