epoch,train_loss,val_loss
1,1.004702,0.360544
2,1.003824,0.344463
3,1.003420,0.344696
4,1.004214,0.353900
5,1.003676,0.347195
6,1.003409,0.346364
7,1.003533,0.345165
8,1.003477,0.345615
9,1.003388,0.348782
10,1.003260,0.343154
11,1.003553,0.346006
12,1.003451,0.343179
13,1.003300,0.350609
14,1.003354,0.348570
15,1.003361,0.345655
16,1.003342,0.347663
17,1.003465,0.350805
18,1.003444,0.348535
19,1.003322,0.344371
20,1.003302,0.345865
21,1.003572,0.345798
22,1.003492,0.346971
23,1.003348,0.346428
24,1.003287,0.346776
25,1.003291,0.347815
26,1.003294,0.344969
27,1.003340,0.344354
28,1.003296,0.349404
29,1.003323,0.346129
30,1.003281,0.345980
31,1.003365,0.347210
32,1.003258,0.345087
33,1.003391,0.346601
34,1.003273,0.345492
35,1.003270,0.347795
36,1.003301,0.349185
37,1.003451,0.346099
38,1.003286,0.348254
39,1.003327,0.347559
40,1.003463,0.348826
41,1.003334,0.347849
42,1.003315,0.347932
43,1.003384,0.345298
44,1.003265,0.347156
45,1.003295,0.345509
46,1.003251,0.346788
47,1.003299,0.347545
48,1.003286,0.344645
49,1.003409,0.342282
50,1.003607,0.347618
