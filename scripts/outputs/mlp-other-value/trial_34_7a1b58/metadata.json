{
  "model_name": "mlp-other-value/trial_34_7a1b58",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.4190941855796525,
    "mid_layer_count": 4,
    "mid_layer_size": 511
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 272,
    "learning_rate": 0.0019939343624554703,
    "weight_decay": 0.00026407913269110866,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149,
      150,
      151,
      152
    ],
    "train_loss": [
      0.42605280074906876,
      0.283096777874424,
      0.25328280439953,
      0.23999662146836198,
      0.22915243831061288,
      0.2212817838187093,
      0.2137158239129386,
      0.20548736549084343,
      0.19883624954734966,
      0.1958914402281706,
      0.19082100497508062,
      0.18499322444307553,
      0.18052992911262963,
      0.17561524847246182,
      0.1749378124403917,
      0.17177027454738314,
      0.16678183121733814,
      0.16784613596714112,
      0.1631114327522227,
      0.1605141906630632,
      0.15856850767300765,
      0.1559574878968111,
      0.15438171323597155,
      0.15174014990974413,
      0.1517983175672709,
      0.1508280903926686,
      0.1467106194450893,
      0.14291761403453235,
      0.143569748017224,
      0.14142332585760725,
      0.1430095382963712,
      0.14215477940943255,
      0.14136043629045666,
      0.13939469649034503,
      0.13655527519791355,
      0.13911642235875313,
      0.13648534172800886,
      0.135868499673838,
      0.1373661442589552,
      0.13356530392640917,
      0.13603833927106343,
      0.13308400869858822,
      0.13144486085948973,
      0.1318789948028378,
      0.13151902007775285,
      0.1323139270019262,
      0.13250347028456327,
      0.13120992962230835,
      0.13004002024755532,
      0.13056211266810006,
      0.12780908318193465,
      0.12724238540833885,
      0.12855954127259106,
      0.12833367381388253,
      0.12851099658465007,
      0.12408270893294485,
      0.1244955358901594,
      0.12385696420429791,
      0.12561374172575968,
      0.12391735930253812,
      0.12425536853096435,
      0.12466252587540691,
      0.12327019809116885,
      0.12357940263338979,
      0.12276077881386611,
      0.12433073324858072,
      0.1241319673819197,
      0.12085748647744378,
      0.12373241850233739,
      0.1215706362578733,
      0.1211584796006096,
      0.12137837002695126,
      0.12036232342929214,
      0.12226126491335369,
      0.12189542557595019,
      0.12054005626487757,
      0.12047082317630838,
      0.11996905263293517,
      0.1183282956595663,
      0.11825991842442748,
      0.11853931424876492,
      0.1191805808199498,
      0.11748902783707633,
      0.11939973611596794,
      0.11876790359302812,
      0.11593928273333348,
      0.11604127121574148,
      0.11730670671682593,
      0.11955189116188292,
      0.11677918843485381,
      0.11795791435036798,
      0.11955541397529483,
      0.11752580720577685,
      0.11864976298585801,
      0.11614098301632335,
      0.11754925754695382,
      0.11484372991210318,
      0.11683627788365468,
      0.11521527694090015,
      0.11601751344732408,
      0.11508260272431826,
      0.11635827835842302,
      0.11596236611908066,
      0.11578117559480937,
      0.11620599831936602,
      0.11606028672210249,
      0.11537212664008202,
      0.11358251810272636,
      0.11493346293869233,
      0.11407231366316314,
      0.11553571726448295,
      0.11479805479865003,
      0.11434942967864781,
      0.11375587589163362,
      0.11356265201453615,
      0.11529900411525221,
      0.11513370095827201,
      0.1133590340461408,
      0.11397597132935898,
      0.11508380252009726,
      0.11241138976099799,
      0.11356419628402892,
      0.11239647704356753,
      0.1135282681814336,
      0.11297283734478297,
      0.11306514893359805,
      0.11516973309375617,
      0.11345321381930024,
      0.11086696661576789,
      0.11476185111249637,
      0.11276753104959408,
      0.1132599409572157,
      0.11253502690880772,
      0.11100928545028751,
      0.11215935861945091,
      0.1113659412494496,
      0.11175119600475232,
      0.110295026986002,
      0.11360537868209103,
      0.11293578543927255,
      0.112742142571187,
      0.11144292895888108,
      0.11296309975705555,
      0.1115226320283972,
      0.11242609071220845,
      0.11245686313535935,
      0.11171088106987598,
      0.11187007460167862,
      0.11091755764064819,
      0.11118623148697715,
      0.10991838182957739,
      0.11334078232177164
    ],
    "val_loss": [
      0.3895702488408117,
      0.4130723052396032,
      0.49264959732215563,
      0.4673950609332787,
      0.46569055825650335,
      0.5103202301585031,
      0.5376730731147492,
      0.5187252238838972,
      0.5087427363424244,
      0.4954982551272044,
      0.47681766213057286,
      0.5023175694985305,
      0.48821641734974114,
      0.48378623516973623,
      0.43740200496719267,
      0.5117026199123816,
      0.49445267016302324,
      0.49898329566338817,
      0.5353888792905979,
      0.45175375752820224,
      0.47376011474403795,
      0.4726324843075461,
      0.48091676320858345,
      0.47904998285327843,
      0.49061689890787274,
      0.47889419658455307,
      0.4456057425744519,
      0.5062762071986399,
      0.5366233671496728,
      0.4627333566814126,
      0.433359867084526,
      0.4633684422441585,
      0.5155585795819403,
      0.4736259667459362,
      0.47974726325737505,
      0.4636521032470429,
      0.4451770058649029,
      0.46971606080403583,
      0.44528495565859855,
      0.4411607662360825,
      0.5151506682355961,
      0.4733860230017565,
      0.47150568441002666,
      0.4412062255208364,
      0.44880135630419155,
      0.47437437694229767,
      0.4604443096115204,
      0.45836790450318843,
      0.45214236239473266,
      0.4864557964359215,
      0.4564280345768272,
      0.4630140657196502,
      0.4098226101812488,
      0.48317383392128405,
      0.436727796842952,
      0.51980032885146,
      0.4884394908379652,
      0.40564705868681034,
      0.4719662386500193,
      0.48033130325956974,
      0.5024704861783695,
      0.4352866179928808,
      0.45039696664867285,
      0.46615126861069733,
      0.44093039321328353,
      0.43490759541174606,
      0.4462265020359062,
      0.46660922544445105,
      0.4618518004160441,
      0.4509836680874853,
      0.47044811577140216,
      0.4345483482954745,
      0.43824755988435116,
      0.450007521606491,
      0.4580311228415209,
      0.4250502445026786,
      0.4591440813270158,
      0.4347409907929198,
      0.43314911662461514,
      0.46428205388748717,
      0.4303580296967558,
      0.4563069117997221,
      0.48313713687622617,
      0.4456718577596242,
      0.4585995378608475,
      0.47054125848644507,
      0.4674899215469817,
      0.44128808347051013,
      0.4593902165304401,
      0.4818824641005008,
      0.4231347770748024,
      0.49854412549983956,
      0.4496492754913376,
      0.4334322171296902,
      0.4134257372267946,
      0.4457459900907414,
      0.45423505220584526,
      0.4441155582131026,
      0.42710996145259833,
      0.4485738031878443,
      0.43512074833144687,
      0.39994571437378845,
      0.4339366984224605,
      0.4308653079107136,
      0.42611133110023547,
      0.409712317175494,
      0.4589859873234869,
      0.4376137963312115,
      0.42424377731220453,
      0.40386887624592127,
      0.45219334171203796,
      0.4940525014957268,
      0.46371918795351497,
      0.4239064730569988,
      0.46513796295234544,
      0.4293611132456157,
      0.4413457011748217,
      0.41546202048570097,
      0.4559636100323614,
      0.42720777602966675,
      0.43689805818888955,
      0.40573321016962655,
      0.4236722178087977,
      0.41830189727737516,
      0.44483227601308306,
      0.4380527128002601,
      0.47676853948010656,
      0.46356550547891034,
      0.4397927495533835,
      0.46231622667369726,
      0.40875400540357576,
      0.4141225437918109,
      0.4277683033914623,
      0.46280501167217414,
      0.410007853136805,
      0.5139041966306949,
      0.444448838976329,
      0.4705213760901354,
      0.4384607928955626,
      0.45728316092919447,
      0.4078129000292567,
      0.4154967916225959,
      0.4580708607228216,
      0.4372105590597598,
      0.43707097447560933,
      0.4082253083497464,
      0.41924052409783097,
      0.42210819835434416,
      0.43284873034425836,
      0.40389355699459234,
      0.43348972055012597,
      0.4460357533243602
    ],
    "best_epoch": 102,
    "best_val_loss": 0.39994571437378845,
    "test_loss": 0.5068012799657703,
    "tracker": {
      "initial_train_loss": 0.42605280074906876,
      "train_threshold": 0.1420176002496896,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.39994571437378845,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_34_7a1b58/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_34_7a1b58/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_34_7a1b58/config.yaml"
}