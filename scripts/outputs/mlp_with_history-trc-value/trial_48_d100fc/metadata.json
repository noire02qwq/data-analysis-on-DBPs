{
  "model_name": "mlp_with_history-trc-value/trial_48_d100fc",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 40,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.36783185675990515,
    "mid_layer_count": 5,
    "mid_layer_size": 595
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 437,
    "learning_rate": 0.001190091571503663,
    "weight_decay": 0.006550434130788714,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7757,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 400,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.8367091428608074,
      0.33455008555929333,
      0.21163944468772394,
      0.16012905632595095,
      0.14903256924316505,
      0.17390010772644898,
      0.1449704054938513,
      0.14192679640065614,
      0.13895638418943745,
      0.1368554021379867,
      0.1379628022187792,
      0.13739071418244891,
      0.13528224759776827,
      0.13400446003850655,
      0.1834225278663254,
      0.17179491877098652,
      0.16377352167531298,
      0.13942568779156905,
      0.13333052752734736,
      0.13728051249404166,
      0.13467349653466393,
      0.13645457164792035,
      0.12917112341815545,
      0.1368992840473809,
      0.12953671875251418,
      0.20206975078300762,
      0.29728178266736976,
      0.20474755785330617,
      0.17565694246746083,
      0.14573566115258266,
      0.14614909777528956,
      0.15330028863674405,
      0.13653591731259454,
      0.1415004757848523,
      0.14369883740111172,
      0.15637152458748682,
      0.15572368202518982,
      0.13685605322959668,
      0.1311903478004076,
      0.13264810123424547,
      0.1383350010352819,
      0.13529526628433805,
      0.15846757323464214,
      0.2745371334301806,
      0.175903744385678,
      0.1434725607163408,
      0.1397516952501724,
      0.13795751001384743,
      0.12859196421510552,
      0.1280575571131488,
      0.13683949878197502,
      0.14540823976069486,
      0.12740226828000803,
      0.13431511234515595,
      0.1290715669631282,
      0.13179885268315097,
      0.12422927112094179,
      0.1317937706716131,
      0.1369874682404707,
      0.14546923896263475,
      0.14012301500766136,
      0.18346949064602508,
      0.13267322112942412,
      0.1361811164258927,
      0.14204678002519677,
      0.1281119765735662,
      0.13012515727958376,
      0.13016740793636722,
      0.13012943499820878,
      0.1264183283701253,
      0.12066128310567711,
      0.12629287205353154,
      0.13270159229488276,
      0.14057685052732286,
      0.20567283803106998,
      0.30125034770024134,
      0.18381804561313778,
      0.1460902809662596,
      0.15935157468227654,
      0.12892966079999296
    ],
    "val_loss": [
      0.3612546481772097,
      0.3727398449610807,
      0.2269444229058966,
      0.2909754097160554,
      0.2607654147084334,
      0.26021401868229677,
      0.2760456025410823,
      0.27264621403335987,
      0.28926350838967607,
      0.2945153246036993,
      0.265761062984695,
      0.26623337291359545,
      0.277756848046835,
      0.27934135318940095,
      0.28466527277414133,
      0.2835456960393997,
      0.27462737041519963,
      0.27591639280453056,
      0.2703225764440384,
      0.3171590884667849,
      0.291359644411076,
      0.2935325068851074,
      0.3333560910789731,
      0.2880266013348888,
      0.28764468742434135,
      0.3877862465461928,
      0.3400199011235894,
      0.28844689754490366,
      0.2908754823885546,
      0.36770348970716943,
      0.307493231708775,
      0.39973590250299895,
      0.362045638865518,
      0.3485041833689024,
      0.34780958957278624,
      0.31633558330644745,
      0.3227147870925729,
      0.30382453679681537,
      0.3128653922168438,
      0.31711367726281375,
      0.3031919254960414,
      0.2865132691952104,
      0.4369512884671281,
      0.3759423524453611,
      0.2822587247971378,
      0.3171718642628657,
      0.2968805909781399,
      0.4167739664856902,
      0.3308885507899041,
      0.30935793694800245,
      0.8917272353332913,
      0.29437318984976785,
      0.3037372794236519,
      0.30977126438906805,
      0.30717707167820124,
      0.3229193899903201,
      0.2897302211892462,
      0.3385324318118081,
      0.29437917610240016,
      0.28000031457377406,
      0.48727755198132494,
      0.2707963799544705,
      0.2803121729937945,
      0.31159830612582184,
      0.31834212714460436,
      0.28063097153706645,
      0.2803369500679884,
      0.2777082953892068,
      0.2795629373188326,
      0.2838589730321201,
      0.2746765281871229,
      0.2850672599318588,
      0.3228722792988766,
      0.28095373683302344,
      0.2724931355777704,
      0.3169136826841239,
      0.2973332338793549,
      0.3076463379144312,
      0.2885249571261292,
      0.30925004576739973
    ],
    "best_epoch": 3,
    "best_val_loss": 0.2269444229058966,
    "test_loss": 5.271691851995208,
    "tracker": {
      "initial_train_loss": 0.8367091428608074,
      "train_threshold": 0.27890304762026913,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.2269444229058966,
      "patience_no_improve_epochs": 78,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_48_d100fc/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_48_d100fc/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_48_d100fc/config.yaml"
}