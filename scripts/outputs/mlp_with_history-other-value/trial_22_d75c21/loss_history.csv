epoch,train_loss,val_loss
1,1.099757,0.460660
2,0.552591,0.680578
3,0.407308,0.490520
4,0.395457,0.486812
5,0.389417,0.547253
6,0.375783,0.537117
7,0.361093,0.550973
8,0.345448,0.537028
9,0.328898,0.575876
10,0.296207,0.434918
11,0.282689,0.413841
12,0.280118,0.354902
13,0.272261,0.504532
14,0.269324,0.378204
15,0.268190,0.445736
16,0.259176,0.418413
17,0.258333,0.564485
18,0.252289,0.424777
19,0.268026,0.460758
20,0.587920,0.930092
21,0.586504,0.558275
22,0.498581,0.565816
23,0.339407,0.576189
24,0.285063,0.556049
25,0.274757,0.416055
26,0.263686,0.395540
27,0.258403,0.449803
28,0.250442,0.460583
29,0.247818,0.464110
30,0.247323,0.452322
31,0.238659,0.431185
32,0.238912,0.424213
33,0.238547,0.484335
34,0.236864,0.485631
35,0.233052,0.443416
36,0.234747,0.484083
37,0.230628,0.499602
38,0.226984,0.463069
39,0.220093,0.454479
40,0.213714,0.432521
41,0.221989,0.518731
42,0.206608,0.449588
43,0.195249,0.536290
44,0.201377,0.481391
45,0.194555,0.457523
46,0.195546,0.459876
47,0.192007,0.449195
48,0.187858,0.446311
49,0.187836,0.496862
50,0.189908,0.478943
51,0.186557,0.473503
52,0.183866,0.465167
53,0.185388,0.496007
54,0.194932,0.594313
55,0.182112,0.454039
56,0.178330,0.564085
57,0.175159,0.486738
58,0.178119,0.426642
59,0.177167,0.428989
60,0.178200,0.464022
61,0.173449,0.511490
62,0.170620,0.465234
63,0.170492,0.476643
64,0.169242,0.449282
65,0.169758,0.442161
66,0.181149,0.427683
67,0.173437,0.479451
68,0.168826,0.505206
69,0.169239,0.580296
70,0.174655,0.442085
71,0.170926,0.489278
72,0.192829,0.442406
73,0.166480,0.444441
74,0.166600,0.461326
75,0.165422,0.461238
76,0.163312,0.483723
77,0.163544,0.470504
78,0.166444,0.422355
79,0.175843,0.495115
80,0.172380,0.479151
