{
  "model_name": "mlp_with_history-trc-value/trial_63_28a24f",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 27,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.1455245495374879,
    "mid_layer_count": 2,
    "mid_layer_size": 493
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 476,
    "learning_rate": 0.0019515221535647768,
    "weight_decay": 0.0007551714419410547,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7770,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 270,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      1.0475818399910455,
      0.7657075386326593,
      0.2526131470998128,
      0.14206753778565037,
      0.13169551964278695,
      0.13407039024808384,
      0.11460685304424784,
      0.12043125632109943,
      0.11309143029623203,
      0.10969381994223809,
      0.11029713293453594,
      0.11025628571037774,
      0.11287213703533551,
      0.13768162147418872,
      0.10721036014524667,
      0.10038741154445184,
      0.10224027232275353,
      0.10671745722626781,
      0.10854517918180775,
      0.10567166017250972,
      0.09974524777483296,
      0.1058294923724355,
      0.1255349545328467,
      0.09898269419466053,
      0.09449583679974616,
      0.10375149251372964,
      0.0923304234673311,
      0.09261549669611562,
      0.08108419065808391,
      0.06623195866877968,
      0.06926985056819142,
      0.07547050590987678,
      0.059133489638029994,
      0.05254052853262102,
      0.06489427391741727,
      0.0526400093895358,
      0.05835341487650399,
      0.049446551233261554,
      0.05488466609705676,
      0.04659136463929941,
      0.04834417021489358,
      0.06233016512281186,
      0.04671212983158258,
      0.04344490294655164,
      0.04385490524876225,
      0.049008839939897124,
      0.04972179319273244,
      0.04614946718688484,
      0.04696936220736117,
      0.04408998944469401,
      0.07802604772486128,
      0.5759443927187103,
      0.9354160828633351,
      1.0636870510943301,
      0.9703557740460645,
      0.8152412590679822,
      0.7481540395332886,
      0.4217153239357579,
      0.25636377189610454,
      0.19424083740324588,
      0.18276688679381534,
      0.16976617099465552,
      0.15850948592027028,
      0.14010612282667073,
      0.1496210040272893,
      0.145023865017805,
      0.1289044318166939,
      0.12412816198827985,
      0.12438160197154896,
      0.11319887130647092,
      0.11218201577126442,
      0.10456749859962378,
      0.10188917595523972,
      0.08750029296219886,
      0.08589076105807279,
      0.07896684230984868,
      0.08016448438436062,
      0.08750841755856265,
      0.07479816148946951,
      0.07211648020389917
    ],
    "val_loss": [
      0.5664591678602253,
      0.25074395274598443,
      0.17791647966393453,
      0.2364667974546284,
      0.3702977799369903,
      0.18417706227231168,
      0.1813837182825197,
      0.20381569493851975,
      0.2600539843925459,
      0.26909583028026685,
      0.24192764900937053,
      0.2406531247728599,
      0.2765517816572132,
      0.3115835398257136,
      0.24803732762079753,
      0.24942193578281802,
      0.2543837800934286,
      0.2776634139036704,
      0.2578415057928619,
      0.27187322260376934,
      0.30753013136501084,
      0.27596802552660066,
      0.27175227994333484,
      0.25776935309885507,
      0.2762161502447314,
      0.27973479408168506,
      0.27647659848193207,
      0.2934323699352984,
      0.28463603214410965,
      0.32532422324854454,
      0.3147575943948266,
      0.31754542435714583,
      0.31478506396273653,
      0.3232351458804336,
      0.33470287180232433,
      0.4444641520787856,
      0.31003738706875705,
      0.31485637023955765,
      0.35576318930722994,
      0.3280545995888596,
      0.2872044327284048,
      0.40651465629835326,
      0.39366936388308416,
      0.3460629797178114,
      0.357606190202122,
      0.34132131073556976,
      0.3072419130293552,
      0.41466710009796176,
      0.3456498205215631,
      0.48662204133000914,
      0.2928857482657461,
      0.36324577028166033,
      0.38300598559979193,
      0.3499658436296943,
      0.3907427471554922,
      0.2988628054628829,
      0.3513503188680032,
      0.4250409650142321,
      0.46690289813601327,
      0.48011701065980034,
      0.49338837874506764,
      0.43151920200464966,
      0.3968466614177841,
      0.4775899947760348,
      0.31743723716207606,
      0.35439708073160603,
      0.3932153511547043,
      0.3576532954584339,
      0.33148906569102565,
      0.31008904161389,
      0.319058024481742,
      0.33097297617953697,
      0.2780400473646775,
      0.27234060626008555,
      0.3103395040699108,
      0.3225763541584957,
      0.27419686955427697,
      0.26355678977188235,
      0.28570421117240796,
      0.2979190747448784
    ],
    "best_epoch": 3,
    "best_val_loss": 0.17791647966393453,
    "test_loss": 4.5618875753936585,
    "tracker": {
      "initial_train_loss": 1.0475818399910455,
      "train_threshold": 0.3491939466636818,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.17791647966393453,
      "patience_no_improve_epochs": 78,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_63_28a24f/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_63_28a24f/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_63_28a24f/config.yaml"
}