epoch,train_loss,val_loss
1,0.314823,0.238015
2,0.085079,0.199022
3,0.046746,0.213841
4,0.042876,0.317208
5,0.036976,0.403842
6,0.035016,0.451573
7,0.036136,0.409416
8,0.035588,0.396156
9,0.030848,0.318964
10,0.030868,0.469243
11,0.030659,0.317489
12,0.028425,0.309014
13,0.025453,0.324249
14,0.030455,0.291791
15,0.026997,0.318128
16,0.025713,0.294019
17,0.027075,0.314706
18,0.023078,0.296505
19,0.022878,0.318286
20,0.023051,0.331641
21,0.023226,0.364725
22,0.039364,0.300854
23,0.029952,0.304484
24,0.025302,0.322883
25,0.033846,0.272192
26,0.026456,0.281792
27,0.024148,0.321623
28,0.022888,0.338524
29,0.022534,0.348569
30,0.021368,0.318167
31,0.022805,0.317728
32,0.022037,0.321203
33,0.023546,0.340553
34,0.022089,0.330837
35,0.021440,0.317704
36,0.021556,0.330704
37,0.024875,0.303806
38,0.023211,0.312292
39,0.023676,0.319195
40,0.020175,0.321020
41,0.020927,0.330942
42,0.021854,0.323868
43,0.021575,0.316858
44,0.021213,0.327239
45,0.022198,0.338252
46,0.020487,0.316421
47,0.020646,0.320410
48,0.021374,0.319553
49,0.023099,0.318524
50,0.020357,0.321103
51,0.020545,0.324815
52,0.020895,0.323378
53,0.019319,0.327048
54,0.021114,0.320865
55,0.021512,0.324948
56,0.022903,0.341746
57,0.019418,0.330469
58,0.019921,0.327854
59,0.020123,0.326454
60,0.020489,0.342318
61,0.020601,0.331050
62,0.020451,0.329874
63,0.022912,0.329332
64,0.036116,0.331547
65,0.033543,0.312269
66,0.027289,0.326069
67,0.032531,0.365848
68,0.023047,0.376276
69,0.022037,0.379314
70,0.022233,0.382215
71,0.022986,0.399398
72,0.020752,0.427200
73,0.019927,0.410185
74,0.020554,0.416581
75,0.020685,0.373089
76,0.021338,0.361219
77,0.021665,0.362783
78,0.020596,0.389011
79,0.019913,0.418570
80,0.019870,0.382366
