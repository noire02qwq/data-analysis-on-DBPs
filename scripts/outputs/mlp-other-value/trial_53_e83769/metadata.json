{
  "model_name": "mlp-other-value/trial_53_e83769",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.3013357380924069,
    "mid_layer_count": 9,
    "mid_layer_size": 474
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 200,
    "learning_rate": 0.0018530363031392255,
    "weight_decay": 0.00045259942159930243,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149,
      150,
      151,
      152,
      153,
      154,
      155,
      156,
      157,
      158,
      159
    ],
    "train_loss": [
      0.36947889860744293,
      0.24424558064459287,
      0.21900812603376535,
      0.20245807275000202,
      0.1966099453743083,
      0.18844667066360757,
      0.17789067716369755,
      0.172213138097858,
      0.16868829995531373,
      0.16747707167517045,
      0.1601079510244851,
      0.1560249880850774,
      0.15631730242103353,
      0.1499498216248953,
      0.14865987541860284,
      0.14542897676369543,
      0.1440986461780694,
      0.14041506342700716,
      0.13874334902748686,
      0.13728166431601443,
      0.13671079277992249,
      0.13581402936215398,
      0.13430936386060446,
      0.13369739421855004,
      0.13059966350256205,
      0.13145020134697333,
      0.13113382129163972,
      0.12596427531135945,
      0.12460783584996209,
      0.12422253960612617,
      0.12451685198977888,
      0.12468820975843975,
      0.12474236034502917,
      0.12051476201777461,
      0.11987838141042921,
      0.1196865242236452,
      0.11882976221237017,
      0.1195939112743272,
      0.11840367972804926,
      0.11528647076692136,
      0.11770643634848744,
      0.1149622873312819,
      0.11591954420718736,
      0.11424236522156989,
      0.11507554364898621,
      0.11406034238449178,
      0.1127806833580618,
      0.11348738729678526,
      0.11265608091471194,
      0.11229110626516249,
      0.11173045540800947,
      0.11082881056020785,
      0.1124550662953894,
      0.11150813063347627,
      0.11121826534044321,
      0.10853084750576714,
      0.11133450164572896,
      0.11198864539291016,
      0.10912815023838648,
      0.10972517274278075,
      0.10781226865660538,
      0.10719561985497478,
      0.10851578494336069,
      0.1097982992127102,
      0.10762958690761112,
      0.10820748034641033,
      0.10682687703510503,
      0.10711858040051561,
      0.10841009269285472,
      0.10698859589322522,
      0.1088306557304924,
      0.10680818998887026,
      0.1066510093218244,
      0.10476720571640273,
      0.10606827286037193,
      0.10526746456793726,
      0.10266462773879777,
      0.1024599937849194,
      0.1053174078930886,
      0.10479122119692426,
      0.1035220984803401,
      0.10513744652730003,
      0.10335020351296759,
      0.10490476711246526,
      0.10351703186763624,
      0.10167847669326445,
      0.10218372668071304,
      0.10351716207503783,
      0.10295054848268131,
      0.10206194466630761,
      0.10247914093222112,
      0.1028922403421446,
      0.10279756264924514,
      0.10162263404885703,
      0.10189304243928045,
      0.1031635852311745,
      0.10268828081298693,
      0.10182515760762316,
      0.10154118287205513,
      0.10130431222083815,
      0.10205211209036742,
      0.10313625884490359,
      0.10079741536072427,
      0.10085334771027499,
      0.10365417975456424,
      0.10137170665214587,
      0.10188334166866012,
      0.10219716517710575,
      0.10086382922834466,
      0.10276311880246133,
      0.09974953918701077,
      0.1002348882875851,
      0.10269582316302348,
      0.09943097745717765,
      0.10298798366685352,
      0.09961818028270067,
      0.10208531233241706,
      0.09988494501427665,
      0.10083885638835553,
      0.10052072567977069,
      0.09968612379006939,
      0.1002655712961233,
      0.09910193355558101,
      0.09929178680377841,
      0.10029921824425046,
      0.09862251534652808,
      0.09893190576716408,
      0.10107245436917824,
      0.10047137979255572,
      0.10195317534895174,
      0.09903492678765335,
      0.09672388091889818,
      0.100335300110162,
      0.09806595797368109,
      0.09943307946130764,
      0.09779225748554139,
      0.09950968363595168,
      0.09925091754035377,
      0.10021933912466342,
      0.099099268973363,
      0.10031822769534227,
      0.09988634476009059,
      0.09840270314172575,
      0.09754028441953072,
      0.0996481981290922,
      0.09850808972346593,
      0.09986519608637075,
      0.09780323141856093,
      0.09862335413128612,
      0.0982213075219698,
      0.09702533666233701,
      0.0985906484678747,
      0.09841814122639173,
      0.09682414059901372,
      0.09792839498352307,
      0.09770936208880822,
      0.09692639664480661,
      0.09868003841606147,
      0.09789827452631349
    ],
    "val_loss": [
      0.3805055075776791,
      0.47962168929819576,
      0.5408336836063933,
      0.47549283397411873,
      0.4447899507191367,
      0.547831531770215,
      0.5811974611467944,
      0.5461247345644556,
      0.5684156435692381,
      0.6112820865686782,
      0.5620480311844878,
      0.5087894788402283,
      0.48222383142945296,
      0.49557629745163606,
      0.5243150033279808,
      0.49197826717428106,
      0.47802802242204817,
      0.5224782346251482,
      0.5191634375891999,
      0.45454778928242756,
      0.4914158700469011,
      0.4778521246538905,
      0.4909175841394299,
      0.4469035874583764,
      0.48307455906611,
      0.5150413591704682,
      0.4659467048630743,
      0.47898521537552335,
      0.47497466010247874,
      0.476530222835655,
      0.445375506035582,
      0.47765893993263475,
      0.4959116424629074,
      0.45871025912775965,
      0.4488632604033647,
      0.447688375582952,
      0.4264187596872181,
      0.45614816935476427,
      0.43236749900315335,
      0.4650545985755806,
      0.46081526193790096,
      0.47570845002899625,
      0.4637809700951605,
      0.4435418708595687,
      0.4351458042681574,
      0.43691524256489234,
      0.4309046546856086,
      0.4523735385455057,
      0.4734208715889982,
      0.48807106724756205,
      0.4428593130882629,
      0.4217735926905078,
      0.43078744054554463,
      0.4802612469581787,
      0.45128296146135843,
      0.47357335187003996,
      0.4832204187701562,
      0.4630673320707447,
      0.5028680966285888,
      0.4596214090992591,
      0.45699860806950554,
      0.48587705203872955,
      0.43875378191828013,
      0.49098518687094045,
      0.43578776610111764,
      0.4516395257261699,
      0.4363168909878074,
      0.4765293450055722,
      0.4510175514363957,
      0.4214582373639067,
      0.4623541639236633,
      0.4908588967637388,
      0.4473823396388642,
      0.44089250471777547,
      0.45759103291048975,
      0.4297929745234415,
      0.45162646320765604,
      0.4425339075976503,
      0.4331127333783818,
      0.4318076457805976,
      0.42612970428552455,
      0.44620411321074666,
      0.4356643696744999,
      0.42796140016909845,
      0.4517615696270309,
      0.42021797695559654,
      0.46040513308462266,
      0.42628789965264097,
      0.4480586940656879,
      0.4344195793131868,
      0.4418321437464503,
      0.43717168762298403,
      0.4347771809486572,
      0.4686332908933034,
      0.40474843907499025,
      0.45154987659283025,
      0.49130735479429094,
      0.45517830657744834,
      0.44390785087368445,
      0.41222946140580546,
      0.49182249293355884,
      0.45141594067305146,
      0.45228846165948283,
      0.449031931732943,
      0.4379938384016117,
      0.4324995036610586,
      0.44896623920537754,
      0.47395603367668426,
      0.3941578568812616,
      0.40893444044147426,
      0.4259865351779732,
      0.4209784708337156,
      0.4474271025486335,
      0.4143174304933605,
      0.4339489565638011,
      0.4702933341443182,
      0.44377163480855747,
      0.4491063022684908,
      0.4296559247071158,
      0.4185509695978222,
      0.42136591708588744,
      0.4432518589282464,
      0.4662553521687399,
      0.4596069187461259,
      0.5083303613933975,
      0.4820774115488201,
      0.4880383312702179,
      0.420042705036209,
      0.4803126689916599,
      0.48714106329186946,
      0.417573121136534,
      0.46082549948178364,
      0.41716518373546485,
      0.4354617336909928,
      0.4432174110127066,
      0.471830788486732,
      0.4617637651052304,
      0.44333302617786885,
      0.4625826824211075,
      0.44167618194739977,
      0.45385643197390846,
      0.4517873868256986,
      0.41551257589620033,
      0.44651127022183584,
      0.45011574797287673,
      0.43411646221212286,
      0.4332302357265335,
      0.4422239215074185,
      0.4198092072309848,
      0.4719165556445093,
      0.4809716233236347,
      0.41444870722508004,
      0.43596183887855733,
      0.4113588722166187,
      0.4196245436539907,
      0.3955580841995285,
      0.4762433829778683,
      0.488945783612257,
      0.3987408553411861
    ],
    "best_epoch": 109,
    "best_val_loss": 0.3941578568812616,
    "test_loss": 0.49763626188182375,
    "tracker": {
      "initial_train_loss": 0.36947889860744293,
      "train_threshold": 0.12315963286914765,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3941578568812616,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_53_e83769/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_53_e83769/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_53_e83769/config.yaml"
}