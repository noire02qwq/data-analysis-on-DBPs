{
  "model_name": "mlp-other-value/trial_30_14f011",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.16318430020428196,
    "mid_layer_count": 3,
    "mid_layer_size": 196
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 187,
    "learning_rate": 0.0017670611770395,
    "weight_decay": 0.00031986979863461273,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113
    ],
    "train_loss": [
      0.33788352484517126,
      0.21767343264197372,
      0.19181434089760405,
      0.17590034646620012,
      0.1635228546461489,
      0.15725996788723032,
      0.14979057634902068,
      0.14203607629489567,
      0.13816518069036102,
      0.134406019998031,
      0.1308629411225398,
      0.12847094033190598,
      0.12716247146044132,
      0.1215958757829657,
      0.11924811567692588,
      0.11935217966497128,
      0.11742654367000736,
      0.11520862639936623,
      0.11100571766484237,
      0.11235374029154285,
      0.10705651973721582,
      0.10925703771075969,
      0.1064635847803643,
      0.10603094923134612,
      0.10274637535810777,
      0.10088437323240117,
      0.1022402784950064,
      0.10118961156565236,
      0.09888397515959285,
      0.0971501578685334,
      0.09659082811992863,
      0.09558907462491355,
      0.09763239211990106,
      0.09359847459313257,
      0.09308990554214136,
      0.09311345627597352,
      0.09036013176363666,
      0.09168167340126235,
      0.09184668168498193,
      0.09114346577723312,
      0.09074526513544885,
      0.09181569834044341,
      0.08905056899574978,
      0.08619590606989617,
      0.09068391409885614,
      0.08771340803301995,
      0.08563064952491338,
      0.08629904716362123,
      0.08603575873858137,
      0.08487781495134943,
      0.08661303565234879,
      0.08407011054400804,
      0.08387854089028655,
      0.08491424048914856,
      0.08444848458348114,
      0.08258720646861305,
      0.08330812656237964,
      0.0832707577501125,
      0.08166999796385364,
      0.0826752330503857,
      0.08056307336427329,
      0.08150895605635007,
      0.08100887782405346,
      0.08218331088724351,
      0.08017106763846511,
      0.0825482257448324,
      0.07981639737889301,
      0.08087651742638503,
      0.08003002456391757,
      0.079318584953117,
      0.07958197510925974,
      0.07798161579075227,
      0.07813514344654156,
      0.07864730094027647,
      0.07782169581396174,
      0.07784552292075446,
      0.07894577639461282,
      0.07856132986818203,
      0.07798407806954195,
      0.07899181972262094,
      0.07751012307182222,
      0.07833040007731742,
      0.07776458115494209,
      0.07576161645316525,
      0.0766314172762718,
      0.07570148696630749,
      0.07601343066727369,
      0.07625038130806158,
      0.07714177051672819,
      0.07830720380514386,
      0.07600639511058427,
      0.07549097728731542,
      0.07467643921672075,
      0.07522860894924849,
      0.07527870961535185,
      0.07701662866892785,
      0.07530664021637637,
      0.0758026182563596,
      0.07545385348121743,
      0.07368587558872122,
      0.07347474232165017,
      0.07463261620330315,
      0.07467391580608929,
      0.07333753664541574,
      0.07383288821303934,
      0.07343158623076528,
      0.07459599314914063,
      0.07394655530564123,
      0.07370215731736496,
      0.072539501894684,
      0.07324514366455066,
      0.07389291454337847,
      0.0757432331757791
    ],
    "val_loss": [
      0.4046639390691312,
      0.5145578976876721,
      0.5448078950052847,
      0.584639584955698,
      0.5873675360338774,
      0.6821409775022261,
      0.5265062769328406,
      0.5008853202005347,
      0.5785369158817265,
      0.5968944680994143,
      0.6425524944406069,
      0.5270062646421487,
      0.4988639627611209,
      0.42992588786664837,
      0.47933206774606674,
      0.5022253946094456,
      0.4756926756642179,
      0.49107748521213046,
      0.5547984557594368,
      0.45376846267880794,
      0.492287139259948,
      0.45527447280948036,
      0.4634642086833894,
      0.4562887231479148,
      0.4999740189153277,
      0.4945163352582269,
      0.4733931429014948,
      0.4562438871064586,
      0.49469419993950936,
      0.44593644059168364,
      0.4504061104205554,
      0.4356413693485146,
      0.503726070664243,
      0.4280070774881783,
      0.4202958154374968,
      0.43194516507719094,
      0.5119711383284923,
      0.4239863177259525,
      0.41474545233977766,
      0.4604121098573693,
      0.43506629277399916,
      0.4816292006723181,
      0.4533742790138293,
      0.4342124215767769,
      0.4382440836799002,
      0.43943983885699406,
      0.43690332741794474,
      0.41292982664026184,
      0.45321488082408906,
      0.4452679257639154,
      0.42924983896270485,
      0.4203786651085237,
      0.4264878610740165,
      0.4819044088576725,
      0.46344267757174495,
      0.484860515799708,
      0.4398096301687692,
      0.46795473132215576,
      0.48291401192992034,
      0.4352903920376372,
      0.4185236984161203,
      0.4777458874631428,
      0.38878027755700184,
      0.4462665498836669,
      0.4541885541584677,
      0.45720369773442876,
      0.4633369957883201,
      0.4412655362067465,
      0.45384931368474474,
      0.4326295987708483,
      0.44721931506416757,
      0.47662919275239557,
      0.4809372247291539,
      0.4473057479647819,
      0.49649139445520446,
      0.44091356154865846,
      0.48766468053761713,
      0.4891757621870426,
      0.4533794553336983,
      0.43917665794759453,
      0.4560626404817233,
      0.4662939826305398,
      0.47704146160426253,
      0.4431311746423473,
      0.49298840773676683,
      0.44863824624412074,
      0.4575516035992228,
      0.4557243980556548,
      0.4363299834291021,
      0.4389490162987195,
      0.44555649934949987,
      0.443851383213333,
      0.4364326241889043,
      0.4373277455746771,
      0.4395975627183557,
      0.4518572093751616,
      0.42458083134389923,
      0.41149307210109903,
      0.48215144628179285,
      0.427774867245894,
      0.4525903546524619,
      0.4326535613950855,
      0.43687230675163385,
      0.4403131478917813,
      0.457183090994458,
      0.4507380608848469,
      0.45126062430842906,
      0.46248358764691266,
      0.45516245772917113,
      0.4881758417911872,
      0.47551331711029576,
      0.5001336763852727,
      0.44740309706348147
    ],
    "best_epoch": 63,
    "best_val_loss": 0.38878027755700184,
    "test_loss": 0.5218823741337186,
    "tracker": {
      "initial_train_loss": 0.33788352484517126,
      "train_threshold": 0.11262784161505708,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.38878027755700184,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_30_14f011/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_30_14f011/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_30_14f011/config.yaml"
}