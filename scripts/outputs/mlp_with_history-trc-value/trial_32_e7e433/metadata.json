{
  "model_name": "mlp_with_history-trc-value/trial_32_e7e433",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 21,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.32238817119282803,
    "mid_layer_count": 4,
    "mid_layer_size": 868
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 485,
    "learning_rate": 0.0014241354338281203,
    "weight_decay": 0.0005862157899293926,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7776,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 210,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      2.297076510909347,
      0.8130339970352289,
      0.3476291687281442,
      0.22354315508563272,
      0.18953983721403797,
      0.16891848669605858,
      0.16465742027563324,
      0.1653168213231788,
      0.15302800211035972,
      0.1488255724596404,
      0.1552298732596323,
      0.19901238989330244,
      0.1405676672169977,
      0.15236380345517686,
      0.1425118907488913,
      0.14221433542645823,
      0.13771140131785117,
      0.1335306413416126,
      0.1329394618946093,
      0.13387846925732805,
      0.14006580398590476,
      0.12675880709444576,
      0.11606635459518605,
      0.11884237385312778,
      0.12253773129169557,
      0.10829243442204631,
      0.10585478382997614,
      0.10102101520409064,
      0.09115308669679358,
      0.09499508567986083,
      0.09157555289815636,
      0.08349714863474324,
      0.09923478610690975,
      0.09265782754895097,
      0.11727265778683708,
      0.10869841538312167,
      0.08510879600524074,
      0.0913412327324366,
      0.09084713160071844,
      0.07884277819479536,
      0.08838065613804715,
      0.08390234698974547,
      0.07806447029224915,
      0.07863043950594685,
      0.07646523601540323,
      0.07991525889163523,
      0.0869649119278485,
      0.08284105448753654,
      0.07853009989830079,
      0.07322385929785516,
      0.06981394484202251,
      0.07791534456550891,
      0.11146533883602162,
      0.08884026581486648,
      0.08837774672560823,
      0.07035136462712407,
      0.06957124384769733,
      0.08834429467748467,
      0.0907610000653476,
      0.07828014365008384,
      0.0760117881795307,
      0.09182058964806145,
      0.08984673727656343,
      0.07822794457437632,
      0.07991365568449821,
      0.071611528858301,
      0.07660977535310044,
      0.06949062774881506,
      0.0662685051941746,
      0.08672176684835474,
      0.07196868236565679,
      0.0726470771713236,
      0.06992271662222167,
      0.07215466218523359,
      0.06882842114183729,
      0.06448645499025168,
      0.07730141150240054,
      0.08289124167892208,
      0.08440885993933742,
      0.10388864867711141
    ],
    "val_loss": [
      0.25483561746642264,
      0.2691653769820215,
      0.234097120413434,
      0.22824376077017564,
      0.24162926391592462,
      0.24759308812013286,
      0.2494795534558996,
      0.349630319987407,
      0.2073466989830761,
      0.24724544685133204,
      1.1267352888505615,
      0.23082549795285315,
      0.256238137656254,
      0.23203093671758554,
      0.27429325937734034,
      0.278639612607881,
      0.25223673170733596,
      0.2431483916425241,
      0.2725349645727052,
      0.31273110822110833,
      0.3035415747610038,
      0.2662439054424713,
      0.4481787545059969,
      0.2594377437639915,
      0.2893244607630604,
      0.3114115252287802,
      0.3023007985003694,
      0.28390125219827284,
      0.2778005844684775,
      0.2970505484218101,
      0.28038135707423,
      0.4723120993393624,
      0.30747967820146127,
      0.5035497309294289,
      0.47456987173168247,
      0.29741478690174883,
      0.3193599883422345,
      0.2892073415063634,
      0.2794669528051229,
      0.3432400711438435,
      0.3012399506716136,
      0.3119736191688362,
      0.33342337564838503,
      0.40185171023323507,
      0.2894143093555809,
      0.38971729718237935,
      0.3869057585412781,
      0.31199970266999244,
      0.3191620474290883,
      0.3320379982295329,
      0.45111042622499126,
      0.35430071161067234,
      0.37324394546672257,
      0.38620327496733853,
      0.34051082878858746,
      0.36505245560122107,
      0.29374760129449967,
      0.4089337618809617,
      0.2897538345887097,
      0.3370301587629818,
      0.3038662427110586,
      0.3830189482046815,
      0.31783358031091935,
      0.31545903023979266,
      0.3319080250482716,
      0.31822001038420344,
      0.2923399175846291,
      0.3047327284818281,
      0.3163017001906466,
      0.35750370980156754,
      0.3083825303788135,
      0.305253296767077,
      0.31686246085042014,
      0.41113308609691923,
      0.39765583122606407,
      0.37247549300779126,
      0.3361246100108245,
      0.3369259053093944,
      0.38441296603842945,
      0.30513543453803676
    ],
    "best_epoch": 9,
    "best_val_loss": 0.2073466989830761,
    "test_loss": 4.598232339158583,
    "tracker": {
      "initial_train_loss": 2.297076510909347,
      "train_threshold": 0.7656921703031156,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.2073466989830761,
      "patience_no_improve_epochs": 71,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_32_e7e433/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_32_e7e433/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_32_e7e433/config.yaml"
}