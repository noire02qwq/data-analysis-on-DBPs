{
  "model_name": "mlp-other-rate/trial_60_d146a5",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.29680518912659426,
    "mid_layer_count": 11,
    "mid_layer_size": 295
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 178,
    "learning_rate": 0.001404624178486954,
    "weight_decay": 0.0007361569254475974,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113
    ],
    "train_loss": [
      0.3710897088991244,
      0.24564926156161565,
      0.2216815814612889,
      0.20759528297347984,
      0.20088570178120854,
      0.1901958667663136,
      0.18399050916660253,
      0.17828218842650634,
      0.1707678624816342,
      0.16813164151604815,
      0.16512304903789324,
      0.1658444558200988,
      0.1590423810254188,
      0.15564319771213248,
      0.1543442760448446,
      0.15118614434354913,
      0.14926665937437222,
      0.1461699213956857,
      0.1448065672392812,
      0.14579972838280505,
      0.1442511117438465,
      0.14114982024668546,
      0.14153005648547715,
      0.14099728021715285,
      0.1367950762209677,
      0.13619086479126888,
      0.1327743371322621,
      0.1341431977283716,
      0.133810022187392,
      0.1306706944039964,
      0.13040401667295326,
      0.1285375983780656,
      0.13203081093908212,
      0.13062242764297236,
      0.1277678675410563,
      0.12826310699493107,
      0.12551435652552598,
      0.12580309263700518,
      0.12445649579205594,
      0.12469436681082519,
      0.12338365611547136,
      0.12615447716568604,
      0.12334548757283,
      0.12170839781422318,
      0.12202232962750423,
      0.12130000664560596,
      0.11885207827241681,
      0.11994184240729397,
      0.11933365620370703,
      0.1196788011425547,
      0.12287493344451783,
      0.1193105440133807,
      0.11783888547075841,
      0.11756088018509105,
      0.11704931140190641,
      0.11789159767861059,
      0.11755374382288716,
      0.11852670570461796,
      0.11785428403944098,
      0.11575320989788038,
      0.11685340752344428,
      0.11348630395407797,
      0.11492581043933342,
      0.11464033064061156,
      0.11415641430694669,
      0.11582332845870931,
      0.11454500543721031,
      0.11431278684212343,
      0.11368777999714622,
      0.11522126191507369,
      0.1132141738831844,
      0.11320079053026276,
      0.11458314851828573,
      0.11248935215851782,
      0.1122441142147599,
      0.11341514005844198,
      0.11198538208257057,
      0.11417773075252695,
      0.11127792828056432,
      0.11101757621477665,
      0.11059156049323914,
      0.11148372099277544,
      0.1113925616750508,
      0.11089940855003369,
      0.11105364647475556,
      0.10973058333606094,
      0.11059707764817116,
      0.11015064245603096,
      0.11004953132822858,
      0.1090664475384035,
      0.10890256920652612,
      0.11063283089722285,
      0.10751896990934294,
      0.10960417248312482,
      0.10820007956505066,
      0.10973777766294085,
      0.11145787095682569,
      0.10827107951733135,
      0.10959237722776498,
      0.1107198405320856,
      0.10910418798612778,
      0.10939736143824931,
      0.10887228672690365,
      0.10962208526915254,
      0.10858906478286096,
      0.10876381943521285,
      0.10855618620213942,
      0.10872612804319688,
      0.10829388329796512,
      0.10778090332167892,
      0.10812718846121772,
      0.10602522763940174,
      0.1090618602839753
    ],
    "val_loss": [
      0.37321158530647885,
      0.49376454704892847,
      0.5351622489576568,
      0.47517095077894406,
      0.5024264877338609,
      0.5215998824485047,
      0.47285165806373436,
      0.5318849156359713,
      0.5957520332789706,
      0.5217310276484775,
      0.7059560692952779,
      0.560404461211787,
      0.4821865614481315,
      0.5202825615952115,
      0.5139028882373593,
      0.4929166504812098,
      0.47123331072444685,
      0.531151792210733,
      0.6258175276532144,
      0.4628881386475649,
      0.4816939593878335,
      0.47561880533923645,
      0.5224885798946112,
      0.46710905790507434,
      0.5406281783552227,
      0.5294972243958604,
      0.5553576312736123,
      0.5016726334027187,
      0.47936730973734826,
      0.4690110636328509,
      0.4313947085759597,
      0.4624012326230546,
      0.5409335846672515,
      0.4712853527889994,
      0.45916676774710236,
      0.4614994831338614,
      0.4660151457358263,
      0.44269801679842485,
      0.4864679897081352,
      0.4872425419038641,
      0.5159693789963951,
      0.47605999055022963,
      0.47841656501600127,
      0.46409887696454627,
      0.47615316487001086,
      0.5010704293668627,
      0.48229373955798005,
      0.4633536108239682,
      0.4560471325220462,
      0.48370734822607325,
      0.4751950751343173,
      0.4606312995006938,
      0.4629597784694797,
      0.5022780289103885,
      0.506411752773973,
      0.478651126148458,
      0.4843486319580478,
      0.5105987203870704,
      0.49286336383062923,
      0.4984667703330874,
      0.45973483046550234,
      0.48063360207273575,
      0.40265734955936133,
      0.5255571595387545,
      0.43927905987836646,
      0.47308284179893084,
      0.45913127778532975,
      0.46415519775030856,
      0.4461337209283235,
      0.4489381292176818,
      0.4741319075137555,
      0.4797861249503975,
      0.4789407105681425,
      0.4529337370467043,
      0.4844618760361643,
      0.46350862953120364,
      0.456895687462327,
      0.48220925081275895,
      0.44424065028479,
      0.46561592692386605,
      0.5093082992616528,
      0.45202428643218057,
      0.47729994028271316,
      0.42484232497786334,
      0.49745860785067436,
      0.457815017743025,
      0.45382744139896897,
      0.47581671126588376,
      0.4621395787436091,
      0.4849522028140679,
      0.4750288639061465,
      0.42577809514756687,
      0.4753887422695131,
      0.4834579305734463,
      0.4637019882034399,
      0.48616826937584107,
      0.467563086578589,
      0.46642142671667886,
      0.4693483721710251,
      0.40432800509615574,
      0.46476212622162827,
      0.47266632966295685,
      0.4711237369183295,
      0.47549412739491037,
      0.45302060912112274,
      0.4344641393173241,
      0.45250114943096026,
      0.4804493662304507,
      0.43215249735795097,
      0.48346614039943603,
      0.49002648449229624,
      0.47956297131712566,
      0.49045627024359334
    ],
    "best_epoch": 63,
    "best_val_loss": 0.40265734955936133,
    "best_val_abs_mse": 0.49512994289398193,
    "test_loss": 0.4909430092209549,
    "test_abs_mse": 1.1530753374099731,
    "tracker": {
      "initial_train_loss": 0.3710897088991244,
      "train_threshold": 0.12369656963304147,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.40265734955936133,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-rate/trial_60_d146a5/best_model.pt",
    "last": "scripts/outputs/mlp-other-rate/trial_60_d146a5/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-rate/trial_60_d146a5/config.yaml"
}