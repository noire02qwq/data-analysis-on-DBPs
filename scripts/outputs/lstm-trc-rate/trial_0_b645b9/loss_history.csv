epoch,train_loss,val_loss
1,1.004839,0.340932
2,1.004797,0.351069
3,1.004609,0.349375
4,1.005165,0.340815
5,1.004498,0.349334
6,1.004458,0.350260
7,1.004441,0.343145
8,1.004696,0.351566
9,1.004324,0.343648
10,1.004573,0.343983
11,1.004346,0.345651
12,1.004320,0.344174
13,1.004474,0.348222
14,1.004472,0.348549
15,1.004505,0.346477
16,1.004322,0.344809
17,1.004622,0.345120
18,1.004456,0.345439
19,1.004331,0.343337
20,1.004342,0.347458
21,1.004375,0.347675
22,1.004577,0.347130
23,1.004456,0.345979
24,1.004398,0.345733
25,1.004478,0.347689
26,1.004318,0.346742
27,1.004304,0.344840
28,1.004319,0.345244
29,1.004325,0.343895
30,1.004436,0.344921
31,1.004471,0.348337
32,1.004344,0.343502
33,1.004314,0.347030
34,1.004323,0.344524
35,1.004378,0.344734
36,1.004332,0.345219
37,1.004343,0.347919
38,1.004281,0.345849
39,1.004294,0.346163
40,1.004305,0.346874
41,1.004470,0.347633
42,1.004337,0.345980
43,1.004343,0.349681
44,1.004286,0.345942
45,1.004469,0.348256
46,1.004327,0.347102
47,1.004379,0.347912
48,1.004371,0.346439
49,1.004311,0.345992
50,1.004302,0.345541
