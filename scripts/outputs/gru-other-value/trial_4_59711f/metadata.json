{
  "model_name": "gru-other-value/trial_4_59711f",
  "model_type": "GRU",
  "model_format": "torch",
  "model_params": {
    "history_length": 123,
    "units": 272,
    "num_layers": 4,
    "dropout": 0.3808511954903963
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 227,
    "learning_rate": 0.0002734003079981186,
    "weight_decay": 0.00037910486446432977,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7674,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 123,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106
    ],
    "train_loss": [
      0.46288615467882666,
      0.26457391136755753,
      0.2386767853547547,
      0.22378014463806079,
      0.21317078983267987,
      0.20231096232919168,
      0.19382210686736845,
      0.18230801222883292,
      0.16672197259051869,
      0.1541439136482944,
      0.1416372756939988,
      0.13696394411127083,
      0.12830936467939594,
      0.12044911283260837,
      0.11395799837752124,
      0.10864612329746398,
      0.10451247856110249,
      0.09881009621672374,
      0.09292589161512999,
      0.0825670990080286,
      0.08026879042744295,
      0.07905585065790847,
      0.0731527669899455,
      0.06890162512813426,
      0.06405594482617917,
      0.06558354942777099,
      0.06088690482349889,
      0.05723012717727621,
      0.057147344076753065,
      0.05228014632424542,
      0.05495472440138315,
      0.05195383362642933,
      0.04754184657435477,
      0.049261105097568154,
      0.049184752513642634,
      0.04561485763389694,
      0.04588542210900802,
      0.04380520903581842,
      0.041895624902123646,
      0.040924724524441194,
      0.040338748687835047,
      0.040004682440503925,
      0.04045054348462847,
      0.03861365017110027,
      0.036246041714143154,
      0.038355799311039454,
      0.03805265120981353,
      0.03591056252206664,
      0.03768730058524333,
      0.036642507768163524,
      0.036551371813140825,
      0.03646943758438194,
      0.035374930294962144,
      0.03590181172729036,
      0.04068768036702018,
      0.035656742925872426,
      0.035270233557515615,
      0.03632819183182446,
      0.03439347656550027,
      0.03402698319308229,
      0.03234474998450983,
      0.03351518338663149,
      0.03276455442301962,
      0.03143118407649122,
      0.03176606472572887,
      0.03398562772993211,
      0.03225167490739025,
      0.032328890943848776,
      0.03119966103691692,
      0.03020357638806229,
      0.03159888812304631,
      0.033312828962079225,
      0.03332907783733096,
      0.030824846035398198,
      0.03321335249324857,
      0.03242788121666384,
      0.03094912799240782,
      0.03003955956117379,
      0.03011746693631658,
      0.030653215027764996,
      0.03033408974893226,
      0.0293097708445622,
      0.030109781767529282,
      0.06201335435244358,
      0.05084313238357578,
      0.037714483435825195,
      0.033211052527465264,
      0.03133476128938113,
      0.029383803765608178,
      0.029627656841061764,
      0.029751775889194566,
      0.02871228446870856,
      0.02901963523841748,
      0.02927607609915887,
      0.028773308204909788,
      0.029807672744137734,
      0.029457339680306314,
      0.02847196694108147,
      0.028190718908887188,
      0.028374556393782734,
      0.027550313168841007,
      0.027878581981204017,
      0.02938996340665876,
      0.027935620829616405,
      0.02870965629509255,
      0.032120495785104446
    ],
    "val_loss": [
      0.39706417090164686,
      0.3926263639848389,
      0.4160535748936459,
      0.4878645510864472,
      0.5534636969204078,
      0.6067909292519806,
      0.751595175163653,
      0.7468330075730106,
      0.7790026465085095,
      0.7141098417832465,
      0.7612911242746307,
      0.8128114950826425,
      0.6597372307615009,
      0.6567267356563115,
      0.6673043362439393,
      0.599772738776878,
      0.5612025265185955,
      0.4397443520451734,
      0.4852269460765009,
      0.49708848295142194,
      0.5340226421634594,
      0.5528561712738996,
      0.49990614270735645,
      0.5299248394584227,
      0.5839058299442965,
      0.45380773263241714,
      0.5393875088743464,
      0.48907228379460155,
      0.4792000176842341,
      0.48082200474814024,
      0.4878410134085281,
      0.4510645863650266,
      0.4806647543332534,
      0.5105145980007277,
      0.518932497644139,
      0.46445217495282254,
      0.4993483912623571,
      0.46502460539787116,
      0.48702284956049774,
      0.45538676599720995,
      0.4547012174602397,
      0.4580947158936255,
      0.4325673589538671,
      0.4248625852479906,
      0.43952611496080896,
      0.45431414971986933,
      0.44281237261024065,
      0.42006202635472406,
      0.4586448151417478,
      0.45605764698214873,
      0.43268847316057385,
      0.4400372076534226,
      0.4420080381819231,
      0.43430959356134524,
      0.4184869547179359,
      0.4087563896562882,
      0.44061125026134673,
      0.4142127027590118,
      0.4270901879730696,
      0.42165831028076706,
      0.4541543396870176,
      0.42678024639448003,
      0.4384156634886108,
      0.4441333470587245,
      0.43537234523428414,
      0.438767416779688,
      0.46467380867211405,
      0.45705344200491194,
      0.4260938397156978,
      0.44273012273772033,
      0.4453618628982298,
      0.4325151925538471,
      0.44614958132276994,
      0.43331853633155365,
      0.4422587154243521,
      0.4502235012407788,
      0.4259118771570885,
      0.44342070321836874,
      0.44135059639365376,
      0.4370602341335334,
      0.4386212173782423,
      0.4486015146051695,
      0.44906168362783816,
      0.4113814488053322,
      0.4357144391420716,
      0.4545103031673474,
      0.4555542448546715,
      0.4540246520927566,
      0.4465435966581642,
      0.441127440685819,
      0.44366432127659905,
      0.44765304889596863,
      0.4608892214423168,
      0.4463375125905711,
      0.44850712095549006,
      0.4564713296196061,
      0.45805261333634756,
      0.4510329945760216,
      0.4536524926027852,
      0.46467166446193964,
      0.44167091544427556,
      0.441425737127394,
      0.45581831994527827,
      0.43871869484999937,
      0.4555968467793065,
      0.43857793291796465
    ],
    "best_epoch": 56,
    "best_val_loss": 0.4087563896562882,
    "test_loss": 0.45197455049826624,
    "tracker": {
      "initial_train_loss": 0.46288615467882666,
      "train_threshold": 0.15429538489294223,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4087563896562882,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/gru-other-value/trial_4_59711f/best_model.pt",
    "last": "scripts/outputs/gru-other-value/trial_4_59711f/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/gru-other-value/trial_4_59711f/config.yaml"
}