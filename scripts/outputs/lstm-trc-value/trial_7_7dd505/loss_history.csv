epoch,train_loss,val_loss
1,1.000572,0.335735
2,1.000325,0.336984
3,1.000001,0.352499
4,0.999927,0.347303
5,1.000041,0.341976
6,0.999851,0.355807
7,0.999724,0.348974
8,0.999787,0.345737
9,0.999696,0.349905
10,0.999863,0.346978
11,0.999706,0.352570
12,0.999712,0.349618
13,0.999769,0.348304
14,0.999690,0.347825
15,0.999678,0.351619
16,0.999710,0.347588
17,0.999709,0.351141
18,0.999646,0.348791
19,0.999675,0.349727
20,0.999684,0.349641
21,0.999648,0.348228
22,0.999641,0.349519
23,0.999662,0.350220
24,0.999634,0.349719
25,0.999621,0.350518
26,0.999629,0.349916
27,0.999616,0.349770
28,0.999646,0.350195
29,0.999646,0.349671
30,0.999646,0.349941
31,0.999774,0.351641
32,0.999606,0.349168
33,0.999656,0.348367
34,0.999662,0.350462
35,0.999626,0.349969
36,0.999621,0.350115
37,0.999624,0.349482
38,0.999644,0.350447
39,0.999638,0.349659
40,0.999622,0.349881
41,0.999631,0.349645
42,0.999624,0.350241
43,0.999621,0.350146
44,0.999628,0.350694
45,0.999619,0.350821
46,0.999607,0.350160
47,0.999616,0.349359
48,0.999617,0.350001
49,0.999644,0.350748
50,0.999626,0.351031
