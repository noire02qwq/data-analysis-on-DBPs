{
  "model_name": "mlp_with_history-other-rate/trial_48_93d222",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 46,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.19565207662521525,
    "mid_layer_count": 13,
    "mid_layer_size": 388
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 185,
    "learning_rate": 0.0009098830364184581,
    "weight_decay": 0.0035506660315211837,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TOC-RT",
    "TOC-RT",
    "DOC-RT",
    "DOC-RT",
    "pH-RT",
    "pH-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7751,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 460,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.9123668994284987,
      0.3878657175693,
      0.3513698687616156,
      0.34551007198819866,
      0.3347978254331033,
      0.3090759121230488,
      0.2777193148641213,
      0.26973663103794254,
      0.26571632328225386,
      0.2599857277181007,
      0.25642317819173926,
      0.25105646398740805,
      0.2530985081611857,
      0.2507802474834799,
      0.24537647231104082,
      0.24295664959231617,
      0.2505988025493029,
      0.24295170139941905,
      0.24610771989341,
      0.24744504794176586,
      0.23816166732783717,
      0.2374202705147866,
      0.2407222425452418,
      0.23747460099439163,
      0.2369326875315468,
      0.23359335940309592,
      0.23107211723771806,
      0.22778945215024296,
      0.22917001254288494,
      0.23286302229494082,
      0.22579509962252564,
      0.2229808520834733,
      0.2277232089064657,
      0.22971174795117597,
      0.2203378639129989,
      0.2231356300487624,
      0.21470607196018937,
      0.21286942332756165,
      0.21391149790513717,
      0.2137712687926821,
      0.21105252958785148,
      0.32426799515795973,
      0.5120273734381731,
      0.33204920321353065,
      0.32607065955949066,
      0.3397656976253875,
      0.2862006864241209,
      0.26375096713576895,
      0.25619426291614267,
      0.2545790556318882,
      0.253536870277031,
      0.2494942812308421,
      0.2507575806698912,
      0.24758424643639088,
      0.24638443498738488,
      0.24811923665556504,
      0.24641669035888367,
      0.24701242144069985,
      0.2462449393961725,
      0.24846936379182172,
      0.24508387742388896,
      0.2453654574730399,
      0.24459038924561857,
      0.24372512625811285,
      0.24551269529312136,
      0.2451358951782968,
      0.24297365231900628,
      0.2476252423338145,
      0.24546424173459808,
      0.24377251999245322,
      0.24185494041961172,
      0.2354547225968359,
      0.23506157800560998,
      0.24021409508098004,
      0.23358449034384182,
      0.23217508526536484,
      0.23284291373254593,
      0.22861755532328504,
      0.2254311163730582,
      0.2640306327961565
    ],
    "val_loss": [
      0.7258330089692584,
      0.4677508405136491,
      0.4665158960722878,
      0.4956358091872252,
      0.49257718979152376,
      0.5265561908394277,
      0.5041532367244809,
      0.5527862576310506,
      0.4654497754074142,
      0.5089470836261433,
      0.47179530552047455,
      0.44274726708581347,
      0.4387611443634162,
      0.4508736981023215,
      0.46633304367789963,
      0.5058264692431081,
      0.45578123901240125,
      0.45832287272561095,
      0.41163194846518025,
      0.43652302510813323,
      0.4780874021217495,
      0.4381508623322327,
      0.44345108656112303,
      0.4920489146279361,
      0.47749887743663644,
      0.4665957986193146,
      0.43906472636732513,
      0.44299032139831673,
      0.47981667781839826,
      0.497927320396115,
      0.47783967330605687,
      0.4762508202857243,
      0.48992395075316914,
      0.4961048307756107,
      0.49107983710612363,
      0.5050119714153384,
      0.501151244016643,
      0.510761480310006,
      0.5088554783584829,
      0.5178284477554038,
      0.5158944885263186,
      1.2809759435985617,
      0.49011979374789194,
      0.4967456148591584,
      0.6470822234175162,
      0.5172486589652693,
      0.5352660828454052,
      0.550808512878989,
      0.5666628502041637,
      0.5849037497432646,
      0.5795173389602921,
      0.589407374357392,
      0.6007985977935577,
      0.5770442958943501,
      0.5793225663953913,
      0.5162120222777664,
      0.5380342397504224,
      0.5387152458825512,
      0.5232313848184255,
      0.572797056800591,
      0.5276297215974617,
      0.5368841097517285,
      0.5374552611328528,
      0.5914291934428101,
      0.5171156469844058,
      0.49346342986215375,
      0.5520371096041388,
      0.5305495935375105,
      0.5988493186538805,
      0.5416238007698945,
      0.49849940956888084,
      0.4728264444825535,
      0.44864363832298865,
      0.5583040153685801,
      0.49477611847980296,
      0.4973758001125858,
      0.45406354319103465,
      0.4461095230932721,
      0.4486959841169283,
      0.726771724081325
    ],
    "best_epoch": 19,
    "best_val_loss": 0.41163194846518025,
    "best_val_abs_mse": 0.4712167978286743,
    "test_loss": 0.5358138256193847,
    "test_abs_mse": 1.2312798500061035,
    "tracker": {
      "initial_train_loss": 0.9123668994284987,
      "train_threshold": 0.30412229980949956,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.41163194846518025,
      "patience_no_improve_epochs": 61,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-rate/trial_48_93d222/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-rate/trial_48_93d222/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-rate/trial_48_93d222/config.yaml"
}