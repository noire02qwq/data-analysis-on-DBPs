{
  "model_name": "mlp-other-value/trial_38_8a7001",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.2592239976136621,
    "mid_layer_count": 10,
    "mid_layer_size": 283
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 205,
    "learning_rate": 0.0010690847673488796,
    "weight_decay": 0.0005703196327340661,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84
    ],
    "train_loss": [
      0.39659867787770947,
      0.25147310108053433,
      0.2223792513493179,
      0.2103044589156674,
      0.20055071972864844,
      0.19567275354270755,
      0.18640597863242284,
      0.18153303612755653,
      0.17581401620654646,
      0.17353012662604567,
      0.17172820624508817,
      0.16705391362210065,
      0.16268690976540268,
      0.15796981621562303,
      0.15924347023273688,
      0.15818348381115938,
      0.1509351520610351,
      0.14830093703334488,
      0.14838375719985697,
      0.14880802608135726,
      0.14474702090418692,
      0.14637574102211573,
      0.14054185747163703,
      0.1423993702756175,
      0.14082754560659763,
      0.14059652459199395,
      0.13800552953942546,
      0.13795867918193983,
      0.13399581109226638,
      0.13366728859560315,
      0.13121417230649782,
      0.13223571084218033,
      0.13140636718062146,
      0.13758936688961465,
      0.12935562714888477,
      0.12758335291100747,
      0.12728142848915935,
      0.1289654849512859,
      0.1257439237068851,
      0.1275917993253503,
      0.12521572582224902,
      0.12599057331394545,
      0.12145084257463634,
      0.12177147923573553,
      0.11981131930980332,
      0.12181862851479623,
      0.12253304608949886,
      0.11918739343168125,
      0.12701299256731632,
      0.11731740389365211,
      0.11834366463809028,
      0.11913893102028389,
      0.11871976296242046,
      0.11648071189532835,
      0.1163162854058107,
      0.11532018495950104,
      0.11773527457759649,
      0.11435565602353531,
      0.12038181316090309,
      0.11409263484267897,
      0.11340900630584554,
      0.11027155292644264,
      0.12393890915695614,
      0.11451209281949186,
      0.11417863595410761,
      0.1101468630926373,
      0.11194284896573206,
      0.10973724384929291,
      0.12130986007093894,
      0.12223176713583712,
      0.11319758998695523,
      0.10727788843482106,
      0.1064613294563595,
      0.11014443122351274,
      0.10792343464778931,
      0.10537060598468646,
      0.10452988843078519,
      0.10555052215672109,
      0.10361170286973083,
      0.10322224292015345,
      0.10558465797035525,
      0.1094435369313956,
      0.1035851182510695,
      0.1033159214601861
    ],
    "val_loss": [
      0.3660997565456493,
      0.5126586440214497,
      0.4850932095355973,
      0.5100184526227548,
      0.5024110190124212,
      0.4901016205326169,
      0.5522339501512978,
      0.5052561406157687,
      0.48207375019074916,
      0.5100789933415231,
      0.5089957643590287,
      0.450560966183147,
      0.5102323421282683,
      0.4629952935000023,
      0.5657262554068765,
      0.5171410667815965,
      0.47632107921613903,
      0.5989623290603746,
      0.594442178835412,
      0.4950321520160058,
      0.47361942655044403,
      0.46481340202296567,
      0.48796917986637817,
      0.45580590755015077,
      0.4975486191179224,
      0.4764445519554401,
      0.4636589036194864,
      0.49729854921380917,
      0.43623266984781106,
      0.4451483729669077,
      0.41746283936018713,
      0.46399459278512145,
      0.4715512061190462,
      0.3998674398990805,
      0.46200404570488157,
      0.44342249301736225,
      0.41698911159249125,
      0.4617991825331471,
      0.4514869548781903,
      0.534780203760741,
      0.43520862033624136,
      0.46438355279896787,
      0.4802311631198415,
      0.46192986658679513,
      0.45378585510000496,
      0.45772495506677086,
      0.4358590379758866,
      0.4294264126055969,
      0.40930856532322435,
      0.44714050755618573,
      0.4412521667956949,
      0.403549074435127,
      0.41187632135199215,
      0.4622964253593348,
      0.44254624020464406,
      0.4466041667375736,
      0.4556584643300422,
      0.4278796190273262,
      0.46421292544660453,
      0.45237697078706973,
      0.4737545445918323,
      0.4562852204202892,
      0.4153562266223445,
      0.4517015777751357,
      0.4227454138997786,
      0.5097246048693171,
      0.44002633187139106,
      0.43407687593898375,
      0.44557802660201123,
      0.4424092169561072,
      0.42973068570662404,
      0.43663167302123085,
      0.43573397609912706,
      0.44174123080280014,
      0.45738833527008216,
      0.43902650178817215,
      0.4405485276958186,
      0.4224468204834147,
      0.4230372852640238,
      0.43425812924693447,
      0.4377225563822392,
      0.4009807213783978,
      0.4344082209030668,
      0.4273373907108507
    ],
    "best_epoch": 34,
    "best_val_loss": 0.3998674398990805,
    "test_loss": 0.518973360934326,
    "tracker": {
      "initial_train_loss": 0.39659867787770947,
      "train_threshold": 0.13219955929256982,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.3998674398990805,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_38_8a7001/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_38_8a7001/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_38_8a7001/config.yaml"
}