# 回归实验

## 回归实验

使用MLP、MLP_with_history、XGBoost、LSTM、RNN尝试回归实验。原始数据使用time_aligned_data.csv。模型输出目标是PPL1和PPL2的TRC, TOC, DOC，PH，非PPL1 PPL2的值为输入数据。训验测划分为7:1.5:1.5。

按每个模型来详细定义输入数据：MLP和XGBoost直接使用非PPL1 PPL2的值为输入数据，MLP_with_history把该时间步与过去固定长度时间步的非PPL1 PPL2数据展平作为模型的输入数据(类比1027的MLP)。LSTM和RNN中，某时间步的输入数据为该时间步的非PPL1 PPL2数据。框架使用torch。

其中：模型本体放在models中，模型超参数配置文件yaml放在models/configs中，训练、测试脚本放在scripts中，要支持加载不同模型。模型训练时每10个epoch保存checkpoint，并在train loss降到初始1/4后使用val loss新低更新best模型。至少80轮epoch且train loss降到初始1/4后当连续50个epoch中val loss不出现新低则停止训练而不是设置固定epoch轮数。如果100轮epoch后train loss降不到初始1/4也提前结束，把最后一个epoch作为best。超参数等根据数据规模采取经验值。训练脚本最终要生成训练曲线，测试脚本要生成真实值和预测值的对比折线图(每个输出目标一张图两条线)。训练和测试脚本产生的文件放在scripts/outputs/模型名称中。

## 自动调参脚本

在双输出回归实验跑通后进行，旨在利用空闲保持运行。对于每个模型编写一个调参网格yaml，来描述config的yaml中哪几个超参数是可调的，调整的最小值、最大值、间隔步长是多少。在网格调参时，每确定一组超参数，在outputs中对应模型的文件夹生成一个名为编号的文件夹，里面先生成这组超参数的yaml，然后按照这个yaml执行训练，训练一切结果保存在这个文件夹中。同时在outputs中的对应模型的文件夹里编写一个调参结果csv，每行包含编号、几个超参的值、best的val loss。