epoch,train_loss,val_loss
1,0.646634,0.188462
2,0.155488,0.204539
3,0.130453,0.266858
4,0.117627,0.256188
5,0.117817,0.258679
6,0.115217,0.281023
7,0.113548,0.296000
8,0.110579,0.306632
9,0.163885,0.283778
10,0.216017,0.260190
11,0.127688,0.316456
12,0.112067,0.272215
13,0.111878,0.292834
14,0.124739,0.268910
15,0.326392,0.290689
16,0.410228,0.267756
17,0.318655,0.336060
18,0.164884,0.365747
19,0.127477,0.625946
20,0.121597,0.493049
21,0.118674,0.493579
22,0.167887,0.321102
23,0.125824,0.364142
24,0.116316,0.650295
25,0.118793,0.366682
26,0.112844,0.392720
27,0.130333,0.407677
28,0.220964,0.393201
29,0.171648,0.319671
30,0.121934,0.461602
31,0.111864,0.390421
32,0.113840,0.378174
33,0.112373,0.425359
34,0.115359,0.604001
35,0.116838,0.876257
36,0.112475,0.436045
37,0.111982,0.350631
38,0.113516,0.336952
39,0.107321,0.297456
40,0.111714,0.381512
41,0.114181,0.441784
42,0.112326,0.554840
43,0.292160,0.279713
44,0.201330,0.519190
45,0.126823,0.314208
46,0.114355,0.354722
47,0.109174,0.294195
48,0.122268,0.980581
49,0.475154,0.394675
50,0.289777,0.275139
51,0.135781,0.302496
52,0.121548,0.291217
53,0.115121,0.271290
54,0.116985,0.288754
55,0.113003,0.327622
56,0.112386,0.303672
57,0.127592,0.287965
58,0.147287,0.321221
59,0.112870,0.292780
60,0.112998,0.334511
61,0.115693,0.281574
62,0.117437,0.279359
63,0.109001,0.322237
64,0.114448,0.304884
65,0.113111,0.417124
66,0.111193,0.286244
67,0.538697,0.292107
68,0.339300,0.298673
69,0.183582,0.259480
70,0.128467,0.265488
71,0.119886,0.341981
72,0.119903,0.288738
73,0.123388,0.266487
74,0.119482,0.275005
75,0.121261,0.284007
76,0.116269,0.284851
77,0.117840,0.296457
78,0.122804,0.263456
79,0.144029,0.342169
80,0.112904,0.286891
