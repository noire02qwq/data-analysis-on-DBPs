epoch,train_loss,val_loss
1,1.001562,0.342113
2,1.000858,0.352974
3,1.000818,0.349378
4,1.001061,0.358085
5,1.001164,0.349654
6,1.000776,0.352210
7,1.000776,0.351358
8,1.000859,0.349505
9,1.000841,0.349475
10,1.000746,0.350658
11,1.000790,0.349859
12,1.000708,0.351357
13,1.000646,0.348189
14,1.000660,0.348480
15,1.000647,0.349910
16,1.000746,0.349805
17,1.000728,0.348590
18,1.000729,0.351360
19,1.000655,0.347975
20,1.000699,0.347911
21,1.000734,0.346817
22,1.000654,0.349288
23,1.000639,0.350426
24,1.000697,0.348127
25,1.000736,0.348569
26,1.000765,0.350821
27,1.000623,0.347830
28,1.000777,0.351101
29,1.000725,0.350163
30,1.000665,0.347704
31,1.000653,0.349224
32,1.000644,0.350749
33,1.000705,0.349503
34,1.000661,0.347824
35,1.000658,0.349586
36,1.000682,0.347408
37,1.000687,0.348089
38,1.000636,0.350821
39,1.000643,0.349925
40,1.000659,0.349887
41,1.000700,0.348142
42,1.000693,0.348657
43,1.000649,0.350099
44,1.000646,0.351455
45,1.000825,0.349813
46,1.000776,0.350713
47,1.000635,0.349566
48,1.000863,0.352002
49,1.000615,0.347445
50,1.000697,0.346829
