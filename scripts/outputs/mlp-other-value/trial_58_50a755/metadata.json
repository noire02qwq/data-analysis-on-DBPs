{
  "model_name": "mlp-other-value/trial_58_50a755",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.28016468988439774,
    "mid_layer_count": 5,
    "mid_layer_size": 476
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 176,
    "learning_rate": 0.0012607140294585884,
    "weight_decay": 0.0003254899148666382,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147,
      148,
      149,
      150
    ],
    "train_loss": [
      0.3740506183648489,
      0.24421894843912295,
      0.21908324511923383,
      0.2037602485740044,
      0.19288125806982667,
      0.18689528954004617,
      0.1778949483456888,
      0.16901654355981033,
      0.1682804036271945,
      0.16065548465856228,
      0.15728516890841793,
      0.15575569848973914,
      0.152622612127284,
      0.14536191378574362,
      0.14654445116828196,
      0.14372806574455466,
      0.14313153396544548,
      0.13887485859484597,
      0.137573928290786,
      0.13563534530264834,
      0.13211150363034135,
      0.13282798760866374,
      0.12992162085408243,
      0.1309099647480748,
      0.12482112344868554,
      0.1237562156644095,
      0.1235970361851129,
      0.12265540119652384,
      0.12069434418762079,
      0.11934512654073792,
      0.12053834303273123,
      0.11977166419092847,
      0.11745741896488043,
      0.1158562425453275,
      0.11418881912592926,
      0.11341653287166079,
      0.11259984259057375,
      0.11318970835166078,
      0.11652825427948359,
      0.11182570864965881,
      0.10797546470223358,
      0.11005288276872982,
      0.10747866212878245,
      0.10604546842222155,
      0.10605407657609223,
      0.10798127720253843,
      0.10654995910796586,
      0.10474639974263095,
      0.1058365612258784,
      0.10457963504474428,
      0.1032734506554699,
      0.10120537077741418,
      0.1028748995191076,
      0.10105726624785967,
      0.103256349936854,
      0.10213486641920672,
      0.0998081416465063,
      0.1005450077488705,
      0.10107825540499298,
      0.09896674731592449,
      0.09913042143346591,
      0.09877663730367016,
      0.0982306185840276,
      0.09939494631561394,
      0.09726605863296539,
      0.1009184542552149,
      0.098183995304871,
      0.09813537388627135,
      0.09660362466030575,
      0.09859478954567917,
      0.0959601422008213,
      0.09626197582516932,
      0.0963996015278849,
      0.09575554478881051,
      0.09438014614575946,
      0.09487082561111988,
      0.09518685228950614,
      0.09413885689503478,
      0.0934786176363464,
      0.09318427159319541,
      0.09491913758023326,
      0.092283988599902,
      0.0934429396003133,
      0.09414849452876996,
      0.0919163669070077,
      0.09168857430849031,
      0.0909221948240585,
      0.09324049790236447,
      0.09401934714715501,
      0.09222698065257794,
      0.09325838258720288,
      0.08956642856027237,
      0.09129376584074325,
      0.09015828502933572,
      0.08943796142163553,
      0.09073533832247041,
      0.09259564434491163,
      0.09023842817242174,
      0.09245068502309935,
      0.09121307877469148,
      0.09045696006242039,
      0.09053634849112728,
      0.08892577000463113,
      0.0890351735082206,
      0.09243869497079982,
      0.09079193532956203,
      0.0891414268344656,
      0.08787179445076625,
      0.09015813762328759,
      0.08803211854414306,
      0.08922688042187825,
      0.0900385078059948,
      0.08960032698174145,
      0.08782518625626386,
      0.08880405625344669,
      0.08768929194767944,
      0.08815297979829004,
      0.0876899682340896,
      0.0870499900590462,
      0.08822136128435018,
      0.08741758830306345,
      0.08772986141411447,
      0.08562702232978478,
      0.08718725488071505,
      0.08882572986242893,
      0.0861606931666523,
      0.08732498072091588,
      0.08676670291382206,
      0.08664123951746538,
      0.08739646597588105,
      0.08691193955855347,
      0.08745928042558232,
      0.08520841717016642,
      0.08676197510566266,
      0.08599008693564789,
      0.0863524969913765,
      0.08732604780920106,
      0.08708867381373206,
      0.08703812163585024,
      0.08463499139996294,
      0.0850677345962999,
      0.08443432200744007,
      0.08598447367051983,
      0.08637678110948155,
      0.08769754310826144,
      0.08604476842866793,
      0.085830820171022,
      0.08484438917250313,
      0.08700181704383438,
      0.08616980348736154
    ],
    "val_loss": [
      0.3774580497227743,
      0.49148044464830865,
      0.526915538525153,
      0.48932747398307935,
      0.4901510650526264,
      0.5700259709786513,
      0.5611226680036077,
      0.5664766735659388,
      0.5806074990483815,
      0.5713018999842112,
      0.6095611308149235,
      0.5062734930101269,
      0.4823676269211455,
      0.5192213344716741,
      0.4908772126643244,
      0.5303621430596905,
      0.4625466658683594,
      0.4791337874121295,
      0.5526082964000588,
      0.44270756801445327,
      0.43925264831074695,
      0.47361654328728864,
      0.45501627322442517,
      0.4190637532108558,
      0.483627701947789,
      0.425748081121616,
      0.47439209986589626,
      0.4865103729470761,
      0.4573966947144377,
      0.43760002016307353,
      0.417188482084674,
      0.5013963639379262,
      0.4738452725781652,
      0.4205802074449505,
      0.4298427192036977,
      0.43363436603260613,
      0.40470683588953077,
      0.42137182001582163,
      0.42703554922949055,
      0.457460626585041,
      0.4358878884486809,
      0.4875843813319406,
      0.43173804497290513,
      0.41917215649953143,
      0.4092240300007209,
      0.4272075645224063,
      0.42227917695473766,
      0.4168314805287801,
      0.4413843853744918,
      0.4713293120532693,
      0.4125987472648392,
      0.42216942167567634,
      0.40624770761250023,
      0.4551331348761827,
      0.45517577089949285,
      0.44236588906385227,
      0.44468757006936444,
      0.4162173703759016,
      0.4152081056269343,
      0.44792128380187257,
      0.44849681461642604,
      0.4235773866048116,
      0.41528123552927715,
      0.4801949932903587,
      0.4316796246402992,
      0.44097071750435285,
      0.4506054338580834,
      0.4143352377200555,
      0.4370161871710223,
      0.45653453801206484,
      0.48834310463088715,
      0.43716042248788706,
      0.4577190234275635,
      0.4322890093226633,
      0.48209338502255744,
      0.443638774806154,
      0.4480432389025203,
      0.4230103709740553,
      0.41344504941723303,
      0.4132160986255029,
      0.45175948257217863,
      0.41638110947466184,
      0.4132331939514526,
      0.39168855273081155,
      0.41137220673932284,
      0.42468428576063966,
      0.41683273993566367,
      0.41858370054267835,
      0.41239302251153365,
      0.4088184394522341,
      0.4190680512411152,
      0.4284958372572939,
      0.4171008516928393,
      0.40571802404826274,
      0.4359433456809221,
      0.427660890253718,
      0.4186614319235979,
      0.4100043745811828,
      0.44841213540402713,
      0.37520623992303176,
      0.4257413405858114,
      0.42387968109039487,
      0.3967077960511168,
      0.39481536656796573,
      0.421741097630141,
      0.43620924314339005,
      0.4440974060646788,
      0.45320216874162594,
      0.4123541896214742,
      0.4412313739696663,
      0.39842528340345373,
      0.4310598356281212,
      0.4406485863074571,
      0.40587028215031423,
      0.40733414595712447,
      0.4187850450327296,
      0.3966830004475074,
      0.40572964609740025,
      0.4199254647700373,
      0.40158285166689023,
      0.4511859330588472,
      0.4290360827645856,
      0.417516477165108,
      0.4514677604515395,
      0.4218907612526488,
      0.4410793803409188,
      0.41348025249149983,
      0.42330874882772296,
      0.45898663555076735,
      0.41414189538555946,
      0.3937452691043922,
      0.41847885161816717,
      0.43843396637967963,
      0.4112673901512237,
      0.4211042124354197,
      0.44796878898928977,
      0.4507610922088166,
      0.4086992506495493,
      0.46961388752132116,
      0.4352114266264224,
      0.4405830420419842,
      0.43405036969099214,
      0.42141583808167965,
      0.3920716219319555,
      0.4422143380085151,
      0.3994356130411525,
      0.3981890234404695,
      0.4030330556595397,
      0.41610995438284504,
      0.43222356470759044
    ],
    "best_epoch": 100,
    "best_val_loss": 0.37520623992303176,
    "test_loss": 0.5400267353183344,
    "tracker": {
      "initial_train_loss": 0.3740506183648489,
      "train_threshold": 0.12468353945494963,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.37520623992303176,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_58_50a755/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_58_50a755/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_58_50a755/config.yaml"
}