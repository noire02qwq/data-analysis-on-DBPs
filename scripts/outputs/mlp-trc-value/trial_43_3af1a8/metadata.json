{
  "model_name": "mlp-trc-value/trial_43_3af1a8",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.1550494491157361,
    "mid_layer_count": 13,
    "mid_layer_size": 271
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 209,
    "learning_rate": 0.0004409467630345723,
    "weight_decay": 0.0020735676304053058,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.4021862680584636,
      0.116707029112597,
      0.08388473251676823,
      0.06858711886678891,
      0.06470282635235325,
      0.06150446952788447,
      0.056601471782758976,
      0.05599476954254158,
      0.05605155282609429,
      0.05228990600996289,
      0.052125406020028034,
      0.051333130582433106,
      0.05138764040245497,
      0.050942097081415255,
      0.04667938966638556,
      0.04929444859623374,
      0.04779012156903682,
      0.04770004548076989,
      0.046780054672516544,
      0.04716994382895954,
      0.046414448691865555,
      0.04656925206939919,
      0.046464807355347325,
      0.04527148232724099,
      0.044643469581551555,
      0.044803319760278563,
      0.04272871798027657,
      0.04337903881219028,
      0.04289180328787566,
      0.044774902625159464,
      0.04317959027318021,
      0.04428842641975159,
      0.04402188230745529,
      0.043100160797470165,
      0.042362625902282576,
      0.041631130619655975,
      0.04264886424962284,
      0.0412616468932558,
      0.0427508363423782,
      0.04075241003762749,
      0.04404488982027803,
      0.04319093259325726,
      0.04139219739284651,
      0.04124477365579343,
      0.04087312103823982,
      0.04046887554048636,
      0.03983608899440228,
      0.04105797698654391,
      0.04206107228969522,
      0.042674119163757566,
      0.03966495174658473,
      0.040557573351621044,
      0.04084491663841314,
      0.04031813695784056,
      0.040026226163621496,
      0.04019955273769249,
      0.039618625580832526,
      0.040236780892535774,
      0.04064309969878903,
      0.0397308282578042,
      0.03959113355843554,
      0.039471975356156916,
      0.04056597088753657,
      0.040935158111697866,
      0.040511624843145924,
      0.04036851538719849,
      0.04007627992886475,
      0.03998592344799359,
      0.03966040773247452,
      0.039012535936794046,
      0.040034076839010724,
      0.03908263370461605,
      0.038962625026351186,
      0.039092034277811515,
      0.038389144941979016,
      0.037791333659927144,
      0.03873507971548045,
      0.03849457426062604,
      0.03915523555609524,
      0.038590785795215875
    ],
    "val_loss": [
      0.32747098214612036,
      0.22138796232328445,
      0.23593661523909268,
      0.3523098907617484,
      0.2470134213544473,
      0.3227502905222738,
      0.26028585444667385,
      0.2722926532827362,
      0.30449061890963663,
      0.344229913879922,
      0.3414168481319072,
      0.2928615698267421,
      0.26498722766643157,
      0.3566984793561661,
      0.36326183671589024,
      0.31043288576009564,
      0.3950624833418848,
      0.44154232006720795,
      0.30282601224046624,
      0.342600775119698,
      0.34622371714941397,
      0.3109005824110644,
      0.31445722949919763,
      0.35588346801720516,
      0.31471775357617054,
      0.3786536604188338,
      0.3385927544962503,
      0.3413357943396815,
      0.356037011589788,
      0.3652118970835191,
      0.3336014698900862,
      0.28569482953516306,
      0.36601038609413866,
      0.44926735238690757,
      0.3645889478863892,
      0.3730262054409274,
      0.32701644780348516,
      0.3792558613696141,
      0.33721173241020674,
      0.3108706081419915,
      0.2822280441527952,
      0.3247068715811579,
      0.36569117619293534,
      0.36990977048896206,
      0.3901935414338629,
      0.3400153823709952,
      0.375776814701716,
      0.30938331140149494,
      0.318041074559271,
      0.3311523695370394,
      0.3709498101120402,
      0.36298836149877595,
      0.33769497115633446,
      0.3595041447001214,
      0.34677441489776806,
      0.372968016355159,
      0.40761602776470834,
      0.37366046050931523,
      0.36010109466461543,
      0.36606763061470615,
      0.38113890063508366,
      0.39468080748296425,
      0.41542866107210247,
      0.3327065409044038,
      0.36207527885893864,
      0.4065627677756512,
      0.37479595714388136,
      0.39748960771893493,
      0.41206262879252076,
      0.34464721084979477,
      0.35691416995254105,
      0.3770123324975996,
      0.3519994377342616,
      0.3617966657917121,
      0.3503794848740458,
      0.34242308265501686,
      0.35029306362555945,
      0.3693712417036295,
      0.3497125012264726,
      0.3689229701249721
    ],
    "best_epoch": 2,
    "best_val_loss": 0.22138796232328445,
    "test_loss": 5.3853528797626495,
    "tracker": {
      "initial_train_loss": 0.4021862680584636,
      "train_threshold": 0.13406208935282118,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.22138796232328445,
      "patience_no_improve_epochs": 79,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_43_3af1a8/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_43_3af1a8/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_43_3af1a8/config.yaml"
}