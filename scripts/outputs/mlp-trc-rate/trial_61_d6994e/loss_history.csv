epoch,train_loss,val_loss
1,0.577810,0.537016
2,0.199248,0.313752
3,0.139549,0.237529
4,0.115790,0.224420
5,0.100462,0.201349
6,0.092712,0.197617
7,0.086909,0.197481
8,0.081030,0.199509
9,0.078094,0.210062
10,0.074546,0.209731
11,0.073998,0.214232
12,0.071947,0.218768
13,0.069345,0.222290
14,0.067433,0.221861
15,0.070015,0.228066
16,0.068267,0.224132
17,0.065230,0.229501
18,0.062374,0.228742
19,0.062905,0.236210
20,0.061494,0.233149
21,0.061656,0.235486
22,0.061750,0.250063
23,0.058283,0.242587
24,0.058715,0.248584
25,0.058010,0.246844
26,0.058336,0.266665
27,0.058181,0.253112
28,0.055425,0.249175
29,0.054739,0.254102
30,0.055887,0.266377
31,0.054277,0.259296
32,0.052836,0.261232
33,0.053723,0.271106
34,0.053912,0.267393
35,0.050774,0.271098
36,0.053868,0.268379
37,0.051167,0.266138
38,0.051198,0.286785
39,0.050994,0.275738
40,0.050213,0.291164
41,0.050965,0.282367
42,0.050361,0.277127
43,0.048900,0.275972
44,0.049486,0.286109
45,0.049412,0.290127
46,0.047982,0.288333
47,0.047596,0.294212
48,0.047248,0.282431
49,0.048890,0.297366
50,0.047884,0.296813
51,0.046431,0.295143
52,0.047314,0.287606
53,0.045900,0.288875
54,0.045716,0.286673
55,0.046356,0.288113
56,0.046208,0.296608
57,0.045372,0.306707
58,0.045797,0.298780
59,0.046324,0.295617
60,0.045240,0.297614
61,0.044213,0.302688
62,0.044545,0.295826
63,0.044356,0.292574
64,0.044397,0.295104
65,0.043845,0.302940
66,0.044552,0.302562
67,0.044534,0.297287
68,0.044723,0.304349
69,0.042646,0.312378
70,0.043283,0.300541
71,0.043343,0.301291
72,0.041248,0.301358
73,0.041977,0.299290
74,0.042627,0.299070
75,0.042918,0.306659
76,0.041551,0.305705
77,0.043731,0.299256
78,0.043893,0.316351
79,0.042871,0.309018
80,0.041954,0.310968
