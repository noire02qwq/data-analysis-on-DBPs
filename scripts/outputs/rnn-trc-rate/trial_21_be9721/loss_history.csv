epoch,train_loss,val_loss
1,0.284371,0.306056
2,0.139855,0.323764
3,0.119257,0.322233
4,0.099808,0.330255
5,0.108842,0.349453
6,0.094409,0.283966
7,0.100820,0.306394
8,0.163982,0.300291
9,0.422185,0.226508
10,0.135537,0.224262
11,0.129005,0.241371
12,0.129044,0.295792
13,0.125062,0.224071
14,0.122117,0.232253
15,0.131086,0.258767
16,0.131931,0.263614
17,0.123561,0.264247
18,0.124713,0.223136
19,0.126717,0.227949
20,0.129265,0.277534
21,0.128721,0.258616
22,0.122290,0.248460
23,0.122624,0.319535
24,0.120333,0.221234
25,0.133303,0.279689
26,0.120882,0.278394
27,0.116546,0.429451
28,0.121129,0.255446
29,0.128798,0.248340
30,0.118452,0.307822
31,0.110853,0.275694
32,0.115864,0.254137
33,0.110701,0.314921
34,0.118451,0.297656
35,0.112649,0.330344
36,0.111898,0.337689
37,0.116134,0.348182
38,0.127171,0.275427
39,0.119098,0.308415
40,0.107999,0.343651
41,0.112301,0.284940
42,0.107129,0.270612
43,0.134860,0.413802
44,0.107677,0.333657
45,0.107039,0.339418
46,0.112257,0.381466
47,0.112100,0.329239
48,0.103631,0.330205
49,0.114528,0.273822
50,0.108277,0.381112
51,0.107174,0.314762
52,0.107956,0.292768
53,0.109519,0.297021
54,0.104887,0.335487
55,0.106677,0.333293
56,0.101793,0.379983
57,0.107278,0.347730
58,0.106524,0.278692
59,0.118485,0.351446
60,0.103287,0.441804
61,0.118494,0.287941
62,0.107746,0.323683
63,0.109845,0.405702
64,0.111385,0.455368
65,0.105879,0.304097
66,0.107138,0.408722
67,0.120812,0.273811
68,0.105399,0.377718
69,0.112417,0.306557
70,0.106760,0.313752
71,0.100460,0.395462
72,0.105781,0.313134
73,0.104371,0.339165
74,0.110577,0.306057
75,0.108970,0.328153
76,0.108979,0.293678
77,0.114102,0.272581
78,0.104894,0.286922
79,0.111300,0.524516
80,0.107803,0.273263
