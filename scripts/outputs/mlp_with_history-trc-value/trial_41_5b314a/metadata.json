{
  "model_name": "mlp_with_history-trc-value/trial_41_5b314a",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 80,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.33315214279282207,
    "mid_layer_count": 6,
    "mid_layer_size": 746
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 467,
    "learning_rate": 0.0011624774089021973,
    "weight_decay": 0.007379022073330871,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7717,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 800,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      1.2010186279130535,
      0.950560158400766,
      0.600418139233156,
      0.23960371600294786,
      0.17672468217694884,
      0.1670377202746209,
      0.16433217790756446,
      0.15712347088529607,
      0.1460251042466561,
      0.16210809763044493,
      0.14846748237406263,
      0.15434505963099193,
      0.14229312704872926,
      0.15216226938344876,
      0.1473250995167213,
      0.146512862848613,
      0.14220865855172798,
      0.14637397685086648,
      0.14092209792201255,
      0.13435839918691042,
      0.13342275465088557,
      0.13760689977067453,
      0.15339260032981947,
      0.13470038196302006,
      0.13864557855280166,
      0.13339386077604254,
      0.1541846844547382,
      0.16389492202395214,
      0.15729761946822318,
      0.13907421102900108,
      0.133461806913979,
      0.13048284028719415,
      0.13306999789207916,
      0.12680746208274396,
      0.1296441190449688,
      0.12238758740140719,
      0.19774694674444027,
      0.18808104114449362,
      0.13854128628239293,
      0.13140594960514151,
      0.13033838937674777,
      0.12992210371847734,
      0.12868201588200243,
      0.12796933795193308,
      0.1265638119679775,
      0.1281978978652464,
      0.12610034335554765,
      0.1308395938301652,
      0.13986761926797536,
      0.1296716786952885,
      0.12393490646700175,
      0.1284936832956071,
      0.2091061503652836,
      0.563999734978239,
      0.29411426445888517,
      0.1653649073590867,
      0.1491811647538124,
      0.14796858120241885,
      0.13921689983127616,
      0.15898842812627187,
      0.14418939639979172,
      0.135222528530006,
      0.13878665963235845,
      0.1297948169327082,
      0.1302014092021815,
      0.14877603044237392,
      0.3532187068487088,
      0.20455310408552646,
      0.15466914850881994,
      0.14862023767055402,
      0.14559294708392712,
      0.1376274462542618,
      0.13367285733146805,
      0.13345680273832766,
      0.13419005337045864,
      0.13215759618805684,
      0.13214232453691907,
      0.20726404087375416,
      0.18703908783846976,
      0.15199813338254142
    ],
    "val_loss": [
      0.32002077464928885,
      0.2543543614491731,
      0.3046791503484734,
      0.20969002723225397,
      0.4781819875368815,
      0.2669195619986175,
      0.2282584864757732,
      0.4376584939658642,
      0.2573393136530579,
      0.2671985492299863,
      0.32292974856933077,
      0.4655866613633886,
      0.3281715342016545,
      0.27640713597285355,
      0.2844438815879786,
      0.2735157772262921,
      0.2696654691689921,
      0.2844848154614607,
      0.3072953693122564,
      0.3347807400352405,
      0.271888000763462,
      0.2719035496767945,
      0.29135809516656896,
      0.2813262937947394,
      0.43342966831729796,
      0.6784231384334986,
      0.2623437008167991,
      0.2835608175280922,
      0.33057875428683386,
      0.28472539281282955,
      0.41017032081406274,
      0.3129944724504819,
      0.3202405316744022,
      0.32674706930930386,
      0.26868940653937484,
      0.29743755089710217,
      0.305955241221243,
      0.3348667098833861,
      0.4686671379418252,
      0.30512894630476745,
      0.4066442791339077,
      0.33759950888036433,
      0.42224073970166154,
      0.4212980656823266,
      0.2673644489335443,
      0.6886396823339387,
      0.3260435292196131,
      0.9558912555793089,
      0.23683412312613633,
      0.27081777637902493,
      0.333535752362923,
      0.368717766366899,
      0.2848064523524867,
      0.2466672409281224,
      0.25699273879545,
      0.31433038988825446,
      0.36471382621564197,
      0.36389674857526483,
      0.2851975233333107,
      0.2830326177369424,
      0.27634333906037184,
      0.3035869851485341,
      0.405745493003842,
      0.3549461576875723,
      0.6110015911591089,
      0.32441256592150575,
      0.25497622088177835,
      0.35498182804708533,
      0.5175405563117412,
      0.28527935595435655,
      0.27529312856941524,
      0.4771025667212413,
      0.34983241005192794,
      0.28373847656331197,
      0.33687367250440187,
      0.33936012562386647,
      0.29163427666766556,
      0.28241382926524045,
      0.2648246948021704,
      0.273550743165755
    ],
    "best_epoch": 4,
    "best_val_loss": 0.20969002723225397,
    "test_loss": 5.1084112245500375,
    "tracker": {
      "initial_train_loss": 1.2010186279130535,
      "train_threshold": 0.4003395426376845,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.20969002723225397,
      "patience_no_improve_epochs": 77,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-value/trial_41_5b314a/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-value/trial_41_5b314a/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-value/trial_41_5b314a/config.yaml"
}