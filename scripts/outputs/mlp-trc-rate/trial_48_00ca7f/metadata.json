{
  "model_name": "mlp-trc-rate/trial_48_00ca7f",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.33111218298768685,
    "mid_layer_count": 9,
    "mid_layer_size": 330
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 248,
    "learning_rate": 0.0006172614068696178,
    "weight_decay": 0.00025108013658115187,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.43399851432422787,
      0.15090994939796737,
      0.10995561916623867,
      0.09662503320599532,
      0.08904926478098209,
      0.08543993855299492,
      0.08259675885742294,
      0.07591479369895528,
      0.07246054354969081,
      0.07227835198314818,
      0.06902789219778094,
      0.06722431341659234,
      0.06473032797587841,
      0.06282914928392364,
      0.06424174315390249,
      0.06354507592517697,
      0.06579963399193849,
      0.06074657619741099,
      0.05827004708475856,
      0.05874947214995121,
      0.056603116833396055,
      0.05569908318380749,
      0.05540974070822171,
      0.05496891566182847,
      0.05649672132683082,
      0.05292122487481464,
      0.05230983326057705,
      0.053561172525031925,
      0.05340011636528252,
      0.05217289440085363,
      0.050525662695187185,
      0.050246694241351746,
      0.05116054920499725,
      0.05048074170549507,
      0.04890925765396877,
      0.049436365733503254,
      0.0483796138272431,
      0.049166660859087545,
      0.04915135166870135,
      0.04707989870561521,
      0.048627046960907264,
      0.04839636819134192,
      0.04683360971391905,
      0.04675256921931253,
      0.0459633526445322,
      0.045381883808195196,
      0.04573994731791451,
      0.046194061182015,
      0.0466157299637978,
      0.04492518559419356,
      0.04471699192760662,
      0.04491693314724913,
      0.045790900112635785,
      0.044160584220065406,
      0.043549512409289226,
      0.046244353239446985,
      0.04418968041931561,
      0.04278239520842935,
      0.04314682684483254,
      0.04314801939263779,
      0.043861583502186205,
      0.04320308755894023,
      0.04248115458378063,
      0.04245484068133453,
      0.0431095688116893,
      0.04258811289206598,
      0.04273321241782591,
      0.04327569763176621,
      0.04382469858677954,
      0.04212663435650031,
      0.04237072730581231,
      0.042896775021315725,
      0.04209161145548566,
      0.0402472633189914,
      0.04083003675810737,
      0.04059287076725172,
      0.040835766957976256,
      0.040600070839756384,
      0.041322846523748416,
      0.04022337291953562
    ],
    "val_loss": [
      0.268655277494185,
      0.21479349994730806,
      0.20143299266963663,
      0.20883797018113964,
      0.20237906155828944,
      0.21642867028713225,
      0.21437777233516384,
      0.21901799353832258,
      0.2297845810294865,
      0.23088458982591858,
      0.25478067630065415,
      0.25032614523065305,
      0.23781005620599507,
      0.24844002709417287,
      0.2788741176892183,
      0.2590613997892705,
      0.2629238246265286,
      0.27151573511833205,
      0.27512473435459023,
      0.27687232245406707,
      0.2708841163955049,
      0.2863751852316057,
      0.2977365207797039,
      0.2903466978740549,
      0.2969518555049411,
      0.2988197391529283,
      0.28469115316332455,
      0.2960929539746153,
      0.31010432191594633,
      0.30866756654249694,
      0.31535426838669234,
      0.30651785186129415,
      0.32773589176867535,
      0.31060377362067115,
      0.32869469615335234,
      0.32269165160770186,
      0.31955424876448635,
      0.32882755745849207,
      0.31636992393139596,
      0.3177218687748481,
      0.3116113137431487,
      0.31079564266754484,
      0.32162957228050976,
      0.31426895497266405,
      0.3261538683029706,
      0.3305757978273009,
      0.35191539179779097,
      0.31538957546571056,
      0.3353747479483753,
      0.3317439925260173,
      0.3290532660876919,
      0.3293683205357569,
      0.31935571457989914,
      0.33303072904041425,
      0.31695175920417923,
      0.3451099314643237,
      0.337247799470753,
      0.3335647991495932,
      0.3453339004498756,
      0.3430372696615265,
      0.3378205422423557,
      0.3406715424831756,
      0.3328144724229853,
      0.33906263769743683,
      0.33487325337475643,
      0.3290663246623056,
      0.3284870891335482,
      0.3292431202834238,
      0.33667503425818,
      0.3334723493117772,
      0.3349662118953859,
      0.3395013279811351,
      0.3212843433468642,
      0.3267802048764543,
      0.33360963385262177,
      0.32671028392579027,
      0.3244396471424017,
      0.3318333148331699,
      0.3124623476745126,
      0.3213044555690474
    ],
    "best_epoch": 3,
    "best_val_loss": 0.20143299266963663,
    "best_val_abs_mse": 0.2259262502193451,
    "test_loss": 4.856016520678142,
    "test_abs_mse": 47.17672348022461,
    "tracker": {
      "initial_train_loss": 0.43399851432422787,
      "train_threshold": 0.14466617144140928,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.20143299266963663,
      "patience_no_improve_epochs": 78,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_48_00ca7f/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_48_00ca7f/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_48_00ca7f/config.yaml"
}