{
  "model_name": "mlp-trc-rate/trial_5_6046d5",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.2747421333054535,
    "mid_layer_count": 8,
    "mid_layer_size": 400
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 284,
    "learning_rate": 0.0019802580109482167,
    "weight_decay": 0.00029197818822261493,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.29174325081891067,
      0.10218034725943977,
      0.0841790927777601,
      0.07423357492940678,
      0.07106272136365346,
      0.06638634642380638,
      0.06276605705257071,
      0.06123310327529907,
      0.05737710006921153,
      0.05621552593497633,
      0.056914469686883,
      0.05447570959334498,
      0.05532742887467773,
      0.05132585096666604,
      0.05146155805122002,
      0.05101812988129746,
      0.0497942382728766,
      0.05061130353147828,
      0.046821987737121186,
      0.047266126353735186,
      0.047802354685537875,
      0.04619769436073585,
      0.04582072919059742,
      0.04424905129400139,
      0.044082033207564555,
      0.04280693941449067,
      0.043028670298618926,
      0.04448287074705954,
      0.04295591998935174,
      0.04417007488737111,
      0.04837952603730806,
      0.045430036134570605,
      0.04159615463312006,
      0.04089717269937707,
      0.042984074236812685,
      0.041218442006133164,
      0.03994924121900911,
      0.04135738936309756,
      0.04134447337068491,
      0.040194721528357145,
      0.041003889790814985,
      0.04031683912279974,
      0.04275498294360886,
      0.03967806710844898,
      0.03915198302310268,
      0.040180210857482496,
      0.03921300444318093,
      0.04008335351041796,
      0.041242690553354444,
      0.038877522046288325,
      0.03757217515923232,
      0.04070095378444891,
      0.0413068689658221,
      0.03925997537564106,
      0.03816143734874696,
      0.04091189652413757,
      0.037866658432215164,
      0.03750364810205411,
      0.03743922357576942,
      0.0375427975390525,
      0.037806925042248064,
      0.03842524114638766,
      0.039485668113647274,
      0.03850088462524074,
      0.03764577551705217,
      0.038929926538280854,
      0.038820842169167875,
      0.03952862065822543,
      0.03856094592485506,
      0.03801046826113579,
      0.03942210703759453,
      0.037243489680640694,
      0.03793588085334199,
      0.03729169678827963,
      0.03807682626564849,
      0.03793741319387799,
      0.03747459778943509,
      0.03775339411153984,
      0.037396434763338454,
      0.037494530397662755
    ],
    "val_loss": [
      0.2997773437799808,
      0.20408690234947346,
      0.22280896438988382,
      0.25385086715310634,
      0.2759864178781738,
      0.24231607604348018,
      0.24032251528369453,
      0.2630136781333092,
      0.2625825272705741,
      0.2658142215923635,
      0.2622832832802199,
      0.2989886433644566,
      0.26535685529073555,
      0.29673814063746773,
      0.3540115959942341,
      0.3042519008506558,
      0.3064661880542418,
      0.3164246353515965,
      0.2889925937363487,
      0.31413012376713184,
      0.32547426084112263,
      0.3053518294618872,
      0.29796009695904696,
      0.3147536164093874,
      0.30579401570076714,
      0.3155712254390031,
      0.3330907004857492,
      0.3353995774766642,
      0.3278708546907602,
      0.2979090649656907,
      0.3278740244220474,
      0.3398473493754864,
      0.32630492734337996,
      0.3482383954578531,
      0.32394582622065515,
      0.3423272984693507,
      0.31197122897573576,
      0.3231080648071038,
      0.3106678257266918,
      0.34171580090940357,
      0.31872873563252524,
      0.31321191934500625,
      0.32765304485480945,
      0.3262279291352826,
      0.3204971713934116,
      0.3219580899901733,
      0.30668096545035256,
      0.30727438590305295,
      0.3128607535879769,
      0.30915172732251134,
      0.33121136975681,
      0.31195940912483694,
      0.30782976095191017,
      0.3145473279728147,
      0.3183866060690252,
      0.32872983954713014,
      0.32337308663897174,
      0.3188877342257671,
      0.3169565546164613,
      0.3179991393032188,
      0.3202545136436374,
      0.33327831641107264,
      0.3361167359405649,
      0.3286272109134825,
      0.32113948926597297,
      0.32197690763159426,
      0.32603019526350996,
      0.3260628084847313,
      0.32219767421930134,
      0.3203219646911421,
      0.3207286089614123,
      0.34146642948160627,
      0.3310587033183275,
      0.3230774755695623,
      0.31993945314141803,
      0.3250236511631997,
      0.31431911634113974,
      0.3161565337129339,
      0.32000765370394657,
      0.32229811564801697
    ],
    "best_epoch": 3,
    "best_val_loss": 0.22280896438988382,
    "best_val_abs_mse": 0.23683932423591614,
    "test_loss": 4.642313116475155,
    "test_abs_mse": 45.407073974609375,
    "tracker": {
      "initial_train_loss": 0.29174325081891067,
      "train_threshold": 0.09724775027297022,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.22280896438988382,
      "patience_no_improve_epochs": 78,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-rate/trial_5_6046d5/best_model.pt",
    "last": "scripts/outputs/mlp-trc-rate/trial_5_6046d5/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-rate/trial_5_6046d5/config.yaml"
}