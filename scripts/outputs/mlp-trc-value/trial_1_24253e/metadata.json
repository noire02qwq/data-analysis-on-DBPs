{
  "model_name": "mlp-trc-value/trial_1_24253e",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.1618472651666113,
    "mid_layer_count": 11,
    "mid_layer_size": 273
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 167,
    "learning_rate": 0.0010152669163181229,
    "weight_decay": 0.002839720187840715,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80
    ],
    "train_loss": [
      0.2505809337812442,
      0.08302405430123462,
      0.06859895992850175,
      0.06219537102647428,
      0.05912361508727517,
      0.05901771952078442,
      0.056082302603627884,
      0.05505180217253055,
      0.05323098188198304,
      0.05125121920995066,
      0.05285082969780134,
      0.04927691556809574,
      0.0486021316799026,
      0.049749377441653204,
      0.047669954931964596,
      0.04881118076412402,
      0.04767323709429916,
      0.04912634413467654,
      0.047090763943876714,
      0.04714702252392251,
      0.048008060815331724,
      0.048722293811361415,
      0.04720503045030974,
      0.04605383481405075,
      0.04472821846933105,
      0.04649449925460667,
      0.04533600097205805,
      0.04491196325829605,
      0.04615480023430992,
      0.04487811734354178,
      0.04495642834480158,
      0.044699405132672954,
      0.04419263626753198,
      0.04500381432028307,
      0.04527147694143455,
      0.04318637260569861,
      0.04417552757557155,
      0.04577708540779618,
      0.04558442228150221,
      0.04379491413393468,
      0.04465323154278875,
      0.04339473526456559,
      0.044726742172528686,
      0.04412437398311586,
      0.04692536135614606,
      0.04451945086051373,
      0.04537880115866615,
      0.04341539349946924,
      0.04418964380672676,
      0.043417002642340864,
      0.04584703119036829,
      0.04397819995719571,
      0.045825528511333126,
      0.04355618687754659,
      0.04345101848953791,
      0.04361252344450916,
      0.044015970281308554,
      0.04374900908367551,
      0.04454897731884725,
      0.043354209557867555,
      0.04531399892827543,
      0.04502205810857972,
      0.04359468214525404,
      0.043055889888854365,
      0.04640272865716985,
      0.0442952782244423,
      0.04357059686858037,
      0.043801871925428046,
      0.04289766499823319,
      0.04311847416258748,
      0.04464085926452299,
      0.04386825440953242,
      0.04326855825626312,
      0.04420066470057613,
      0.04387752565599714,
      0.04453810637940071,
      0.04434070955979145,
      0.043490069725762394,
      0.042333054806886115,
      0.04136179362434708
    ],
    "val_loss": [
      0.3975828684866428,
      0.23375221379101277,
      0.2294862436130643,
      0.33385240770876407,
      0.44465486947447064,
      0.3087729366496205,
      0.2929961308836937,
      0.422490275837481,
      0.2605760445818305,
      0.5265074759721756,
      0.34412629939615724,
      0.3473820012062788,
      0.3631219871342182,
      0.43325497563928367,
      0.3981259249150753,
      0.38044555243104694,
      0.31621711868792773,
      0.356766264885664,
      0.3028261611238122,
      0.3106580814346671,
      0.3325231023132801,
      0.31666828580200673,
      0.31017028652131556,
      0.2954761855304241,
      0.29584296569228175,
      0.3229382634162903,
      0.30779855605214834,
      0.3107821626588702,
      0.3417410165071487,
      0.34323404505848887,
      0.3861391007900238,
      0.31414472181349995,
      0.3579053696244955,
      0.3754588089883327,
      0.3616726167500019,
      0.362379652634263,
      0.34801564235240223,
      0.3344696758314967,
      0.3092446614056826,
      0.3757267419248819,
      0.3402076900005341,
      0.31528644133359196,
      0.40332913491874933,
      0.4478812234476209,
      0.33878772184252737,
      0.34832320027053354,
      0.3907378811389208,
      0.2938679836690426,
      0.2998153407126665,
      0.39085215851664545,
      0.35619069952517746,
      0.3767605749890208,
      0.31250440776348115,
      0.3429473290219903,
      0.28432337287813425,
      0.36929078828543427,
      0.29906177017837765,
      0.38948120065033437,
      0.3404829874634743,
      0.35822763089090587,
      0.363884150236845,
      0.3293403033167124,
      0.3316542746499181,
      0.3252085303887725,
      0.36713950950652363,
      0.2812444657087326,
      0.28711124174296854,
      0.29023443125188353,
      0.3356145840138197,
      0.355539651401341,
      0.3478018816560507,
      0.33006516713649037,
      0.37059110067784784,
      0.29368447959423066,
      0.3169584745541215,
      0.3375527948141098,
      0.2717873688787222,
      0.37107776049524543,
      0.36957742664963006,
      0.31944150999188425
    ],
    "best_epoch": 3,
    "best_val_loss": 0.2294862436130643,
    "test_loss": 4.967035442305524,
    "tracker": {
      "initial_train_loss": 0.2505809337812442,
      "train_threshold": 0.0835269779270814,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.2294862436130643,
      "patience_no_improve_epochs": 77,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-trc-value/trial_1_24253e/best_model.pt",
    "last": "scripts/outputs/mlp-trc-value/trial_1_24253e/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-trc-value/trial_1_24253e/config.yaml"
}