{
  "model_name": "mlp_with_history-other-value/trial_41_da8379",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 99,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.3455929319552244,
    "mid_layer_count": 4,
    "mid_layer_size": 412
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 294,
    "learning_rate": 0.0005840292597288539,
    "weight_decay": 0.008694342405542201,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7698,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 990,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100
    ],
    "train_loss": [
      1.004983197221139,
      1.0039478795006231,
      1.0038943308364203,
      1.0039436159334607,
      1.0037644172866922,
      1.0038375269130906,
      1.0038272586541537,
      1.0038019636136335,
      1.00372541071564,
      1.0037750595729051,
      1.0037770253647516,
      1.0037488614964651,
      1.0037301514451613,
      1.0037238190904412,
      1.0037288581683872,
      1.0037152667298321,
      1.0037265686624606,
      1.003713800074621,
      1.003713959794628,
      1.0037010203835004,
      1.003706084641273,
      1.0036920815915311,
      1.0036877044364054,
      1.0036886706077206,
      1.003704872896963,
      1.003690018796958,
      1.0037042999397658,
      1.0036870897606027,
      1.003684206809834,
      1.003692784443184,
      1.0036861859813668,
      1.0036801750643218,
      1.0036811851377332,
      1.0036790082441673,
      1.003684568665312,
      1.0036803732509272,
      1.0036849814379298,
      1.0036796569266733,
      1.0036849644810357,
      1.0036853474745597,
      1.0036846122886647,
      1.00367533891162,
      1.0036834594521407,
      1.0036858874006562,
      1.0036897366621118,
      1.0036793036193283,
      1.0036874694556626,
      1.0037030332365355,
      1.0036809591232383,
      1.0036823512145716,
      1.0036798190159995,
      1.0036843010715832,
      1.0036782948002625,
      1.0036773171075508,
      1.0036866305771974,
      1.0036866114368126,
      1.003681242280144,
      1.0036761237138523,
      1.0036863397548463,
      1.0036864893007167,
      1.003679953230979,
      1.0036795644767564,
      1.003692405863098,
      1.0036755770049983,
      1.0037057000217453,
      1.0036846394196954,
      1.0037075495775658,
      1.0036680858207696,
      1.003689723793455,
      1.0037040624967888,
      1.0036900733377632,
      1.0036867030040417,
      1.0036896528532424,
      1.0036811135935766,
      1.0036870128274056,
      1.0036881208791457,
      1.0037000475223419,
      1.0036791648050816,
      1.0036968010900917,
      1.0036885666828645,
      1.003677840494868,
      1.0037122584374176,
      1.0037012906717493,
      1.003675583973585,
      1.0036773070263287,
      1.0037127829861658,
      1.0037035535576746,
      1.0036967527745575,
      1.0036688540842231,
      1.0037134067675888,
      1.0036767372746813,
      1.0036883975320372,
      1.0036913562081144,
      1.003716150393081,
      1.0036856134887422,
      1.0036860874920084,
      1.0036735013417686,
      1.0036760096613169,
      1.0036870646736906,
      1.0036905278754438
    ],
    "val_loss": [
      1.4238860540761205,
      1.4259953205100078,
      1.4274736717789474,
      1.4321683610270837,
      1.4310703663055055,
      1.43172257767466,
      1.4338295114968351,
      1.4264704502628236,
      1.4297866159570431,
      1.4289269604368837,
      1.4275036707966628,
      1.4294904326607367,
      1.4331027547756354,
      1.4312601919659598,
      1.4340181809699464,
      1.4354854504505317,
      1.4345114529489758,
      1.4293500586898027,
      1.432298883992041,
      1.4318071351079884,
      1.435893850911877,
      1.4335253834010597,
      1.432825743081327,
      1.4349624621653985,
      1.4362204333979212,
      1.4343274409185627,
      1.4390446418773628,
      1.4374644649956754,
      1.4349437357422834,
      1.435119533681584,
      1.4357306344780378,
      1.4364284450422504,
      1.436068500730092,
      1.4332570885469813,
      1.4325998792391337,
      1.435589312436338,
      1.4359206041176162,
      1.4354402309406304,
      1.4335827034390616,
      1.4366855444308526,
      1.4367458518393739,
      1.4364423684731216,
      1.4364661341655753,
      1.436297291981246,
      1.4349209893249466,
      1.4360543475893444,
      1.4336979503403167,
      1.4331366869503865,
      1.4347252069119207,
      1.4348632017295517,
      1.4340139938685708,
      1.4326207943305285,
      1.4325004821765923,
      1.4343485117672445,
      1.435754721535894,
      1.4337054995005716,
      1.4338303043456848,
      1.4325461900876668,
      1.4320517128099224,
      1.434694715674052,
      1.434194659330174,
      1.433560585190436,
      1.4317552739274717,
      1.432656838579806,
      1.4299059589465934,
      1.433309924459743,
      1.4315333000200237,
      1.4354170537994293,
      1.439133105449334,
      1.437294846808839,
      1.4360645534749517,
      1.4392549949491809,
      1.4373652037746179,
      1.4346896260084507,
      1.4328583826561887,
      1.4344964086652516,
      1.432963880379043,
      1.433284634672953,
      1.4322850145979555,
      1.4361966805543729,
      1.4365007262743876,
      1.4379346266478121,
      1.434693320282919,
      1.4348637963483433,
      1.435263639866949,
      1.4379861337696007,
      1.4330592438132463,
      1.4344845499107224,
      1.4362875672157653,
      1.4390779154743263,
      1.4369350770990292,
      1.4342384930142384,
      1.4372584657040899,
      1.4352399379193426,
      1.4347895382407183,
      1.4335214540630044,
      1.4334945149050502,
      1.4332896192630609,
      1.4353530880219922,
      1.434849511078018
    ],
    "best_epoch": 100,
    "best_val_loss": 1.434849511078018,
    "test_loss": 1.4618596331924913,
    "tracker": {
      "initial_train_loss": 1.004983197221139,
      "train_threshold": 0.334994399073713,
      "best_tracking": false,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 1.4299059589465934,
      "patience_no_improve_epochs": 35,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": true
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-other-value/trial_41_da8379/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-other-value/trial_41_da8379/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-other-value/trial_41_da8379/config.yaml"
}