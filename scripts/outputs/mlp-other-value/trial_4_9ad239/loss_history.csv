epoch,train_loss,val_loss
1,0.426974,0.360741
2,0.280629,0.410729
3,0.252941,0.493742
4,0.236887,0.437462
5,0.227882,0.433852
6,0.216802,0.475067
7,0.210475,0.492076
8,0.203734,0.476449
9,0.195597,0.478232
10,0.189663,0.508313
11,0.185901,0.474897
12,0.181719,0.496534
13,0.177129,0.476753
14,0.174461,0.500509
15,0.172253,0.488884
16,0.170025,0.475168
17,0.163609,0.479037
18,0.161312,0.478489
19,0.159854,0.573140
20,0.159150,0.469119
21,0.157850,0.496243
22,0.152955,0.502397
23,0.153033,0.483328
24,0.151427,0.457394
25,0.148808,0.462731
26,0.146996,0.409964
27,0.143523,0.457073
28,0.143647,0.445292
29,0.143260,0.472253
30,0.140747,0.455260
31,0.141505,0.403002
32,0.137572,0.460478
33,0.139491,0.460660
34,0.134698,0.423050
35,0.134534,0.416418
36,0.131754,0.425790
37,0.132006,0.449234
38,0.132995,0.456626
39,0.130498,0.432349
40,0.129225,0.432750
41,0.129806,0.441089
42,0.126773,0.454047
43,0.128464,0.415941
44,0.126276,0.455492
45,0.126866,0.454107
46,0.123399,0.459436
47,0.124023,0.444819
48,0.121901,0.449732
49,0.123009,0.420003
50,0.121083,0.439873
51,0.124531,0.444756
52,0.120629,0.415072
53,0.120736,0.404344
54,0.119597,0.418520
55,0.117636,0.418815
56,0.118112,0.430021
57,0.116784,0.442602
58,0.116733,0.437686
59,0.117791,0.418558
60,0.114881,0.428767
61,0.115275,0.460500
62,0.116608,0.443797
63,0.116171,0.451700
64,0.115838,0.440740
65,0.113458,0.416393
66,0.113614,0.439653
67,0.113156,0.450448
68,0.111699,0.456726
69,0.113300,0.437666
70,0.111546,0.465533
71,0.109603,0.438216
72,0.109808,0.426893
73,0.110230,0.461464
74,0.111640,0.481573
75,0.110795,0.453364
76,0.109802,0.459686
77,0.108212,0.440317
78,0.107483,0.430169
79,0.109244,0.434931
80,0.106177,0.438653
81,0.107502,0.440439
