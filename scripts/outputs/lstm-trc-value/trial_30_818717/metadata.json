{
  "model_name": "lstm-trc-value/trial_30_818717",
  "model_type": "LSTM",
  "model_format": "torch",
  "model_params": {
    "history_length": 104,
    "units": 343,
    "num_layers": 6,
    "dropout": 0.28300205348538726
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 218,
    "learning_rate": 0.0005020223492860393,
    "weight_decay": 0.0007283981045063294,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7693,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 104,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92
    ],
    "train_loss": [
      0.9922167825928191,
      0.3122319929271716,
      0.15577770474013466,
      0.11147901926121383,
      0.09138196400051601,
      0.08179541866672871,
      0.07289407946664274,
      0.0653044392470884,
      0.07319785142747182,
      0.06719803393863352,
      0.06703465314354154,
      0.06291975369867013,
      0.062485319304033136,
      0.06012590119055169,
      0.05596421708579369,
      0.05594385702472413,
      0.056341190877505276,
      0.0682492854583795,
      0.059361768629071186,
      0.06292894626481549,
      0.06385082340389238,
      0.06370768113620845,
      0.058586618763897175,
      0.05577934359998212,
      0.09988286241697239,
      0.1252229956806628,
      0.07883146335682571,
      0.07634487622533123,
      0.06320488179700824,
      0.059932845091282834,
      0.06074416727683765,
      0.057023758103788465,
      0.051949613047145085,
      0.05377455814088428,
      0.05935151633042268,
      0.05473280284807026,
      0.053758296633257166,
      0.06491551099251387,
      0.07745081344158151,
      0.058692254604020916,
      0.06660644171100188,
      0.06571188052525667,
      0.05925120578914877,
      0.05938409391902489,
      0.0544023342976819,
      0.05191704170916645,
      0.0516461672649479,
      0.050390974653723275,
      0.05624029151373794,
      0.06200097323076074,
      0.051972686318540455,
      0.051631828127207346,
      0.05266072762623791,
      0.050679203076366794,
      0.0585992329009531,
      0.11774206660851598,
      0.09872563919939858,
      0.08079021878566665,
      0.06552916193126966,
      0.07244416252485598,
      0.1578017428496035,
      0.08128826594350398,
      0.06386132526890471,
      0.06062846972930188,
      0.06146805297041472,
      0.06067447253196258,
      0.05523262906373593,
      0.05406309221456563,
      0.05165750656534075,
      0.049927228046020636,
      0.06129999097543684,
      0.05778583571562745,
      0.05422127265645363,
      0.05420055993392349,
      0.051065380094374606,
      0.04997495512784217,
      0.044219494301302294,
      0.0437843855196821,
      0.043936719220380054,
      0.052279124239571734,
      0.06310438487742202,
      0.06413100719457715,
      0.05068981256076903,
      0.046282484995734625,
      0.04970655503180268,
      0.042113565846485415,
      0.04464514054194331,
      0.04627758176457614,
      0.05726838397484645,
      0.04597068442658595,
      0.08944168530552746,
      0.07833493127353586
    ],
    "val_loss": [
      0.599776445106118,
      0.2819381148470733,
      0.4435975625040288,
      0.3882612428354646,
      0.25978868974004676,
      0.2424897787456741,
      0.24252664136538604,
      0.2591350799571433,
      0.25180129623877073,
      0.26330262736646,
      0.23485014407845314,
      0.24269243257042178,
      0.22152320937571413,
      0.24067718828777354,
      0.21410871030773945,
      0.23172338086286348,
      0.2655129525542795,
      0.3048788610823497,
      0.47189481197047733,
      0.3856983340094368,
      0.3185554197426149,
      0.23641821598399898,
      0.22178796819316413,
      0.22357444037532734,
      0.3141927292849311,
      0.26138601563647834,
      0.26004511372236433,
      0.24969588467059378,
      0.23894885031361424,
      0.2539108533523754,
      0.23513714347458528,
      0.23735297363987584,
      0.2652472832424198,
      0.26465253183495496,
      0.27554416380778046,
      0.2861042785876525,
      0.3483926676347584,
      0.28133220873371567,
      0.23936157045428624,
      0.20784644842326283,
      0.20973162891086705,
      0.17795546366693732,
      0.18453558383587593,
      0.17920645827394047,
      0.18443600252984527,
      0.19073476205150525,
      0.24698491698789027,
      0.2360622031959945,
      0.209653946132717,
      0.23463211405107717,
      0.22584225775194383,
      0.19866718520259785,
      0.23261474051518355,
      0.19699985152723903,
      0.2186117937464914,
      0.2504884971205346,
      0.33697775598771557,
      0.36776703721035026,
      0.24771766854438954,
      0.6645244630689393,
      0.18041029335808254,
      0.21174076033343456,
      0.19475295376590268,
      0.257069987388785,
      0.19986966050670532,
      0.2084754949558281,
      0.22045923901755296,
      0.2297742897031193,
      0.22406783904768748,
      0.2251650618155024,
      0.22172410679523816,
      0.20647939051875097,
      0.21294449048038727,
      0.2304469345550159,
      0.25717663408931857,
      0.23800608735241577,
      0.2168021588424544,
      0.22582669849702697,
      0.23884260936411555,
      0.22285580370062125,
      0.23030988318834475,
      0.2505347129916716,
      0.21538579027854396,
      0.20933153105977767,
      0.20648893006145955,
      0.20162719674408436,
      0.20715507274705494,
      0.20721666380584597,
      0.21945669767920842,
      0.2268281509553244,
      0.3831367490177383,
      0.25271009332137906
    ],
    "best_epoch": 42,
    "best_val_loss": 0.17795546366693732,
    "test_loss": 4.722476161695553,
    "tracker": {
      "initial_train_loss": 0.9922167825928191,
      "train_threshold": 0.3307389275309397,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.17795546366693732,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/lstm-trc-value/trial_30_818717/best_model.pt",
    "last": "scripts/outputs/lstm-trc-value/trial_30_818717/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/lstm-trc-value/trial_30_818717/config.yaml"
}