{
  "model_name": "rnn-other-value/trial_44_92131d",
  "model_type": "RNN",
  "model_format": "torch",
  "model_params": {
    "history_length": 67,
    "units": 362,
    "num_layers": 2,
    "dropout": 0.21152717546447924
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 312,
    "learning_rate": 0.001112983851429439,
    "weight_decay": 0.00013939321921241504,
    "checkpoint_interval": 10,
    "seed": 947
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7730,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": 67,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123
    ],
    "train_loss": [
      0.3400234067655936,
      0.24734056286639106,
      0.23490991492166557,
      0.2272836133895531,
      0.2044207488079429,
      0.1824932597818535,
      0.15046885943505312,
      0.13787857940634965,
      0.13477447320927624,
      0.12358976918697974,
      0.1519441698493501,
      0.13001248340711558,
      0.22443696366861599,
      0.16534040825487262,
      0.16802505873153312,
      0.13150983164990548,
      0.1622548364883561,
      0.17932630972828317,
      0.1608331840297383,
      0.23216869612097896,
      0.16144991828969657,
      0.19031523830446512,
      0.1660067489276728,
      0.15267857552577113,
      0.12090638501022642,
      0.13452647656472194,
      0.12072479813172932,
      0.09844734959815174,
      0.09875022238855374,
      0.09975999604915431,
      0.09387951927960766,
      0.10402768008304906,
      0.1777825874545133,
      0.11569095668593786,
      0.10200231861983357,
      0.10483518441582404,
      0.09219023574909911,
      0.08890093192168998,
      0.11384227181005292,
      0.10127037220561026,
      0.08788286336681976,
      0.12567304137992982,
      0.09874697807612426,
      0.09378226728095429,
      0.09479340902815198,
      0.11124693694853381,
      0.10489506649785948,
      0.08762467835691275,
      0.10239123062822211,
      0.08409735237912096,
      0.07268303620013351,
      0.06839448293673421,
      0.06476814351098811,
      0.10034625247448567,
      0.06833840385946852,
      0.10826369302123207,
      0.12539973612898841,
      0.07801160517246264,
      0.09774596757059109,
      0.08186057365727147,
      0.08947449891911133,
      0.08563989758260192,
      0.07371360750876145,
      0.05999512141341534,
      0.05441603599860782,
      0.06919391713699116,
      0.05487479775816318,
      0.04620552549348303,
      0.05845268534503655,
      0.10602383415225561,
      0.08734168002206018,
      0.06926741792036059,
      0.06885921043304083,
      0.06009695429504303,
      0.06319546149646017,
      0.06561457991002448,
      0.0652539193071184,
      0.05889037131280054,
      0.08919946439901577,
      0.2532689609240745,
      0.3148562118661666,
      0.222413883777516,
      0.16617122113627572,
      0.1540896931294482,
      0.14255896872644436,
      0.20540110430310338,
      0.19735061117625022,
      0.17038748858045946,
      0.11912368943705133,
      0.1212139917511064,
      0.11389318175835567,
      0.10945362214283369,
      0.09029468755788359,
      0.09145984649658204,
      0.0918613039853502,
      0.0848020747014807,
      0.075611493569759,
      0.09534662990875417,
      0.11668117088187405,
      0.10517638404148824,
      0.08322129758486926,
      0.07082338461129509,
      0.1039908219509569,
      0.09019109178792305,
      0.14171904452713774,
      0.12309373125029104,
      0.09035004685990715,
      0.07507725832610358,
      0.06320306229444864,
      0.07780053309450483,
      0.17016872081226087,
      0.1691782403539717,
      0.13498086887682856,
      0.12019629703032246,
      0.09843414937655645,
      0.09058040587513444,
      0.08724926453165681,
      0.07900391016324156,
      0.08264277256822833,
      0.07213697988650777,
      0.08017857522543467,
      0.07178971896967326,
      0.06323310709516258
    ],
    "val_loss": [
      0.4045317735500678,
      0.39183212632904507,
      0.3808829797242216,
      0.3880252199258633,
      0.35984149796520165,
      0.5476160730430466,
      0.7808741132299343,
      0.5007606306832707,
      0.5320655738879106,
      0.5728471875904563,
      0.7304588656939432,
      0.7284744465779401,
      0.44551042075642566,
      0.69329462087083,
      0.6968285992830813,
      0.713264435101412,
      0.5852279173756788,
      0.5179175759503941,
      0.6177187495245905,
      0.4741156966386441,
      0.768885007946791,
      0.43690084704381976,
      0.6743220307869826,
      0.5830866642340928,
      0.6663106243053596,
      0.46314746940921164,
      0.5423988607829202,
      0.6603811472475886,
      0.6165778648710536,
      0.5941313575484796,
      0.8159793899444763,
      0.4735096425710324,
      0.5338961935328866,
      0.6956679050080077,
      0.8026325655554583,
      0.78104016977156,
      0.6792948918785163,
      0.6212880108170881,
      0.5819376962627479,
      0.6413078887733871,
      0.6722858593849365,
      0.4565526532198855,
      0.586122690917489,
      0.6023536832032803,
      0.6140790275470939,
      0.6557910943102694,
      0.6368588478622322,
      0.591852923067744,
      0.6549907090421209,
      0.7645936787842277,
      0.7726359468020365,
      0.6935745162878207,
      0.7610070923845211,
      0.6682261414870531,
      0.5914514960286146,
      0.4383715779481534,
      0.45205209572872,
      0.5073285524002806,
      0.6060072127573505,
      0.7248982295304716,
      0.5649896051712379,
      0.6248714619054052,
      0.5404106371060103,
      0.6191835102206933,
      0.5979270675225172,
      0.5927641751523504,
      0.5029113124587579,
      0.5463694359014134,
      0.6945221071471711,
      0.4124766268416079,
      0.47680396998,
      0.549376741105211,
      0.38051309314316617,
      0.44002003983823124,
      0.48180513446202533,
      0.508611615617832,
      0.40730868092554057,
      0.5460560296110051,
      0.5072114342700935,
      0.611623794518545,
      0.7985024536441186,
      0.6471400101027803,
      0.6794520323861859,
      0.5896771301766356,
      0.6403818426374903,
      0.6005658357086295,
      0.6147576560517272,
      0.5106453273467675,
      0.6380149289876401,
      0.6945928726010694,
      0.6724002433037329,
      0.6432940394221666,
      0.599564350472239,
      0.6348052688701424,
      0.6712156051290249,
      0.5713345895984215,
      0.6822374408830426,
      0.699111714156088,
      0.6260570560029881,
      0.6895592358297931,
      0.7472979922851403,
      0.7169995921457599,
      0.789395459112293,
      0.6450587405416066,
      0.7670925131814922,
      0.6854198717071625,
      0.7768648567313919,
      0.7317784538169108,
      0.8012781643225048,
      0.7348155266867427,
      0.5884118216480324,
      0.7102327066624236,
      0.6693464809549069,
      0.7445988203237157,
      0.8092033043236075,
      0.7609656423508764,
      0.6873367357396793,
      0.7746933491644031,
      0.7291925252197745,
      0.8096077626336834,
      0.7703996683309178,
      0.8012568925312179,
      0.7174931215311953
    ],
    "best_epoch": 73,
    "best_val_loss": 0.38051309314316617,
    "test_loss": 0.4757238724157571,
    "tracker": {
      "initial_train_loss": 0.3400234067655936,
      "train_threshold": 0.1133411355885312,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.38051309314316617,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/rnn-other-value/trial_44_92131d/best_model.pt",
    "last": "scripts/outputs/rnn-other-value/trial_44_92131d/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/rnn-other-value/trial_44_92131d/config.yaml"
}