{
  "model_name": "mlp-other-value/trial_55_084f20",
  "model_type": "MLP",
  "model_format": "torch",
  "model_params": {
    "history_length": 1,
    "hidden_layers": [
      512,
      256,
      128
    ],
    "dropout": 0.32734245197250117,
    "mid_layer_count": 6,
    "mid_layer_size": 434
  },
  "training_params": {
    "max_epochs": 400,
    "batch_size": 161,
    "learning_rate": 0.0015511595472277701,
    "weight_decay": 0.004039046790947637,
    "checkpoint_interval": 10,
    "seed": 42
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-PPL1",
    "DOC-PPL2",
    "pH-PPL1",
    "pH-PPL2"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7796,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 10,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84
    ],
    "train_loss": [
      0.37186493925662334,
      0.2559209819032542,
      0.2393061128975857,
      0.22776937690597426,
      0.22375888866933877,
      0.2191827895015616,
      0.21839491733225141,
      0.21530111116849807,
      0.21230843705457256,
      0.211291115320053,
      0.210368957848366,
      0.20937780164499475,
      0.20914921112140672,
      0.207196269234047,
      0.20749078489545678,
      0.20748941642373203,
      0.2053103502639108,
      0.20378930442964133,
      0.2058276882545192,
      0.2031144856806441,
      0.2022972596687895,
      0.20293278465780495,
      0.1996400850118277,
      0.20059874076768947,
      0.19877984449114477,
      0.19640115627482832,
      0.19706478800381863,
      0.19753921519737477,
      0.20026265911991134,
      0.19694337089392636,
      0.1966722871785197,
      0.1956005347591599,
      0.19867554114698568,
      0.19574394244308838,
      0.19587486181666203,
      0.1974868735135091,
      0.19449454486148365,
      0.19464753996896217,
      0.19353156464949456,
      0.1921782444334905,
      0.19459661375396736,
      0.1940739584686268,
      0.19053549778429346,
      0.19144262539546816,
      0.19232844875761335,
      0.19308180519102047,
      0.19086835450999795,
      0.1927649744348137,
      0.1905203966673305,
      0.19156465243228954,
      0.19196616842952857,
      0.1896434666415922,
      0.1912110707086591,
      0.19264465182820853,
      0.1899798006667976,
      0.18819271702378637,
      0.19051932198702218,
      0.1878346304742265,
      0.19336461546850425,
      0.19138685901342997,
      0.18776993115187426,
      0.18842111051029092,
      0.1883960439894767,
      0.1898303575500303,
      0.18576475269347048,
      0.18745020963920575,
      0.18954733648304453,
      0.18865475307226853,
      0.18951199323764636,
      0.18916598999688355,
      0.18652662979854628,
      0.18873308016022639,
      0.18964290530972752,
      0.18871282176398937,
      0.18655913544120148,
      0.1851548427011552,
      0.1862182037502512,
      0.18655378303049527,
      0.18511688822030775,
      0.18609736253889234,
      0.18400590957786073,
      0.18530485651366463,
      0.18545842244112534,
      0.18685983757886476
    ],
    "val_loss": [
      0.3633176595552596,
      0.43655152619777327,
      0.48439134214809554,
      0.4804509132118996,
      0.4663634663124284,
      0.6213170443287866,
      0.5274241311732166,
      0.555946389099438,
      0.6121719178950001,
      0.5846507764326598,
      0.5087632002186275,
      0.6119634213829469,
      0.5013729782607741,
      0.533535838617893,
      0.5167177646192248,
      0.5665884277777757,
      0.5040343945254823,
      0.558093401745051,
      0.5177393185342857,
      0.5428777754842165,
      0.570907116132582,
      0.6075255819378855,
      0.6062144484437868,
      0.5112861698794507,
      0.5341353717901393,
      0.5958478492355632,
      0.6018775146610723,
      0.5540653806246684,
      0.5422724989270735,
      0.5254677575862337,
      0.49372030532288697,
      0.5027414860125787,
      0.5749611641653998,
      0.4601278388125454,
      0.6041502251061137,
      0.5797067375864812,
      0.4761317448344773,
      0.5821670765826802,
      0.5467879290976924,
      0.6082025898207805,
      0.5408421939183138,
      0.6079339272604731,
      0.5855446588850307,
      0.5188895147896099,
      0.5961431257471353,
      0.542511929964234,
      0.5548067317662125,
      0.5445459797353802,
      0.5571676726291279,
      0.6299202664883551,
      0.5895722840851295,
      0.5052828982650877,
      0.5876198210848306,
      0.5709320826534026,
      0.5546502828598022,
      0.5357829120701658,
      0.5369107736263447,
      0.6811732585380177,
      0.597070460369487,
      0.5936488532823717,
      0.5144189122372759,
      0.5891349493475732,
      0.5101316536436538,
      0.549455008178414,
      0.618689293044056,
      0.5606131758161648,
      0.5227964224661895,
      0.5128566205233871,
      0.5452858133141152,
      0.6200790340939681,
      0.6066094202017356,
      0.593458199179815,
      0.5260841828263448,
      0.5617898283247462,
      0.6541214601008478,
      0.5318430217395642,
      0.6396823482777544,
      0.5252922231030321,
      0.5685725237794979,
      0.5817091210159713,
      0.61926555927999,
      0.5543385832431074,
      0.645409351025156,
      0.6086473402238177
    ],
    "best_epoch": 84,
    "best_val_loss": 0.6086473402238177,
    "test_loss": 0.5567083696892672,
    "tracker": {
      "initial_train_loss": 0.37186493925662334,
      "train_threshold": 0.12395497975220778,
      "best_tracking": false,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.4601278388125454,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp-other-value/trial_55_084f20/best_model.pt",
    "last": "scripts/outputs/mlp-other-value/trial_55_084f20/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp-other-value/trial_55_084f20/config.yaml"
}