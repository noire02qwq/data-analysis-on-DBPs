epoch,train_loss,val_loss
1,0.327914,0.366828
2,0.108095,0.331154
3,0.088979,0.290750
4,0.080002,0.289597
5,0.069456,0.325764
6,0.060254,0.371523
7,0.059455,0.325182
8,0.051800,0.383153
9,0.050519,0.293814
10,0.054845,0.293820
11,0.053690,0.312260
12,0.057847,0.283949
13,0.049231,0.334494
14,0.046427,0.319765
15,0.048079,0.342194
16,0.048523,0.348650
17,0.045581,0.308093
18,0.053764,0.318178
19,0.046526,0.298747
20,0.052951,0.301887
21,0.046486,0.314623
22,0.043938,0.336791
23,0.051536,0.308388
24,0.049623,0.300826
25,0.046380,0.324963
26,0.042168,0.299016
27,0.046243,0.367962
28,0.050284,0.361249
29,0.052450,0.346842
30,0.051060,0.355171
31,0.046119,0.317413
32,0.041886,0.301617
33,0.041126,0.336964
34,0.042645,0.356562
35,0.047136,0.317368
36,0.051124,0.351583
37,0.044999,0.355931
38,0.044932,0.342734
39,0.040735,0.327068
40,0.053905,0.380279
41,0.043792,0.326054
42,0.039357,0.334626
43,0.041145,0.319527
44,0.042308,0.362103
45,0.049624,0.315154
46,0.043108,0.312177
47,0.048677,0.309773
48,0.043795,0.325200
49,0.043795,0.340343
50,0.048022,0.320826
51,0.045537,0.313252
52,0.042625,0.328884
53,0.041846,0.320752
54,0.046139,0.405817
55,0.044229,0.325209
56,0.042074,0.305610
57,0.049373,0.328991
58,0.043705,0.335368
59,0.043153,0.305672
60,0.041033,0.320283
61,0.043845,0.317320
62,0.040012,0.365214
63,0.041523,0.326136
64,0.042109,0.331718
65,0.040908,0.330318
66,0.044440,0.356945
67,0.039619,0.340258
68,0.041947,0.378749
69,0.040804,0.362496
70,0.039542,0.331026
71,0.041180,0.325458
72,0.043863,0.379988
73,0.052025,0.299979
74,0.039683,0.326944
75,0.041999,0.348485
76,0.041558,0.328356
77,0.038673,0.324511
78,0.063881,0.322631
79,0.038785,0.330615
80,0.041796,0.299921
