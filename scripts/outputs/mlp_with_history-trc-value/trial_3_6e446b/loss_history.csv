epoch,train_loss,val_loss
1,1.000792,0.355853
2,0.911652,0.322503
3,0.423542,0.242243
4,0.179109,0.279253
5,0.134653,0.235237
6,0.117530,0.665019
7,0.115428,0.327265
8,0.111058,0.280450
9,0.113090,0.336834
10,0.102060,0.932718
11,0.116885,0.558887
12,0.109835,0.507934
13,0.102893,0.371775
14,0.103562,0.691090
15,0.107456,0.289761
16,0.180879,0.249981
17,0.145730,0.272770
18,0.117387,0.275743
19,0.103924,0.351412
20,0.101482,0.697337
21,0.106078,0.344940
22,0.102886,0.392131
23,0.104839,0.330324
24,0.110271,0.280661
25,0.115068,0.619657
26,0.101802,0.366054
27,0.099947,0.487232
28,0.099147,0.416522
29,0.104689,0.399886
30,0.103248,0.587606
31,0.098596,0.470954
32,0.102739,0.551432
33,0.110185,0.571079
34,0.105475,0.278916
35,0.098064,0.752135
36,0.200631,0.278837
37,0.369668,0.284576
38,0.216961,0.331628
39,0.142587,0.495372
40,0.117446,0.640065
41,0.113129,0.388893
42,0.112406,0.370967
43,0.110079,0.586994
44,0.119059,0.416143
45,0.108895,0.397344
46,0.106481,0.379309
47,0.120332,0.363380
48,0.106479,0.381153
49,0.109512,0.584477
50,0.101215,1.089503
51,0.110237,0.532653
52,0.102296,0.459768
53,0.106885,0.737607
54,0.104407,0.428221
55,0.101933,0.445822
56,0.179830,1.007751
57,0.206326,0.411518
58,0.138873,0.433140
59,0.111587,0.492431
60,0.109579,0.615343
61,0.106296,0.339052
62,0.108267,0.611077
63,0.104298,0.580300
64,0.103752,0.419264
65,0.104421,0.552703
66,0.110557,0.770137
67,0.126100,0.442264
68,0.114342,0.304802
69,0.120391,0.359693
70,0.128068,0.319142
71,0.105072,0.446506
72,0.104771,0.914269
73,0.106841,0.755121
74,0.101487,0.786969
75,0.108312,0.424972
76,0.104066,0.864071
77,0.105852,0.382838
78,0.100999,0.437935
79,0.102612,0.686252
80,0.099731,0.791951
