{
  "model_name": "mlp_with_history-trc-rate/trial_4_5a7177",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 75,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.22435781970728186,
    "mid_layer_count": 5,
    "mid_layer_size": 282
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 334,
    "learning_rate": 0.0017084135187345761,
    "weight_decay": 0.005264748216007563,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7722,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 750,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93,
      94,
      95,
      96,
      97,
      98,
      99,
      100,
      101,
      102,
      103,
      104,
      105,
      106,
      107,
      108,
      109,
      110,
      111,
      112,
      113,
      114,
      115,
      116,
      117,
      118,
      119,
      120,
      121,
      122,
      123,
      124,
      125,
      126,
      127,
      128,
      129,
      130,
      131,
      132,
      133,
      134,
      135,
      136,
      137,
      138,
      139,
      140,
      141,
      142,
      143,
      144,
      145,
      146,
      147
    ],
    "train_loss": [
      2.9875356566408886,
      0.823009476679281,
      0.3506291799866699,
      0.38404677470200915,
      0.20368878951315988,
      0.2034160583416312,
      0.16590837648003806,
      0.15787623253426877,
      0.15725813162115318,
      0.1447920024557084,
      0.15851971051083794,
      0.14272958529223992,
      0.1455338701752454,
      0.13555618238337946,
      0.13002463335031922,
      0.13139661638670652,
      0.13830760736727585,
      0.12529571738785888,
      0.15884039262722144,
      0.12706266746515438,
      0.12856928536239542,
      0.121942604672211,
      0.11966928601751238,
      0.12099354953824223,
      0.11229997102583174,
      0.11953426847160557,
      0.09665804877742157,
      0.09175132712693265,
      0.10858950827428017,
      0.09181857546919277,
      0.09516651202856768,
      0.08436912504873631,
      0.11999942944692657,
      0.08836721166933612,
      0.10359674598563369,
      0.11873945577045514,
      0.09075723547363986,
      0.08105201255052517,
      0.08364327436390703,
      0.10661867712676232,
      0.10138853553878431,
      0.08638798115966512,
      0.07979678664413396,
      0.08201743458484281,
      0.08198224635333078,
      0.07932968839821622,
      0.09531124536699657,
      0.17800076319953068,
      0.15688785558628685,
      0.08840868738039699,
      0.13130136035677992,
      0.08571954288613268,
      0.11258375708942925,
      0.09279255493433325,
      0.08681877082461244,
      0.07934585090256731,
      0.08375770244935546,
      0.07616330644830278,
      0.09999427245483594,
      0.14294646196771674,
      0.1216247852306019,
      0.0876119404981032,
      0.0883880197940111,
      0.10622760879077987,
      0.07957608301006305,
      0.08096588073779314,
      0.08910825213707349,
      0.076295905754962,
      0.0769750002797667,
      0.09176704416433105,
      0.23874681040826037,
      0.13544051590568815,
      0.15389441227363324,
      0.11569742481346051,
      0.11795094632802927,
      0.11471066536896589,
      0.11692278566284212,
      0.11189134804518906,
      0.1359385338835505,
      0.23427568237511676,
      0.13418911047409124,
      0.12144139884157953,
      0.12194373754447249,
      0.11978151704233195,
      0.14690016620333904,
      0.2032216803354786,
      0.126912931630152,
      0.11863627578465934,
      0.12515672478256556,
      0.11633151710975112,
      0.1382120407729901,
      0.12459431843949365,
      0.11962764471483738,
      0.11620650565113252,
      0.11898195564291447,
      0.1287554443283916,
      0.2921911445739386,
      0.16132284214006623,
      0.1262436644655378,
      0.1300850277064656,
      0.12426080047019063,
      0.11992905658279729,
      0.1328799437825095,
      0.27684332189921795,
      0.3893750691793645,
      0.9758284595833329,
      0.8839246281624087,
      0.7901679430715595,
      0.5622930637498311,
      0.31939309888693745,
      0.2440068141895698,
      0.18642811308914256,
      0.1595904318023858,
      0.19343231073842398,
      0.16082244759101813,
      0.14710703435045425,
      0.19270401827969783,
      0.1477248681059343,
      0.17275318455909144,
      0.1460634650741177,
      0.1454657283653808,
      0.14404628125574884,
      0.15767331436812893,
      0.1330489652109282,
      0.13802913298487385,
      0.15080683303640408,
      0.1315294231633793,
      0.13846511712379328,
      0.1464529992292286,
      0.13871090864384925,
      0.16540498027519623,
      0.1378754652579255,
      0.13768167476314733,
      0.1365682580188685,
      0.16444700532967918,
      0.23356690527367116,
      0.1477883424406316,
      0.13983784520087295,
      0.13553074096821344,
      0.14593522443236603,
      0.12987313718684318,
      0.1291275848724996,
      0.1272487183755403,
      0.1336202277239664,
      0.146550728433168,
      0.17933411597896814,
      0.14930456392206512
    ],
    "val_loss": [
      0.35121005177497866,
      0.2800978280603886,
      0.5593912109732628,
      0.24866015873849392,
      0.6920130640268326,
      0.25598492808640005,
      0.24367612414062023,
      0.41740743815898895,
      0.25043726749718187,
      0.24587563537061213,
      0.26555350571870806,
      0.28972445577383044,
      0.2628882221877575,
      0.2789578206837177,
      0.2804745137691498,
      0.2962955109775066,
      0.3435001201927662,
      1.980509603023529,
      0.3945547267794609,
      0.26447840183973315,
      0.2773851744830608,
      0.3059346556663513,
      0.383461944013834,
      0.28469195663928987,
      0.5018629364669323,
      0.2785485923290253,
      0.3256442382931709,
      0.294100970774889,
      0.28943030834197997,
      0.83792729601264,
      0.2864202082157135,
      0.3037155032157898,
      0.327775177359581,
      0.29823114573955534,
      0.8870395168662071,
      0.2817777968943119,
      0.29109947681427,
      0.6236317560076714,
      0.2797724843025208,
      0.38588277287781236,
      0.289484591037035,
      0.33025641813874246,
      0.2932050064206123,
      0.7568358007818461,
      0.5456502519547939,
      0.3044621698558331,
      0.4099069103598595,
      0.2827101401984692,
      0.28693317137658597,
      0.4444993380457163,
      0.3707262821495533,
      0.31137908548116683,
      0.26932500042021273,
      0.29528561010956766,
      0.6975837327539921,
      0.28660504668951037,
      0.3002874914556742,
      1.6428244531154632,
      0.3027655243873596,
      0.2991716623306274,
      0.30347750559449194,
      0.2699666738510132,
      0.3010214019566774,
      0.27246260903775693,
      0.2985755052417517,
      0.5379240781068801,
      0.37530564442276954,
      0.3629823084920645,
      1.1885884448885917,
      0.5818079963326455,
      0.2638724364340305,
      0.2644530929625034,
      0.291289946436882,
      0.43112226128578185,
      0.25182257033884525,
      0.7781822845339775,
      0.2869512908160686,
      0.25811483040452005,
      0.24202321618795394,
      0.4341255135834217,
      1.063943450152874,
      0.2839430600404739,
      0.291056127846241,
      0.30583148188889026,
      0.2997755974531174,
      0.281790629029274,
      0.2659352619200945,
      0.957287959754467,
      0.26623246297240255,
      0.2911936305463314,
      0.442513295263052,
      0.2619176980108023,
      0.3251020397990942,
      0.539896784350276,
      0.27296734377741816,
      0.45128532946109773,
      0.21113198772072791,
      0.4445458546280861,
      0.25980589762330053,
      0.24874301254749298,
      0.2708315573632717,
      0.2575483664870262,
      1.7514458686113357,
      0.2999969877302647,
      0.25131181851029394,
      0.24614812433719635,
      0.29109513461589814,
      0.32199774086475375,
      0.6032698407769204,
      0.8343653470277786,
      0.3187114387750626,
      0.29434212669730186,
      0.27148895636200904,
      0.2795152224600315,
      0.35733496099710466,
      0.2895912304520607,
      0.284751208871603,
      0.27126760855317117,
      0.2642042562365532,
      0.2716676454991102,
      0.29398353919386866,
      0.6345644190907478,
      0.28684183582663536,
      0.2983181342482567,
      0.30018202066421507,
      0.2893664870411158,
      0.2663344521075487,
      0.2778523128479719,
      0.4121014256030321,
      0.3582259964197874,
      0.26882524117827417,
      0.33761484511196616,
      0.6830633372068405,
      0.3102566096931696,
      0.28202411606907846,
      0.2858352795243263,
      0.28236583173274993,
      0.43383277803659437,
      0.34309280589222907,
      0.7034947045147419,
      0.2728076554834843,
      0.2922463040798903,
      0.26731076948344706,
      0.2781999010592699,
      0.26450579054653645,
      0.5973506480455398,
      0.3165681429207325
    ],
    "best_epoch": 97,
    "best_val_loss": 0.21113198772072791,
    "best_val_abs_mse": 0.21897974610328674,
    "test_loss": 5.06315992280627,
    "test_abs_mse": 49.15533447265625,
    "tracker": {
      "initial_train_loss": 2.9875356566408886,
      "train_threshold": 0.9958452188802962,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.21113198772072791,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-rate/trial_4_5a7177/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-rate/trial_4_5a7177/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-rate/trial_4_5a7177/config.yaml"
}