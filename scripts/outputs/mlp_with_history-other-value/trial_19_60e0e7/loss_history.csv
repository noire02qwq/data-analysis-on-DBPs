epoch,train_loss,val_loss
1,0.940469,1.153032
2,0.519000,0.498833
3,0.400365,0.471341
4,0.382814,0.464870
5,0.372105,0.510435
6,0.376240,0.484860
7,0.356553,0.490179
8,0.341202,0.540807
9,0.318323,0.546560
10,0.292256,0.545656
11,0.283315,0.573082
12,0.275678,0.512915
13,0.269694,0.499056
14,0.265882,0.497603
15,0.259333,0.462867
16,0.258621,0.391733
17,0.258995,0.423093
18,0.250262,0.450524
19,0.247505,0.389943
20,0.252717,0.523747
21,0.250712,0.368382
22,0.243302,0.403954
23,0.236601,0.406491
24,0.247373,0.520270
25,0.349962,0.528811
26,0.292748,0.424247
27,0.246676,0.473911
28,0.242022,0.440295
29,0.236958,0.445882
30,0.234224,0.432660
31,0.231002,0.437348
32,0.225742,0.430930
33,0.243045,0.468851
34,0.255112,0.420465
35,0.233724,0.507222
36,0.236173,0.461912
37,0.228412,0.507631
38,0.220893,0.498230
39,0.230915,0.432828
40,0.222218,0.436606
41,0.211786,0.467035
42,0.205385,0.488277
43,0.204735,0.448844
44,0.202678,0.473518
45,0.204790,0.484913
46,0.194528,0.460798
47,0.189652,0.509926
48,0.183133,0.479404
49,0.186451,0.476387
50,0.194044,0.565991
51,0.182972,0.477977
52,0.184143,0.467493
53,0.178908,0.592675
54,0.178771,0.475867
55,0.174485,0.556104
56,0.171720,0.479504
57,0.173537,0.482849
58,0.172851,0.448632
59,0.168396,0.505555
60,0.166058,0.502998
61,0.164738,0.457298
62,0.163617,0.568501
63,0.168316,0.492061
64,0.164958,0.490897
65,0.158772,0.480693
66,0.161259,0.541881
67,0.165209,0.591710
68,0.167314,0.512524
69,0.161387,0.466008
70,0.155829,0.448651
71,0.158501,0.448744
72,0.156508,0.601955
73,0.155455,0.478688
74,0.156383,0.461956
75,0.155546,0.624963
76,0.150769,0.550306
77,0.156317,0.496094
78,0.147490,0.454005
79,0.153893,0.486822
80,0.155122,0.466896
