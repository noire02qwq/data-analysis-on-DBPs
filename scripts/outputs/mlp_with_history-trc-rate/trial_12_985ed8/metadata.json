{
  "model_name": "mlp_with_history-trc-rate/trial_12_985ed8",
  "model_type": "MLP_WITH_HISTORY",
  "model_format": "torch",
  "model_params": {
    "history_length": 55,
    "hidden_layers": [
      4096,
      3072,
      2048,
      1024,
      768,
      512,
      256,
      128
    ],
    "dropout": 0.4996486132333802,
    "mid_layer_count": 8,
    "mid_layer_size": 821
  },
  "training_params": {
    "max_epochs": 500,
    "batch_size": 415,
    "learning_rate": 0.0011221592544660862,
    "weight_decay": 0.004054771965296506,
    "checkpoint_interval": 10,
    "seed": 77
  },
  "data_csv": "data/time_aligned_data.csv",
  "timestamp_column": "Date, Time",
  "columns": [
    "TRC-DT",
    "TRC-RT",
    "TRC-PPL1",
    "TRC-PPL2",
    "pH-DT",
    "pH-RT",
    "pH-PPL1",
    "pH-PPL2",
    "cond-DT",
    "cond-PPL1",
    "cond-PPL2",
    "fDOM-RT",
    "fDOM-PPL1",
    "fDOM-PPL2",
    "DO-RT",
    "DO-PPL1",
    "DO-PPL2",
    "TOC-RT",
    "TOC-PPL1",
    "TOC-PPL2",
    "DOC-RT",
    "DOC-PPL1",
    "DOC-PPL2",
    "minutes_since_start"
  ],
  "feature_columns": [
    "TRC-DT",
    "TRC-RT",
    "pH-DT",
    "pH-RT",
    "cond-DT",
    "fDOM-RT",
    "DO-RT",
    "TOC-RT",
    "DOC-RT",
    "minutes_since_start"
  ],
  "target_columns": [
    "TRC-PPL1",
    "TRC-PPL2"
  ],
  "target_mode": "rate",
  "target_base_columns": [
    "TRC-RT",
    "TRC-RT"
  ],
  "split_boundaries": {
    "train_end": 7796,
    "val_end": 9466,
    "test_end": 11138
  },
  "dataset_sizes": {
    "train": 7742,
    "val": 1670,
    "test": 1672
  },
  "input_dim": 550,
  "sequence_length": null,
  "training_history": {
    "epochs": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
      68,
      69,
      70,
      71,
      72,
      73,
      74,
      75,
      76,
      77,
      78,
      79,
      80,
      81,
      82,
      83,
      84,
      85,
      86,
      87,
      88,
      89,
      90,
      91,
      92,
      93
    ],
    "train_loss": [
      0.9826197239109109,
      0.8208783955321205,
      0.42043041388784014,
      0.23839756142366336,
      0.21575817333939032,
      0.20754654933795913,
      0.1817307102702533,
      0.2116469505320714,
      0.25439522164031475,
      0.19385640565291512,
      0.17956480410626557,
      0.18302078502172342,
      0.1736228115138728,
      0.17417169074753833,
      0.17650340655513033,
      0.1687020031911894,
      0.16782375024374188,
      0.1697354399820718,
      0.16894752642337557,
      0.1742853749494348,
      0.14799728656432573,
      0.15210133052070884,
      0.15389693764769055,
      0.16677043417786727,
      0.16152825492916104,
      0.21280361141107768,
      0.16447493554824577,
      0.15843494166024616,
      0.1574366429459291,
      0.16443305647949075,
      0.14850701074888464,
      0.15382157649351194,
      0.14813443052925765,
      0.1562430121907274,
      0.15473222755640553,
      0.17902269429767573,
      0.19425112902309752,
      0.1540045807644767,
      0.15477471205845447,
      0.17327328050161203,
      0.1536554936170424,
      0.1543567891219918,
      0.1515268434711942,
      0.15538263455845533,
      0.15006061179890123,
      0.14893467814784986,
      0.14878599043118496,
      0.1561833605251088,
      0.14544387696514416,
      0.14585382324477186,
      0.1711731011038817,
      0.3668304416802126,
      0.3734361132165622,
      0.2899379810812522,
      0.21005798097737413,
      0.1683106125017002,
      0.17911113180206653,
      0.15714384132894674,
      0.15037402496977512,
      0.16260687187525752,
      0.16392492085071658,
      0.15371456970750624,
      0.14747222194034781,
      0.15365857183471326,
      0.1492135382859598,
      0.14819401325535264,
      0.14543070233886754,
      0.14730635770502493,
      0.14550738891399484,
      0.14872584521320092,
      0.16971366334772947,
      0.15619959909727762,
      0.1356763193834678,
      0.13957505809247603,
      0.140509371511259,
      0.1385816621777701,
      0.1380841654507158,
      0.1347923156483187,
      0.13550902400921247,
      0.1332369442789538,
      0.14179499461203698,
      0.1465241395512529,
      0.13072773301456672,
      0.13216740598176008,
      0.13334254522451103,
      0.13232507884071273,
      0.1479564569823134,
      0.14717061993372715,
      0.13797183727469747,
      0.12829896178961694,
      0.13305544356344684,
      0.1339767816815996,
      0.1222869853691918
    ],
    "val_loss": [
      0.32433316435017984,
      0.7325868959466141,
      0.23525312887560465,
      0.3286647936385013,
      0.2557066109555656,
      0.5628095341032137,
      0.23837743235562375,
      0.2361911623487751,
      0.2620696065456657,
      0.23801664350565502,
      0.30273640691720977,
      0.27945591338692666,
      0.5168168855730645,
      0.2824587215039277,
      0.28701130679981435,
      0.27447102745314556,
      0.2785794072433146,
      0.28465732553984946,
      0.35089467581874595,
      0.2872312545419453,
      0.2794653296939092,
      0.26903922985793055,
      0.382651786102417,
      0.26952198023411506,
      0.28540354405535373,
      0.2799951137339105,
      0.2752864862162018,
      0.27286540995725617,
      0.28550017491250695,
      0.26620746174726834,
      0.27966140260819544,
      0.27545792860408386,
      0.2555345806298766,
      0.28877222221233173,
      0.27426288686246575,
      0.2824380956255569,
      0.2722318416550577,
      0.2570508032602197,
      0.5080644281993726,
      0.27967172542665,
      0.2873041461707054,
      0.28451660535337325,
      0.22301739049395045,
      0.2997737295791775,
      0.2899947738063014,
      0.28632939708402416,
      0.26793564499138356,
      0.272632802094885,
      0.2641432251346236,
      0.28637371764345443,
      0.28149110421226053,
      0.2852870461135032,
      0.32245892536140486,
      0.38278414951470086,
      0.3001983826979995,
      0.28700599978360053,
      0.30379972309097203,
      0.3016438138264114,
      0.35969997757298505,
      0.29262563522659735,
      0.27438126920449163,
      0.29102017113682394,
      0.2890517722848736,
      0.3622796230888117,
      0.30163696074222557,
      0.2947888179308551,
      0.29351740823445205,
      0.27275672010118196,
      0.282254201254088,
      0.2958261917852713,
      0.2741307700610536,
      0.2835509386248217,
      0.28002930295369227,
      0.3050851529954882,
      0.2895068249269249,
      0.29458988438957107,
      0.3166970181317922,
      0.3530372284341626,
      0.2822917909333538,
      0.3074221702091797,
      0.3622675605932485,
      0.27056694693283406,
      0.28872858463580203,
      0.27916221417665127,
      0.28741310498939304,
      0.30831159249193474,
      0.4333145022894183,
      0.297713597076471,
      0.3051122449516893,
      0.34327243986779343,
      0.2978591245437364,
      0.2833738177847452,
      0.34724480107783556
    ],
    "best_epoch": 43,
    "best_val_loss": 0.22301739049395045,
    "best_val_abs_mse": 0.25095945596694946,
    "test_loss": 4.587767547397522,
    "test_abs_mse": 44.72515106201172,
    "tracker": {
      "initial_train_loss": 0.9826197239109109,
      "train_threshold": 0.32753990797030363,
      "best_tracking": true,
      "patience_active": true,
      "patience_best_train": null,
      "patience_best_val": 0.22301739049395045,
      "patience_no_improve_epochs": 50,
      "best_train_loss": Infinity,
      "forced_stop_due_to_threshold": false
    }
  },
  "model_files": {
    "best": "scripts/outputs/mlp_with_history-trc-rate/trial_12_985ed8/best_model.pt",
    "last": "scripts/outputs/mlp_with_history-trc-rate/trial_12_985ed8/last_model.pt"
  },
  "config_path": "/home/amoris/data-analysis-on-dbps/scripts/outputs/mlp_with_history-trc-rate/trial_12_985ed8/config.yaml"
}